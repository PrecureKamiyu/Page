<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:mbp="Kindle">
  <head>
    <title>C++ Concurrency in Action, Second Edition</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
<h2 class="part" id="ch05">Chapter 5. <a id="ch05__title" class="calibre3"></a>The C++ memory model and operations on atomic types
      </h2>
      
      <p class="noind"><i class="calibre6">This chapter covers</i></p>
      
      <p class="calibre19"></p>
      <ul class="calibre21">
         
         <li class="calibre22">The details of the C++ memory model</li>
         
         <li class="calibre22">The atomic types provided by the C++</li>
         
         <li class="calibre22">Standard Library</li>
         
         <li class="calibre22">The operations that are available on those types</li>
         
         <li class="calibre22">How those operations can be used to provide synchronization between threads</li>
         
      </ul>
      
      <p class="noind">One of the most important features of the C++ Standard is something most programmers won’t even notice. It’s not the new syntax
         features, nor is it the new library facilities, but the new multithreading-aware memory model. Without the memory model to
         define exactly how the fundamental building blocks work, none of the facilities I’ve covered could be relied on to work. There’s
         a reason that most programmers won’t notice: if you use mutexes to protect your data and condition variables, futures, latches,
         or barriers to signal events, the details of <i class="calibre6">why</i> they work aren’t important. It’s only when you start trying to get “close to the machine” that the precise details of the
         memory model matter.
      </p>
      
      <p class="noind">Whatever else it is, C++ is a systems programming language. One of the goals of the Standards Committee is that there will
         be no need for a lower-level language <a id="iddle1585" class="calibre4"></a><a id="iddle1587" class="calibre4"></a><a id="iddle1588" class="calibre4"></a><a id="iddle1591" class="calibre4"></a><a id="iddle1593" class="calibre4"></a><a id="iddle1694" class="calibre4"></a><a id="iddle1706" class="calibre4"></a>than C++. Programmers should be provided with enough flexibility within C++ to do whatever they need without the language
         getting in the way, allowing them to get “close to the machine” when the need arises. The atomic types and operations allow
         just that, providing facilities for low-level synchronization operations that will commonly reduce to one or two CPU instructions.
      </p>
      
      <p class="noind">In this chapter, I’ll start by covering the basics of the memory model, then move on to the atomic types and operations, and
         finally cover the various types of synchronization available with the operations on atomic types. This is quite complex: unless
         you’re planning on writing code that uses the atomic operations for synchronization (such as the lock-free data structures
         in <a href="kindle_split_017.html#ch07" class="calibre4">chapter 7</a>), you won’t need to know these details.
      </p>
      
      <p class="noind">Let’s ease into things with a look at the basics of the memory model.</p>
      
      
      <h3 id="ch05lev1sec1" class="chapter"><a id="ch05lev1sec1__title" class="calibre3"></a>5.1. Memory model basics
      </h3>
      
      <p class="noind">There are two aspects to the memory model: the basic <i class="calibre6">structural</i> aspects, which relate to how things are laid out in memory, and the <i class="calibre6">concurrency</i> aspects. The structural aspects are important for concurrency, particularly when you’re looking at low-level atomic operations,
         so I’ll start with those. In C++, it’s all about objects and memory locations.
      </p>
      
      
      <h4 id="ch05lev2sec1" class="calibre23">5.1.1. <a id="ch05lev2sec1__title" class="calibre4"></a>Objects and memory locations
      </h4>
      
      <p class="noind">All data in a C++ program is made up of <i class="calibre6">objects</i>. This is not to say that you can create a new class derived from <kbd class="calibre17">int</kbd>, or that the fundamental types have member functions, or any of the other consequences often implied when people say “everything
         is an object” when discussing a language like Smalltalk or Ruby. It’s a statement about the building blocks of data in C++.
         The C++ Standard defines an object as “a region of storage,” although it goes on to assign properties to these objects, such
         as their type and lifetime.
      </p>
      
      <p class="noind">Some of these objects are simple values of a fundamental type such as <kbd class="calibre17">int</kbd> or <kbd class="calibre17">float</kbd>, whereas others are instances of user-defined classes. Some objects (such as arrays, instances of derived classes, and instances
         of classes with non-<kbd class="calibre17">static</kbd> data members) have sub-objects, but others don’t.
      </p>
      
      <p class="noind">Whatever its type, an object is stored in one or more <i class="calibre6">memory locations</i>. Each memory location is either an object (or sub-object) of a scalar type such as <kbd class="calibre17">unsigned short</kbd> or <kbd class="calibre17">my_class*</kbd> or a sequence of adjacent bit fields. If you use bit fields, this is an important point to note: though adjacent bit fields
         are distinct objects, they’re still counted as the same memory location. <a href="#ch05fig01" class="calibre4">Figure 5.1</a> shows how a <kbd class="calibre17">struct</kbd> divides into objects and memory locations.
      </p>
      
      
      
      <h5 class="notetitle" id="ch05fig01">Figure 5.1. <a id="ch05fig01__title" class="calibre4"></a>The division of a <kbd class="calibre17">struct</kbd> into objects and memory locations
      </h5>
      
      <p class="center1"><img alt="" src="05fig01_alt.jpg" class="calibre2"/></p>
      
      
      <p class="noind">First, the entire <kbd class="calibre17">struct</kbd> is one object that consists of several sub-objects, one for each data member. The <kbd class="calibre17">bf1</kbd> and <kbd class="calibre17">bf2</kbd> bit fields share a memory location, and the <kbd class="calibre17">std::string</kbd> object, <kbd class="calibre17">s</kbd>, consists of several memory locations internally, but otherwise each member has its own memory location. Note how the zero-length
         bit field <kbd class="calibre17">bf3</kbd> (the name is commented out because zero-length bit fields must be unnamed) separates <kbd class="calibre17">bf4</kbd> into its own memory location, but doesn’t have a memory location itself.
      </p>
      
      <p class="noind"><a id="iddle1138" class="calibre4"></a><a id="iddle1590" class="calibre4"></a><a id="iddle1881" class="calibre4"></a><a id="iddle1888" class="calibre4"></a><a id="iddle2414" class="calibre4"></a>There are four important things to take away from this:
      </p>
      
      <p class="calibre19"></p>
      <ul class="calibre21">
         
         <li class="calibre22">Every variable is an object, including those that are members of other objects.</li>
         
         <li class="calibre22">Every object occupies <i class="calibre6">at least one</i> memory location.
         </li>
         
         <li class="calibre22">Variables of fundamental types such as <kbd class="calibre17">int</kbd> or <kbd class="calibre17">char</kbd> occupy <i class="calibre6">exactly one</i> memory location, whatever their size, even if they’re adjacent or part of an array.
         </li>
         
         <li class="calibre22">Adjacent bit fields are part of the same memory location.</li>
         
      </ul>
      
      <p class="noind">I’m sure you’re wondering what this has to do with concurrency, so let’s take a look.</p>
      
      
      
      <h4 id="ch05lev2sec2" class="calibre23">5.1.2. <a id="ch05lev2sec2__title" class="calibre4"></a>Objects, memory locations, and concurrency
      </h4>
      
      <p class="noind">Now, here’s the part that’s crucial for multithreaded applications in C++: everything hinges on those memory locations. If
         two threads access <i class="calibre6">separate</i> memory locations, there’s no problem: everything works fine. On the other hand, if two threads access the <i class="calibre6">same</i> memory location, then you have to be careful. If neither thread is updating the memory location, you’re fine; read-only data
         doesn’t need protection or synchronization. If either thread is modifying the data, there’s a potential for a race condition,
         as described in <a href="kindle_split_013.html#ch03" class="calibre4">chapter 3</a>.
      </p>
      
      <p class="noind">In order to avoid the race condition, there has to be an enforced ordering between the accesses in the two threads. This could
         be a fixed ordering such that one access is always before the other, or it could be an ordering that varies between runs of
         the application, but guarantees that there is <i class="calibre6">some</i> defined ordering. One way to ensure there’s a defined ordering is to use mutexes as described in <a href="kindle_split_013.html#ch03" class="calibre4">chapter 3</a>; if the same mutex is locked prior to both accesses, only one thread can access the memory location <a id="iddle1037" class="calibre4"></a><a id="iddle1592" class="calibre4"></a><a id="iddle1625" class="calibre4"></a>at a time, so one must happen before the other (though, in general, you can’t know in advance which will be first). The other
         way is to use the synchronization properties of <i class="calibre6">atomic</i> operations (see <a href="#ch05lev1sec2" class="calibre4">section 5.2</a> for the definition of atomic operations) either on the same or other memory locations to enforce an ordering between the
         accesses in the two threads. The use of atomic operations to enforce an ordering is described in <a href="#ch05lev1sec3" class="calibre4">section 5.3</a>. If more than two threads access the same memory location, each pair of accesses must have a defined ordering.
      </p>
      
      <p class="noind">If there’s no enforced ordering between two accesses to a single memory location from separate threads, one or both of those
         accesses is not atomic, and if one or both is a write, then this is a data race and causes undefined behavior.
      </p>
      
      <p class="noind">This statement is crucially important: undefined behavior is one of the nastiest corners of C++. According to the language
         standard, once an application contains any undefined behavior, all bets are off; the behavior of the complete application
         is now undefined, and it may do anything at all. I know of one case where a particular instance of undefined behavior caused
         someone’s monitor to catch fire. Although this is rather unlikely to happen to you, a data race is definitely a serious bug
         and should be avoided at all costs.
      </p>
      
      <p class="noind">There’s another important point in that statement: you can also avoid the undefined behavior by using atomic operations to
         access the memory location involved in the race. This doesn’t prevent the race itself—which of the atomic operations touches
         the memory location first is still not specified—but it does bring the program back into the realm of defined behavior.
      </p>
      
      <p class="noind">Before we look at atomic operations, there’s one more concept that’s important to understand about objects and memory locations:
         modification orders.
      </p>
      
      
      
      <h4 id="ch05lev2sec3" class="calibre23">5.1.3. <a id="ch05lev2sec3__title" class="calibre4"></a>Modification orders
      </h4>
      
      <p class="noind">Every object in a C++ program has a <i class="calibre6">modification order</i> composed of all the writes to that object from all threads in the program, starting with the object’s initialization. In
         most cases this order will vary between runs, but in any given execution of the program all threads in the system must agree
         on the order. If the object in question isn’t one of the atomic types described in <a href="#ch05lev1sec2" class="calibre4">section 5.2</a>, you’re responsible for making certain that there’s sufficient synchronization to ensure that threads agree on the modification
         order of each variable. If different threads see distinct sequences of values for a single variable, you have a data race
         and undefined behavior (see <a href="#ch05lev2sec2" class="calibre4">section 5.1.2</a>). If you do use atomic operations, the compiler is responsible for ensuring that the necessary synchronization is in place.
      </p>
      
      <p class="noind">This requirement means that certain kinds of speculative execution aren’t permitted, because once a thread has seen a particular
         entry in the modification order, subsequent reads from that thread must return later values, and subsequent writes from that
         thread to that object must occur later in the modification order. Also, a read of an object that follows a write to that object
         in the same thread must either return the value written or another value that occurs later in the modification order of that
         <a id="iddle1025" class="calibre4"></a><a id="iddle1041" class="calibre4"></a><a id="iddle1495" class="calibre4"></a><a id="iddle2672" class="calibre4"></a>object. Although all threads must agree on the modification orders of each individual object in a program, they don’t necessarily
         have to agree on the relative order of operations on separate objects. See <a href="#ch05lev2sec13" class="calibre4">section 5.3.3</a> for more on the ordering of operations between threads.
      </p>
      
      <p class="noind">So, what constitutes an atomic operation, and how can these be used to enforce ordering?</p>
      
      
      
      
      <h3 id="ch05lev1sec2" class="chapter"><a id="ch05lev1sec2__title" class="calibre3"></a>5.2. Atomic operations and types in C++
      </h3>
      
      <p class="noind">An <i class="calibre6">atomic operation</i> is an indivisible operation. You can’t observe such an operation half-done from any thread in the system; it’s either done
         or not done. If the load operation that reads the value of an object is <i class="calibre6">atomic</i>, and all modifications to that object are also <i class="calibre6">atomic</i>, that load will retrieve either the initial value of the object or the value stored by one of the modifications.
      </p>
      
      <p class="noind">The flip side of this is that a non-atomic operation might be seen as half-done by another thread. If the non-atomic operation
         is composed of atomic operations (for example, assignment to a <kbd class="calibre17">struct</kbd> with <kbd class="calibre17">atomic</kbd> members), then other threads may observe some subset of the constituent atomic operations as complete, but others as not
         yet started, so you might observe or end up with a value that is a mixed-up combination of the various values stored. In any
         case, unsynchronized accesses to non-atomic variables form a simple problematic race condition, as described in <a href="kindle_split_013.html#ch03" class="calibre4">chapter 3</a>, but at this level it may constitute a <i class="calibre6">data race</i> (see <a href="#ch05lev1sec1" class="calibre4">section 5.1</a>) and cause undefined behavior.
      </p>
      
      <p class="noind">In C++, you need to use an atomic type to get an atomic operation in most cases, so let’s look at those.</p>
      
      
      <h4 id="ch05lev2sec4" class="calibre23">5.2.1. <a id="ch05lev2sec4__title" class="calibre4"></a>The standard atomic types
      </h4>
      
      <p class="noind">The standard <i class="calibre6">atomic types</i> can be found in the <kbd class="calibre17">&lt;atomic&gt;</kbd> header. All operations on such types are atomic, and only operations on these types are atomic in the sense of the language
         definition, although you can use mutexes to make other operations <i class="calibre6">appear</i> atomic. In fact, the standard atomic types themselves might use such emulation: they (almost) all have an <kbd class="calibre17">is_lock_free()</kbd> member function, which allows the user to determine whether operations on a given type are done directly with atomic instructions
         (<kbd class="calibre17">x.is_lock_free()</kbd> returns <kbd class="calibre17">true</kbd>) or done by using a lock internal to the compiler and library (<kbd class="calibre17">x.is_lock_free()</kbd> returns <kbd class="calibre17">false</kbd>).
      </p>
      
      <p class="noind">This is important to know in many cases—the key use case for atomic operations is as a replacement for an operation that would
         otherwise use a mutex for synchronization; if the atomic operations themselves use an internal mutex then the hoped-for performance
         gains will probably not materialize, and you might be better off using the easier-to-get-right mutex-based implementation
         instead. This is the case with lock-free data structures such as those discussed in <a href="kindle_split_017.html#ch07" class="calibre4">chapter 7</a>.
      </p>
      
      <p class="noind">In fact, this is so important that the library provides a set of macros to identify at compile time whether the atomic types
         for the various integral types are lock-free. <a id="iddle1939" class="calibre4"></a><a id="iddle1989" class="calibre4"></a><a id="iddle2462" class="calibre4"></a>Since C++17, all atomic types have a <kbd class="calibre17">static constexpr</kbd> member variable, <kbd class="calibre17">X::is_always_lock_free</kbd>, which is <kbd class="calibre17">true</kbd> if and only if the atomic type <kbd class="calibre17">X</kbd> is lock-free for all supported hardware that the output of the current compilation might run on. For example, for a given
         target platform, <kbd class="calibre17">std::atomic&lt;int&gt;</kbd> might always be lock-free, so <kbd class="calibre17">std::atomic&lt;int&gt;::is_always_lock_free</kbd> will be <kbd class="calibre17">true</kbd>, but <kbd class="calibre17">std::atomic&lt;uintmax_t&gt;</kbd> might only be lock-free if the hardware the program ends up running on supports the necessary instructions, so this is a
         run-time property, and <kbd class="calibre17">std::atomic&lt;uintmax_t&gt;::is_always_lock_free</kbd> would be <kbd class="calibre17">false</kbd> when compiling for that platform.
      </p>
      
      <p class="noind">The macros are <kbd class="calibre17">ATOMIC_BOOL_LOCK_FREE</kbd>, <kbd class="calibre17">ATOMIC_CHAR_LOCK_FREE</kbd>, <kbd class="calibre17">ATOMIC_CHAR16_T_LOCK_FREE</kbd>, <kbd class="calibre17">ATOMIC_CHAR32_T_LOCK_FREE</kbd>, <kbd class="calibre17">ATOMIC_WCHAR_T_LOCK_FREE</kbd>, <kbd class="calibre17">ATOMIC_SHORT_LOCK_FREE</kbd>, <kbd class="calibre17">ATOMIC_INT_LOCK_FREE</kbd>, <kbd class="calibre17">ATOMIC_LONG_LOCK_FREE</kbd>, <kbd class="calibre17">ATOMIC_LLONG_LOCK_FREE</kbd>, and <kbd class="calibre17">ATOMIC_POINTER_LOCK_FREE</kbd>. They specify the lock-free status of the corresponding atomic types for the specified built-in types and their <kbd class="calibre17">unsigned</kbd> counterparts (<kbd class="calibre17">LLONG</kbd> refers to <kbd class="calibre17">long long</kbd>, and <kbd class="calibre17">POINTER</kbd> refers to all pointer types). They evaluate to the value <kbd class="calibre17">0</kbd> if the atomic type is <i class="calibre6">never</i> lock-free, to the value <kbd class="calibre17">2</kbd> if the atomic type is <i class="calibre6">always</i> lock-free, and to the value <kbd class="calibre17">1</kbd> if the lock-free status of the corresponding atomic type is a runtime property as described previously.
      </p>
      
      <p class="noind">The only type that doesn’t provide an <kbd class="calibre17">is_lock_free()</kbd> member function is <kbd class="calibre17">std::atomic_flag</kbd>. This type is a simple Boolean flag, and operations on this type are <i class="calibre6">required</i> to be lock-free; once you have a simple lock-free Boolean flag, you can use that to implement a simple lock and implement
         all the other atomic types using that as a basis. When I said <i class="calibre6">simple</i>, I meant it: objects of the <kbd class="calibre17">std::atomic_flag</kbd> type are initialized to clear, and they can then either be queried and set (with the <kbd class="calibre17">test_and_set()</kbd> member function) or cleared (with the <kbd class="calibre17">clear()</kbd> member function). That’s it: no assignment, no copy construction, no test and clear, no other operations at all.
      </p>
      
      <p class="noind">The remaining atomic types are all accessed through specializations of the <kbd class="calibre17">std::atomic&lt;&gt;</kbd> class template and are a bit more full-featured but may not be lock-free (as explained previously). On most popular platforms
         it’s expected that the atomic variants of all the built-in types (such as <kbd class="calibre17">std::atomic&lt;int&gt;</kbd> and <kbd class="calibre17">std::atomic &lt;void*&gt;</kbd>) are indeed lock-free, but it isn’t required. As you’ll see shortly, the interface of each specialization reflects the properties
         of the type; bitwise operations such as <kbd class="calibre17">&amp;=</kbd> aren’t defined for plain pointers, so they aren’t defined for atomic pointers either, for example.
      </p>
      
      <p class="noind">In addition to using the <kbd class="calibre17">std::atomic&lt;&gt;</kbd> class template directly, you can use the set of names shown in <a href="#ch05table01" class="calibre4">table 5.1</a> to refer to the implementation-supplied atomic types. Because of the history of how atomic types were added to the C++ Standard,
         if you have an older compiler, these alternative type names may refer either to the corresponding <kbd class="calibre17">std::atomic&lt;&gt;</kbd> specialization or to a base class of that specialization, whereas in a compiler that fully supports C++17, these are always
         aliases for the corresponding <kbd class="calibre17">std::atomic&lt;&gt;</kbd> specializations. Mixing these alternative names with the direct naming of <kbd class="calibre17">std::atomic&lt;&gt;</kbd> specializations in the same program can therefore lead to nonportable code.
      </p>
      
      
      <p class="noind"></p>
      <h5 class="notetitle" id="ch05table01">Table 5.1. <a id="ch05table01__title" class="calibre4"></a>The alternative names for the standard atomic types and their corresponding <kbd class="calibre17">std::atomic&lt;&gt;</kbd> specializations
      </h5>
      <table cellspacing="5" frame="hsides" rules="groups" cellpadding="8" width="100%" class="calibre25">
         <colgroup span="2" class="calibre8">
            <col width="300" class="calibre9"/>
            <col width="300" class="calibre9"/>
         </colgroup>
         <thead class="calibre26">
            <tr class="calibre11">
               <th class="doctablecell1" scope="col" valign="top">
                  <p class="noind"><a id="iddle1042" class="calibre4"></a><a id="iddle2594" class="calibre4"></a>Atomic type
                  </p>
               </th>
               <th class="doctablecell1" scope="col" valign="top">
                  <p class="noind">Corresponding specialization</p>
               </th>
            </tr>
         </thead>
         <tbody class="calibre10">
            <tr class="calibre11">
               <td class="doctablecell">atomic_bool</td>
               <td class="doctablecell">std::atomic&lt;bool&gt;</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_char</td>
               <td class="doctablecell">std::atomic&lt;char&gt;</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_schar</td>
               <td class="doctablecell">std::atomic&lt;signed char&gt;</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_uchar</td>
               <td class="doctablecell">std::atomic&lt;unsigned char&gt;</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_int</td>
               <td class="doctablecell">std::atomic&lt;int&gt;</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_uint</td>
               <td class="doctablecell">std::atomic&lt;unsigned&gt;</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_short</td>
               <td class="doctablecell">std::atomic&lt;short&gt;</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_ushort</td>
               <td class="doctablecell">std::atomic&lt;unsigned short&gt;</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_long</td>
               <td class="doctablecell">std::atomic&lt;long&gt;</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_ulong</td>
               <td class="doctablecell">std::atomic&lt;unsigned long&gt;</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_llong</td>
               <td class="doctablecell">std::atomic&lt;long long&gt;</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_ullong</td>
               <td class="doctablecell">std::atomic&lt;unsigned long long&gt;</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_char16_t</td>
               <td class="doctablecell">std::atomic&lt;char16_t&gt;</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_char32_t</td>
               <td class="doctablecell">std::atomic&lt;char32_t&gt;</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_wchar_t</td>
               <td class="doctablecell">std::atomic&lt;wchar_t&gt;</td>
            </tr>
         </tbody>
      </table>
      
      <p class="noind">As well as the basic atomic types, the C++ Standard Library also provides a set of <kbd class="calibre17">typedef</kbd>s for the atomic types corresponding to the various non-atomic Standard Library <kbd class="calibre17">typedef</kbd>s such as <kbd class="calibre17">std::size_t</kbd>. These are shown in <a href="#ch05table02" class="calibre4">table 5.2</a>.
      </p>
      
      <h5 class="notetitle" id="ch05table02">Table 5.2. <a id="ch05table02__title" class="calibre4"></a>The standard atomic <kbd class="calibre17">typedef</kbd>s and their corresponding built-in <kbd class="calibre17">typedef</kbd>s
      </h5>
      <table cellspacing="5" frame="hsides" rules="groups" cellpadding="8" width="100%" class="calibre25">
         <colgroup span="2" class="calibre8">
            <col width="300" class="calibre9"/>
            <col width="300" class="calibre9"/>
         </colgroup>
         <thead class="calibre26">
            <tr class="calibre11">
               <th class="doctablecell1" scope="col" valign="top">
                  <p class="noind">Atomic typedef</p>
               </th>
               <th class="doctablecell1" scope="col" valign="top">
                  <p class="noind">Corresponding Standard Library typedef</p>
               </th>
            </tr>
         </thead>
         <tbody class="calibre10">
            <tr class="calibre11">
               <td class="doctablecell">atomic_int_least8_t</td>
               <td class="doctablecell">int_least8_t</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_uint_least8_t</td>
               <td class="doctablecell">uint_least8_t</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_int_least16_t</td>
               <td class="doctablecell">int_least16_t</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_uint_least16_t</td>
               <td class="doctablecell">uint_least16_t</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_int_least32_t</td>
               <td class="doctablecell">int_least32_t</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_uint_least32_t</td>
               <td class="doctablecell">uint_least32_t</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_int_least64_t</td>
               <td class="doctablecell">int_least64_t</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_uint_least64_t</td>
               <td class="doctablecell">uint_least64_t</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell"><a id="iddle1341" class="calibre4"></a><a id="iddle1361" class="calibre4"></a><a id="iddle1364" class="calibre4"></a><a id="iddle1517" class="calibre4"></a><a id="iddle2410" class="calibre4"></a>atomic_int_fast8_t
               </td>
               <td class="doctablecell">int_fast8_t</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_uint_fast8_t</td>
               <td class="doctablecell">uint_fast8_t</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_int_fast16_t</td>
               <td class="doctablecell">int_fast16_t</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_uint_fast16_t</td>
               <td class="doctablecell">uint_fast16_t</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_int_fast32_t</td>
               <td class="doctablecell">int_fast32_t</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_uint_fast32_t</td>
               <td class="doctablecell">uint_fast32_t</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_int_fast64_t</td>
               <td class="doctablecell">int_fast64_t</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_uint_fast64_t</td>
               <td class="doctablecell">uint_fast64_t</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_intptr_t</td>
               <td class="doctablecell">intptr_t</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_uintptr_t</td>
               <td class="doctablecell">uintptr_t</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_size_t</td>
               <td class="doctablecell">size_t</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_ptrdiff_t</td>
               <td class="doctablecell">ptrdiff_t</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_intmax_t</td>
               <td class="doctablecell">intmax_t</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">atomic_uintmax_t</td>
               <td class="doctablecell">uintmax_t</td>
            </tr>
         </tbody>
      </table>
      
      <p class="noind">That’s a lot of types! There’s a rather simple pattern to it; for a standard <kbd class="calibre17">typedef T</kbd>, the corresponding atomic type is the same name with an <kbd class="calibre17">atomic_</kbd> prefix: <kbd class="calibre17">atomic_T</kbd>. The same applies to the built-in types, except that <kbd class="calibre17">signed</kbd> is abbreviated as <kbd class="calibre17">s</kbd>, <kbd class="calibre17">unsigned</kbd> as <kbd class="calibre17">u</kbd>, and <kbd class="calibre17">long long</kbd> as <kbd class="calibre17">llong</kbd>. It’s generally simpler to say <kbd class="calibre17">std::atomic&lt;T&gt;</kbd> for whichever <kbd class="calibre17">T</kbd> you want to work with, rather than use the alternative names.
      </p>
      
      <p class="noind">The standard atomic types are not copyable or assignable in the conventional sense, in that they have no copy constructors
         or copy assignment operators. They <i class="calibre6">do</i>, however, support assignment from and implicit conversion to the corresponding built-in types as well as direct <kbd class="calibre17">load()</kbd> and <kbd class="calibre17">store()</kbd> member functions, <kbd class="calibre17">exchange()</kbd>, <kbd class="calibre17">compare_exchange_weak()</kbd>, and <kbd class="calibre17">compare_exchange_strong()</kbd>. They also support the compound assignment operators where appropriate: <kbd class="calibre17">+=, -=, *=, |=,</kbd> and so on, and the integral types and <kbd class="calibre17">std::atomic&lt;&gt;</kbd> specializations for <kbd class="calibre17">++</kbd> and <kbd class="calibre17">--</kbd> pointers support. These operators also have corresponding named member functions with the same functionality: <kbd class="calibre17">fetch_add()</kbd>, <kbd class="calibre17">fetch_or()</kbd>, and so on. The return value from the assignment operators and member functions is either the value stored (in the case of
         the assignment operators) or the value prior to the operation (in the case of the named functions). This avoids the potential
         problems that could stem from the usual habit of these assignment operators returning a reference to the object being assigned
         to. In order to get the stored value from these references, the code would have to perform a separate read, allowing another
         thread to modify the value between the assignment and the read and opening the door for a race condition.
      </p>
      
      <p class="noind"><a id="iddle1035" class="calibre4"></a><a id="iddle1043" class="calibre4"></a><a id="iddle1714" class="calibre4"></a><a id="iddle1845" class="calibre4"></a><a id="iddle1988" class="calibre4"></a><a id="iddle2179" class="calibre4"></a><a id="iddle2409" class="calibre4"></a>The <kbd class="calibre17">std::atomic&lt;&gt;</kbd> class template isn’t only a set of specializations, though. It does have a primary template that can be used to create an
         atomic variant of a user-defined type. Because it’s a generic class template, the operations are limited to <kbd class="calibre17">load()</kbd>, <kbd class="calibre17">store()</kbd> (and assignment from and conversion to the user-defined type), <kbd class="calibre17">exchange()</kbd>, <kbd class="calibre17">compare_exchange_weak()</kbd>, and <kbd class="calibre17">compare_exchange_strong()</kbd>.
      </p>
      
      <p class="noind">Each of the operations on the atomic types has an optional memory-ordering argument which is one of the values of the <kbd class="calibre17">std::memory_order</kbd> enumeration. This argument is used to specify the required memory-ordering semantics. The <kbd class="calibre17">std::memory_order</kbd> enumeration has six possible values: <kbd class="calibre17">std::memory_order_relaxed</kbd>, <kbd class="calibre17">std:: memory_order_acquire</kbd>, <kbd class="calibre17">std::memory_order_consume</kbd>, <kbd class="calibre17">std::memory_order_acq_rel</kbd>, <kbd class="calibre17">std::memory_order_release</kbd>, and <kbd class="calibre17">std::memory_order_seq_cst</kbd>.
      </p>
      
      <p class="noind">The permitted values for the memory ordering depend on the operation category. If you don’t specify an ordering value, then
         the default ordering is used, which is the strongest ordering: <kbd class="calibre17">std::memory_order_seq_cst</kbd>. The precise semantics of the memory-ordering options are covered in <a href="#ch05lev1sec3" class="calibre4">section 5.3</a>. For now, it suffices to know that the operations are divided into three categories:
      </p>
      
      <p class="calibre19"></p>
      <ul class="calibre21">
         
         <li class="calibre22"><i class="calibre6">Store</i> operations, which can have <kbd class="calibre17">memory_order_relaxed</kbd>, <kbd class="calibre17">memory_order_release</kbd>, or <kbd class="calibre17">memory_order_seq_cst</kbd> ordering
         </li>
         
         <li class="calibre22"><i class="calibre6">Load</i> operations, which can have <kbd class="calibre17">memory_order_relaxed</kbd>, <kbd class="calibre17">memory_order_consume</kbd>, <kbd class="calibre17">memory_order_acquire,</kbd> or <kbd class="calibre17">memory_order_seq_cst</kbd> ordering
         </li>
         
         <li class="calibre22"><i class="calibre6">Read-modify-write</i> operations, which can have <kbd class="calibre17">memory_order_relaxed</kbd>, <kbd class="calibre17">memory_order_consume</kbd>, <kbd class="calibre17">memory_order_acquire</kbd>, <kbd class="calibre17">memory_order_release</kbd>, <kbd class="calibre17">memory_order_acq_rel</kbd>, or <kbd class="calibre17">memory_order_seq_cst</kbd> ordering
         </li>
         
      </ul>
      
      <p class="noind">Let’s now look at the operations you can perform on each of the standard atomic types, starting with <kbd class="calibre17">std::atomic_flag</kbd>.
      </p>
      
      
      
      <h4 id="ch05lev2sec5" class="calibre23">5.2.2. <a id="ch05lev2sec5__title" class="calibre4"></a>Operations on std::atomic_flag
      </h4>
      
      <p class="noind"><kbd class="calibre17">std::atomic_flag</kbd> is the simplest standard atomic type, which represents a Boolean flag. Objects of this type can be in one of two states:
         set or clear. It’s deliberately basic and is intended as a building block only. As such, I’d never expect to see it in use,
         except under special circumstances. Even so, it will serve as a starting point for discussing the other atomic types, because
         it shows some of the general policies that apply to the atomic types.
      </p>
      
      <p class="noind">Objects of the <kbd class="calibre17">std::atomic_flag</kbd> type <i class="calibre6">must</i> be initialized with <kbd class="calibre17">ATOMIC_FLAG_INIT</kbd>. This initializes the flag to a <i class="calibre6">clear</i> state. There’s no choice in the matter; the flag always starts clear:
      </p>
      
      <pre id="PLd0e15554" class="calibre5">std::atomic_flag f=ATOMIC_FLAG_INIT;</pre>
      
      <p class="noind">This applies no matter where the object is declared and what scope it has. It’s the only atomic type to require such special
         treatment for initialization, but it’s also the only type guaranteed to be lock-free. If the <kbd class="calibre17">std::atomic_flag</kbd> object has static storage <a id="iddle1109" class="calibre4"></a><a id="iddle1615" class="calibre4"></a><a id="iddle2463" class="calibre4"></a>duration, it’s guaranteed to be statically initialized, which means that there are no initialization-order issues; it will
         always be initialized by the time of the first operation on the flag.
      </p>
      
      <p class="noind">Once you have your flag object initialized, there are only three things you can do with it: destroy it, clear it, or set it
         and query the previous value. These correspond to the destructor, the <kbd class="calibre17">clear()</kbd> member function, and the <kbd class="calibre17">test_and_set()</kbd> member function, respectively. Both the <kbd class="calibre17">clear()</kbd> and <kbd class="calibre17">test_and_set()</kbd> member functions can have a memory order specified. <kbd class="calibre17">clear()</kbd> is a store operation and so can’t have <kbd class="calibre17">memory_order_acquire</kbd> or <kbd class="calibre17">memory_order_acq_rel</kbd> semantics, but <kbd class="calibre17">test_and_set()</kbd> is a read-modify-write operation and so can have any of the memory-ordering tags applied. As with every atomic operation,
         the default for both is <kbd class="calibre17">memory_order_seq_cst</kbd>. For example:
      </p>
      
      <pre id="PLd0e15614" class="calibre5">f.clear(std::memory_order_release);     <b class="calibre24"><i class="calibre6">1</i></b>
bool x=f.test_and_set();                <b class="calibre24"><i class="calibre6">2</i></b></pre>
      
      <p class="noind">Here, the call to <kbd class="calibre17">clear()</kbd> <b class="calibre24"><i class="calibre6">1</i></b> explicitly requests that the flag is cleared with release semantics, whereas the call to <kbd class="calibre17">test_and_set()</kbd> <b class="calibre24"><i class="calibre6">2</i></b> uses the default memory ordering for setting the flag and retrieving the old value.
      </p>
      
      <p class="noind">You can’t copy-construct another <kbd class="calibre17">std::atomic_flag</kbd> object from the first, and you can’t assign one <kbd class="calibre17">std::atomic_flag</kbd> to another. This isn’t something peculiar to <kbd class="calibre17">std::atomic_flag</kbd> but something common with all the atomic types. All operations on an atomic type are defined as atomic, and assignment and
         copy-construction involve two objects. A single operation on two distinct objects can’t be atomic. In the case of copy-construction
         or copy-assignment, the value must first be read from one object and then written to the other. These are two separate operations
         on two separate objects, and the combination can’t be atomic. Therefore, these operations aren’t permitted.
      </p>
      
      <p class="noind">The limited feature set makes <kbd class="calibre17">std::atomic_flag</kbd> ideally suited to use as a spin-lock mutex. Initially, the flag is clear and the mutex is unlocked. To lock the mutex, loop
         on <kbd class="calibre17">test_and_set()</kbd> until the old value is <kbd class="calibre17">false</kbd>, indicating that <i class="calibre6">this</i> thread set the value to <kbd class="calibre17">true</kbd>. Unlocking the mutex is simply a matter of clearing the flag. This implementation is shown in the following listing.
      </p>
      
      
      
      <h5 class="notetitle" id="ch05ex01">Listing 5.1. <a id="ch05ex01__title" class="calibre4"></a>Implementation of a spinlock mutex using std::atomic_flag
      </h5>
      <pre id="PLd0e15679" class="calibre5">class spinlock_mutex
{
    std::atomic_flag flag;
public:
    spinlock_mutex():
        flag(ATOMIC_FLAG_INIT)
    {}
    void lock()
    {
        while(flag.test_and_set(std::memory_order_acquire));
    }
    void unlock()
    {
        flag.clear(std::memory_order_release);
    }
};</pre>
      
      <p class="noind"><a id="iddle1034" class="calibre4"></a><a id="iddle1692" class="calibre4"></a><a id="iddle1713" class="calibre4"></a><a id="iddle1948" class="calibre4"></a><a id="iddle2411" class="calibre4"></a>This mutex is basic, but it’s enough to use with <kbd class="calibre17">std::lock_guard&lt;&gt;</kbd> (see <a href="kindle_split_013.html#ch03" class="calibre4">chapter 3</a>). By its nature it does a busy-wait in <kbd class="calibre17">lock()</kbd>, so it’s a poor choice if you expect there to be any degree of contention, but it’s enough to ensure mutual exclusion. When
         we look at the memory-ordering semantics, you’ll see how this guarantees the necessary enforced ordering that goes with a
         mutex lock. This example is covered in <a href="#ch05lev2sec16" class="calibre4">section 5.3.6</a>.
      </p>
      
      <p class="noind"><kbd class="calibre17">std::atomic_flag</kbd> is so limited that it can’t even be used as a general Boolean flag, because it doesn’t have a simple nonmodifying query operation.
         For that you’re better off using <kbd class="calibre17">std::atomic&lt;bool&gt;</kbd>, so I’ll cover that next.
      </p>
      
      
      
      <h4 id="ch05lev2sec6" class="calibre23">5.2.3. <a id="ch05lev2sec6__title" class="calibre4"></a>Operations on std::atomic&lt;bool&gt;
      </h4>
      
      <p class="noind">The most basic of the atomic integral types is <kbd class="calibre17">std::atomic&lt;bool&gt;</kbd>. This is a more full-featured Boolean flag than <kbd class="calibre17">std::atomic_flag</kbd>, as you might expect. Although it’s still not copy-constructible or copy-assignable, you can construct it from a non-atomic
         <kbd class="calibre17">bool</kbd>, so it can be initially <kbd class="calibre17">true</kbd> or <kbd class="calibre17">false</kbd>, and you can also assign to instances of <kbd class="calibre17">std::atomic&lt;bool&gt;</kbd> from a non-atomic <kbd class="calibre17">bool:</kbd></p>
      
      <pre id="PLd0e15770" class="calibre5">std::atomic&lt;bool&gt; b(true);
b=false;</pre>
      
      <p class="noind">One other thing to note about the assignment operator from a non-atomic <kbd class="calibre17">bool</kbd> is that it differs from the general convention of returning a reference to the object it’s assigned to: it returns a <kbd class="calibre17">bool</kbd> with the value assigned instead. This is another common pattern with the atomic types: the assignment operators they support
         return values (of the corresponding non-atomic type) rather than references. If a reference to the atomic variable was returned,
         any code that depended on the result of the assignment would then have to explicitly load the value, potentially getting the
         result of a modification by another thread. By returning the result of the assignment as a non-atomic value, you can avoid
         this additional load, and you know that the value obtained is the value stored.
      </p>
      
      <p class="noind">Rather than using the restrictive <kbd class="calibre17">clear()</kbd> function of <kbd class="calibre17">std::atomic_flag</kbd>, writes (of either <kbd class="calibre17">true</kbd> or <kbd class="calibre17">false</kbd>) are done by calling <kbd class="calibre17">store()</kbd>, although the memory-order semantics can still be specified. Similarly, <kbd class="calibre17">test_and_set()</kbd> has been replaced with the more general <kbd class="calibre17">exchange()</kbd> member function that allows you to replace the stored value with a new one of your choosing and atomically retrieve the original
         value. <kbd class="calibre17">std::atomic&lt;bool&gt;</kbd> also supports a plain nonmodifying query of the value with an implicit conversion to plain <kbd class="calibre17">bool</kbd> or with an explicit call to <kbd class="calibre17">load()</kbd>. As you might expect, <kbd class="calibre17">store()</kbd> is a store operation, whereas <kbd class="calibre17">load()</kbd> is a load operation. <kbd class="calibre17">exchange()</kbd> is a read-modify-write operation:
      </p>
      
      
      <pre id="PLd0e15829" class="calibre5">std::atomic&lt;bool&gt; b;
bool x=b.load(std::memory_order_acquire);
b.store(true);
x=b.exchange(false,std::memory_order_acq_rel);</pre>
      
      <p class="noind"><a id="iddle1128" class="calibre4"></a><a id="iddle1132" class="calibre4"></a><a id="iddle1935" class="calibre4"></a><a id="iddle2611" class="calibre4"></a><kbd class="calibre17">exchange()</kbd> isn’t the only read-modify-write operation supported by <kbd class="calibre17">std::atomic&lt;bool&gt;</kbd>; it also introduces an operation to store a new value if the current value is equal to an expected value.
      </p>
      
      
      <h5 class="notetitle" id="ch05lev3sec1"><a id="ch05lev3sec1__title" class="calibre4"></a>Storing a new value (or not) depending on the current value
      </h5>
      
      <p class="noind">This new operation is called compare-exchange, and it comes in the form of the <kbd class="calibre17">compare_exchange_weak()</kbd> and <kbd class="calibre17">compare_exchange_strong()</kbd> member functions. The compare-exchange operation is the cornerstone of programming with atomic types; it compares the value
         of the atomic variable with a supplied expected value and stores the supplied desired value if they’re equal. If the values
         aren’t equal, the expected value is updated with the value of the atomic variable. The return type of the compare-exchange
         functions is a <kbd class="calibre17">bool</kbd>, which is <kbd class="calibre17">true</kbd> if the store was performed and <kbd class="calibre17">false</kbd> otherwise. The operation is said to <i class="calibre6">succeed</i> if the store was done (because the values were equal), and <i class="calibre6">fail</i> otherwise; the return value is <kbd class="calibre17">true</kbd> for success, and <kbd class="calibre17">false</kbd> for failure.
      </p>
      
      <p class="noind">For <kbd class="calibre17">compare_exchange_weak()</kbd>, the store might not be successful even if the original value was equal to the expected value, in which case the value of
         the variable is unchanged and the return value of <kbd class="calibre17">compare_exchange_weak()</kbd> is <kbd class="calibre17">false</kbd>. This is most likely to happen on machines that lack a single compare-and-exchange instruction, if the processor can’t guarantee
         that the operation has been done atomically—possibly because the thread performing the operation was switched out in the middle
         of the necessary sequence of instructions and another thread scheduled in its place by the operating system where there are
         more threads than processors. This is called a <i class="calibre6">spurious failure</i>, because the reason for the failure is a function of timing rather than the values of the variables.
      </p>
      
      <p class="noind">Because <kbd class="calibre17">compare_exchange_weak()</kbd> can fail spuriously, it must typically be used in a loop:
      </p>
      
      <pre id="PLd0e15922" class="calibre5">bool expected=false;
extern atomic&lt;bool&gt; b; // set somewhere else
while(!b.compare_exchange_weak(expected,true) &amp;&amp; !expected);</pre>
      
      <p class="noind">In this case, you keep looping as long as <kbd class="calibre17">expected</kbd> is still <kbd class="calibre17">false</kbd>, indicating that the <kbd class="calibre17">compare_exchange_weak()</kbd> call failed spuriously.
      </p>
      
      <p class="noind">On the other hand, <kbd class="calibre17">compare_exchange_strong()</kbd> is guaranteed to return <kbd class="calibre17">false</kbd> only if the value wasn’t equal to the <kbd class="calibre17">expected</kbd> value. This can eliminate the need for loops like the one shown where you want to know whether you successfully changed a
         variable or whether another thread got there first.
      </p>
      
      <p class="noind">If you want to change the variable whatever the initial value is (perhaps with an updated value that depends on the current
         value), the update of <kbd class="calibre17">expected</kbd> becomes <a id="iddle1600" class="calibre4"></a><a id="iddle1602" class="calibre4"></a><a id="iddle1607" class="calibre4"></a><a id="iddle1608" class="calibre4"></a>useful; each time through the loop, <kbd class="calibre17">expected</kbd> is reloaded, so if no other thread modifies the value in the meantime, the <kbd class="calibre17">compare_exchange_weak()</kbd> or <kbd class="calibre17">compare_exchange_strong()</kbd> call should be successful the next time around the loop. If the calculation of the value to be stored is simple, it may be
         beneficial to use <kbd class="calibre17">compare_exchange_weak()</kbd> in order to avoid a double loop on platforms where <kbd class="calibre17">compare_exchange_weak()</kbd> <i class="calibre6">can</i> fail spuriously (and so <kbd class="calibre17">compare_exchange_strong()</kbd> contains a loop). On the other hand, if the calculation of the value to be stored is time-consuming, it may make sense to
         use <kbd class="calibre17">compare_exchange_strong()</kbd> to avoid having to recalculate the value to store when the <kbd class="calibre17">expected</kbd> value hasn’t changed. For <kbd class="calibre17">std::atomic&lt;bool&gt;</kbd> this isn’t so important—there are only two possible values after all—but for the larger atomic types this can make a difference.
      </p>
      
      <p class="noind">The compare-exchange functions are also unusual in that they can take two memory-ordering parameters. This allows for the
         memory-ordering semantics to differ in the case of success and failure; it might be desirable for a successful call to have
         <kbd class="calibre17">memory_order_acq_rel</kbd> semantics, whereas a failed call has <kbd class="calibre17">memory_order_relaxed</kbd> semantics. A failed compare-exchange doesn’t do a store, so it can’t have <kbd class="calibre17">memory_order_release</kbd> or <kbd class="calibre17">memory_order_acq_rel</kbd> semantics. It’s therefore not permitted to supply these values as the ordering for failure. You also can’t supply stricter
         memory ordering for failure than for success; if you want <kbd class="calibre17">memory_order_acquire</kbd> or <kbd class="calibre17">memory_order_seq_cst</kbd> semantics for failure, you must specify those for success as well.
      </p>
      
      <p class="noind">If you don’t specify an ordering for failure, it’s assumed to be the same as that for success, except that the <kbd class="calibre17">release</kbd> part of the ordering is stripped: <kbd class="calibre17">memory_order_release</kbd> becomes <kbd class="calibre17">memory_order_relaxed</kbd>, and <kbd class="calibre17">memory_order_acq_rel</kbd> becomes <kbd class="calibre17">memory_order_acquire</kbd>. If you specify neither, they default to <kbd class="calibre17">memory_order_seq_cst</kbd> as usual, which provides the full sequential ordering for both success and failure. The following two calls to <kbd class="calibre17">compare_exchange_weak()</kbd> are equivalent:
      </p>
      
      <pre id="PLd0e16055" class="calibre5">std::atomic&lt;bool&gt; b;
bool expected;
b.compare_exchange_weak(expected,true,
    memory_order_acq_rel,memory_order_acquire);
b.compare_exchange_weak(expected,true,memory_order_acq_rel);</pre>
      
      <p class="noind">I’ll leave the consequences of the choice of memory ordering to <a href="#ch05lev1sec3" class="calibre4">section 5.3</a>.
      </p>
      
      <p class="noind">One further difference between <kbd class="calibre17">std::atomic&lt;bool&gt;</kbd> and <kbd class="calibre17">std::atomic_flag</kbd> is that <kbd class="calibre17">std::atomic&lt;bool&gt;</kbd> may not be lock-free; the implementation may have to acquire a mutex internally in order to ensure the atomicity of the operations.
         For the rare case when this matters, you can use the <kbd class="calibre17">is_lock_free()</kbd> member function to check whether operations on <kbd class="calibre17">std::atomic&lt;bool&gt;</kbd> are lock-free. This is another feature common to all atomic types other than <kbd class="calibre17">std::atomic_flag.</kbd></p>
      
      <p class="noind">The next simplest of the atomic types are the atomic pointer specializations <kbd class="calibre17">std::atomic&lt;T*&gt;</kbd>, so we’ll look at those next.
      </p>
      
      
      
      
      
      <h4 id="ch05lev2sec7" class="calibre23">5.2.4. <a id="ch05lev2sec7__title" class="calibre4"></a>Operations on std::atomic&lt;T*&gt;: pointer arithmetic
      </h4>
      
      <p class="noind"><a id="iddle1036" class="calibre4"></a><a id="iddle1342" class="calibre4"></a><a id="iddle1362" class="calibre4"></a><a id="iddle1365" class="calibre4"></a><a id="iddle1715" class="calibre4"></a><a id="iddle2019" class="calibre4"></a>The atomic form of a pointer to some type <kbd class="calibre17">T</kbd> is <kbd class="calibre17">std::atomic&lt;T*&gt;</kbd>, just as the atomic form of <kbd class="calibre17">bool</kbd> is <kbd class="calibre17">std::atomic&lt;bool&gt;</kbd>. The interface is the same, although it operates on values of the corresponding pointer type rather than <kbd class="calibre17">bool</kbd> values. Like <kbd class="calibre17">std::atomic&lt;bool&gt;</kbd>, it’s neither copy-constructible nor copy-assignable, although it can be both constructed and assigned from the suitable
         pointer values. As well as the obligatory <kbd class="calibre17">is_lock_free()</kbd> member function, <kbd class="calibre17">std::atomic&lt;T*&gt;</kbd> also has <kbd class="calibre17">load()</kbd>, <kbd class="calibre17">store()</kbd>, <kbd class="calibre17">exchange()</kbd>, <kbd class="calibre17">compare_exchange_weak()</kbd>, and <kbd class="calibre17">compare_exchange_strong()</kbd> member functions, with similar semantics to those of <kbd class="calibre17">std::atomic&lt;bool&gt;</kbd>, again taking and returning <kbd class="calibre17">T*</kbd> rather than <kbd class="calibre17">bool</kbd>.
      </p>
      
      <p class="noind">The new operations provided by <kbd class="calibre17">std::atomic&lt;T*&gt;</kbd> are the pointer arithmetic operations. The basic operations are provided by the <kbd class="calibre17">fetch_add()</kbd> and <kbd class="calibre17">fetch_sub()</kbd> member functions, which do atomic addition and subtraction on the stored address, and the <kbd class="calibre17">+=</kbd> and <kbd class="calibre17">-=</kbd> operators, and both pre- and post-increment and decrement with <kbd class="calibre17">++</kbd> and <kbd class="calibre17">--</kbd>, which provide convenient wrappers. The operators work as you’d expect from the built-in types: if <kbd class="calibre17">x</kbd> is <kbd class="calibre17">std::atomic&lt;Foo*&gt;</kbd> to the first entry of an array of <kbd class="calibre17">Foo</kbd> objects, then <kbd class="calibre17">x+=3</kbd> changes it to point to the fourth entry and returns a plain <kbd class="calibre17">Foo*</kbd> that also points to that fourth entry. <kbd class="calibre17">fetch_add()</kbd> and <kbd class="calibre17">fetch_sub()</kbd> are slightly different in that they return the original value (so <kbd class="calibre17">x.fetch_add(3)</kbd> will update <kbd class="calibre17">x</kbd> to point to the fourth value but return a pointer to the first value in the array). This operation is also known as <i class="calibre6">exchange-and-add</i>, and it’s an atomic read-modify-write operation, like <kbd class="calibre17">exchange()</kbd> and <kbd class="calibre17">compare_exchange_weak()</kbd>/<kbd class="calibre17">compare_exchange_strong()</kbd>. As with the other operations, the return value is a plain <kbd class="calibre17">T*</kbd> value rather than a reference to the <kbd class="calibre17">std::atomic&lt;T*&gt;</kbd> object, so that the calling code can perform actions based on what the previous value was:
      </p>
      
      <pre id="PLd0e16258" class="calibre5">class Foo{};
Foo some_array[5];
std::atomic&lt;Foo*&gt; p(some_array);
Foo* x=p.fetch_add(2);               <b class="calibre24"><i class="calibre6">1</i></b>
assert(x==some_array);
assert(p.load()==&amp;some_array[2]);
x=(p-=1);                            <b class="calibre24"><i class="calibre6">2</i></b>
assert(x==&amp;some_array[1]);
assert(p.load()==&amp;some_array[1]);</pre>
      
      <p class="calibre19"></p>
      <ul class="calibre21">
         
         <li class="calibre22"><b class="calibre24"><i class="calibre6">1</i> Add 2 to p and return old value</b></li>
         
         <li class="calibre22"><b class="calibre24"><i class="calibre6">2</i> Subtract 1 from p and return new value</b></li>
         
      </ul>
      
      <p class="noind">The function forms also allow the memory-ordering semantics to be specified as an additional function call argument:</p>
      
      <pre id="PLd0e16292" class="calibre5">p.fetch_add(3,std::memory_order_release);</pre>
      
      <p class="noind">Because both <kbd class="calibre17">fetch_add()</kbd> and <kbd class="calibre17">fetch_sub()</kbd> are read-modify-write operations, they can have any of the memory-ordering tags and can participate in a <i class="calibre6">release sequence</i>. Specifying <a id="iddle1033" class="calibre4"></a><a id="iddle1039" class="calibre4"></a><a id="iddle1133" class="calibre4"></a><a id="iddle1219" class="calibre4"></a><a id="iddle1712" class="calibre4"></a><a id="iddle1964" class="calibre4"></a><a id="iddle2575" class="calibre4"></a>the ordering semantics isn’t possible for the operator forms, because there’s no way of providing the information: these forms
         therefore always have <kbd class="calibre17">memory_order_seq_cst</kbd> semantics.
      </p>
      
      <p class="noind">The remaining basic atomic types are all the same: they’re all atomic integral types and have the same interface as each other,
         except that the associated built-in type is different. We’ll look at them as a group.
      </p>
      
      
      
      <h4 id="ch05lev2sec8" class="calibre23">5.2.5. <a id="ch05lev2sec8__title" class="calibre4"></a>Operations on standard atomic integral types
      </h4>
      
      <p class="noind">As well as the usual set of operations (<kbd class="calibre17">load()</kbd>, <kbd class="calibre17">store()</kbd>, <kbd class="calibre17">exchange()</kbd>, <kbd class="calibre17">compare_exchange_weak()</kbd>, and <kbd class="calibre17">compare_exchange_strong()</kbd>), the atomic integral types such as <kbd class="calibre17">std::atomic&lt;int&gt;</kbd> or <kbd class="calibre17">std::atomic&lt;unsigned long long&gt;</kbd> have quite a comprehensive set of operations available: <kbd class="calibre17">fetch_add()</kbd>, <kbd class="calibre17">fetch_sub()</kbd>, <kbd class="calibre17">fetch_and()</kbd>, <kbd class="calibre17">fetch_or()</kbd>, <kbd class="calibre17">fetch_xor()</kbd>, compound-assignment forms of these operations (<kbd class="calibre17">+=</kbd>, <kbd class="calibre17">-=</kbd>, <kbd class="calibre17">&amp;=</kbd>, <kbd class="calibre17">|=</kbd>, and <kbd class="calibre17">^=</kbd>), and pre- and post-increment and decrement (<kbd class="calibre17">++x</kbd>, <kbd class="calibre17">x++</kbd>, --<kbd class="calibre17">x</kbd>, and <kbd class="calibre17">x--</kbd>). It’s not quite the full set of compound-assignment operations you could do on a normal integral type, but it’s close enough:
         only division, multiplication, and shift operators are missing. Because atomic integral values are typically used either as
         counters or as bitmasks, this isn’t a particularly noticeable loss; additional operations can easily be done using <kbd class="calibre17">compare_exchange_weak()</kbd> in a loop, if required.
      </p>
      
      <p class="noind">The semantics closely match those of <kbd class="calibre17">fetch_add()</kbd> and <kbd class="calibre17">fetch_sub()</kbd> for <kbd class="calibre17">std::atomic&lt;T*&gt;</kbd>; the named functions atomically perform their operation and return the <i class="calibre6">old</i> value, whereas the compound-assignment operators return the <i class="calibre6">new</i> value. Pre- and post- increment and decrement work as usual: <kbd class="calibre17">++x</kbd> increments the variable and returns the new value, whereas <kbd class="calibre17">x++</kbd> increments the variable and returns the old value. As you’ll be expecting, the result is a value of the associated integral
         type in both cases.
      </p>
      
      <p class="noind">We’ve now looked at all the basic atomic types; all that remains is the generic <kbd class="calibre17">std::atomic&lt;&gt;</kbd> primary class template rather than the specializations, so let’s look at that next.
      </p>
      
      
      
      <h4 id="ch05lev2sec9" class="calibre23">5.2.6. <a id="ch05lev2sec9__title" class="calibre4"></a>The std::atomic&lt;&gt; primary class template
      </h4>
      
      <p class="noind">The presence of the primary template allows a user to create an atomic variant of a user-defined type, in addition to the
         standard atomic types. Given a user-defined type <kbd class="calibre17">UDT</kbd>, <kbd class="calibre17">std::atomic&lt;UDT&gt;</kbd> provides the same interface as <kbd class="calibre17">std::atomic&lt;bool&gt;</kbd> (as described in <a href="#ch05lev2sec6" class="calibre4">section 5.2.3</a>), except that the <kbd class="calibre17">bool</kbd> parameters and return types that relate to the stored value (rather than the success/failure result of the compare-exchange
         operations) are <kbd class="calibre17">UDT</kbd> instead. You can’t use just any user-defined type with <kbd class="calibre17">std::atomic&lt;&gt;</kbd>, though; the type has to fulfill certain criteria. In order to use <kbd class="calibre17">std::atomic&lt;UDT&gt;</kbd> for some user-defined type <kbd class="calibre17">UDT</kbd>,, this type must have a <i class="calibre6">trivial</i> copy-assignment operator. This means that the type must not have any virtual functions or virtual base classes and must use
         the compiler-generated copy-assignment operator. Not only that, but every base class and non-<kbd class="calibre17">static</kbd> data member of a user-defined type must also have a trivial copy-assignment operator. This permits the compiler to use <a id="iddle1305" class="calibre4"></a><a id="iddle1312" class="calibre4"></a><a id="iddle1583" class="calibre4"></a><kbd class="calibre17">memcpy()</kbd> or an equivalent operation for assignment operations, because there’s no user-written code to run.
      </p>
      
      <p class="noind">Finally, it is worth noting that the compare-exchange operations do bitwise comparison as if using <kbd class="calibre17">memcmp</kbd>, rather than using any comparison operator that may be defined for <kbd class="calibre17">UDT</kbd>. If the type provides comparison operations that have different semantics, or the type has padding bits that do not participate
         in normal comparisons, then this can lead to a compare-exchange operation failing, even though the values compare equally.
      </p>
      
      <p class="noind">The reasoning behind these restrictions goes back to one of the guidelines from <a href="kindle_split_013.html#ch03" class="calibre4">chapter 3</a>: don’t pass pointers and references to protected data outside the scope of the lock by passing them as arguments to user-supplied
         functions. In general, the compiler isn’t going to be able to generate lock-free code for <kbd class="calibre17">std::atomic&lt;UDT&gt;</kbd>, so it will have to use an internal lock for all the operations. If user-supplied copy-assignment or comparison operators
         were permitted, this would require passing a reference to the protected data as an argument to a user-supplied function, violating
         the guideline. Also, the library is entirely at liberty to use a single lock for all atomic operations that need it, and allowing
         user-supplied functions to be called while holding that lock might cause deadlock or cause other threads to block because
         a comparison operation took a long time. Finally, these restrictions increase the chance that the compiler will be able to
         make use of atomic instructions directly for <kbd class="calibre17">std::atomic&lt;UDT&gt;</kbd> (and make a particular instantiation lock-free), because it can treat the user-defined type as a set of raw bytes.
      </p>
      
      <p class="noind">Note that although you can use <kbd class="calibre17">std::atomic&lt;float&gt;</kbd> or <kbd class="calibre17">std::atomic&lt;double&gt;</kbd>, because the built-in floating point types do satisfy the criteria for use with <kbd class="calibre17">memcpy</kbd> and <kbd class="calibre17">memcmp</kbd>, the behavior may be surprising in the case of <kbd class="calibre17">compare_exchange_strong</kbd> (<kbd class="calibre17">compare_exchange_weak</kbd> can always fail for arbitrary internal reasons, as described previously). The operation may fail even though the old stored
         value was equal in value to the comparand, if the stored value had a different representation. Note that there are no atomic
         arithmetic operations on floating-point values. You’ll get similar behavior with <kbd class="calibre17">compare_exchange_strong</kbd> if you use <kbd class="calibre17">std::atomic&lt;&gt;</kbd> with a user-defined type that has an equality-comparison operator defined, and that operator differs from the comparison
         using <kbd class="calibre17">memcmp</kbd>—the operation may fail because the otherwise-equal values have a different representation.
      </p>
      
      <p class="noind">If your <kbd class="calibre17">UDT</kbd> is the same size as (or smaller than) an <kbd class="calibre17">int</kbd> or a <kbd class="calibre17">void*</kbd>, most common platforms will be able to use atomic instructions for <kbd class="calibre17">std::atomic&lt;UDT&gt;</kbd>. Some platforms will also be able to use atomic instructions for user-defined types that are twice the size of an <kbd class="calibre17">int</kbd> or <kbd class="calibre17">void*</kbd>. These platforms are typically those that support a so-called <i class="calibre6">double-word-compare-and-swap (DWCAS)</i> instruction corresponding to the <kbd class="calibre17">compare_exchange_xxx</kbd> functions. As you’ll see in <a href="kindle_split_017.html#ch07" class="calibre4">chapter 7</a>, such support can be helpful when writing lock-free code.
      </p>
      
      <p class="noind">These restrictions mean that you can’t, for example, create <kbd class="calibre17">std::atomic&lt;std:: vector&lt;int&gt;&gt;</kbd> (because it has a non-trivial copy constructor and copy assignment <a id="iddle1026" class="calibre4"></a><a id="iddle1401" class="calibre4"></a>operator), but you can instantiate <kbd class="calibre17">std::atomic&lt;&gt;</kbd> with classes containing counters or flags or pointers or even arrays of simple data elements. This isn’t particularly a problem;
         the more complex the data structure, the more likely you’ll want to do operations on it other than simple assignment and comparison.
         If that’s the case, you’re better off using an <kbd class="calibre17">std::mutex</kbd> to ensure that the data is appropriately protected for the desired operations, as described in <a href="kindle_split_013.html#ch03" class="calibre4">chapter 3</a>.
      </p>
      
      <p class="noind">As already mentioned, when instantiated with a user-defined type <kbd class="calibre17">T</kbd>, the interface of <kbd class="calibre17">std::atomic&lt;T&gt;</kbd> is limited to the set of operations available for <kbd class="calibre17">std::atomic&lt;bool&gt;</kbd>: <kbd class="calibre17">load()</kbd>, <kbd class="calibre17">store()</kbd>, <kbd class="calibre17">exchange()</kbd>, <kbd class="calibre17">compare_exchange_weak()</kbd>, <kbd class="calibre17">compare_exchange_strong()</kbd>, and assignment from and conversion to an instance of type <kbd class="calibre17">T</kbd>.
      </p>
      
      <p class="noind"><a href="#ch05table03" class="calibre4">Table 5.3</a> shows the operations available on each atomic type.
      </p>
      
      <h5 class="notetitle" id="ch05table03">Table 5.3. <a id="ch05table03__title" class="calibre4"></a>The operations available on atomic types
      </h5>
      <table cellspacing="5" frame="hsides" rules="groups" cellpadding="8" width="100%" class="calibre25">
         <colgroup span="6" class="calibre8">
            <col width="100" class="calibre9"/>
            <col width="100" class="calibre9"/>
            <col width="100" class="calibre9"/>
            <col width="100" class="calibre9"/>
            <col width="100" class="calibre9"/>
            <col width="100" class="calibre9"/>
         </colgroup>
         <thead class="calibre26">
            <tr class="calibre11">
               <th class="doctablecell1" scope="col" valign="top">
                  <p class="noind">Operation</p>
               </th>
               <th class="doctablecell1" scope="col" valign="top">
                  <p class="noind">atomic_flag</p>
               </th>
               <th class="doctablecell1" scope="col" valign="top">
                  <p class="noind">atomic&lt;bool&gt;</p>
               </th>
               <th class="doctablecell1" scope="col" valign="top">
                  <p class="noind">atomic&lt;T*&gt;</p>
               </th>
               <th class="doctablecell1" scope="col" valign="top">
                  <p class="noind">atomic&lt;integral-type&gt;</p>
               </th>
               <th class="doctablecell1" scope="col" valign="top">
                  <p class="noind">atomic&lt;other-type&gt;</p>
               </th>
            </tr>
         </thead>
         <tbody class="calibre10">
            <tr class="calibre11">
               <td class="doctablecell">test_and_set</td>
               <td class="doctablecell">Y</td>
               <td class="doctablecell"> </td>
               <td class="doctablecell"> </td>
               <td class="doctablecell"> </td>
               <td class="doctablecell"> </td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">clear</td>
               <td class="doctablecell">Y</td>
               <td class="doctablecell"> </td>
               <td class="doctablecell"> </td>
               <td class="doctablecell"> </td>
               <td class="doctablecell"> </td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">is_lock_free</td>
               <td class="doctablecell"> </td>
               <td class="doctablecell">Y</td>
               <td class="doctablecell">Y</td>
               <td class="doctablecell">Y</td>
               <td class="doctablecell">Y</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">load</td>
               <td class="doctablecell"> </td>
               <td class="doctablecell">Y</td>
               <td class="doctablecell">Y</td>
               <td class="doctablecell">Y</td>
               <td class="doctablecell">Y</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">store</td>
               <td class="doctablecell"> </td>
               <td class="doctablecell">Y</td>
               <td class="doctablecell">Y</td>
               <td class="doctablecell">Y</td>
               <td class="doctablecell">Y</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">exchange</td>
               <td class="doctablecell"> </td>
               <td class="doctablecell">Y</td>
               <td class="doctablecell">Y</td>
               <td class="doctablecell">Y</td>
               <td class="doctablecell">Y</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">compare_exchange_weak, compare_exchange_strong</td>
               <td class="doctablecell"> </td>
               <td class="doctablecell">Y</td>
               <td class="doctablecell">Y</td>
               <td class="doctablecell">Y</td>
               <td class="doctablecell">Y</td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">fetch_add, +=</td>
               <td class="doctablecell"> </td>
               <td class="doctablecell"> </td>
               <td class="doctablecell">Y</td>
               <td class="doctablecell">Y</td>
               <td class="doctablecell"> </td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">fetch_sub, -=</td>
               <td class="doctablecell"> </td>
               <td class="doctablecell"> </td>
               <td class="doctablecell">Y</td>
               <td class="doctablecell">Y</td>
               <td class="doctablecell"> </td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">fetch_or, |=</td>
               <td class="doctablecell"> </td>
               <td class="doctablecell"> </td>
               <td class="doctablecell"> </td>
               <td class="doctablecell">Y</td>
               <td class="doctablecell"> </td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">fetch_and, &amp;=</td>
               <td class="doctablecell"> </td>
               <td class="doctablecell"> </td>
               <td class="doctablecell"> </td>
               <td class="doctablecell">Y</td>
               <td class="doctablecell"> </td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">fetch_xor, ^=</td>
               <td class="doctablecell"> </td>
               <td class="doctablecell"> </td>
               <td class="doctablecell"> </td>
               <td class="doctablecell">Y</td>
               <td class="doctablecell"> </td>
            </tr>
            <tr class="calibre11">
               <td class="doctablecell">++, --</td>
               <td class="doctablecell"> </td>
               <td class="doctablecell"> </td>
               <td class="doctablecell">Y</td>
               <td class="doctablecell">Y</td>
               <td class="doctablecell"> </td>
            </tr>
         </tbody>
      </table>
      
      
      
      <h4 id="ch05lev2sec10" class="calibre23">5.2.7. <a id="ch05lev2sec10__title" class="calibre4"></a>Free functions for atomic operations
      </h4>
      
      <p class="noind">Up until now I’ve limited myself to describing the member function forms of the operations on the atomic types. But there
         are also equivalent nonmember functions for all the operations on the various atomic types. For the most part, the nonmember
         functions are named after the corresponding member functions but with an <kbd class="calibre17">atomic_</kbd> prefix (for example, <kbd class="calibre17">std::atomic_load()</kbd>). These functions are then overloaded for each of the atomic types. Where there’s opportunity for specifying a memory-ordering
         tag, they come in two varieties: one without the tag and one with an <kbd class="calibre17">_explicit</kbd> suffix and an additional parameter or parameters for the memory-ordering tag or tags (for example, <kbd class="calibre17">std::atomic_store(&amp;atomic_var,new_value)</kbd> versus <kbd class="calibre17">std::atomic_store_explicit(&amp;atomic_var,new_value,std::memory_order_release)</kbd>. Whereas the atomic object being referenced by the member functions is implicit, all the free functions take a pointer to
         the atomic object as the first parameter.
      </p>
      
      <p class="noind">For example, <kbd class="calibre17">std::atomic_is_lock_free()</kbd> comes in one variety (though overloaded for each type), and <kbd class="calibre17">std::atomic_is_lock_free(&amp;a)</kbd> returns the same value as <kbd class="calibre17">a.is_lock_free()</kbd> for an object of atomic type <kbd class="calibre17">a</kbd>. Likewise, <kbd class="calibre17">std::atomic_load(&amp;a)</kbd> is the same as <kbd class="calibre17">a.load()</kbd>, but the equivalent <kbd class="calibre17">of a.load(std::memory_order_acquire)</kbd> is <kbd class="calibre17">std::atomic_load_explicit(&amp;a, std::memory_order_acquire)</kbd>.
      </p>
      
      <p class="noind">The free functions are designed to be C-compatible, so they use pointers rather than references in all cases. For example,
         the first parameter of the <kbd class="calibre17">compare_exchange_weak()</kbd> and <kbd class="calibre17">compare_exchange_strong()</kbd> member functions (the expected value) is a reference, whereas the second parameter of <kbd class="calibre17">std::atomic_compare_exchange_weak()</kbd> (the first is the object pointer) is a pointer. <kbd class="calibre17">std::atomic_compare_exchange_weak_explicit()</kbd> also requires both the success and failure memory orders to be specified, whereas the compare-exchange member functions have
         both a single memory order form (with a default of <kbd class="calibre17">std::memory_order_seq_cst</kbd>) and an overload that takes the success and failure memory orders separately.
      </p>
      
      <p class="noind">The operations on <kbd class="calibre17">std::atomic_flag</kbd> buck the trend in that they spell out the <kbd class="calibre17">flag</kbd> part in the names: <kbd class="calibre17">std::atomic_flag_test_and_set()</kbd>, <kbd class="calibre17">std::atomic_flag_clear()</kbd>. The additional variants that specify the memory ordering again have the <kbd class="calibre17">_explicit</kbd> suffix: <kbd class="calibre17">std::atomic_flag_test_and_set_explicit()</kbd> and <kbd class="calibre17">std::atomic_flag_clear_explicit()</kbd>.
      </p>
      
      <p class="noind">The C++ Standard Library also provides free functions for accessing instances of <kbd class="calibre17">std::shared_ptr&lt;&gt;</kbd> in an atomic fashion. This is a break from the principle that only the atomic types support atomic operations, because <kbd class="calibre17">std::shared_ptr&lt;&gt;</kbd> is quite definitely not an atomic type (accessing the same <kbd class="calibre17">std::shared_ptr&lt;T&gt;</kbd> object from multiple threads without using the atomic access functions from all threads, or using suitable other external
         synchronization, is a data race and undefined behavior). But the C++ Standards Committee felt it was sufficiently important
         to provide these extra functions. The atomic operations available are <kbd class="calibre17">load</kbd>, <kbd class="calibre17">store</kbd>, <kbd class="calibre17">exchange</kbd>, and <kbd class="calibre17">compare-exchange</kbd>, which are provided as overloads of the same operations on the standard atomic types, taking an <kbd class="calibre17">std::shared_ptr&lt;&gt;*</kbd> as the first argument:
      </p>
      
      <pre id="PLd0e17154" class="calibre5">std::shared_ptr&lt;my_data&gt; p;
void process_global_data()
{
    std::shared_ptr&lt;my_data&gt; local=std::atomic_load(&amp;p);
    process_data(local);
}
void update_global_data()
{
    std::shared_ptr&lt;my_data&gt; local(new my_data);
    std::atomic_store(&amp;p,local);
}</pre>
      
      <p class="noind"><a id="iddle1320" class="calibre4"></a><a id="iddle1716" class="calibre4"></a><a id="iddle1724" class="calibre4"></a><a id="iddle1954" class="calibre4"></a><a id="iddle2127" class="calibre4"></a><a id="iddle2436" class="calibre4"></a>As with the atomic operations on other types, the <kbd class="calibre17">_explicit</kbd> variants are also provided to allow you to specify the desired memory ordering, and the <kbd class="calibre17">std::atomic_is_lock_free()</kbd> function can be used to check whether the implementation uses locks to ensure the atomicity.
      </p>
      
      <p class="noind">The Concurrency TS also provides <kbd class="calibre17">std::experimental::atomic_shared_ptr&lt;T</kbd>&gt;, which is an atomic type. To use it you must include the <kbd class="calibre17">&lt;experimental/atomic&gt;</kbd> header. It provides the same set of operations as <kbd class="calibre17">std::atomic&lt;UDT</kbd>&gt;: <kbd class="calibre17">load</kbd>, <kbd class="calibre17">store</kbd>, <kbd class="calibre17">exchange</kbd>, <kbd class="calibre17">compare-exchange</kbd>. It is provided as a separate type because that allows for a lock-free implementation that does not impose an additional
         cost on plain <kbd class="calibre17">std::shared_ptr</kbd> instances. But as with the <kbd class="calibre17">std::atomic</kbd> template, you still need to check whether it is lock-free on your platform, which can be tested with the <kbd class="calibre17">is_lock_free</kbd> member function. Even if it is not lock-free, <kbd class="calibre17">std::experimental::atomic_shared_ptr</kbd> is to be recommended over using the atomic free functions on a plain <kbd class="calibre17">std::shared_ptr</kbd>, as it is clearer in your code, ensures that all accesses are atomic, and avoids the potential for data races due to forgetting
         to use the atomic free functions. As with all uses of atomic types and operations, if you are using them for a potential speed
         gain, it is important to profile, and compare with using alternative synchronization mechanisms.
      </p>
      
      <p class="noind">As described in the introduction, the standard atomic types do more than avoid the undefined behavior associated with a data
         race; they allow the user to enforce an ordering of operations between threads. This enforced ordering is the basis of the
         facilities for protecting data and synchronizing operations such as <kbd class="calibre17">std::mutex</kbd> and <kbd class="calibre17">std::future&lt;&gt;</kbd>. With that in mind, let’s move on to the real meat of this chapter: the details of the concurrency aspects of the memory
         model and how atomic operations can be used to synchronize data and enforce ordering.
      </p>
      
      
      
      
      <h3 id="ch05lev1sec3" class="chapter"><a id="ch05lev1sec3__title" class="calibre3"></a>5.3. Synchronizing operations and enforcing ordering
      </h3>
      
      <p class="noind">Suppose you have two threads, one of which is populating a data structure to be read by the second. In order to avoid a problematic
         race condition, the first thread sets a flag to indicate that the data is ready, and the second thread doesn’t read the data
         until the flag is set. The following listing shows such a scenario.
      </p>
      
      
      
      <h5 class="notetitle" id="ch05ex02">Listing 5.2. <a id="ch05ex02__title" class="calibre4"></a>Reading and writing variables from different threads
      </h5>
      <pre id="PLd0e17276" class="calibre5">#include &lt;vector&gt;
#include &lt;atomic&gt;
#include &lt;iostream&gt;
std::vector&lt;int&gt; data;
std::atomic&lt;bool&gt; data_ready(false);
void reader_thread()
{
    while(!data_ready.load())                   <b class="calibre24"><i class="calibre6">1</i></b>
    {
        std::this_thread::sleep(std::chrono::milliseconds(1));
    }
    std::cout&lt;&lt;"The answer="&lt;&lt;data[0]&lt;&lt;"\n";    <b class="calibre24"><i class="calibre6">2</i></b>
}
void writer_thread()
{
    data.push_back(42);                         <b class="calibre24"><i class="calibre6">3</i></b>
    data_ready=true;                            <b class="calibre24"><i class="calibre6">4</i></b>
}</pre>
      
      <p class="noind"><a id="iddle1262" class="calibre4"></a><a id="iddle1719" class="calibre4"></a><a id="iddle2428" class="calibre4"></a><a id="iddle2439" class="calibre4"></a>Setting aside the inefficiency of the loop waiting for the data to be ready <b class="calibre24"><i class="calibre6">1</i></b>, you need this to work, because otherwise sharing data between threads becomes impractical: every item of data is forced
         to be atomic. You’ve already learned that it’s undefined behavior to have non-atomic reads <b class="calibre24"><i class="calibre6">2</i></b> and writes <b class="calibre24"><i class="calibre6">3</i></b> accessing the same data without an enforced ordering, so for this to work there must be an enforced ordering somewhere.
      </p>
      
      <p class="noind">The required enforced ordering comes from the operations on the <kbd class="calibre17">std:: atomic&lt;bool&gt;</kbd> variable, <kbd class="calibre17">data_ready</kbd>;, they provide the necessary ordering by virtue of the memory model relations <i class="calibre6">happens-before</i> and <i class="calibre6">synchronizes-with</i>. The write of the data <b class="calibre24"><i class="calibre6">3</i></b> happens before the write to the <kbd class="calibre17">data_ready</kbd> flag <b class="calibre24"><i class="calibre6">4</i></b>, and the read of the flag <b class="calibre24"><i class="calibre6">1</i></b> happens before the read of the data <b class="calibre24"><i class="calibre6">2</i></b>. When the value read from <kbd class="calibre17">data_ready</kbd> <b class="calibre24"><i class="calibre6">1</i></b> is <kbd class="calibre17">true</kbd>, the write synchronizes with that read, creating a happens-before relationship. Because happens-before is transitive, the
         write to the data <b class="calibre24"><i class="calibre6">3</i></b> happens before the write to the flag <b class="calibre24"><i class="calibre6">4</i></b>, which happens before the read of the <kbd class="calibre17">true</kbd> value from the flag <b class="calibre24"><i class="calibre6">1</i></b>, which happens before the read of the data <b class="calibre24"><i class="calibre6">2</i></b>, and you have an enforced ordering: the write of the data happens before the read of the data and everything is OK. <a href="#ch05fig02" class="calibre4">Figure 5.2</a> shows the important happens-before relationships in the two threads. I’ve added a couple of iterations of the <kbd class="calibre17">while</kbd> loop from the reader thread.
      </p>
      
      
      
      <h5 class="notetitle" id="ch05fig02">Figure 5.2. <a id="ch05fig02__title" class="calibre4"></a>Enforcing an ordering between non-atomic operations using atomic operations
      </h5>
      
      <p class="center1"><img alt="" src="05fig02_alt.jpg" class="calibre2"/></p>
      
      
      <p class="noind">All this might seem fairly intuitive: the operation that writes a value happens before an operation that reads that value.
         With the default atomic operations, that’s indeed true (which is why this is the default), but it does need spelling out:
         the atomic operations also have other options for the ordering requirements, which I’ll come to shortly.
      </p>
      
      <p class="noind">Now that you’ve seen happens-before and synchronizes-with in action, it’s time to look at what they mean. I’ll start with
         synchronizes-with.
      </p>
      
      
      <h4 id="ch05lev2sec11" class="calibre23">5.3.1. <a id="ch05lev2sec11__title" class="calibre4"></a>The synchronizes-with relationship
      </h4>
      
      <p class="noind">The <i class="calibre6">synchronizes-with</i> relationship is something that you can get only between operations on atomic types. Operations on a data structure (such
         as locking a mutex) might provide this relationship if the data structure contains atomic types and the operations on that
         data structure perform the appropriate atomic operations internally, but fundamentally it comes only from operations on atomic
         types.
      </p>
      
      <p class="noind"><a id="iddle1038" class="calibre4"></a>The basic idea is this: a suitably-tagged atomic write operation, <kbd class="calibre17">W</kbd>, on a variable, <kbd class="calibre17">x</kbd>, synchronizes with a suitably-tagged atomic read operation on <kbd class="calibre17">x</kbd> that reads the value stored by either that write, <kbd class="calibre17">W</kbd>, or a subsequent atomic write operation on <kbd class="calibre17">x</kbd> by the same thread that performed the initial write, <kbd class="calibre17">W</kbd>, or a sequence of atomic read-modify-write operations on <kbd class="calibre17">x</kbd> (such as <kbd class="calibre17">fetch_add()</kbd> or <kbd class="calibre17">compare_exchange_weak()</kbd>) by any thread, where the value read by the first thread in the sequence is the value written by <kbd class="calibre17">W</kbd> (see <a href="#ch05lev2sec14" class="calibre4">section 5.3.4</a>).
      </p>
      
      <p class="noind">Leave the “suitably-tagged” part aside for now, because all operations on atomic types are suitably tagged by default. This
         means what you might expect: if thread A stores a value and thread B reads that value, there’s a synchronizes-with relationship
         between the store in thread A and the load in thread B, as in <a href="#ch05ex02" class="calibre4">listing 5.2</a>. This is illustrated in <a href="#ch05fig02" class="calibre4">figure 5.2</a>.
      </p>
      
      <p class="noind">As I’m sure you’ve guessed, the nuances are all in the “suitably-tagged” part. The C++ memory model allows various ordering
         constraints to be applied to the operations on atomic types, and this is the tagging to which I refer. The various options
         for memory ordering and how they relate to the synchronizes-with relationship are covered in <a href="#ch05lev2sec13" class="calibre4">section 5.3.3</a>. First, let’s step back and look at the happens-before relationship.
      </p>
      
      
      
      
      <h4 id="ch05lev2sec12" class="calibre23">5.3.2. <a id="ch05lev2sec12__title" class="calibre4"></a>The happens-before relationship
      </h4>
      
      <p class="noind"><a id="iddle1435" class="calibre4"></a><a id="iddle1441" class="calibre4"></a><a id="iddle1717" class="calibre4"></a><a id="iddle2413" class="calibre4"></a><a id="iddle2437" class="calibre4"></a>The <i class="calibre6">happens-before</i> and <i class="calibre6">strongly-happens-before</i> relationships are the basic building blocks of operation ordering in a program; it specifies which operations see the effects
         of which other operations. For a single thread, it’s largely straightforward: if one operation is sequenced before another,
         then it also happens before it, and strongly-happens-before it. This means that if one operation (A) occurs in a statement
         prior to another (B) in the source code, then A happens before B, and A strongly-happens-before B. You saw that in <a href="#ch05ex02" class="calibre4">listing 5.2</a>: the write to <kbd class="calibre17">data</kbd> <b class="calibre24"><i class="calibre6">3</i></b> happens before the write to <kbd class="calibre17">data_ready</kbd> <b class="calibre24"><i class="calibre6">4</i></b>. If the operations occur in the same statement, in general there’s no happens-before relationship between them, because they’re
         unordered. This is another way of saying that the ordering is unspecified. You know that the program in the following listing
         will output <kbd class="calibre17">"1,2"</kbd> or <kbd class="calibre17">"2,1"</kbd>, but it’s unspecified which, because the order of the two calls to <kbd class="calibre17">get_num()</kbd> is unspecified.
      </p>
      
      
      
      <h5 class="notetitle" id="ch05ex03">Listing 5.3. <a id="ch05ex03__title" class="calibre4"></a>Order of evaluation of arguments to a function call is unspecified
      </h5>
      <pre id="PLd0e17589" class="calibre5">#include &lt;iostream&gt;
void foo(int a,int b)
{
    std::cout&lt;&lt;a&lt;&lt;","&lt;&lt;b&lt;&lt;std::endl;
}
int get_num()
{
    static int i=0;
    return ++i;
}
int main()
{
    foo(get_num(),get_num());   <b class="calibre24"><i class="calibre6">1</i></b>
}</pre>
      
      <p class="calibre19"></p>
      <ul class="calibre21">
         
         <li class="calibre22"><b class="calibre24"><i class="calibre6">1</i> Calls to get_num() are unordered.</b></li>
         
      </ul>
      
      <p class="noind">There are circumstances where operations within a single statement are sequenced, such as where the built-in comma operator
         is used or where the result of one expression is used as an argument to another expression. But in general, operations within
         a single statement are nonsequenced, and there’s no sequenced-before (and thus no happens-before) relationship between them.
         All operations in a statement happen before all of the operations in the next statement.
      </p>
      
      <p class="noind">This is a restatement of the single-threaded sequencing rules you’re used to, so what’s new? The new part is the interaction
         between threads: if operation A on one thread inter-thread happens before operation B on another thread, then A happens before
         B. This doesn’t help much: you’ve added a new relationship (inter-thread happens-before), but this is an important relationship
         when you’re writing multithreaded code.
      </p>
      
      <p class="noind">At the basic level, inter-thread happens-before is relatively simple and relies on the synchronizes-with relationship introduced
         in <a href="#ch05lev2sec11" class="calibre4">section 5.3.1</a>: if operation A in one thread <a id="iddle1007" class="calibre4"></a><a id="iddle1027" class="calibre4"></a><a id="iddle1322" class="calibre4"></a><a id="iddle1594" class="calibre4"></a><a id="iddle1601" class="calibre4"></a><a id="iddle1603" class="calibre4"></a><a id="iddle1605" class="calibre4"></a><a id="iddle1609" class="calibre4"></a><a id="iddle1613" class="calibre4"></a><a id="iddle1616" class="calibre4"></a><a id="iddle1726" class="calibre4"></a><a id="iddle1857" class="calibre4"></a>synchronizes with operation B in another thread, then A inter-thread happens before B. It’s also a transitive relation: if
         A inter-thread happens before B and B inter-thread happens before C, then A inter-thread happens before C. You saw this in
         <a href="#ch05ex02" class="calibre4">listing 5.2</a> as well.
      </p>
      
      <p class="noind">Inter-thread happens-before also combines with the sequenced-before relation: if operation A is sequenced before operation
         B, and operation B inter-thread happens before operation C, then A inter-thread happens before C. Similarly, if A synchronizes
         with B and B is sequenced before C, then A inter-thread happens before C. These two together mean that if you make a series
         of changes to data in a single thread, you need only one synchronizes-with relationship for the data to be visible to subsequent
         operations on the thread that executed C.
      </p>
      
      <p class="noind">The strongly-happens-before relationship is slightly different, but in most cases comes down the same. The same two rules
         described above apply: if operation A synchronizes-with operation B, or operation A is sequenced-before operation B, then
         A strongly-happens-before B. Transitive ordering also applies: if A strongly-happens-before B, and B strongly-happens-before
         C, then A strongly-happens-before C. The difference is that operations tagged with <kbd class="calibre17">memory_order_consume</kbd> (see <a href="#ch05lev2sec13" class="calibre4">section 5.3.3</a>) participate in inter-thread-happens-before relationships (and thus happens-before relationships), but not in strongly-happens-before
         relationships. Since the vast majority of code should not be using <kbd class="calibre17">memory_order_consume</kbd>, this distinction is unlikely to affect you in practice. I will use “happens-before” in the rest of this book for brevity.
      </p>
      
      <p class="noind">These are the crucial rules that enforce the ordering of operations between threads and make everything in <a href="#ch05ex02" class="calibre4">listing 5.2</a> work. There are some additional nuances with data dependency, as you’ll see shortly. In order for you to understand this,
         I need to cover the memory-ordering tags used for atomic operations and how they relate to the synchronizes-with relation.
      </p>
      
      
      
      <h4 id="ch05lev2sec13" class="calibre23">5.3.3. <a id="ch05lev2sec13__title" class="calibre4"></a>Memory ordering for atomic operations
      </h4>
      
      <p class="noind">There are six memory ordering options that can be applied to operations on atomic types: <kbd class="calibre17">memory_order_relaxed</kbd>, <kbd class="calibre17">memory_order_consume</kbd>, <kbd class="calibre17">memory_order_acquire</kbd>, <kbd class="calibre17">memory_order_release</kbd>, <kbd class="calibre17">memory_order_acq_rel</kbd>, and <kbd class="calibre17">memory_order_seq_cst</kbd>. Unless you specify otherwise for a particular operation, the memory-ordering option for all operations on atomic types is
         <kbd class="calibre17">memory_order_seq_cst</kbd>, which is the most stringent of the available options. Although there are six ordering options, they represent three models:
         <i class="calibre6">sequentially consistent</i> ordering (<kbd class="calibre17">memory_order_seq_cst</kbd>), <i class="calibre6">acquire-release</i> ordering (<kbd class="calibre17">memory_order_consume</kbd>, <kbd class="calibre17">memory_order_acquire</kbd>, <kbd class="calibre17">memory_order_release</kbd>, and <kbd class="calibre17">memory_order_acq_rel</kbd>), and <i class="calibre6">relaxed</i> ordering (<kbd class="calibre17">memory_order_relaxed</kbd>).
      </p>
      
      <p class="noind">These distinct memory-ordering models can have varying costs on different CPU architectures. For example, on systems based
         on architectures with fine control over the visibility of operations by processors other than the one that made the change,
         additional synchronization instructions can be required for sequentially consistent ordering over acquire-release ordering
         or relaxed ordering and for acquire-release ordering over relaxed ordering. If these systems have many processors, these additional
         <a id="iddle1032" class="calibre4"></a><a id="iddle1599" class="calibre4"></a><a id="iddle1730" class="calibre4"></a><a id="iddle1892" class="calibre4"></a>synchronization instructions may take a significant amount of time, reducing the overall performance of the system. On the
         other hand, CPUs that use the x86 or x8664 architectures (such as the Intel and AMD processors common in desktop PCs) don’t
         require any additional instructions for acquire-release ordering beyond those necessary for ensuring atomicity, and even sequentially-consistent
         ordering doesn’t require any special treatment for load operations, although there’s a small additional cost on stores.
      </p>
      
      <p class="noind">The availability of the distinct memory-ordering models allows experts to take advantage of the increased performance of the
         more fine-grained ordering relationships where they’re advantageous while allowing the use of the default sequentially-consistent
         ordering (which is considerably easier to reason about than the others) for those cases that are less critical.
      </p>
      
      <p class="noind">In order to choose which ordering model to use, or to understand the ordering relationships in code that uses the different
         models, it’s important to know how the choices affect the program behavior. Let’s therefore look at the consequences of each
         choice for operation ordering and synchronizes-with.
      </p>
      
      
      <h5 class="notetitle" id="ch05lev3sec2"><a id="ch05lev3sec2__title" class="calibre4"></a>Sequentially consistent ordering
      </h5>
      
      <p class="noind">The default ordering is named <i class="calibre6">sequentially consistent</i> because it implies that the behavior of the program is consistent with a simple sequential view of the world. If all operations
         on instances of atomic types are sequentially consistent, the behavior of a multithreaded program is as if all these operations
         were performed in some particular sequence by a single thread. This is by far the easiest memory ordering to understand, which
         is why it’s the default: all threads must see the same order of operations. This makes it easy to reason about the behavior
         of code written with atomic variables. You can write down all the possible sequences of operations by different threads, eliminate
         those that are inconsistent, and verify that your code behaves as expected in the others. It also means that operations can’t
         be reordered; if your code has one operation before another in one thread, that ordering must be seen by all other threads.
      </p>
      
      <p class="noind">From the point of view of synchronization, a sequentially consistent store synchronizes with a sequentially consistent load
         of the same variable that reads the value stored. This provides one ordering constraint on the operation of two (or more)
         threads, but sequential consistency is more powerful than that. Any sequentially consistent atomic operations done after that
         load must also appear after the store to other threads in the system using sequentially consistent atomic operations. The
         example in <a href="#ch05ex04" class="calibre4">listing 5.4</a> demonstrates this ordering constraint in action. This constraint doesn’t carry forward to threads that use atomic operations
         with relaxed memory orderings; they can still see the operations in a different order, so you must use sequentially consistent
         operations on all your threads in order to get the benefit.
      </p>
      
      <p class="noind">This ease of understanding can come at a price, though. On a weakly-ordered machine with many processors, it can impose a
         noticeable performance penalty, because the overall sequence of operations must be kept consistent between the processors,
         possibly requiring extensive (and expensive!) synchronization operations between the processors. That said, some processor
         architectures (such as the common x86 and x86-64 architectures) offer sequential consistency relatively cheaply, so if you’re
         concerned about the performance implications of using sequentially consistent ordering, check the documentation for your target
         processor architectures.
      </p>
      
      <p class="noind">The following listing shows sequential consistency in action. The loads and stores to <kbd class="calibre17">x</kbd> and <kbd class="calibre17">y</kbd> are explicitly tagged with <kbd class="calibre17">memory_order_seq_cst</kbd>, although this tag could be omitted in this case because it’s the default.
      </p>
      
      
      
      <h5 class="notetitle" id="ch05ex04">Listing 5.4. <a id="ch05ex04__title" class="calibre4"></a>Sequential consistency implies a total ordering
      </h5>
      <pre id="PLd0e17859" class="calibre5">#include &lt;atomic&gt;
#include &lt;thread&gt;
#include &lt;assert.h&gt;
std::atomic&lt;bool&gt; x,y;
std::atomic&lt;int&gt; z;
void write_x()
{
    x.store(true,std::memory_order_seq_cst);  <b class="calibre24"><i class="calibre6">1</i></b>
}
void write_y()
{
    y.store(true,std::memory_order_seq_cst);  <b class="calibre24"><i class="calibre6">2</i></b>
}
void read_x_then_y()
{
    while(!x.load(std::memory_order_seq_cst));
    if(y.load(std::memory_order_seq_cst))     <b class="calibre24"><i class="calibre6">3</i></b>
        ++z;
}
void read_y_then_x()
{
    while(!y.load(std::memory_order_seq_cst));
    if(x.load(std::memory_order_seq_cst))     <b class="calibre24"><i class="calibre6">4</i></b>
        ++z;
}
int main()
{
    x=false;
    y=false;
    z=0;
    std::thread a(write_x);
    std::thread b(write_y);
    std::thread c(read_x_then_y);
    std::thread d(read_y_then_x);
    a.join();
    b.join();
    c.join();
    d.join();
    assert(z.load()!=0);                      <b class="calibre24"><i class="calibre6">5</i></b>
}</pre>
      
      <p class="noind">The <kbd class="calibre17">assert</kbd> <b class="calibre24"><i class="calibre6">5</i></b> can never fire, because either the store to <kbd class="calibre17">x</kbd> <b class="calibre24"><i class="calibre6">1</i></b> or the store to <kbd class="calibre17">y</kbd> <b class="calibre24"><i class="calibre6">2</i></b> must happen first, even though it’s not specified which. If the load of <kbd class="calibre17">y</kbd> in <kbd class="calibre17">read_x_then_y</kbd> <b class="calibre24"><i class="calibre6">3</i></b> <a id="iddle1030" class="calibre4"></a><a id="iddle1597" class="calibre4"></a><a id="iddle1617" class="calibre4"></a><a id="iddle1693" class="calibre4"></a>returns <kbd class="calibre17">false</kbd>, the store to <kbd class="calibre17">x</kbd> must occur before the store to <kbd class="calibre17">y</kbd>, in which case the load of <kbd class="calibre17">x</kbd> in <kbd class="calibre17">read_y_then_x</kbd> <b class="calibre24"><i class="calibre6">4</i></b> must return <kbd class="calibre17">true</kbd>, because the <kbd class="calibre17">while</kbd> loop ensures that the <kbd class="calibre17">y</kbd> is <kbd class="calibre17">true</kbd> at this point. Because the semantics of <kbd class="calibre17">memory_order_seq_cst</kbd> require a single total ordering over all operations tagged <kbd class="calibre17">memory_order_seq_cst</kbd>, there’s an implied ordering relationship between a load of <kbd class="calibre17">y</kbd> that returns <kbd class="calibre17">false</kbd> <b class="calibre24"><i class="calibre6">3</i></b> and the store to <kbd class="calibre17">y</kbd> <b class="calibre24"><i class="calibre6">1</i></b>. For there to be a single total order, if one thread sees <kbd class="calibre17">x==true</kbd> and then subsequently sees <kbd class="calibre17">y==false</kbd>, this implies that the store to <kbd class="calibre17">x</kbd> occurs before the store to <kbd class="calibre17">y</kbd> in this total order.
      </p>
      
      <p class="noind">Because everything is symmetrical, it could also happen the other way around, with the load of <kbd class="calibre17">x</kbd> <b class="calibre24"><i class="calibre6">4</i></b> returning <kbd class="calibre17">false</kbd>, forcing the load of <kbd class="calibre17">y</kbd> <b class="calibre24"><i class="calibre6">3</i></b> to return <kbd class="calibre17">true</kbd>. In both cases, <kbd class="calibre17">z</kbd> is equal to 1. Both loads can return <kbd class="calibre17">true</kbd>, leading to <kbd class="calibre17">z</kbd> being 2, but under no circumstances can <kbd class="calibre17">z</kbd> be 0.
      </p>
      
      <p class="noind">The operations and happens-before relationships for the case that <kbd class="calibre17">read_x_then_y</kbd> sees <kbd class="calibre17">x</kbd> as <kbd class="calibre17">true</kbd> and <kbd class="calibre17">y</kbd> as <kbd class="calibre17">false</kbd> are shown in <a href="#ch05fig03" class="calibre4">figure 5.3</a>. The dashed line from the load of <kbd class="calibre17">y</kbd> in <kbd class="calibre17">read_x_then_y</kbd> to the store to <kbd class="calibre17">y</kbd> in <kbd class="calibre17">write_y</kbd> shows the implied ordering relationship required in order to maintain sequential consistency: the load must occur before
         the store in the global order of <kbd class="calibre17">memory_order_seq_cst</kbd> operations in order to achieve the outcomes given here.
      </p>
      
      
      
      <h5 class="notetitle" id="ch05fig03">Figure 5.3. <a id="ch05fig03__title" class="calibre4"></a>Sequential consistency and happens-before
      </h5>
      
      <p class="center1"><img alt="" src="05fig03_alt.jpg" class="calibre2"/></p>
      
      
      <p class="noind">Sequential consistency is the most straightforward and intuitive ordering, but it’s also the most expensive memory ordering
         because it requires global synchronization between all threads. On a multiprocessor system this may require extensive and
         time-consuming communication between processors.
      </p>
      
      <p class="noind">In order to avoid this synchronization cost, you need to step outside the world of sequential consistency and consider using
         other memory orderings.
      </p>
      
      
      
      <h5 class="notetitle" id="ch05lev3sec3"><a id="ch05lev3sec3__title" class="calibre4"></a>Non-sequentially consistent memory orderings
      </h5>
      
      <p class="noind">Once you step outside the nice sequentially-consistent world, things start to get complicated. The single biggest issue to
         get to grips with is probably the fact that <i class="calibre6">there’s no <a id="iddle1031" class="calibre4"></a><a id="iddle1598" class="calibre4"></a><a id="iddle1610" class="calibre4"></a><a id="iddle1729" class="calibre4"></a><a id="iddle1858" class="calibre4"></a>longer a single global order of events</i>. This means that different threads can see different views of the same operations, and any mental model you have of operations
         from different threads neatly interleaved one after the other must be thrown away. Not only do you have to account for things
         happening truly concurrently, but <i class="calibre6">threads don’t have to agree on the order of events</i>. In order to write (or even to understand) any code that uses a memory ordering other than the default <kbd class="calibre17">memory_order_seq_cst</kbd>, it’s absolutely vital to get your head around this. It’s not just that the compiler can reorder the instructions. Even if
         the threads are running the same bit of code, they can disagree on the order of events because of operations in other threads
         in the absence of explicit ordering constraints, because the different CPU caches and internal buffers can hold different
         values for the same memory. It’s so important I’ll say it again: <i class="calibre6">threads don’t have to agree on the order of events</i>.
      </p>
      
      <p class="noind">Not only do you have to throw out mental models based on interleaving operations, you also have to throw out mental models
         based on the idea of the compiler or processor reordering the instructions. <i class="calibre6">In the absence of other ordering constraints, the only requirement is that all threads agree on the modification order of
            each individual variable.</i> Operations on distinct variables can appear in different orders on different threads, provided the values seen are consistent
         with any additional ordering constraints imposed.
      </p>
      
      <p class="noind">This is best demonstrated by stepping completely outside the sequentially consistent world and using <kbd class="calibre17">memory_order_relaxed</kbd> for all operations. Once you’ve come to grips with that, you can move back to acquire-release ordering, which allows you
         to selectively introduce ordering relationships between operations and claw back some of your sanity.
      </p>
      
      
      
      <h5 class="notetitle" id="ch05lev3sec4"><a id="ch05lev3sec4__title" class="calibre4"></a>Relaxed ordering
      </h5>
      
      <p class="noind">Operations on atomic types performed with relaxed ordering don’t participate in synchronizes-with relationships. Operations
         on the same variable within a single thread still obey happens-before relationships, but there’s almost no requirement on
         ordering relative to other threads. The only requirement is that accesses to a single atomic variable from the same thread
         can’t be reordered; once a given thread has seen a particular value of an atomic variable, a subsequent read by that thread
         can’t retrieve an earlier value of the variable. Without any additional synchronization, the modification order of each variable
         is the only thing shared between threads that are using <kbd class="calibre17">memory_order_relaxed</kbd>.
      </p>
      
      <p class="noind">To demonstrate how relaxed your relaxed operations can be, you need only two threads, as shown in the following listing.</p>
      
      
      
      <h5 class="notetitle" id="ch05ex05">Listing 5.5. <a id="ch05ex05__title" class="calibre4"></a>Relaxed operations have few ordering requirements
      </h5>
      <pre id="PLd0e18198" class="calibre5">#include &lt;atomic&gt;
#include &lt;thread&gt;
#include &lt;assert.h&gt;
std::atomic&lt;bool&gt; x,y;
std::atomic&lt;int&gt; z;
void write_x_then_y()
{
    x.store(true,std::memory_order_relaxed);     <b class="calibre24"><i class="calibre6">1</i></b>
    y.store(true,std::memory_order_relaxed);     <b class="calibre24"><i class="calibre6">2</i></b>
}
void read_y_then_x()
{
    while(!y.load(std::memory_order_relaxed));   <b class="calibre24"><i class="calibre6">3</i></b>
    if(x.load(std::memory_order_relaxed))        <b class="calibre24"><i class="calibre6">4</i></b>
        ++z;
}
int main()
{
    x=false;
    y=false;
    z=0;
    std::thread a(write_x_then_y);
    std::thread b(read_y_then_x);
    a.join();
    b.join();
    assert(z.load()!=0);                         <b class="calibre24"><i class="calibre6">5</i></b>
}</pre>
      
      <p class="noind">This time the assert <b class="calibre24"><i class="calibre6">5</i></b> <i class="calibre6">can</i> fire, because the load of <kbd class="calibre17">x</kbd> <b class="calibre24"><i class="calibre6">4</i></b> can read <kbd class="calibre17">false</kbd>, even though the load of <kbd class="calibre17">y</kbd> <b class="calibre24"><i class="calibre6">3</i></b> reads <kbd class="calibre17">true</kbd> and the store of <kbd class="calibre17">x</kbd> <b class="calibre24"><i class="calibre6">1</i></b> happens before the store of <kbd class="calibre17">y</kbd> <b class="calibre24"><i class="calibre6">2</i></b>. <kbd class="calibre17">x</kbd> and <kbd class="calibre17">y</kbd> are different variables, so there are no ordering guarantees relating to the visibility of values arising from operations
         on each.
      </p>
      
      <p class="noind">Relaxed operations on different variables can be freely reordered provided they obey any happens-before relationships they’re
         bound by (for example, within the same thread). They don’t introduce synchronizes-with relationships. The happens-before relationships
         from <a href="#ch05ex05" class="calibre4">listing 5.5</a> are shown in <a href="#ch05fig04" class="calibre4">figure 5.4</a>, along with a possible outcome. Even though there’s a happens-before relationship between the stores and between the loads,
         there isn’t one between either store and either load, and so the loads can see the stores out of order.
      </p>
      
      
      
      <h5 class="notetitle" id="ch05fig04">Figure 5.4. <a id="ch05fig04__title" class="calibre4"></a>Relaxed atomics and happens-before
      </h5>
      
      
      
      <p class="center1"><img alt="" src="05fig04.jpg" class="calibre2"/></p>
      
      
      
      <p class="noind">Let’s look at the slightly more complex example with three variables and five threads in the next listing.</p>
      
      
      
      <h5 class="notetitle" id="ch05ex06">Listing 5.6. <a id="ch05ex06__title" class="calibre4"></a>Relaxed operations on multiple threads
      </h5>
      <pre id="PLd0e18312" class="calibre5">#include &lt;thread&gt;
#include &lt;atomic&gt;
#include &lt;iostream&gt;
std::atomic&lt;int&gt; x(0),y(0),z(0);                            <b class="calibre24"><i class="calibre6">1</i></b>
std::atomic&lt;bool&gt; go(false);                                <b class="calibre24"><i class="calibre6">2</i></b>
unsigned const loop_count=10;
struct read_values
{
    int x,y,z;
};
read_values values1[loop_count];
read_values values2[loop_count];
read_values values3[loop_count];
read_values values4[loop_count];
read_values values5[loop_count];
void increment(std::atomic&lt;int&gt;* var_to_inc,read_values* values)
{
    while(!go)                                              <b class="calibre24"><i class="calibre6">3</i></b>
        std::this_thread::yield();
    for(unsigned i=0;i&lt;loop_count;++i)
    {
        values[i].x=x.load(std::memory_order_relaxed);
        values[i].y=y.load(std::memory_order_relaxed);
        values[i].z=z.load(std::memory_order_relaxed);
        var_to_inc-&gt;store(i+1,std::memory_order_relaxed);   <b class="calibre24"><i class="calibre6">4</i></b>
        std::this_thread::yield();
    }
}
void read_vals(read_values* values)
{
    while(!go)                                              <b class="calibre24"><i class="calibre6">5</i></b>
        std::this_thread::yield();
    for(unsigned i=0;i&lt;loop_count;++i)
    {
        values[i].x=x.load(std::memory_order_relaxed);
        values[i].y=y.load(std::memory_order_relaxed);
        values[i].z=z.load(std::memory_order_relaxed);
        std::this_thread::yield();
    }
}
void print(read_values* v)
{
    for(unsigned i=0;i&lt;loop_count;++i)
    {
        if(i)
            std::cout&lt;&lt;",";
        std::cout&lt;&lt;"("&lt;&lt;v[i].x&lt;&lt;","&lt;&lt;v[i].y&lt;&lt;","&lt;&lt;v[i].z&lt;&lt;")";
    }
    std::cout&lt;&lt;std::endl;
}
int main()
{
    std::thread t1(increment,&amp;x,values1);
    std::thread t2(increment,&amp;y,values2);
    std::thread t3(increment,&amp;z,values3);
    std::thread t4(read_vals,values4);
    std::thread t5(read_vals,values5);
    go=true;                                              <b class="calibre24"><i class="calibre6">6</i></b>
    t5.join();
    t4.join();
    t3.join();
    t2.join();
    t1.join();
    print(values1);                                       <b class="calibre24"><i class="calibre6">7</i></b>
    print(values2);
    print(values3);
    print(values4);
    print(values5);
}</pre>
      
      <p class="calibre19"></p>
      <ul class="calibre21">
         
         <li class="calibre22"><a id="iddle1437" class="calibre4"></a><a id="iddle1611" class="calibre4"></a><b class="calibre24"><i class="calibre6">3</i> Spin, waiting for the signal</b></li>
         
         <li class="calibre22"><b class="calibre24"><i class="calibre6">5</i> Spin, waiting for the signal</b></li>
         
         <li class="calibre22"><b class="calibre24"><i class="calibre6">6</i> Signal to start execution of main loop</b></li>
         
         <li class="calibre22"><b class="calibre24"><i class="calibre6">7</i> Prints the final values</b></li>
         
      </ul>
      
      <p class="noind">This is a simple program. You have three shared global atomic variables <b class="calibre24"><i class="calibre6">1</i></b> and five threads. Each thread loops 10 times, reading the values of the three atomic variables using <kbd class="calibre17">memory_order_relaxed</kbd> and storing them in an array. Three of the threads each update one of the atomic variables each time through the loop <b class="calibre24"><i class="calibre6">4</i></b>, whereas the other two threads read. Once all the threads have been joined, you print the values from the arrays stored by
         each thread <b class="calibre24"><i class="calibre6">7</i></b>.
      </p>
      
      <p class="noind">The <kbd class="calibre17">go atomic variable</kbd> <b class="calibre24"><i class="calibre6">2</i></b> is used to ensure that the threads all start the loop as near to the same time as possible. Launching a thread is an expensive
         operation, and without the explicit delay, the first thread may be finished before the last one has started. Each thread waits
         for <kbd class="calibre17">go</kbd> to become <kbd class="calibre17">true</kbd> before entering the main loop <b class="calibre24"><i class="calibre6">3</i></b> and <b class="calibre24"><i class="calibre6">5</i></b>, and <kbd class="calibre17">go</kbd> is set to <kbd class="calibre17">true</kbd> only once all the threads have started <b class="calibre24"><i class="calibre6">6</i></b>.
      </p>
      
      <p class="noind">One possible output from this program is as follows:</p>
      
      <pre id="PLd0e18444" class="calibre5">(0,0,0),(1,0,0),(2,0,0),(3,0,0),(4,0,0),(5,7,0),(6,7,8),(7,9,8),(8,9,8),
(9,9,10)
(0,0,0),(0,1,0),(0,2,0),(1,3,5),(8,4,5),(8,5,5),(8,6,6),(8,7,9),(10,8,9),
(10,9,10)
(0,0,0),(0,0,1),(0,0,2),(0,0,3),(0,0,4),(0,0,5),(0,0,6),(0,0,7),(0,0,8),
(0,0,9)
(1,3,0),(2,3,0),(2,4,1),(3,6,4),(3,9,5),(5,10,6),(5,10,8),(5,10,10),
(9,10,10),(10,10,10)
(0,0,0),(0,0,0),(0,0,0),(6,3,7),(6,5,7),(7,7,7),(7,8,7),(8,8,7),(8,8,9),
(8,8,9)</pre>
      
      <p class="noind">The first three lines are the threads doing the updating, and the last two are the threads doing the reading. Each triplet
         is a set of the variables <kbd class="calibre17">x</kbd>, <kbd class="calibre17">y</kbd>, and <kbd class="calibre17">z</kbd>, in that order, from one pass through the loop. There are a few things to notice from this output:
      </p>
      
      <p class="calibre19"></p>
      <ul class="calibre21">
         
         <li class="calibre22">The first set of values shows <kbd class="calibre17">x</kbd> increasing by one with each triplet, the second set has <kbd class="calibre17">y</kbd> increasing by one, and the third has <kbd class="calibre17">z</kbd> increasing by one.
         </li>
         
         <li class="calibre22">The <kbd class="calibre17">x</kbd> elements of each triplet only increase within a given set, as do the <kbd class="calibre17">y</kbd> and <kbd class="calibre17">z</kbd> elements, but the increments are uneven, and the relative orderings vary between all threads.
         </li>
         
         <li class="calibre22">Thread 3 doesn’t see any of the updates to <kbd class="calibre17">x</kbd> or <kbd class="calibre17">y</kbd>; it sees only the updates it makes to <kbd class="calibre17">z</kbd>. This doesn’t stop the other threads from seeing the updates to <kbd class="calibre17">z</kbd> mixed in with the updates to <kbd class="calibre17">x</kbd> and <kbd class="calibre17">y</kbd>, though.
         </li>
         
      </ul>
      
      <p class="noind">This is a valid outcome for relaxed operations, but it’s not the only valid outcome. Any set of values that’s consistent with
         the three variables, each holding the values 0 to 10 in turn, and that has the thread incrementing a given variable printing
         the values 0 to 9 for that variable, is valid.
      </p>
      
      
      
      <h5 class="notetitle" id="ch05lev3sec5"><a id="ch05lev3sec5__title" class="calibre4"></a>Understanding relaxed ordering
      </h5>
      
      <p class="noind">To understand how this works, imagine that each variable is a man in a cubicle with a notepad. On his notepad is a list of
         values. You can phone him and ask him to give you a value, or you can tell him to write down a new value. If you tell him
         to write down a new value, he writes it at the bottom of the list. If you ask him for a value, he reads you a number from
         the list.
      </p>
      
      <p class="noind">The first time you talk to this man, if you ask him for a value, he may give you any value from the list he has on his pad
         at the time. If you then ask him for another value, he may give you the same one again or a value from farther down the list.
         He’ll never give you a value from farther up the list. If you tell him to write down a number and then subsequently ask him
         for a value, he’ll give you either the number you told him to write down or a number below that on the list.
      </p>
      
      <p class="noind">Imagine for a moment that his list starts with the values 5, 10, 23, 3, 1, and 2. If you ask for a value, you could get any
         of those. If he gives you 10, then the next time you ask he could give you 10 again, or any of the later ones, but not 5.
         If you call him five times, he could say “10, 10, 1, 2, 2,” for example. If you tell him to write down 42, he’ll add it to
         the end of the list. If you ask him for a number again, he’ll keep telling you “42” until he has another number on his list
         and he feels like telling it to you.
      </p>
      
      <p class="noind">Now, imagine your friend Carl also has this man’s number. Carl can also phone him and either ask him to write down a number
         or ask for one, and he applies the same rules to Carl as he does to you. He has only one phone, so he can only deal with one
         of you at a time, so the list on his pad is a nice straightforward list. But just because you got him to write down a new
         number doesn’t mean he has to tell it to Carl, and vice versa. If Carl asked him for a number and was told “23,” then just
         because you asked the man to write down 42 doesn’t mean he’ll tell that to Carl next time. He may tell Carl any of the numbers
         23, 3, 1, 2, 42, or even the 67 that Fred told <a id="iddle1005" class="calibre4"></a><a id="iddle1028" class="calibre4"></a><a id="iddle1044" class="calibre4"></a><a id="iddle1595" class="calibre4"></a><a id="iddle1721" class="calibre4"></a>him to write down after you called. He could very well tell Carl “23, 3, 3, 1, 67” without being inconsistent with what he
         told you. It’s like he keeps track of which number he told to whom with a little moveable sticky note for each person, like
         in <a href="#ch05fig05" class="calibre4">figure 5.5</a>.
      </p>
      
      
      
      <h5 class="notetitle" id="ch05fig05">Figure 5.5. <a id="ch05fig05__title" class="calibre4"></a>The notebook for the man in the cubicle
      </h5>
      
      
      
      <p class="center1"><img alt="" src="05fig05.jpg" class="calibre2"/></p>
      
      
      
      <p class="noind">Now imagine that there’s not just one man in a cubicle but a whole cubicle farm, with loads of men with phones and notepads.
         These are all our atomic variables. Each variable has its own modification order (the list of values on the pad), but there’s
         no relationship between them at all. If each caller (you, Carl, Anne, Dave, and Fred) is a thread, then this is what you get
         when every operation uses <kbd class="calibre17">memory_order_relaxed</kbd>. There are a few additional things you can tell the man in the cubicle, such as “Write down this number, and tell me what
         was at the bottom of the list” (<kbd class="calibre17">exchange</kbd>) and “Write down <i class="calibre6">this</i> number if the number on the bottom of the list is <i class="calibre6">that</i>; otherwise tell me what I should have guessed” (<kbd class="calibre17">compare_exchange_strong</kbd>), but that doesn’t affect the general principle.
      </p>
      
      <p class="noind">If you think about the program logic from <a href="#ch05ex05" class="calibre4">listing 5.5</a>, then <kbd class="calibre17">write_x_then_y</kbd> is like some guy calling up the man in cubicle <kbd class="calibre17">x</kbd> and telling him to write <kbd class="calibre17">true</kbd>, then calling up the man in cubicle <kbd class="calibre17">y</kbd> and telling <i class="calibre6">him</i> to write <kbd class="calibre17">true</kbd>. The thread running <kbd class="calibre17">read_y_then_x</kbd> repeatedly calls up the man in cubicle <kbd class="calibre17">y</kbd> asking for a value until he says <kbd class="calibre17">true</kbd> and then calls the man in cubicle <kbd class="calibre17">x</kbd> to ask for a value. The man in cubicle <kbd class="calibre17">x</kbd> is under no obligation to tell you any specific value off his list and is quite within his rights to say <kbd class="calibre17">false</kbd>.
      </p>
      
      <p class="noind">This makes relaxed atomic operations difficult to deal with. They must be used in combination with atomic operations that
         feature stronger ordering semantics in order to be useful for inter-thread synchronization. I strongly recommend avoiding
         relaxed atomic operations unless they’re absolutely necessary, and even then using them only with extreme caution. Given the
         unintuitive results that can be achieved with only two threads and two variables in <a href="#ch05ex05" class="calibre4">listing 5.5</a>, it’s not hard to imagine the possible complexity when more threads and more variables are involved.
      </p>
      
      <p class="noind">One way to achieve additional synchronization without the overhead of full-blown sequential consistency is to use <i class="calibre6">acquire-release ordering</i>.
      </p>
      
      
      
      <h5 class="notetitle" id="ch05lev3sec6"><a id="ch05lev3sec6__title" class="calibre4"></a>Acquire-release ordering
      </h5>
      
      <p class="noind">Acquire-release ordering is a step up from relaxed ordering; there’s still no total order of operations, but it does introduce
         some synchronization. Under this ordering model, atomic loads are <i class="calibre6">acquire</i> operations (<kbd class="calibre17">memory_order_acquire</kbd>), atomic stores are <i class="calibre6">release</i> operations (<kbd class="calibre17">memory_order_release</kbd>), and atomic read-modify-write operations (such as <kbd class="calibre17">fetch_add()</kbd> or <kbd class="calibre17">exchange()</kbd>) are either <i class="calibre6">acquire</i>, <i class="calibre6">release</i>, or both (<kbd class="calibre17">memory_order_acq_rel</kbd>). Synchronization is pairwise between the thread that does the release and the thread that does the acquire. <i class="calibre6">A release operation synchronizes-with an acquire operation that reads the value written.</i> This means that different threads can still see different orderings, but these orderings are restricted. The following listing
         is a reworking of <a href="#ch05ex04" class="calibre4">listing 5.4</a> using acquire-release semantics rather than sequentially-consistent ones.
      </p>
      
      
      
      <h5 class="notetitle" id="ch05ex07">Listing 5.7. <a id="ch05ex07__title" class="calibre4"></a>Acquire-release doesn’t imply a total ordering
      </h5>
      <pre id="PLd0e18709" class="calibre5">#include &lt;atomic&gt;
#include &lt;thread&gt;
#include &lt;assert.h&gt;
std::atomic&lt;bool&gt; x,y;
std::atomic&lt;int&gt; z;
void write_x()
{
    x.store(true,std::memory_order_release);
}
void write_y()
{
    y.store(true,std::memory_order_release);
}
void read_x_then_y()
{
    while(!x.load(std::memory_order_acquire));
    if(y.load(std::memory_order_acquire))       <b class="calibre24"><i class="calibre6">1</i></b>
        ++z;
}
void read_y_then_x()
{
    while(!y.load(std::memory_order_acquire));
    if(x.load(std::memory_order_acquire))       <b class="calibre24"><i class="calibre6">2</i></b>
        ++z;
}
int main()
{
    x=false;
    y=false;
    z=0;
    std::thread a(write_x);
    std::thread b(write_y);
    std::thread c(read_x_then_y);
    std::thread d(read_y_then_x);
    a.join();
    b.join();
    c.join();
    d.join();
    assert(z.load()!=0);                        <b class="calibre24"><i class="calibre6">3</i></b>
}</pre>
      
      <p class="noind">In this case the assert <b class="calibre24"><i class="calibre6">3</i></b> <i class="calibre6">can</i> fire (like in the relaxed-ordering case), because it’s possible for both the load of <kbd class="calibre17">x</kbd> <b class="calibre24"><i class="calibre6">2</i></b> and the load of <kbd class="calibre17">y</kbd> <b class="calibre24"><i class="calibre6">1</i></b> to read <kbd class="calibre17">false</kbd>. <kbd class="calibre17">x</kbd> and <kbd class="calibre17">y</kbd> are written by <a id="iddle1604" class="calibre4"></a><a id="iddle1614" class="calibre4"></a>different threads, so the ordering from the release to the acquire in each case has no effect on the operations in the other
         threads.
      </p>
      
      <p class="noind"><a href="#ch05fig06" class="calibre4">Figure 5.6</a> shows the happens-before relationships from <a href="#ch05ex07" class="calibre4">listing 5.7</a>, along with a possible outcome where the two reading threads each have a different view of the world. This is possible because
         there’s no happens-before relationship to force an ordering, as described previously.
      </p>
      
      
      
      <h5 class="notetitle" id="ch05fig06">Figure 5.6. <a id="ch05fig06__title" class="calibre4"></a>Acquire-release and happens-before
      </h5>
      
      <p class="center1"><img alt="" src="05fig06_alt.jpg" class="calibre2"/></p>
      
      
      <p class="noind">In order to see the benefit of acquire-release ordering, you need to consider two stores from the same thread, like in <a href="#ch05ex05" class="calibre4">listing 5.5</a>. If you change the store to <kbd class="calibre17">y</kbd> to use <kbd class="calibre17">memory_order_release</kbd> and the load from <kbd class="calibre17">y</kbd> to use <kbd class="calibre17">memory_order_acquire</kbd> like in the following listing, then you impose an ordering on the operations on <kbd class="calibre17">x</kbd>.
      </p>
      
      
      
      <h5 class="notetitle" id="ch05ex08">Listing 5.8. <a id="ch05ex08__title" class="calibre4"></a>Acquire-release operations can impose ordering on relaxed operations
      </h5>
      <pre id="PLd0e18819" class="calibre5">#include &lt;atomic&gt;
#include &lt;thread&gt;
#include &lt;assert.h&gt;
std::atomic&lt;bool&gt; x,y;
std::atomic&lt;int&gt; z;
void write_x_then_y()
{
    x.store(true,std::memory_order_relaxed);           <b class="calibre24"><i class="calibre6">1</i></b>
    y.store(true,std::memory_order_release);           <b class="calibre24"><i class="calibre6">2</i></b>
}
void read_y_then_x()
{
    while(!y.load(std::memory_order_acquire));         <b class="calibre24"><i class="calibre6">3</i></b>
    if(x.load(std::memory_order_relaxed))              <b class="calibre24"><i class="calibre6">4</i></b>
        ++z;
}
int main()
{
    x=false;
    y=false;
    z=0;
    std::thread a(write_x_then_y);
    std::thread b(read_y_then_x);
    a.join();
    b.join();
    assert(z.load()!=0);                              <b class="calibre24"><i class="calibre6">5</i></b>
}</pre>
      
      <p class="calibre19"></p>
      <ul class="calibre21">
         
         <li class="calibre22"><a id="iddle2663" class="calibre4"></a><b class="calibre24"><i class="calibre6">3</i> Spin, waiting for y to be set to true</b></li>
         
      </ul>
      
      <p class="noind">Eventually, the load from <kbd class="calibre17">y</kbd>, <b class="calibre24"><i class="calibre6">3</i></b> will see <kbd class="calibre17">true</kbd> as written by the store <b class="calibre24"><i class="calibre6">2</i></b>. Because the store uses <kbd class="calibre17">memory_order_release</kbd> and the load uses <kbd class="calibre17">memory_order_acquire</kbd>, the store synchronizes with the load. The store to <kbd class="calibre17">x</kbd> <b class="calibre24"><i class="calibre6">1</i></b> happens before the store to <kbd class="calibre17">y</kbd> <b class="calibre24"><i class="calibre6">2</i></b> because they’re in the same thread. Because the store to <kbd class="calibre17">y</kbd> synchronizes with the load from <kbd class="calibre17">y</kbd>, the store to <kbd class="calibre17">x</kbd> also happens before the load from <kbd class="calibre17">y</kbd> and by extension happens before the load from <kbd class="calibre17">x</kbd> <b class="calibre24"><i class="calibre6">4</i></b>. Thus, the load from <kbd class="calibre17">x</kbd> must read <kbd class="calibre17">true</kbd>, and the assert <b class="calibre24"><i class="calibre6">5</i></b> can’t fire. If the load from <kbd class="calibre17">y</kbd> wasn’t in a <kbd class="calibre17">while</kbd> loop, this wouldn’t necessarily be the case; the load from <kbd class="calibre17">y</kbd> might read <kbd class="calibre17">false</kbd>, in which case there’d be no requirement on the value read from <kbd class="calibre17">x</kbd>. In order to provide any synchronization, acquire and release operations must be paired up. The value stored by a release
         operation must be seen by an acquire operation for either to have any effect. If either the store at <b class="calibre24"><i class="calibre6">2</i></b> or the load at <b class="calibre24"><i class="calibre6">3</i></b> was a relaxed operation, there’d be no ordering on the accesses to <kbd class="calibre17">x</kbd>, so there’d be no guarantee that the load at <b class="calibre24"><i class="calibre6">4</i></b> would read <kbd class="calibre17">true</kbd>, and the <kbd class="calibre17">assert</kbd> could fire.
      </p>
      
      <p class="noind">You can still think about acquire-release ordering in terms of our men with notepads in their cubicles, but you have to add
         more to the model. First, imagine that every store that’s done is part of some batch of updates, so when you call a man to
         tell him to write down a number, you also tell him which batch this update is part of: “Please write down 99, as part of batch
         423.” For the last store in a batch, you tell this to the man too: “Please write down 147, which is the last store in batch
         423.” The man in the cubicle will then duly write down this information, along with who gave him the value. This models a
         store-release operation. The next time you tell someone to write down a value, you increase the batch number: “Please write
         down 41, as part of batch 424.”
      </p>
      
      <p class="noind">When you ask for a value, you now have a choice: you can either ask for a value (which is a relaxed load), in which case the
         man only gives you the number, or you can ask for a value and information about whether it’s the last in a batch (which models
         a load-acquire). If you ask for the batch information, and the value wasn’t the last in a batch, the man will tell you something
         like, “The number is 987, which is a ‘normal’ value,” whereas if it <i class="calibre6">was</i> the last in a batch, he’ll tell you something like “The number is 987, which is the last number in batch 956 from Anne.”
         Now, here’s where the acquire-release semantics kick in: if you tell the man all the batches you know about when you <a id="iddle1008" class="calibre4"></a><a id="iddle1491" class="calibre4"></a><a id="iddle1723" class="calibre4"></a><a id="iddle2441" class="calibre4"></a><a id="iddle2574" class="calibre4"></a>ask for a value, he’ll look down his list for the last value from any of the batches you know about and either give you that
         number or one further down the list.
      </p>
      
      <p class="noind">How does this model acquire-release semantics? Let’s look at our example and see. First off, thread <kbd class="calibre17">a</kbd> is running <kbd class="calibre17">write_x_then_y</kbd> and says to the man in cubicle <kbd class="calibre17">x</kbd>, “Please write <kbd class="calibre17">true</kbd> as part of batch 1 from thread <kbd class="calibre17">a,</kbd>” which he duly writes down. Thread <kbd class="calibre17">a</kbd> then says to the man in cubicle <kbd class="calibre17">y</kbd>, “Please write <kbd class="calibre17">true</kbd> as the last write of batch 1 from thread <kbd class="calibre17">a</kbd>,” which he duly writes down. In the meantime, thread <kbd class="calibre17">b</kbd> is running <kbd class="calibre17">read_y_then_x</kbd>. Thread <kbd class="calibre17">b</kbd> keeps asking the man in box <kbd class="calibre17">y</kbd> for a value with batch information until he says “<kbd class="calibre17">true</kbd>.” It may have to ask many times, but eventually the man will say “<kbd class="calibre17">true</kbd>.” The man in box <kbd class="calibre17">y</kbd> doesn’t <i class="calibre6">only</i> say “<kbd class="calibre17">true</kbd>” though; he also says, “This is the last write in batch 1 from thread <kbd class="calibre17">a</kbd>.”
      </p>
      
      <p class="noind">Now, thread <kbd class="calibre17">b</kbd> goes on to ask the man in box <kbd class="calibre17">x</kbd> for a value, but this time it says, “Please can I have a value, and by the way I know about batch 1 from thread <kbd class="calibre17">a</kbd>.” Now the man from cubicle <kbd class="calibre17">x</kbd> has to look down his list for the last mention of batch 1 from thread <kbd class="calibre17">a</kbd>. The only mention he has is the value <kbd class="calibre17">true</kbd>, which is also the last value on his list, so he <i class="calibre6">must</i> read out that value; otherwise, he’s breaking the rules of the game.
      </p>
      
      <p class="noind">If you look at the definition of inter-thread happens-before back in <a href="#ch05lev2sec12" class="calibre4">section 5.3.2</a>, one of the important properties is that it’s transitive: <i class="calibre6">if A inter-thread happens before B</i> and <i class="calibre6">B inter-thread happens before C</i>, then <i class="calibre6">A inter-thread happens before C</i>. This means that acquire-release ordering can be used to synchronize data across several threads, even when the “intermediate”
         threads haven’t touched the data.
      </p>
      
      
      
      <h5 class="notetitle" id="ch05lev3sec7"><a id="ch05lev3sec7__title" class="calibre4"></a>Transitive synchronization with acquire-release ordering
      </h5>
      
      <p class="noind">In order to think about transitive ordering, you need at least three threads. The first thread modifies some shared variables
         and does a store-release to one of them. A second thread then reads the variable subject to the store-release with a load-acquire
         and performs a store-release on a second shared variable. Finally, a third thread does a load-acquire on that second shared
         variable. Provided that the load-acquire operations see the values written by the store-release operations to ensure the synchronizes-with
         relationships, this third thread can read the values of the other variables stored by the first thread, even if the intermediate
         thread didn’t touch any of them. This scenario is shown in the next listing.
      </p>
      
      
      
      <h5 class="notetitle" id="ch05ex09">Listing 5.9. <a id="ch05ex09__title" class="calibre4"></a>Transitive synchronization using acquire and release ordering
      </h5>
      <pre id="PLd0e19127" class="calibre5">std::atomic&lt;int&gt; data[5];
std::atomic&lt;bool&gt; sync1(false),sync2(false);
void thread_1()
{
    data[0].store(42,std::memory_order_relaxed);
    data[1].store(97,std::memory_order_relaxed);
    data[2].store(17,std::memory_order_relaxed);
    data[3].store(-141,std::memory_order_relaxed);
    data[4].store(2003,std::memory_order_relaxed);
    sync1.store(true,std::memory_order_release);             <b class="calibre24"><i class="calibre6">1</i></b>
}
void thread_2()
{
    while(!sync1.load(std::memory_order_acquire));           <b class="calibre24"><i class="calibre6">2</i></b>
    sync2.store(true,std::memory_order_release);             <b class="calibre24"><i class="calibre6">3</i></b>
}
void thread_3()
{
    while(!sync2.load(std::memory_order_acquire));           <b class="calibre24"><i class="calibre6">4</i></b>
    assert(data[0].load(std::memory_order_relaxed)==42);
    assert(data[1].load(std::memory_order_relaxed)==97);
    assert(data[2].load(std::memory_order_relaxed)==17);
    assert(data[3].load(std::memory_order_relaxed)==-141);
    assert(data[4].load(std::memory_order_relaxed)==2003);
}</pre>
      
      <p class="calibre19"></p>
      <ul class="calibre21">
         
         <li class="calibre22"><a id="iddle1129" class="calibre4"></a><a id="iddle2664" class="calibre4"></a><b class="calibre24"><i class="calibre6">1</i> Set sync1</b></li>
         
         <li class="calibre22"><b class="calibre24"><i class="calibre6">2</i> Loop until sync1 is set</b></li>
         
         <li class="calibre22"><b class="calibre24"><i class="calibre6">3</i> Set sync2</b></li>
         
         <li class="calibre22"><b class="calibre24"><i class="calibre6">4</i> Loop until sync2 is set</b></li>
         
      </ul>
      
      <p class="noind">Even though <kbd class="calibre17">thread_2</kbd> only touches the variables <kbd class="calibre17">sync1</kbd> <b class="calibre24"><i class="calibre6">2</i></b> and <kbd class="calibre17">sync2</kbd> <b class="calibre24"><i class="calibre6">3</i></b>, this is enough for synchronization between <kbd class="calibre17">thread_1</kbd> and <kbd class="calibre17">thread_3</kbd> to ensure that the <kbd class="calibre17">assert</kbd>s don’t fire. First off, the stores to <kbd class="calibre17">data</kbd> from <kbd class="calibre17">thread_1</kbd> happens before the store to <kbd class="calibre17">sync1</kbd> <b class="calibre24"><i class="calibre6">1</i></b> because they’re sequenced before it in the same thread. Because the load from <kbd class="calibre17">sync1</kbd> <b class="calibre24"><i class="calibre6">1</i></b> is in a <kbd class="calibre17">while</kbd> loop, it will eventually see the value stored from <kbd class="calibre17">thread_1</kbd> and form the second half of the release-acquire pair. Therefore, the store to <kbd class="calibre17">sync1</kbd> happens before the final load from <kbd class="calibre17">sync1</kbd> in the <kbd class="calibre17">while</kbd> loop. This load is sequenced before (and thus happens before) the store to <kbd class="calibre17">sync2</kbd> <b class="calibre24"><i class="calibre6">3</i></b>, which forms a release-acquire pair with the final load from the <kbd class="calibre17">while</kbd> loop in <kbd class="calibre17">thread_3</kbd> <b class="calibre24"><i class="calibre6">4</i></b>. The store to <kbd class="calibre17">sync2</kbd> <b class="calibre24"><i class="calibre6">3</i></b> thus happens before the load <b class="calibre24"><i class="calibre6">4</i></b>, which happens before the loads from <kbd class="calibre17">data</kbd>. Because of the transitive nature of happens-before, you can chain it all together: the stores to <kbd class="calibre17">data</kbd> happen before the store to <kbd class="calibre17">sync1</kbd> <b class="calibre24"><i class="calibre6">1</i></b>, which happens before the load from <kbd class="calibre17">sync1</kbd> <b class="calibre24"><i class="calibre6">2</i></b>, which happens before the store to <kbd class="calibre17">sync2</kbd> <b class="calibre24"><i class="calibre6">3</i></b>, which happens before the load from <kbd class="calibre17">sync2</kbd> <b class="calibre24"><i class="calibre6">4</i></b>, which happens before the loads from <kbd class="calibre17">data</kbd>. Thus the stores to <kbd class="calibre17">data</kbd> in <kbd class="calibre17">thread_1</kbd> happen before the loads from <kbd class="calibre17">data</kbd> in <kbd class="calibre17">thread_3</kbd>, and the <kbd class="calibre17">assert</kbd>s can’t fire.
      </p>
      
      <p class="noind">In this case, you could combine <kbd class="calibre17">sync1</kbd> and <kbd class="calibre17">sync2</kbd> into a single variable by using a read-modify-write operation with <kbd class="calibre17">memory_order_acq_rel</kbd> in <kbd class="calibre17">thread_2</kbd>. One option would be to use <kbd class="calibre17">compare_exchange_strong()</kbd> to ensure that the value is updated only once the store from <kbd class="calibre17">thread_1</kbd> has been seen:
      </p>
      
      <pre id="PLd0e19357" class="calibre5">std::atomic&lt;int&gt; sync(0);
void thread_1()
{
    // ...
    sync.store(1,std::memory_order_release);
}
void thread_2()
{
    int expected=1;
    while(!sync.compare_exchange_strong(expected,2,
                                        std::memory_order_acq_rel))
        expected=1;
}
void thread_3()
{
    while(sync.load(std::memory_order_acquire)&lt;2);
    // ...
}</pre>
      
      <p class="noind"><a id="iddle1006" class="calibre4"></a><a id="iddle1029" class="calibre4"></a><a id="iddle1244" class="calibre4"></a><a id="iddle1245" class="calibre4"></a><a id="iddle1596" class="calibre4"></a><a id="iddle1606" class="calibre4"></a><a id="iddle1722" class="calibre4"></a>If you use read-modify-write operations, it’s important to pick which semantics you desire. In this case, you want both acquire
         and release semantics, so <kbd class="calibre17">memory_order_acq_rel</kbd> is appropriate, but you can use other orderings too. A <kbd class="calibre17">fetch_sub</kbd> operation with <kbd class="calibre17">memory_order_acquire</kbd> semantics doesn’t synchronize with anything, even though it stores a value, because it isn’t a release operation. Likewise,
         a store can’t synchronize with a <kbd class="calibre17">fetch_or</kbd> with <kbd class="calibre17">memory_order_release</kbd> semantics, because the read part of the <kbd class="calibre17">fetch_or</kbd> isn’t an acquire operation. Read-modify-write operations with <kbd class="calibre17">memory_order_acq_rel</kbd> semantics behave as both an acquire and a release, so a prior store can synchronize with such an operation, and it can synchronize
         with a subsequent load, as is the case in this example.
      </p>
      
      <p class="noind">If you mix acquire-release operations with sequentially consistent operations, the sequentially consistent loads behave like
         loads with acquire semantics, and sequentially consistent stores behave like stores with release semantics. Sequentially consistent
         read-modify-write operations behave as both acquire and release operations. Relaxed operations are still relaxed but are bound
         by the additional synchronizes-with and consequent happens-before relationships introduced through the use of acquire-release
         semantics.
      </p>
      
      <p class="noind">Despite the potentially non-intuitive outcomes, anyone who’s used locks has had to deal with the same ordering issues: locking
         a mutex is an acquire operation, and unlocking the mutex is a release operation. With mutexes, you learn that you must ensure
         that the same mutex is locked when you read a value as was locked when you wrote it, and the same applies here; your acquire
         and release operations have to be on the same variable to ensure an ordering. If data is protected with a mutex, the exclusive
         nature of the lock means that the result is indistinguishable from what it would have been had the lock and unlock been sequentially
         consistent operations. Similarly, if you use acquire and release orderings on atomic variables to build a simple lock, then
         from the point of view of code that <i class="calibre6">uses</i> the lock, the behavior will appear sequentially consistent, even though the internal operations are not.
      </p>
      
      <p class="noind">If you don’t need the stringency of sequentially consistent ordering for your atomic operations, the pairwise synchronization
         of acquire-release ordering has the potential for a much lower synchronization cost than the global ordering required for
         sequentially consistent operations. The trade-off here is the mental cost required to ensure that the ordering works correctly
         and that the non-intuitive behavior across threads isn’t problematic.
      </p>
      
      
      
      
      <h5 class="notetitle" id="ch05lev3sec8"><a id="ch05lev3sec8__title" class="calibre4"></a>Data dependency with acquire-release ordering and memory_order_consume
      </h5>
      
      <p class="noind"><a id="iddle1098" class="calibre4"></a><a id="iddle1285" class="calibre4"></a>In the introduction to this section I said that <kbd class="calibre17">memory_order_consume</kbd> was part of the acquire-release ordering model, but it was conspicuously absent from the preceding description. This is because
         <kbd class="calibre17">memory_order_consume</kbd> is special: it’s all about data dependencies, and it introduces the data-dependency nuances to the inter-thread happens-before
         relationship mentioned in <a href="#ch05lev2sec12" class="calibre4">section 5.3.2</a>. It is also special in that the C++17 standard explicitly recommends that you do not use it. It is therefore only covered
         here for completeness: you should not use <kbd class="calibre17">memory_order_consume</kbd> in your code!
      </p>
      
      <p class="noind">The concept of a data dependency is relatively straightforward: there is a data dependency between two operations if the second
         one operates on the result of the first. There are two new relations that deal with data dependencies: <i class="calibre6">dependency-ordered-before</i> and <i class="calibre6">carries-a-dependency-to</i>. Like sequenced-before, carries-a-dependency-to applies strictly within a single thread and models the data dependency between
         operations; if the result of an operation (A) is used as an operand for an operation (B), then A carries a dependency to B.
         If the result of operation A is a value of a scalar type such as an <kbd class="calibre17">int</kbd>, then the relationship still applies if the result of A is stored in a variable, and that variable is then used as an operand
         for operation B. This operation is also transitive, so if A carries a dependency to B, and B carries a dependency to C, then
         A carries a dependency to C.
      </p>
      
      <p class="noind">On the other hand, the dependency-ordered-before relationship can apply between threads. It’s introduced by using atomic load
         operations tagged with <kbd class="calibre17">memory_order_consume</kbd>. This is a special case of <kbd class="calibre17">memory_order_acquire</kbd> that limits the synchronized data to direct dependencies; a store operation (A) tagged with <kbd class="calibre17">memory_order_release</kbd>, <kbd class="calibre17">memory_order_acq_rel</kbd>, or <kbd class="calibre17">memory_order_seq_cst</kbd> is dependency-ordered-before a load operation (B) tagged with <kbd class="calibre17">memory_order_consume</kbd> if the consume reads the value stored. This is as opposed to the synchronizes-with relationship you get if the load uses
         <kbd class="calibre17">memory_order_acquire</kbd>. If this operation (B) then carries a dependency to some operation (C), then A is also dependency-ordered-before C.
      </p>
      
      <p class="noind">This wouldn’t do you any good for synchronization purposes if it didn’t affect the inter-thread happens-before relation, but
         it does: if A is dependency-ordered-before B, then A also inter-thread happens-before B.
      </p>
      
      <p class="noind">One important use for this kind of memory ordering is where the atomic operation loads a pointer to some data. By using <kbd class="calibre17">memory_order_consume</kbd> on the load and <kbd class="calibre17">memory_order_release</kbd> on the prior store, you ensure that the pointed-to data is correctly synchronized, without imposing any synchronization requirements
         on any other nondependent data. The following listing shows an example of this scenario.
      </p>
      
      
      
      <h5 class="notetitle" id="ch05ex10">Listing 5.10. <a id="ch05ex10__title" class="calibre4"></a>Using <kbd class="calibre17">std::memory_order_consume</kbd> to synchronize data
      </h5>
      <pre id="PLd0e19551" class="calibre5">struct X
{
    int i;
    std::string s;
};
std::atomic&lt;X*&gt; p;
std::atomic&lt;int&gt; a;
void create_x()
{
    X* x=new X;
    x-&gt;i=42;
    x-&gt;s="hello";
    a.store(99,std::memory_order_relaxed);                     <b class="calibre24"><i class="calibre6">1</i></b>
    p.store(x,std::memory_order_release);                      <b class="calibre24"><i class="calibre6">2</i></b>
}
void use_x()
{
    X* x;
    while(!(x=p.load(std::memory_order_consume)))              <b class="calibre24"><i class="calibre6">3</i></b>
        std::this_thread::sleep(std::chrono::microseconds(1));
    assert(x-&gt;i==42);                                          <b class="calibre24"><i class="calibre6">4</i></b>
    assert(x-&gt;s=="hello");                                     <b class="calibre24"><i class="calibre6">5</i></b>
    assert(a.load(std::memory_order_relaxed)==99);             <b class="calibre24"><i class="calibre6">6</i></b>
}
int main()
{
    std::thread t1(create_x);
    std::thread t2(use_x);
    t1.join();
    t2.join();
}</pre>
      
      <p class="noind"><a id="iddle2164" class="calibre4"></a><a id="iddle2184" class="calibre4"></a>Even though the store to <kbd class="calibre17">a</kbd> <b class="calibre24"><i class="calibre6">1</i></b> is sequenced before the store to <kbd class="calibre17">p</kbd> <b class="calibre24"><i class="calibre6">2</i></b>, and the store to <kbd class="calibre17">p</kbd> is tagged <kbd class="calibre17">memory_order_release</kbd>, the load of <kbd class="calibre17">p</kbd> <b class="calibre24"><i class="calibre6">3</i></b> is tagged <kbd class="calibre17">memory_order_consume</kbd>. This means that the store to <kbd class="calibre17">p</kbd> only happens before those expressions that are dependent on the value loaded from <kbd class="calibre17">p</kbd>. This means that the asserts on the data members of the <kbd class="calibre17">X</kbd> structure (<b class="calibre24"><i class="calibre6">4</i></b> and <b class="calibre24"><i class="calibre6">5</i></b>) are guaranteed not to fire, because the load of <kbd class="calibre17">p</kbd> carries a dependency to those expressions through the variable <kbd class="calibre17">x</kbd>. On the other hand, the assert on the value of <kbd class="calibre17">a</kbd> <b class="calibre24"><i class="calibre6">6</i></b> may or may not fire; this operation isn’t dependent on the value loaded from <kbd class="calibre17">p</kbd>, and so there’s no guarantee on the value that’s read. This is particularly apparent because it’s tagged with <kbd class="calibre17">memory_order_relaxed</kbd>, as you’ll see.
      </p>
      
      <p class="noind">Sometimes, you don’t want the overhead of carrying the dependency around. You want the compiler to be able to cache values
         in registers and reorder operations to optimize the code rather than fussing about the dependencies. In these scenarios, you
         can use <kbd class="calibre17">std::kill_dependency()</kbd> to explicitly break the dependency chain. <kbd class="calibre17">std:: kill_dependency()</kbd> is a simple function template that copies the supplied argument to the return value but breaks the dependency chain in doing
         so. For example, if you have a global read-only array, and you use <kbd class="calibre17">std::memory_order_consume</kbd> when retrieving an index into that array from another thread, you can use <kbd class="calibre17">std::kill_dependency()</kbd> to let the compiler know that it doesn’t need to reread the contents of the array entry, as in the following example:
      </p>
      
      <pre id="PLd0e19677" class="calibre5">int global_data[]={ ... };
std::atomic&lt;int&gt; index;
void f()
{
    int i=index.load(std::memory_order_consume);
    do_something_with(global_data[std::kill_dependency(i)]);
}</pre>
      
      <p class="noind"><a id="iddle1325" class="calibre4"></a><a id="iddle1718" class="calibre4"></a><a id="iddle1727" class="calibre4"></a><a id="iddle1860" class="calibre4"></a><a id="iddle2429" class="calibre4"></a><a id="iddle2438" class="calibre4"></a>In real code, you should always use <kbd class="calibre17">memory_order_acquire</kbd> where you might be tempted to use <kbd class="calibre17">memory_order_consume</kbd>, and <kbd class="calibre17">std::kill_dependency</kbd> is unnecessary.
      </p>
      
      <p class="noind">Now that I’ve covered the basics of the memory orderings, it’s time to look at the more complex parts of the synchronizes-with
         relation, which manifest in the form of <i class="calibre6">release sequences</i>.
      </p>
      
      
      
      
      <h4 id="ch05lev2sec14" class="calibre23">5.3.4. <a id="ch05lev2sec14__title" class="calibre4"></a>Release sequences and synchronizes-with
      </h4>
      
      <p class="noind">Back in <a href="#ch05lev2sec11" class="calibre4">section 5.3.1</a>, I mentioned that you could get a synchronizes-with relationship between a store to an atomic variable and a load of that
         atomic variable from another thread, even when there’s a sequence of read-modify-write operations between the store and the
         load, provided all the operations are suitably tagged. Now that I’ve covered the possible memory-ordering “tags,” I can elaborate
         on this. If the store is tagged with <kbd class="calibre17">memory_order_release</kbd>, <kbd class="calibre17">memory_order_acq_rel</kbd>, or <kbd class="calibre17">memory_order_seq_cst</kbd>, and the load is tagged with <kbd class="calibre17">memory_order_consume</kbd>, <kbd class="calibre17">memory_order_acquire</kbd>, or <kbd class="calibre17">memory_order_seq_cst</kbd>, and each operation in the chain loads the value written by the previous operation, then the chain of operations constitutes
         a <i class="calibre6">release sequence</i> and the initial store synchronizes with (for <kbd class="calibre17">memory_order_acquire</kbd> or <kbd class="calibre17">memory_order_seq_cst</kbd>) or is dependency-ordered-before (for <kbd class="calibre17">memory_order_consume</kbd>) the final load. Any atomic read-modify-write operations in the chain can have <i class="calibre6">any</i> memory ordering (even <kbd class="calibre17">memory_order_relaxed</kbd>).
      </p>
      
      <p class="noind">To see what this means and why it’s important, consider <kbd class="calibre17">atomic&lt;int&gt;</kbd> being used as a <kbd class="calibre17">count</kbd> of the number of items in a shared queue, as in the following listing.
      </p>
      
      
      
      <h5 class="notetitle" id="ch05ex11">Listing 5.11. <a id="ch05ex11__title" class="calibre4"></a>Reading values from a queue with atomic operations
      </h5>
      <pre id="PLd0e19818" class="calibre5">#include &lt;atomic&gt;
#include &lt;thread&gt;
std::vector&lt;int&gt; queue_data;
std::atomic&lt;int&gt; count;
void populate_queue()
{
    unsigned const number_of_items=20;
    queue_data.clear();
    for(unsigned i=0;i&lt;number_of_items;++i)
    {
        queue_data.push_back(i);
    }

    count.store(number_of_items,std::memory_order_release);               <b class="calibre24"><i class="calibre6">1</i></b>
}
void consume_queue_items()
{
    while(true)
    {
        int item_index;
        if((item_index=count.fetch_sub(1,std::memory_order_acquire))&lt;=0)  <b class="calibre24"><i class="calibre6">2</i></b>
        {
            wait_for_more_items();                                        <b class="calibre24"><i class="calibre6">3</i></b>
            continue;
        }
        process(queue_data[item_index-1]);                                <b class="calibre24"><i class="calibre6">4</i></b>
    }
}
int main()
{
    std::thread a(populate_queue);
    std::thread b(consume_queue_items);
    std::thread c(consume_queue_items);
    a.join();
    b.join();
    c.join();
}</pre>
      
      <p class="calibre19"></p>
      <ul class="calibre21">
         
         <li class="calibre22"><a id="iddle1366" class="calibre4"></a><a id="iddle2412" class="calibre4"></a><b class="calibre24"><i class="calibre6">1</i> The initial store</b></li>
         
         <li class="calibre22"><b class="calibre24"><i class="calibre6">2</i> An RMW operation</b></li>
         
         <li class="calibre22"><b class="calibre24"><i class="calibre6">3</i> Wait for more items.</b></li>
         
         <li class="calibre22"><b class="calibre24"><i class="calibre6">4</i> Reading queue_data is safe.</b></li>
         
      </ul>
      
      <p class="noind">One way to handle things would be to have the thread that’s producing the data store the items in a shared buffer and then
         do <kbd class="calibre17">count.store(number_of_items, memory_order_release)</kbd> <b class="calibre24"><i class="calibre6">1</i></b> to let the other threads know that data is available. The threads consuming the queue items might then do <kbd class="calibre17">count.fetch_sub(1,memory_order_acquire)</kbd> <b class="calibre24"><i class="calibre6">2</i></b> to claim an item from the queue, prior to reading the shared buffer <b class="calibre24"><i class="calibre6">4</i></b>. Once the <kbd class="calibre17">count</kbd> becomes zero, there are no more items, and the thread must wait <b class="calibre24"><i class="calibre6">3</i></b>.
      </p>
      
      <p class="noind">If there’s one consumer thread, this is fine; <kbd class="calibre17">fetch_sub()</kbd> is a read with <kbd class="calibre17">memory_order_acquire</kbd> semantics, and the store had <kbd class="calibre17">memory_order_release</kbd> semantics, so the store synchronizes with the load and the thread can read the item from the buffer. If there are two threads
         reading, the second <kbd class="calibre17">fetch_sub()</kbd> will see the value written by the first and not the value written by the <kbd class="calibre17">store</kbd>. Without the rule about the release sequence, this second thread wouldn’t have a happens-before relationship with the first
         thread, and it wouldn’t be safe to read the shared buffer unless the first <kbd class="calibre17">fetch_sub()</kbd> also had <kbd class="calibre17">memory_order_release</kbd> semantics, which would introduce unnecessary synchronization between the two consumer threads. Without the release sequence
         rule or <kbd class="calibre17">memory_order_release</kbd> on the <kbd class="calibre17">fetch_sub</kbd> operations, there would be nothing to require that the stores to the <kbd class="calibre17">queue_data</kbd> were visible to the second consumer, and you would have a data race. Thankfully, the first <kbd class="calibre17">fetch_sub()</kbd> <i class="calibre6">does</i> participate in the release sequence, and so the <kbd class="calibre17">store()</kbd> synchronizes with the second <kbd class="calibre17">fetch_sub()</kbd>. There’s still no synchronizes-with relationship between the two consumer threads. This is shown in <a href="#ch05fig07" class="calibre4">figure 5.7</a>. The dotted lines in <a href="#ch05fig07" class="calibre4">figure 5.7</a> show the release sequence, and the solid lines show the happens-before relationships.
      </p>
      
      
      <p class="noind"></p>
      
      
      <h5 class="notetitle" id="ch05fig07">Figure 5.7. <a id="ch05fig07__title" class="calibre4"></a>The release sequence for the queue operations from <a href="#ch05ex11" class="calibre4">listing 5.11</a></h5>
      
      <p class="center1"><img alt="" src="05fig07_alt.jpg" class="calibre2"/></p>
      
      
      <p class="noind"><a id="iddle1321" class="calibre4"></a><a id="iddle1360" class="calibre4"></a><a id="iddle1586" class="calibre4"></a><a id="iddle1725" class="calibre4"></a>There can be any number of links in the chain, but provided they’re all read-modify-write operations such as <kbd class="calibre17">fetch_sub()</kbd>, the <kbd class="calibre17">store()</kbd> will still synchronize with each one that’s tagged <kbd class="calibre17">memory_order_acquire</kbd>. In this example, all the links are the same, and all are acquire operations, but they could be a mix of different operations
         with different memory-ordering semantics.
      </p>
      
      <p class="noind">Although most of the synchronization relationships come from the memory-ordering semantics applied to operations on atomic
         variables, it’s also possible to introduce additional ordering constraints by using <i class="calibre6">fences</i>.
      </p>
      
      
      
      <h4 id="ch05lev2sec15" class="calibre23">5.3.5. <a id="ch05lev2sec15__title" class="calibre4"></a>Fences
      </h4>
      
      <p class="noind">An atomic operations library wouldn’t be complete without a set of fences. These are operations that enforce memory-ordering
         constraints without modifying any data and are typically combined with atomic operations that use the <kbd class="calibre17">memory_order_relaxed</kbd> ordering constraints. Fences are global operations and affect the ordering of other atomic operations in the thread that
         executed the fence. Fences are also commonly called <i class="calibre6">memory barriers</i>, and they get their name because they put a line in the code that certain operations can’t cross. As you may recall from
         <a href="#ch05lev2sec13" class="calibre4">section 5.3.3</a>, relaxed operations on separate variables can usually be freely reordered by the compiler or the hardware. Fences restrict
         this freedom and introduce happens-before and synchronizes-with relationships that weren’t present before.
      </p>
      
      <p class="noind">Let’s start by adding a fence between the two atomic operations on each thread in <a href="#ch05ex05" class="calibre4">listing 5.5</a>, as shown in the following listing.
      </p>
      
      
      <p class="noind"></p>
      
      
      <h5 class="notetitle" id="ch05ex12">Listing 5.12. <a id="ch05ex12__title" class="calibre4"></a>Relaxed operations can be ordered with fences
      </h5>
      <pre id="PLd0e20053" class="calibre5">#include &lt;atomic&gt;
#include &lt;thread&gt;
#include &lt;assert.h&gt;
std::atomic&lt;bool&gt; x,y;
std::atomic&lt;int&gt; z;
void write_x_then_y()
{
    x.store(true,std::memory_order_relaxed);               <b class="calibre24"><i class="calibre6">1</i></b>
    std::atomic_thread_fence(std::memory_order_release);   <b class="calibre24"><i class="calibre6">2</i></b>
    y.store(true,std::memory_order_relaxed);               <b class="calibre24"><i class="calibre6">3</i></b>
}
void read_y_then_x()
{
    while(!y.load(std::memory_order_relaxed));             <b class="calibre24"><i class="calibre6">4</i></b>
    std::atomic_thread_fence(std::memory_order_acquire);   <b class="calibre24"><i class="calibre6">5</i></b>
    if(x.load(std::memory_order_relaxed))                  <b class="calibre24"><i class="calibre6">6</i></b>
        ++z;
}
int main()
{
    x=false;
    y=false;
    z=0;
    std::thread a(write_x_then_y);
    std::thread b(read_y_then_x);
    a.join();
    b.join();
    assert(z.load()!=0);                                   <b class="calibre24"><i class="calibre6">7</i></b>
}</pre>
      
      <p class="noind">The release fence <b class="calibre24"><i class="calibre6">2</i></b> synchronizes with the acquire fence <b class="calibre24"><i class="calibre6">5</i></b> because the load from <kbd class="calibre17">y</kbd> at <b class="calibre24"><i class="calibre6">4</i></b> reads the value stored at <b class="calibre24"><i class="calibre6">3</i></b>. This means that the store to <kbd class="calibre17">x</kbd> at <b class="calibre24"><i class="calibre6">1</i></b> happens before the load from <kbd class="calibre17">x</kbd> at <b class="calibre24"><i class="calibre6">6</i></b>, so the value read must be <kbd class="calibre17">true</kbd> and the assert at <b class="calibre24"><i class="calibre6">7</i></b> won’t fire. This is in contrast to the original case without the fences where the store to and load from <kbd class="calibre17">x</kbd> weren’t ordered, and so the assert could fire. Note that both fences are necessary: you need a release in one thread and
         an acquire in another to get a synchronizes-with relationship.
      </p>
      
      <p class="noind">In this case, the release fence <b class="calibre24"><i class="calibre6">2</i></b> has the same effect as if the store to <kbd class="calibre17">y</kbd> <b class="calibre24"><i class="calibre6">3</i></b> was tagged with <kbd class="calibre17">memory_order_release</kbd> rather than <kbd class="calibre17">memory_order_relaxed</kbd>. Likewise, the acquire fence <b class="calibre24"><i class="calibre6">5</i></b> makes it as if the load from <kbd class="calibre17">y</kbd> <b class="calibre24"><i class="calibre6">4</i></b> was tagged with <kbd class="calibre17">memory_order_acquire</kbd>. This is the general idea with fences: if an acquire operation sees the result of a store that takes place after a release
         fence, the fence synchronizes with that acquire operation; and if a load that takes place before an acquire fence sees the
         result of a release operation, the release operation synchronizes with the acquire fence. You can have fences on both sides,
         as in the example here, in which case if a load that takes place before the acquire fence sees a value written by a store
         that takes place after the release fence, the release fence synchronizes with the acquire fence.
      </p>
      
      <p class="noind"><a id="iddle1057" class="calibre4"></a><a id="iddle1324" class="calibre4"></a><a id="iddle1687" class="calibre4"></a><a id="iddle1711" class="calibre4"></a><a id="iddle1728" class="calibre4"></a>Although the fence synchronization depends on the values read or written by operations before or after the fence, it’s important
         to note that the synchronization point is the fence itself. If you take <kbd class="calibre17">write_x_then_y</kbd> from <a href="#ch05ex12" class="calibre4">listing 5.12</a> and move the write to <kbd class="calibre17">x</kbd> after the fence as follows, the condition in the assert is no longer guaranteed to be true, even though the write to <kbd class="calibre17">x</kbd> comes before the write to <kbd class="calibre17">y</kbd>:
      </p>
      
      <pre id="PLd0e20224" class="calibre5">void write_x_then_y()
{
    std::atomic_thread_fence(std::memory_order_release);
    x.store(true,std::memory_order_relaxed);
    y.store(true,std::memory_order_relaxed);
}</pre>
      
      <p class="noind">These two operations are no longer separated by the fence and so are no longer ordered. It’s only when the fence comes <i class="calibre6">between</i> the store to <kbd class="calibre17">x</kbd> and the store to <kbd class="calibre17">y</kbd> that it imposes an ordering. The presence or absence of a fence doesn’t affect any enforced orderings on happens-before relationships
         that exist because of other atomic operations.
      </p>
      
      <p class="noind">This example, and almost every other example so far in this chapter, is built entirely from variables with an atomic type.
         But the real benefit of using atomic operations to enforce an ordering is that they can enforce an ordering on non-atomic
         operations and avoid the undefined behavior of a data race, as you saw back in <a href="#ch05ex02" class="calibre4">listing 5.2</a>.
      </p>
      
      
      
      <h4 id="ch05lev2sec16" class="calibre23">5.3.6. <a id="ch05lev2sec16__title" class="calibre4"></a>Ordering non-atomic operations with atomics
      </h4>
      
      <p class="noind">If you replace <kbd class="calibre17">x</kbd> from <a href="#ch05ex12" class="calibre4">listing 5.12</a> with an ordinary non-atomic <kbd class="calibre17">bool</kbd> (as in the following listing), the behavior is guaranteed to be the same.
      </p>
      
      
      
      <h5 class="notetitle" id="ch05ex13">Listing 5.13. <a id="ch05ex13__title" class="calibre4"></a>Enforcing ordering on non-atomic operations
      </h5>
      <pre id="PLd0e20271" class="calibre5">#include &lt;atomic&gt;
#include &lt;thread&gt;
#include &lt;assert.h&gt;
bool x=false;                                               <b class="calibre24"><i class="calibre6">1</i></b>
std::atomic&lt;bool&gt; y;
std::atomic&lt;int&gt; z;
void write_x_then_y()
{
    x=true;                                                 <b class="calibre24"><i class="calibre6">2</i></b>
    std::atomic_thread_fence(std::memory_order_release);
    y.store(true,std::memory_order_relaxed);                <b class="calibre24"><i class="calibre6">3</i></b>
}
void read_y_then_x()
{
    while(!y.load(std::memory_order_relaxed));              <b class="calibre24"><i class="calibre6">4</i></b>
    std::atomic_thread_fence(std::memory_order_acquire);
    if(x)                                                   <b class="calibre24"><i class="calibre6">5</i></b>
        ++z;
}
int main()
{
    x=false;
    y=false;
    z=0;
    std::thread a(write_x_then_y);
    std::thread b(read_y_then_x);
    a.join();
    b.join();
    assert(z.load()!=0);                                    <b class="calibre24"><i class="calibre6">6</i></b>
}</pre>
      
      <p class="calibre19"></p>
      <ul class="calibre21">
         
         <li class="calibre22"><a id="iddle1323" class="calibre4"></a><a id="iddle1382" class="calibre4"></a><a id="iddle1383" class="calibre4"></a><a id="iddle1520" class="calibre4"></a><a id="iddle1710" class="calibre4"></a><a id="iddle2602" class="calibre4"></a><b class="calibre24"><i class="calibre6">1</i> x is now a plain non-atomic variable.</b></li>
         
         <li class="calibre22"><b class="calibre24"><i class="calibre6">2</i> Store to x before the fence</b></li>
         
         <li class="calibre22"><b class="calibre24"><i class="calibre6">3</i> Store to y after the fence</b></li>
         
         <li class="calibre22"><b class="calibre24"><i class="calibre6">4</i> Wait until you see the write from <b class="calibre24"><i class="calibre6">2</i></b>.</b></li>
         
         <li class="calibre22"><b class="calibre24"><i class="calibre6">5</i> This will read the value written by <b class="calibre24"><i class="calibre6">1</i></b>.</b></li>
         
         <li class="calibre22"><b class="calibre24"><i class="calibre6">6</i> This assert won’t fire.</b></li>
         
      </ul>
      
      <p class="noind">The fences still provide an enforced ordering of the store to <kbd class="calibre17">x</kbd> <b class="calibre24"><i class="calibre6">1</i></b> and the store to <kbd class="calibre17">y</kbd> <b class="calibre24"><i class="calibre6">2</i></b>, and the load from <kbd class="calibre17">y</kbd> <b class="calibre24"><i class="calibre6">3</i></b> and the load from <kbd class="calibre17">x</kbd> <b class="calibre24"><i class="calibre6">5</i></b>, and there’s still a happens-before relationship between the store to <kbd class="calibre17">x</kbd> and the load from <kbd class="calibre17">x</kbd>, so the assert <b class="calibre24"><i class="calibre6">6</i></b> still won’t fire. The store to <b class="calibre24"><i class="calibre6">2</i></b> and load from <kbd class="calibre17">y</kbd> <b class="calibre24"><i class="calibre6">3</i></b> still have to be atomic; otherwise, there would be a data race on <kbd class="calibre17">y</kbd>, but the fences enforce an ordering on the operations on <kbd class="calibre17">x</kbd>, once the reading thread has seen the stored value of <kbd class="calibre17">y</kbd>. This enforced ordering means that there’s no data race on <kbd class="calibre17">x</kbd>, even though it’s modified by one thread and read by another.
      </p>
      
      <p class="noind">It’s not only fences that can order non-atomic operations. You saw the ordering effects back in <a href="#ch05ex10" class="calibre4">listing 5.10</a> with a <kbd class="calibre17">memory_order_release</kbd>/<kbd class="calibre17">memory_order_consume</kbd> pair ordering non-atomic accesses to a dynamically allocated object, and many of the examples in this chapter could be rewritten
         with some of the <kbd class="calibre17">memory_order_relaxed</kbd> operations replaced with plain non-atomic operations instead.
      </p>
      
      
      
      <h4 id="ch05lev2sec17" class="calibre23">5.3.7. <a id="ch05lev2sec17__title" class="calibre4"></a>Ordering non-atomic operations
      </h4>
      
      <p class="noind">Ordering of non-atomic operations through the use of atomic operations is where the sequenced-before part of happens-before
         becomes so important. If a non-atomic operation is sequenced before an atomic operation, and that atomic operation happens
         before an operation in another thread, the non-atomic operation also happens before that operation in the other thread. This
         is where the ordering of the operations on <kbd class="calibre17">x</kbd> in <a href="#ch05ex13" class="calibre4">listing 5.13</a> comes from and why the example in <a href="#ch05ex02" class="calibre4">listing 5.2</a> works. This is also the basis for the higher-level synchronization facilities in the C++ Standard Library, such as mutexes
         and condition variables. To see how this works, consider the simple spinlock mutex from <a href="#ch05ex01" class="calibre4">listing 5.1</a>.
      </p>
      
      <p class="noind">The <kbd class="calibre17">lock()</kbd> operation is a loop on <kbd class="calibre17">flag.test_and_set()</kbd> using <kbd class="calibre17">std::memory_order_acquire</kbd> ordering, and the <kbd class="calibre17">unlock()</kbd> is a call to <kbd class="calibre17">flag.clear()</kbd> with <kbd class="calibre17">std::memory_order_release</kbd> ordering. When the first thread calls <kbd class="calibre17">lock()</kbd>, the flag is initially clear, <a id="iddle1916" class="calibre4"></a><a id="iddle2150" class="calibre4"></a><a id="iddle2193" class="calibre4"></a><a id="iddle2251" class="calibre4"></a><a id="iddle2259" class="calibre4"></a><a id="iddle2280" class="calibre4"></a><a id="iddle2311" class="calibre4"></a>so the first call to <kbd class="calibre17">test_and_set()</kbd> will set the flag and return <kbd class="calibre17">false</kbd>, indicating that this thread now has the lock, and terminating the loop. The thread is then free to modify any data protected
         by the mutex. Any other thread that calls <kbd class="calibre17">lock()</kbd> at this time will find the flag already set and will be blocked in the <kbd class="calibre17">test_and_set()</kbd> loop.
      </p>
      
      <p class="noind">When the thread with the lock has finished modifying the protected data, it calls <kbd class="calibre17">unlock()</kbd>, which calls <kbd class="calibre17">flag.clear()</kbd> with <kbd class="calibre17">std::memory_order_release</kbd> semantics. This then synchronizes (see <a href="#ch05lev2sec11" class="calibre4">section 5.3.1</a>) with a subsequent call to <kbd class="calibre17">flag.test_and_set()</kbd> from an invocation of <kbd class="calibre17">lock()</kbd> on another thread, because this call has <kbd class="calibre17">std::memory_order_acquire</kbd> semantics. Because the modification of the protected data is necessarily sequenced before the <kbd class="calibre17">unlock()</kbd> call, this modification happens before the <kbd class="calibre17">unlock()</kbd> and thus happens before the subsequent <kbd class="calibre17">lock()</kbd> call from the second thread (because of the synchronizes with relationship between the <kbd class="calibre17">unlock()</kbd> and the <kbd class="calibre17">lock()</kbd>) and happens before any accesses to that data from this second thread once it has acquired the lock.
      </p>
      
      <p class="noind">Although other mutex implementations will have different internal operations, the basic principle is the same: <kbd class="calibre17">lock()</kbd> is an acquire operation on an internal memory location, and <kbd class="calibre17">unlock()</kbd> is a release operation on that same memory location.
      </p>
      
      <p class="noind">Each of the synchronization mechanisms described in <a href="kindle_split_012.html#ch02" class="calibre4">chapters 2</a>, <a href="kindle_split_013.html#ch03" class="calibre4">3</a>, and <a href="kindle_split_014.html#ch04" class="calibre4">4</a> will provide ordering guarantees in terms of the synchronizes-with relationship. This is what enables you to use them to
         synchronize your data, and provide ordering guarantees. The following are the synchronization relationships provided by these
         facilities:
      </p>
      
      
      <h5 class="notetitle" id="ch05lev3sec9"><a id="ch05lev3sec9__title" class="calibre4"></a><kbd class="calibre17">std::thread</kbd></h5>
      
      <p class="calibre19"></p>
      <ul class="calibre21">
         
         <li class="calibre22">The completion of the <kbd class="calibre17">std::thread</kbd> constructor synchronizes with the invocation of the supplied function or callable object on the new thread.
         </li>
         
         <li class="calibre22">The completion of a thread synchronizes with the return from a successful call to <kbd class="calibre17">join</kbd> on the <kbd class="calibre17">std::thread</kbd> object that owns that thread.
         </li>
         
      </ul>
      
      
      
      <h5 class="notetitle" id="ch05lev3sec10"><a id="ch05lev3sec10__title" class="calibre4"></a><kbd class="calibre17">std::mutex</kbd>, <kbd class="calibre17">std::timed_mutex</kbd>, <kbd class="calibre17">std::recursive_mutex</kbd>, <kbd class="calibre17">std::recursive_timed_mutex</kbd></h5>
      
      <p class="calibre19"></p>
      <ul class="calibre21">
         
         <li class="calibre22">All calls to <kbd class="calibre17">lock</kbd> and <kbd class="calibre17">unlock</kbd>, and successful calls to <kbd class="calibre17">try_lock</kbd>, <kbd class="calibre17">try_lock_for</kbd>, or <kbd class="calibre17">try_lock_until</kbd>, on a given <i class="calibre6">mutex</i> object form a single total order: the <i class="calibre6">lock order</i> of the mutex.
         </li>
         
         <li class="calibre22">A call to <kbd class="calibre17">unlock</kbd> on a given mutex object synchronizes with a subsequent call to <kbd class="calibre17">lock</kbd>, or a subsequent successful call to <kbd class="calibre17">try_lock</kbd>, <kbd class="calibre17">try_lock_for</kbd>, or <kbd class="calibre17">try_lock_until</kbd>, on that object in the lock order of the mutex.
         </li>
         
         <li class="calibre22">Failed calls to <kbd class="calibre17">try_lock</kbd>, <kbd class="calibre17">try_lock_for</kbd>, or <kbd class="calibre17">try_lock_until</kbd> do not participate in any synchronization relationships.
         </li>
         
      </ul>
      
      
      
      <h5 class="notetitle" id="ch05lev3sec11"><a id="ch05lev3sec11__title" class="calibre4"></a><kbd class="calibre17">std::shared_mutex</kbd>, <kbd class="calibre17">std::shared_timed_mutex</kbd></h5>
      
      <p class="calibre19"></p>
      <ul class="calibre21">
         
         <li class="calibre22">All calls to <kbd class="calibre17">lock</kbd>, <kbd class="calibre17">unlock</kbd>, <kbd class="calibre17">lock_shared</kbd>, and <kbd class="calibre17">unlock_shared,</kbd> and successful calls to <kbd class="calibre17">try_lock</kbd>, <kbd class="calibre17">try_lock_for</kbd>, <kbd class="calibre17">try_lock_until</kbd>, <kbd class="calibre17">try_lock_shared</kbd>, <kbd class="calibre17">try_lock_shared_for</kbd>, or <kbd class="calibre17">try_lock_shared_until</kbd>, on a given mutex object form a single total order: the lock order of the mutex.
         </li>
         
         <li class="calibre22"><a id="iddle1945" class="calibre4"></a><a id="iddle2137" class="calibre4"></a><a id="iddle2139" class="calibre4"></a><a id="iddle2141" class="calibre4"></a><a id="iddle2211" class="calibre4"></a>A call to <kbd class="calibre17">unlock</kbd> on a given mutex object synchronizes with a subsequent call to <kbd class="calibre17">lock</kbd> or <kbd class="calibre17">shared_lock</kbd>, or a successful call to <kbd class="calibre17">try_lock</kbd>, <kbd class="calibre17">try_lock_for</kbd>, <kbd class="calibre17">try_lock_until</kbd>, <kbd class="calibre17">try_lock_shared</kbd>, <kbd class="calibre17">try_lock_shared_for</kbd>, or <kbd class="calibre17">try_lock_shared_until</kbd>, on that object in the lock order of the mutex.
         </li>
         
         <li class="calibre22">Failed calls to <kbd class="calibre17">try_lock</kbd>, <kbd class="calibre17">try_lock_for</kbd>, <kbd class="calibre17">try_lock_until</kbd>, <kbd class="calibre17">try_lock_shared</kbd>, <kbd class="calibre17">try_lock_shared_for</kbd>, or <kbd class="calibre17">try_lock_shared_until</kbd> do not participate in any synchronization relationships.
         </li>
         
      </ul>
      
      
      
      <h5 class="notetitle" id="ch05lev3sec12"><a id="ch05lev3sec12__title" class="calibre4"></a><kbd class="calibre17">std::promise</kbd>, <kbd class="calibre17">std::future</kbd> and <kbd class="calibre17">std::shared_future</kbd></h5>
      
      <p class="calibre19"></p>
      <ul class="calibre21">
         
         <li class="calibre22">The successful completion of a call to <kbd class="calibre17">set_value</kbd> or <kbd class="calibre17">set_exception</kbd> on a given <kbd class="calibre17">std::promise</kbd> object synchronizes with a successful return from a call to <kbd class="calibre17">wait</kbd> or <kbd class="calibre17">get</kbd>, or a call to <kbd class="calibre17">wait_for</kbd> or <kbd class="calibre17">wait_until</kbd> that returns <kbd class="calibre17">std::future_status:: ready</kbd> on a future that shares the same asynchronous state as the promise.
         </li>
         
         <li class="calibre22">The destructor of a given <kbd class="calibre17">std::promise</kbd> object that stores an <kbd class="calibre17">std::future_error</kbd> exception in the shared asynchronous state associated with the promise synchronizes with a successful return from a call
            to <kbd class="calibre17">wait</kbd> or <kbd class="calibre17">get</kbd>, or a call to <kbd class="calibre17">wait_for</kbd> or <kbd class="calibre17">wait_until</kbd> that returns <kbd class="calibre17">std::future_status::ready</kbd> on a future that shares the same asynchronous state as the promise.
         </li>
         
      </ul>
      
      
      
      <h5 class="notetitle" id="ch05lev3sec13"><a id="ch05lev3sec13__title" class="calibre4"></a><kbd class="calibre17">std::packaged_task</kbd>, <kbd class="calibre17">std::future</kbd> and <kbd class="calibre17">std::shared_future</kbd></h5>
      
      <p class="calibre19"></p>
      <ul class="calibre21">
         
         <li class="calibre22">The successful completion of a call to the function call operator of a given <kbd class="calibre17">std::packaged_task</kbd> object synchronizes with a successful return from a call to <kbd class="calibre17">wait</kbd> or <kbd class="calibre17">get</kbd>, or a call to <kbd class="calibre17">wait_for</kbd> or <kbd class="calibre17">wait_until</kbd> that returns <kbd class="calibre17">std::future_status::ready</kbd> on a future that shares the same asynchronous state as the packaged task.
         </li>
         
         <li class="calibre22">The destructor of a given <kbd class="calibre17">std::packaged_task</kbd> object that stores an <kbd class="calibre17">std:: future_error</kbd> exception in the shared asynchronous state associated with the packaged task synchronizes with a successful return from a
            call to <kbd class="calibre17">wait</kbd> or <kbd class="calibre17">get</kbd>, or a call to <kbd class="calibre17">wait_for</kbd> or <kbd class="calibre17">wait_until</kbd> that returns <kbd class="calibre17">std::future_status::ready</kbd> on a future that shares the same asynchronous state as the packaged task.
         </li>
         
      </ul>
      
      
      
      <h5 class="notetitle" id="ch05lev3sec14"><a id="ch05lev3sec14__title" class="calibre4"></a><kbd class="calibre17">std::async</kbd>, <kbd class="calibre17">std::future</kbd> and <kbd class="calibre17">std::shared_future</kbd></h5>
      
      <p class="calibre19"></p>
      <ul class="calibre21">
         
         <li class="calibre22">The completion of the thread running a task launched via a call to <kbd class="calibre17">std::async</kbd> with a policy of <kbd class="calibre17">std::launch::async</kbd> synchronizes with a successful return from a call to <kbd class="calibre17">wait</kbd> or <kbd class="calibre17">get</kbd>, or a call to <kbd class="calibre17">wait_for</kbd> or <kbd class="calibre17">wait_until</kbd> that returns <kbd class="calibre17">std::future_status::ready</kbd> on a future that shares the same asynchronous state as the spawned task.
         </li>
         
         <li class="calibre22">The completion of a task launched via a call to <kbd class="calibre17">std::async</kbd> with a policy of <kbd class="calibre17">std::launch::deferred</kbd> synchronizes with a successful return from a call to <kbd class="calibre17">wait</kbd> or <kbd class="calibre17">get</kbd>, or a call to <kbd class="calibre17">wait_for</kbd> or <kbd class="calibre17">wait_until</kbd> that returns <kbd class="calibre17">std::future_status::ready</kbd> on a future that shares the same asynchronous state as the promise.
         </li>
         
      </ul>
      
      
      
      
      <h5 class="notetitle" id="ch05lev3sec15"><a id="ch05lev3sec15__title" class="calibre4"></a><kbd class="calibre17">std::experimental::future</kbd>, <kbd class="calibre17">std::experimental::shared_future</kbd> and continuations
      </h5>
      
      <p class="calibre19"></p>
      <ul class="calibre21">
         
         <li class="calibre22"><a id="iddle1191" class="calibre4"></a><a id="iddle2099" class="calibre4"></a><a id="iddle2111" class="calibre4"></a><a id="iddle2128" class="calibre4"></a><a id="iddle2131" class="calibre4"></a><a id="iddle2134" class="calibre4"></a>The event that causes an asynchronous shared state to become ready synchronizes with the invocation of a continuation function
            scheduled on that shared state.
         </li>
         
         <li class="calibre22">The completion of a continuation function synchronizes with a successful return from a call to <kbd class="calibre17">wait</kbd> or <kbd class="calibre17">get</kbd>, or a call to <kbd class="calibre17">wait_for</kbd> or <kbd class="calibre17">wait_until</kbd> that returns <kbd class="calibre17">std::future_status::ready</kbd> on a future that shares the same asynchronous state as the future returned from the call to <kbd class="calibre17">then</kbd> that scheduled the continuation, or the invocation of any continuation scheduled on that future.
         </li>
         
      </ul>
      
      
      
      <h5 class="notetitle" id="ch05lev3sec16"><a id="ch05lev3sec16__title" class="calibre4"></a><kbd class="calibre17">std::experimental::latch</kbd></h5>
      
      <p class="calibre19"></p>
      <ul class="calibre21">
         
         <li class="calibre22">The invocation of each call to <kbd class="calibre17">count_down</kbd> or <kbd class="calibre17">count_down_and_wait</kbd> on a given instance of <kbd class="calibre17">std::experimental::latch</kbd> synchronizes with the completion of each successful call to <kbd class="calibre17">wait</kbd> or <kbd class="calibre17">count_down_and_wait</kbd> on that latch.
         </li>
         
      </ul>
      
      
      
      <h5 class="notetitle" id="ch05lev3sec17"><a id="ch05lev3sec17__title" class="calibre4"></a><kbd class="calibre17">std::experimental::barrier</kbd></h5>
      
      <p class="calibre19"></p>
      <ul class="calibre21">
         
         <li class="calibre22">The invocation of each call to <kbd class="calibre17">arrive_and_wait</kbd> or <kbd class="calibre17">arrive_and_drop</kbd> on a given instance of <kbd class="calibre17">std::experimental::barrier</kbd> synchronizes with the completion of each subsequent successful call to <kbd class="calibre17">arrive_and_wait</kbd> on that barrier.
         </li>
         
      </ul>
      
      
      
      <h5 class="notetitle" id="ch05lev3sec18"><a id="ch05lev3sec18__title" class="calibre4"></a><kbd class="calibre17">std::experimental::flex_barrier</kbd></h5>
      
      <p class="calibre19"></p>
      <ul class="calibre21">
         
         <li class="calibre22">The invocation of each call to <kbd class="calibre17">arrive_and_wait</kbd> or <kbd class="calibre17">arrive_and_drop</kbd> on a given instance of <kbd class="calibre17">std::experimental::flex_barrier</kbd> synchronizes with the completion of each subsequent successful call to <kbd class="calibre17">arrive_and_wait</kbd> on that barrier.
         </li>
         
         <li class="calibre22">The invocation of each call to <kbd class="calibre17">arrive_and_wait</kbd> or <kbd class="calibre17">arrive_and_drop</kbd> on a given instance of <kbd class="calibre17">std::experimental::flex_barrier</kbd> synchronizes with the subsequent invocation of the completion function on that barrier.
         </li>
         
         <li class="calibre22">The return from the completion function on a given instance of <kbd class="calibre17">std:: experimental::flex_barrier</kbd> synchronizes with the completion of each call to <kbd class="calibre17">arrive_and_wait</kbd> on that barrier that was blocked waiting for that barrier when the completion function was invoked.
         </li>
         
      </ul>
      
      
      
      <h5 class="notetitle" id="ch05lev3sec19"><a id="ch05lev3sec19__title" class="calibre4"></a><kbd class="calibre17">std::condition_variable</kbd> and <kbd class="calibre17">std::condition_variable_any</kbd></h5>
      
      <p class="calibre19"></p>
      <ul class="calibre21">
         
         <li class="calibre22">Condition variables do not provide any synchronization relationships. They are optimizations over busy-wait loops, and all
            the synchronization is provided by the operations on the associated mutex.
         </li>
         
      </ul>
      
      
      
      
      
      <h3 id="ch05lev1sec4" class="chapter"><a id="ch05lev1sec4__title" class="calibre3"></a>Summary
      </h3>
      
      <p class="noind">In this chapter I’ve covered the low-level details of the C++ memory model and the atomic operations that provide the basis
         for synchronization between threads. This includes the basic atomic types provided by specializations of the <kbd class="calibre17">std::atomic&lt;&gt;</kbd> class template as well as the generic atomic interface provided by the primary <kbd class="calibre17">std::atomic&lt;&gt;</kbd> template and the <kbd class="calibre17">std::experimental::atomic_shared_ptr&lt;&gt;</kbd> template, the operations on these types, and the complex details of the various memory-ordering options.
      </p>
      
      <p class="noind">We’ve also looked at fences and how they can be paired with operations on atomic types to enforce an ordering. Finally, we’ve
         come back to the beginning with a look at how the atomic operations can be used to enforce an ordering between non-atomic
         operations on separate threads, and the synchronization relationships provided by the higher-level facilities.
      </p>
      
      <p class="noind">In the next chapter we’ll look at using the high-level synchronization facilities alongside atomic operations to design efficient
         containers for concurrent access, and we’ll write algorithms that process data in parallel.
      </p>
      
      
      
      
      <div class="calibre13" id="calibre_pb_22"></div>
</body></html>
