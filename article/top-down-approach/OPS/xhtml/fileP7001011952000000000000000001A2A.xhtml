<?xml version="1.0" encoding="utf-8"?><html xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:svg="http://www.w3.org/2000/svg" xmlns:epub="http://www.idpf.org/2007/ops" xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" epub:prefix="index: http://www.index.com/"><head>
<meta name="dcterms.conformsTo" content="PXE Basic 1.0"></meta>
<meta name="generator" content="PXE Tools version 1.39.109"></meta>
<!--Created by pxe.pl for standard version PXE Basic 1.0,data-profile-product=standard by PXE Tools 1.39.109, partial=false-->
<title>4.2 What’s Inside a Router?</title><link rel="alternate stylesheet" type="text/css" title="sepia" href="../css/sepia.css"></link><link rel="alternate stylesheet" type="text/css" title="night" href="../css/night.css"></link><link rel="stylesheet" type="text/css" title="day" href="../css/main.css"></link><link rel="stylesheet" type="text/css" title="day" href="../css/print.css"></link>
<script src="js/format_lg_obj.js"></script>
</head><body epub:type="bodymatter">
<section id="P7001011952000000000000000001A2A" class="level1"><header><h1 class="title" id="P700101195200000000000000000A7BE" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7BE" epub:type="title"><span class="number">4.2</span> What’s Inside a Router?</h1></header>
<p id="P700101195200000000000000000A7BF" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7BF">Now that we’ve overviewed the data and control planes within the network layer, the important distinction between forwarding and routing, and the services and functions of the network layer, let’s turn our attention to its forwarding function—the actual transfer of packets from a router’s incoming links to the appropriate outgoing links at that router.</p>
<p id="P700101195200000000000000000A7C0" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7C0">A high-level view of a generic router architecture is shown in <a class="xref" href="#P7001011952000000000000000001A2E" data-foobar="1"><span class="label">Figure</span> <span class="number">4.4</span></a>. Four router components can be identified:</p>
<figure id="P7001011952000000000000000001A2E" class="figure" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001A2E">
<img alt="Illustration of router architecture." height="366" width="766" aria-describedby="P7001011952000000000000000001A32" id="P700101195200000000000000000A7C1" data-uri="P7001011952000000000000000005584" src="../images/4055104004.png"></img>
<figcaption id="P700101195200000000000000000A7C2" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7C2"><header><h1 class="title" id="P700101195200000000000000000A7C3" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7C3" epub:type="title"><span class="label">Figure </span><span class="number">4.4</span> Router architecture</h1></header>

</figcaption>
</figure><div class="longdesc" id="P7001011952000000000000000001A32" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001A32" aria-hidden="false"><a class="xref" aria-hidden="false" href="../longalt/la_4055104004.xhtml#la_4055104004"><span class="label">Description</span></a></div>
<ul id="P700101195200000000000000000A7C5" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7C5">
<li id="P700101195200000000000000000A7C6" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7C6"><p id="P700101195200000000000000000A7C7" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7C7"><span class="pagebreak" title="314" id="P7001011952000000000000000001A37" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001A37" epub:type="pagebreak" role="doc-pagebreak"></span><span class="leadin">Input ports.</span> An <span class="keyword" id="P7001011952000000000000000001A38" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001A38"><b>input port</b></span> performs several key functions. It performs the physical layer function of terminating an incoming physical link at a router; this is shown in the leftmost box of an input port and the rightmost box of an output port in <a class="xref" href="#P7001011952000000000000000001A2E" data-foobar="1"><span class="label">Figure</span> <span class="number">4.4</span></a>. An input port also performs link-layer functions needed to interoperate with the link layer at the other side of the incoming link; this is represented by the middle boxes in the input and output ports. Perhaps most crucially, a lookup function is also performed at the input port; this will occur in the rightmost box of the input port. It is here that the forwarding table is consulted to determine the router output port to which an arriving packet will be forwarded via the switching fabric. Control packets (for example, packets carrying routing protocol information) are forwarded from an input port to the routing processor. Note that the term “port” here—referring to the physical input and output router interfaces—is distinctly different from the software ports associated with network applications and sockets discussed in <a class="xref" href="fileP700101195200000000000000000096B.xhtml#P700101195200000000000000000096B" data-foobar="7"><span class="label">Chapters</span> <span class="number">2</span></a> and <a class="xref" href="fileP70010119520000000000000000010EC.xhtml#P70010119520000000000000000010EC" data-foobar="7"><span class="number">3</span></a>. In practice, the number of ports supported by a router can range from a relatively small number in enterprise routers, to hundreds of 10 Gbps ports in a router at an ISP’s edge, where the number of incoming lines tends to be the greatest. The Juniper MX2020, edge router, for example, supports up to 960 10 Gbps Ethernet ports, with an overall router system capacity of 80 Tbps <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P70010119520000000000000000039C9" data-foobar="7">[Juniper MX 2020 2016]</a>.</p></li>
<li id="P700101195200000000000000000A7C8" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7C8"><p id="P700101195200000000000000000A7C9" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7C9"><span class="leadin">Switching fabric.</span> The switching fabric connects the router’s input ports to its output ports. This switching fabric is completely contained within the router—a network inside of a network router!</p></li>
<li id="P700101195200000000000000000A7CA" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7CA"><p id="P700101195200000000000000000A7CB" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7CB"><span class="leadin">Output ports.</span> An <span class="keyword" id="P7001011952000000000000000001A3D" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001A3D"><b>output port</b></span> stores packets received from the switching fabric and transmits these packets on the outgoing link by performing the necessary link-layer and physical-layer functions. When a link is bidirectional (that is, carries traffic in both directions), an output port will typically be paired with the input port for that link on the same line card.</p></li>
<li id="P700101195200000000000000000A7CC" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7CC"><p id="P700101195200000000000000000A7CD" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7CD"><span class="leadin">Routing processor.</span> The routing processor performs control-plane functions. In traditional routers, it executes the routing protocols (which we’ll study in <a class="xref" href="fileP7001011952000000000000000002092.xhtml#P7001011952000000000000000002092" data-foobar="7"><span class="label">Sections</span> <span class="number">5.3</span></a> and <a class="xref" href="fileP70010119520000000000000000020BA.xhtml#P70010119520000000000000000020BA" data-foobar="7"><span class="number">5.4</span></a>), maintains routing tables and attached link state information, and computes the forwarding table for the router. In SDN routers, the routing processor is responsible for communicating with the remote controller in order to (among other activities) receive forwarding table entries computed by the remote controller, and install these entries in the router’s input ports. The routing processor also performs the network management functions that we’ll study in <a class="xref" href="fileP7001011952000000000000000002202.xhtml#P7001011952000000000000000002202" data-foobar="7"><span class="label">Section</span> <span class="number">5.7</span></a>.</p></li>
</ul>
<p id="P700101195200000000000000000A7CE" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7CE">A router’s input ports, output ports, and switching fabric are almost always implemented in hardware, as shown in <a class="xref" href="#P7001011952000000000000000001A2E" data-foobar="1"><span class="label">Figure</span> <span class="number">4.4</span></a>. To appreciate why a hardware implementation is needed, consider that with a 10 Gbps input link and a 64-byte IP datagram, the input port has only 51.2 ns to process the datagram before another datagram may arrive. If <i>N</i> ports are combined on a line card (as is often done in practice), the datagram-processing pipeline must operate <i>N</i> times faster—far too <span class="pagebreak" title="315" id="P7001011952000000000000000001A41" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001A41" epub:type="pagebreak" role="doc-pagebreak"></span>fast for software implementation. Forwarding hardware can be implemented either using a router vendor’s own hardware designs, or constructed using purchased merchant-silicon chips (e.g., as sold by companies such as Intel and Broadcom).</p>
<p id="P700101195200000000000000000A7CF" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7CF">While the data plane operates at the nanosecond time scale, a router’s control functions—executing the routing protocols, responding to attached links that go up or down, communicating with the remote controller (in the SDN case) and performing management functions—operate at the millisecond or second timescale. These <span class="keyword" id="P7001011952000000000000000001A43" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001A43"><b>control plane</b></span> functions are thus usually implemented in software and execute on the routing processor (typically a traditional CPU).</p>
<p id="P700101195200000000000000000A7D0" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7D0">Before delving into the details of router internals, let’s return to our analogy from the beginning of this chapter, where packet forwarding was compared to cars entering and leaving an interchange. Let’s suppose that the interchange is a roundabout, and that as a car enters the roundabout, a bit of processing is required. Let’s consider what information is required for this processing:</p>
<ul id="P700101195200000000000000000A7D1" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7D1">
<li id="P700101195200000000000000000A7D2" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7D2"><p id="P700101195200000000000000000A7D3" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7D3"><span class="leadin">Destination-based forwarding.</span> Suppose the car stops at an entry station and indicates its final destination (not at the local roundabout, but the ultimate destination of its journey). An attendant at the entry station looks up the final destination, determines the roundabout exit that leads to that final destination, and tells the driver which roundabout exit to take.</p></li>
<li id="P700101195200000000000000000A7D4" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7D4"><p id="P700101195200000000000000000A7D5" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7D5"><span class="leadin">Generalized forwarding.</span> The attendant could also determine the car’s exit ramp on the basis of many other factors besides the destination. For example, the selected exit ramp might depend on the car’s origin, for example the state that issued the car’s license plate. Cars from a certain set of states might be directed to use one exit ramp (that leads to the destination via a slow road), while cars from other states might be directed to use a different exit ramp (that leads to the destination via superhighway). The same decision might be made based on the model, make and year of the car. Or a car not deemed roadworthy might be blocked and not be allowed to pass through the roundabout. In the case of generalized forwarding, any number of factors may contribute to the attendant’s choice of the exit ramp for a given car.</p></li>
</ul>
<p id="P700101195200000000000000000A7D6" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7D6">Once the car enters the roundabout (which may be filled with other cars entering from other input roads and heading to other roundabout exits), it eventually leaves at the prescribed roundabout exit ramp, where it may encounter other cars leaving the roundabout at that exit.</p>
<p id="P700101195200000000000000000A7D7" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7D7">We can easily recognize the principal router components in <a class="xref" href="#P7001011952000000000000000001A2E" data-foobar="1"><span class="label">Figure</span> <span class="number">4.4</span></a> in this analogy—the entry road and entry station correspond to the input port (with a lookup function to determine to local outgoing port); the roundabout corresponds to the switch fabric; and the roundabout exit road corresponds to the output port. With this analogy, it’s instructive to consider where bottlenecks might occur. What happens if cars arrive blazingly fast (for example, the roundabout is in Germany or Italy!) but the station attendant is slow? How fast must the attendant work to ensure there’s no backup on an entry road? Even with a blazingly fast attendant, what happens if cars <span class="pagebreak" title="316" id="P7001011952000000000000000001A4C" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001A4C" epub:type="pagebreak" role="doc-pagebreak"></span>traverse the roundabout slowly—can backups still occur? And what happens if most of the cars entering at all of the roundabout’s entrance ramps all want to leave the roundabout at the same exit ramp—can backups occur at the exit ramp or elsewhere? How should the roundabout operate if we want to assign priorities to different cars, or block certain cars from entering the roundabout in the first place? These are all analogous to critical questions faced by router and switch designers.</p>
<p id="P700101195200000000000000000A7D8" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7D8">In the following subsections, we’ll look at router functions in more detail. <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P70010119520000000000000000039B0" data-foobar="7">[Iyer 2008</a>, <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003875" data-foobar="7">Chao 2001</a>; <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003886" data-foobar="7">Chuang 2005</a>; <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003C54" data-foobar="7">Turner 1988</a>; <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003A43" data-foobar="7">McKeown 1997a</a>; <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003A9C" data-foobar="7">Partridge 1998</a>; Sopranos 2011] provide a discussion of specific router architectures. For concreteness and simplicity, we’ll initially assume in this section that forwarding decisions are based only on the packet’s destination address, rather than on a generalized set of packet header fields. We will cover the case of more generalized packet forwarding in <a class="xref" href="fileP7001011952000000000000000001CE3.xhtml#P7001011952000000000000000001CE3" data-foobar="7"><span class="label">Section</span> <span class="number">4.4</span></a>.</p>
<section id="P7001011952000000000000000001A4E" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001A4E" class="level2"><header><h1 class="title" id="P700101195200000000000000000A7D9" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7D9" epub:type="title"><span class="number">4.2.1</span> Input Port Processing and Destination-Based Forwarding</h1></header>
<p id="P700101195200000000000000000A7DA" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7DA">A more detailed view of input processing is shown in <a class="xref" href="#P7001011952000000000000000001A52" data-foobar="1"><span class="label">Figure</span> <span class="number">4.5</span></a>. As just discussed, the input port’s line-termination function and link-layer processing implement the physical and link layers for that individual input link. The lookup performed in the input port is central to the router’s operation—it is here that the router uses the forwarding table to look up the output port to which an arriving packet will be forwarded via the switching fabric. The forwarding table is either computed and updated by the routing processor (using a routing protocol to interact with the routing processors in other network routers) or is received from a remote SDN controller. The forwarding table is copied from the routing processor to the line cards over a separate bus (e.g., a PCI bus) indicated by the dashed line from the routing processor to the input line cards in <a class="xref" href="#P7001011952000000000000000001A2E" data-foobar="1"><span class="label">Figure</span> <span class="number">4.4</span></a>. With such a shadow copy at each line card, forwarding decisions can be made locally, at each input port, without invoking the centralized routing processor on a per-packet basis and thus avoiding a centralized processing bottleneck.</p>
<p id="P700101195200000000000000000A7DB" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7DB">Let’s now consider the “simplest” case that the output port to which an incoming packet is to be switched is based on the packet’s destination address. In the case of 32-bit IP addresses, a brute-force implementation of the forwarding table would have one entry for every possible destination address. Since there are more than 4 billion possible addresses, this option is totally out of the question.</p>
<figure id="P7001011952000000000000000001A52" class="figure" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001A52">
<img alt="Illustration of input port processing." height="154" width="669" aria-describedby="P7001011952000000000000000001A56" id="P700101195200000000000000000A7DC" data-uri="P7001011952000000000000000005585" src="../images/4055104005.png"></img>
<figcaption id="P700101195200000000000000000A7DD" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7DD"><header><h1 class="title" id="P700101195200000000000000000A7DE" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7DE" epub:type="title"><span class="label">Figure </span><span class="number">4.5</span> Input port processing</h1></header>

</figcaption>
</figure><div class="longdesc" id="P7001011952000000000000000001A56" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001A56" aria-hidden="false"><a class="xref" aria-hidden="false" href="../longalt/la_4055104005.xhtml#la_4055104005"><span class="label">Description</span></a></div>
<p id="P700101195200000000000000000A7E0" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7E0"><span class="pagebreak" title="317" id="P7001011952000000000000000001A59" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001A59" epub:type="pagebreak" role="doc-pagebreak"></span>As an example of how this issue of scale can be handled, let’s suppose that our router has four links, numbered 0 through 3, and that packets are to be forwarded to the link interfaces as follows:</p>
<table class="informaltable" id="P700101195200000000000000000A7E1" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7E1">
<thead>
<tr>
<th id="P700101195200000000000000000A7E2" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7E2">Destination Address Range</th>
<th id="P700101195200000000000000000A7E3" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7E3">Link Interface</th>
</tr>
</thead>
<tbody>
<tr>
<td id="P700101195200000000000000000A7E4" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7E4"><p id="P700101195200000000000000000A7E5" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7E5"><code id="P700101195200000000000000000A7E6" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7E6">11001000 00010111 00010000 00000000</code></p>
<p id="P700101195200000000000000000A7E7" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7E7"><b>through</b></p>
<p id="P700101195200000000000000000A7E8" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7E8"><code id="P700101195200000000000000000A7E9" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7E9">11001000 00010111 00010111 11111111</code></p></td>
<td id="P700101195200000000000000000A7EA" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7EA"><code id="P700101195200000000000000000A7EB" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7EB">0</code></td>
</tr>
<tr>
<td id="P700101195200000000000000000A7EC" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7EC"><p id="P700101195200000000000000000A7ED" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7ED"><code id="P700101195200000000000000000A7EE" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7EE">11001000 00010111 00011000 00000000</code></p>
<p id="P700101195200000000000000000A7EF" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7EF"><b>through</b></p>
<p id="P700101195200000000000000000A7F0" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7F0"><code id="P700101195200000000000000000A7F1" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7F1">11001000 00010111 00011000 11111111</code></p></td>
<td id="P700101195200000000000000000A7F2" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7F2"><code id="P700101195200000000000000000A7F3" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7F3">1</code></td>
</tr>
<tr>
<td id="P700101195200000000000000000A7F4" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7F4"><p id="P700101195200000000000000000A7F5" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7F5"><code id="P700101195200000000000000000A7F6" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7F6">11001000 00010111 00011001 00000000</code></p>
<p id="P700101195200000000000000000A7F7" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7F7"><b>through</b></p>
<p id="P700101195200000000000000000A7F8" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7F8"><code id="P700101195200000000000000000A7F9" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7F9">11001000 00010111 00011111 11111111</code></p></td>
<td id="P700101195200000000000000000A7FA" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7FA"><code id="P700101195200000000000000000A7FB" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7FB">2</code></td>
</tr>
<tr>
<td id="P700101195200000000000000000A7FC" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7FC"><b>Otherwise</b></td>
<td id="P700101195200000000000000000A7FD" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7FD"><code id="P700101195200000000000000000A7FE" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7FE">3</code></td>
</tr>
</tbody>
</table>
<p class="continued" id="P700101195200000000000000000A7FF" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A7FF">Clearly, for this example, it is not necessary to have 4 billion entries in the router’s forwarding table. We could, for example, have the following forwarding table with just four entries:</p>
<table class="informaltable" id="P700101195200000000000000000A800" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A800">
<thead>
<tr>
<th id="P700101195200000000000000000A801" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A801">Prefix</th>
<th id="P700101195200000000000000000A802" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A802">Link Interface</th>
</tr>
</thead>
<tbody>
<tr>
<td id="P700101195200000000000000000A803" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A803"><code id="P700101195200000000000000000A804" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A804">11001000 00010111 00010</code></td>
<td id="P700101195200000000000000000A805" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A805"><code id="P700101195200000000000000000A806" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A806">0</code></td>
</tr>
<tr>
<td id="P700101195200000000000000000A807" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A807"><code id="P700101195200000000000000000A808" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A808">11001000 00010111 00011000</code></td>
<td id="P700101195200000000000000000A809" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A809"><code id="P700101195200000000000000000A80A" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A80A">1</code></td>
</tr>
<tr>
<td id="P700101195200000000000000000A80B" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A80B"><code id="P700101195200000000000000000A80C" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A80C">11001000 00010111 00011</code></td>
<td id="P700101195200000000000000000A80D" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A80D"><code id="P700101195200000000000000000A80E" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A80E">2</code></td>
</tr>
<tr>
<td id="P700101195200000000000000000A80F" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A80F">Otherwise</td>
<td id="P700101195200000000000000000A810" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A810"><code id="P700101195200000000000000000A811" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A811">3</code></td>
</tr>
</tbody>
</table>
<p class="continued" id="P700101195200000000000000000A812" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A812">With this style of forwarding table, the router matches a <span class="keyword" id="P7001011952000000000000000001A8C" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001A8C"><b>prefix</b></span> of the packet’s destination address with the entries in the table; if there’s a match, the router forwards the packet to a link associated with the match. For example, suppose the packet’s destination address is <code id="P700101195200000000000000000A813" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A813">11001000 00010111 00010110 10100001</code>; because the 21-bit prefix of this address matches the first entry in the table, the router forwards the packet to link interface 0. If a prefix doesn’t match any of the first three entries, then the router forwards the packet to the default interface 3. Although this sounds simple enough, there’s a very important subtlety here. You may have noticed that it is possible for a destination address to match more than one entry. For example, the first 24 bits of the address <code id="P700101195200000000000000000A814" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A814">11001000 00010111 00011000 10101010</code> match the second entry in the table, and the first 21 bits of the address match the third entry in the table. When there are multiple matches, the router uses the <span class="keyword" id="P7001011952000000000000000001A8F" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001A8F"><b>longest prefix matching rule</b></span>; that is, it finds the longest matching entry in the table and forwards the packet to the link interface associated with the longest prefix match. We’ll see exactly <i>why</i> this <span class="pagebreak" title="318" id="P7001011952000000000000000001A90" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001A90" epub:type="pagebreak" role="doc-pagebreak"></span>longest prefix-matching rule is used when we study Internet addressing in more detail in <a class="xref" href="fileP7001011952000000000000000001B24.xhtml#P7001011952000000000000000001B24" data-foobar="7"><span class="label">Section</span> <span class="number">4.3</span></a>.</p>
<p id="P700101195200000000000000000A815" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A815">Given the existence of a forwarding table, lookup is conceptually simple—­hardware logic just searches through the forwarding table looking for the longest prefix match. But at Gigabit transmission rates, this lookup must be performed in nanoseconds (recall our earlier example of a 10 Gbps link and a 64-byte IP datagram). Thus, not only must lookup be performed in hardware, but techniques beyond a simple linear search through a large table are needed; surveys of fast lookup algorithms can be found in <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P700101195200000000000000000393E" data-foobar="7">[Gupta 2001</a>, <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003BE0" data-foobar="7">Ruiz-Sanchez 2001]</a>. Special attention must also be paid to memory access times, resulting in designs with embedded on-chip DRAM and faster SRAM (used as a DRAM cache) memories. In practice, Ternary Content Addressable Memories (TCAMs) are also often used for lookup <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003C96" data-foobar="7">[Yu 2004]</a>. With a TCAM, a 32-bit IP address is presented to the memory, which returns the content of the forwarding table entry for that address in essentially constant time. The Cisco Catalyst 6500 and 7600 Series routers and switches can hold upwards of a million TCAM forwarding table entries <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P700101195200000000000000000389E" data-foobar="7">[Cisco TCAM 2014]</a>.</p>
<p id="P700101195200000000000000000A816" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A816">Once a packet’s output port has been determined via the lookup, the packet can be sent into the switching fabric. In some designs, a packet may be temporarily blocked from entering the switching fabric if packets from other input ports are currently using the fabric. A blocked packet will be queued at the input port and then scheduled to cross the fabric at a later point in time. We’ll take a closer look at the blocking, queuing, and scheduling of packets (at both input ports and output ports) shortly. Although “lookup” is arguably the most important action in input port processing, many other actions must be taken: (1) physical- and link-layer processing must occur, as discussed previously; (2) the packet’s version number, checksum and time-to-live field—all of which we’ll study in <a class="xref" href="fileP7001011952000000000000000001B24.xhtml#P7001011952000000000000000001B24" data-foobar="7"><span class="label">Section</span> <span class="number">4.3</span></a>—must be checked and the latter two fields rewritten; and (3) counters used for network management (such as the number of IP datagrams received) must be updated.</p>
<p id="P700101195200000000000000000A817" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A817">Let’s close our discussion of input port processing by noting that the input port steps of looking up a destination IP address (“match”) and then sending the packet into the switching fabric to the specified output port (“action”) is a specific case of a more general “match plus action” abstraction that is performed in many networked devices, not just routers. In link-layer switches (covered in <a class="xref" href="fileP7001011952000000000000000001EDE.xhtml#P7001011952000000000000000001EDE" data-foobar="7"><span class="label">Chapter</span> <span class="number">6</span></a>), link-layer destination addresses are looked up and several actions may be taken in addition to sending the frame into the switching fabric towards the output port. In firewalls (covered in <a class="xref" href="fileP7001011952000000000000000002D4B.xhtml#P7001011952000000000000000002D4B" data-foobar="7"><span class="label">Chapter</span> <span class="number">8</span></a>)—devices that filter out selected incoming packets—an incoming packet whose header matches a given criteria (e.g., a combination of source/destination IP addresses and transport-layer port numbers) may be dropped (action). In a network address translator (NAT, covered in <a class="xref" href="fileP7001011952000000000000000001B24.xhtml#P7001011952000000000000000001B24" data-foobar="7"><span class="label">Section</span> <span class="number">4.3</span></a>), an incoming packet whose transport-layer port number matches a given value will have its port number rewritten before forwarding (action). Indeed, the “match plus action” abstraction is both powerful and prevalent in network devices today, and is central to the notion of generalized forwarding that we’ll study in <a class="xref" href="fileP7001011952000000000000000001CE3.xhtml#P7001011952000000000000000001CE3" data-foobar="7"><span class="label">Section</span> <span class="number">4.4</span></a>.</p>
</section>
<section id="P7001011952000000000000000001A94" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001A94" class="level2"><header><h1 class="title" id="P700101195200000000000000000A818" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A818" epub:type="title"><span class="pagebreak" title="319" id="P7001011952000000000000000001A96" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001A96" epub:type="pagebreak" role="doc-pagebreak"></span><span class="number">4.2.2</span> Switching</h1></header>
<p id="P700101195200000000000000000A819" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A819">The switching fabric is at the very heart of a router, as it is through this fabric that the packets are actually switched (that is, forwarded) from an input port to an output port. Switching can be accomplished in a number of ways, as shown in <a class="xref" href="#P7001011952000000000000000001A9B" data-foobar="1"><span class="label">Figure</span> <span class="number">4.6</span></a>:</p>
<ul id="P700101195200000000000000000A81A" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A81A">
<li id="P700101195200000000000000000A81B" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A81B"><p id="P700101195200000000000000000A81C" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A81C"><span class="leadin">Switching via memory.</span> The simplest, earliest routers were traditional computers, with switching between input and output ports being done under direct control of the CPU (routing processor). Input and output ports functioned as traditional I/O devices in a traditional operating system. An input port with an arriving packet first signaled the routing processor via an interrupt. The packet was then copied from the input port into processor memory. The routing processor then extracted the destination address from the header, looked up the appropriate output port in the forwarding table, and copied the packet to the output port’s buffers. In this scenario, if the memory bandwidth is such that a maximum of <i>B</i> packets per second can be written into, or read from, memory, then the overall forwarding throughput (the total rate at which packets are transferred from input ports to output ports) must be less than <i>B</i>/2. Note also that two packets cannot be forwarded</p>
<figure id="P7001011952000000000000000001A9B" class="figure" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001A9B">
<img alt="Illustration of the three switching techniques: Memory." height="151" width="375" aria-describedby="P7001011952000000000000000001A9F" id="P700101195200000000000000000A81D" data-uri="P7001011952000000000000000005586" src="../images/4055104006.png"></img>
<figcaption id="P700101195200000000000000000A81E" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A81E"><header><h1 class="title" id="P700101195200000000000000000A81F" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A81F" epub:type="title"><span class="label">Figure </span><span class="number">4.6</span> Three switching techniques</h1></header>

</figcaption>
</figure><div class="longdesc" id="P7001011952000000000000000001A9F" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001A9F" aria-hidden="false"><a class="xref" aria-hidden="false" href="../longalt/la_4055104006.xhtml#la_4055104006"><span class="label">Description</span></a></div>
<figure id="P7001011952000000000000000001AA1" class="figure" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001AA1">
<img alt="Illustration of the three switching techniques: Bus." height="245" width="317" aria-describedby="P7001011952000000000000000001AA3" id="P700101195200000000000000000A821" data-uri="P7001011952000000000000000005587" src="../images/4055104006a.png"></img>
<details class="longdesc" id="P7001011952000000000000000001AA3" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001AA3">
<summary><span class="label">Description</span></summary>
<p id="P700101195200000000000000000A822" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A822">This illustration is similar to the previous one, with three rows of input and output ports labeled A, B, C and X, Y, Z. However, where the large box labeled "Memory" had been we now see a thick vertical line. Data travels the same path here as it did in the previous figure.</p>
</details>
</figure>
<figure id="P7001011952000000000000000001AA5" class="figure" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001AA5">
<img alt=" Illustration of the three switching techniques: Crossbar." height="325" width="283" aria-describedby="P7001011952000000000000000001AA7" id="P700101195200000000000000000A823" data-uri="P7001011952000000000000000005588" src="../images/4055104006b.png"></img>
<details class="longdesc" id="P7001011952000000000000000001AA7" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001AA7">
<summary><span class="label">Description</span></summary>
<p id="P700101195200000000000000000A824" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A824">In this illustration we see the three rows of input ports as in the previous two figures. Here, however, the inputs and outputs are separated by a crossbar switch, which is represented by a 3 X 3 grid of dots and lines. And while the input ports are arranged in three rows, the output ports are arranged in three columns beneath the crossbar switch. Data travels through input port A and enters the grid. At the second dot, the data makes a 90-degree turn downward, passes through the grid, and exits through output port Y.</p>
</details>
</figure>
<p class="continued" id="P700101195200000000000000000A825" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A825"><span class="pagebreak" title="320" id="P7001011952000000000000000001AAA" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001AAA" epub:type="pagebreak" role="doc-pagebreak"></span>at the same time, even if they have different destination ports, since only one memory read/write can be done at a time over the shared system bus.</p>
<p class="continued" id="P700101195200000000000000000A826" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A826">Some modern routers switch via memory. A major difference from early routers, however, is that the lookup of the destination address and the storing of the packet into the appropriate memory location are performed by processing on the input line cards. In some ways, routers that switch via memory look very much like shared-memory multiprocessors, with the processing on a line card switching (writing) packets into the memory of the appropriate output port. Cisco’s Catalyst 8500 series switches <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P700101195200000000000000000388C" data-foobar="7">[Cisco 8500 2016]</a> internally switches packets via a shared memory.</p></li>
<li id="P700101195200000000000000000A827" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A827"><p id="P700101195200000000000000000A828" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A828"><span class="leadin">Switching via a bus.</span> In this approach, an input port transfers a packet directly to the output port over a shared bus, without intervention by the routing processor. This is typically done by having the input port pre-pend a switch-internal label (header) to the packet indicating the local output port to which this packet is being transferred and transmitting the packet onto the bus. All output ports receive the packet, but only the port that matches the label will keep the packet. The label is then removed at the output port, as this label is only used within the switch to cross the bus. If multiple packets arrive to the router at the same time, each at a different input port, all but one must wait since only one packet can cross the bus at a time. Because every packet must cross the single bus, the switching speed of the router is limited to the bus speed; in our roundabout analogy, this is as if the roundabout could only contain one car at a time. Nonetheless, switching via a bus is often sufficient for routers that operate in small local area and enterprise networks. The Cisco 6500 router <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003894" data-foobar="7">[Cisco 6500 2016]</a> internally switches packets over a 32-Gbps-backplane bus.</p></li>
<li id="P700101195200000000000000000A829" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A829"><p id="P700101195200000000000000000A82A" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A82A"><span class="leadin">Switching via an interconnection network.</span> One way to overcome the bandwidth limitation of a single, shared bus is to use a more sophisticated interconnection network, such as those that have been used in the past to interconnect processors in a multiprocessor computer architecture. A crossbar switch is an interconnection network consisting of 2<i>N</i> buses that connect <i>N</i> input ports to <i>N</i> output ports, as shown in <a class="xref" href="#P7001011952000000000000000001A9B" data-foobar="1"><span class="label">Figure</span> <span class="number">4.6</span></a>. Each vertical bus intersects each horizontal bus at a crosspoint, which can be opened or closed at any time by the switch fabric controller (whose logic is part of the switching fabric itself). When a packet arrives from port A and needs to be forwarded to port Y, the switch controller closes the crosspoint at the intersection of busses A and Y, and port A then sends the packet onto its bus, which is picked up (only) by bus Y. Note that a packet from port B can be forwarded to port X at the same time, since the A-to-Y and B-to-X packets use different input and output busses. Thus, unlike the previous two switching approaches, crossbar switches are capable of forwarding multiple packets in parallel. A crossbar switch is <span class="keyword" id="P7001011952000000000000000001AB0" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001AB0"><b>non-blocking</b></span>—a packet being forwarded to an output port will not be blocked from reaching that output port as long as no other packet is currently being forwarded to that output port. However, if two packets from two different input ports are destined to that same output port, then one will have to wait at the input, since only one packet can be sent over any given bus at a time. Cisco 12000 series <span class="pagebreak" title="321" id="P7001011952000000000000000001AB1" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001AB1" epub:type="pagebreak" role="doc-pagebreak"></span>switches <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P700101195200000000000000000388E" data-foobar="7">[Cisco 12000 2016]</a> use a crossbar switching network; the Cisco 7600 series can be configured to use either a bus or crossbar switch <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P700101195200000000000000000388A" data-foobar="7">[Cisco 7600 2016]</a>.</p>
<p class="continued" id="P700101195200000000000000000A82B" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A82B">More sophisticated interconnection networks use multiple stages of switching elements to allow packets from different input ports to proceed towards the same output port at the same time through the multi-stage switching fabric. See <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003C4C" data-foobar="7">[Tobagi 1990]</a> for a survey of switch architectures. The Cisco CRS employs a three-stage non-blocking switching strategy. A router’s switching capacity can also be scaled by running multiple switching fabrics in parallel. In this approach, input ports and output ports are connected to <i>N</i> switching fabrics that operate in parallel. An input port breaks a packet into <i>K</i> smaller chunks, and sends (“sprays”) the chunks through <i>K</i> of these <i>N</i> switching fabrics to the selected output port, which reassembles the <i>K</i> chunks back into the original packet.</p></li>
</ul>
</section>
<section id="P7001011952000000000000000001AB3" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001AB3" class="level2"><header><h1 class="title" id="P700101195200000000000000000A82C" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A82C" epub:type="title"><span class="number">4.2.3</span> Output Port Processing</h1></header>
<p id="P700101195200000000000000000A82D" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A82D">Output port processing, shown in <a class="xref" href="#P7001011952000000000000000001ABA" data-foobar="1"><span class="label">Figure</span> <span class="number">4.7</span></a>, takes packets that have been stored in the output port’s memory and transmits them over the output link. This includes selecting and de-queueing packets for transmission, and performing the needed link-layer and physical-layer transmission functions.</p>
</section>
<section id="P7001011952000000000000000001AB6" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001AB6" class="level2"><header><h1 class="title" id="P700101195200000000000000000A82E" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A82E" epub:type="title"><span class="number">4.2.4</span> Where Does Queuing Occur?</h1></header>
<p id="P700101195200000000000000000A82F" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A82F">If we consider input and output port functionality and the configurations shown in <a class="xref" href="#P7001011952000000000000000001A9B" data-foobar="1"><span class="label">Figure</span> <span class="number">4.6</span></a>, it’s clear that packet queues may form at both the input ports <i>and</i> the output ports, just as we identified cases where cars may wait at the inputs and outputs of the traffic intersection in our roundabout analogy. The location and extent of queueing (either at the input port queues or the output port queues) will depend on the traffic load, the relative speed of the switching fabric, and the line speed. Let’s now consider these queues in a bit more detail, since as these queues grow large, the router’s memory can eventually be exhausted and <span class="keyword" id="P7001011952000000000000000001AB9" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001AB9"><b>packet loss</b></span> will occur when no memory is available to store arriving packets. Recall that in our earlier ­discussions, we said that packets were “lost within the network” or “dropped at a router.” <i>It is here, at these queues within a router, where such packets are actually dropped and lost.</i></p>
<figure id="P7001011952000000000000000001ABA" class="figure" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001ABA">
<img alt="Illustration of output port processing." height="154" width="667" aria-describedby="P7001011952000000000000000001ABE" id="P700101195200000000000000000A830" data-uri="P7001011952000000000000000005589" src="../images/4055104007.png"></img>
<figcaption id="P700101195200000000000000000A831" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A831"><header><h1 class="title" id="P700101195200000000000000000A832" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A832" epub:type="title"><span class="label">Figure </span><span class="number">4.7</span> Output port processing</h1></header>

</figcaption>
</figure><div class="longdesc" id="P7001011952000000000000000001ABE" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001ABE" aria-hidden="false"><a class="xref" aria-hidden="false" href="../longalt/la_4055104007.xhtml#la_4055104007"><span class="label">Description</span></a></div>
<p id="P700101195200000000000000000A834" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A834"><span class="pagebreak" title="322" id="P7001011952000000000000000001AC1" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001AC1" epub:type="pagebreak" role="doc-pagebreak"></span>Suppose that the input and output line speeds (transmission rates) all have an identical transmission rate of <i>R<sub>line</sub></i> packets per second, and that there are <i>N</i> input ports and <i>N</i> output ports. To further simplify the discussion, let’s assume that all packets have the same fixed length, and that packets arrive to input ports in a synchronous manner. That is, the time to send a packet on any link is equal to the time to receive a packet on any link, and during such an interval of time, either zero or one packets can arrive on an input link. Define the switching fabric transfer rate <i>R<sub>switch</sub></i> as the rate at which packets can be moved from input port to output port. If <i>R<sub>switch</sub></i> is <i>N</i> times faster than <i>R<sub>line</sub></i>, then only negligible queuing will occur at the input ports. This is because even in the worst case, where all <i>N</i> input lines are receiving packets, and all packets are to be forwarded to the same output port, each batch of <i>N</i> packets (one packet per input port) can be cleared through the switch fabric before the next batch arrives.</p>
<section id="P7001011952000000000000000001AC2" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001AC2" class="level3"><header><h1 class="title" id="P700101195200000000000000000A835" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A835" epub:type="title">Input Queueing</h1></header>
<p id="P700101195200000000000000000A836" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A836">But what happens if the switch fabric is not fast enough (relative to the input line speeds) to transfer <i>all</i> arriving packets through the fabric without delay? In this case, packet queuing can also occur at the input ports, as packets must join input port queues to wait their turn to be transferred through the switching fabric to the output port. To illustrate an important consequence of this queuing, consider a crossbar switching fabric and suppose that (1) all link speeds are identical, (2) that one packet can be transferred from any one input port to a given output port in the same amount of time it takes for a packet to be received on an input link, and (3) packets are moved from a given input queue to their desired output queue in an FCFS manner. Multiple packets can be transferred in parallel, as long as their output ports are different. However, if two packets at the front of two input queues are destined for the same output queue, then one of the packets will be blocked and must wait at the input queue—the switching fabric can transfer only one packet to a given output port at a time.</p>
<p id="P700101195200000000000000000A837" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A837"><a class="xref" href="#P7001011952000000000000000001AC8" data-foobar="1"><span class="label">Figure</span> <span class="number">4.8</span></a> shows an example in which two packets (darkly shaded) at the front of their input queues are destined for the same upper-right output port. Suppose that the switch fabric chooses to transfer the packet from the front of the upper-left queue. In this case, the darkly shaded packet in the lower-left queue must wait. But not only must this darkly shaded packet wait, so too must the lightly shaded packet that is queued behind that packet in the lower-left queue, even though there is <i>no</i> contention for the middle-right output port (the destination for the lightly shaded packet). This phenomenon is known as <span class="keyword" id="P7001011952000000000000000001AC6" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001AC6"><b>head-of-the-line</b> (<b>HOL</b>) <b>blocking</b></span> in an input-queued switch—a queued packet in an input queue must wait for transfer through the fabric (even though its output port is free) because it is blocked by another packet at the head of the line. <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P70010119520000000000000000039D7" data-foobar="7">[Karol 1987]</a> shows that due to HOL blocking, the input queue will grow to unbounded length (informally, this is equivalent to saying that significant packet loss will occur) under certain assumptions as soon as the packet arrival rate on the input links reaches only 58 percent of their capacity. A number of solutions to HOL blocking are discussed in <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003A43" data-foobar="7">[McKeown 1997]</a>.<span class="pagebreak" title="323" id="P7001011952000000000000000001AC7" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001AC7" epub:type="pagebreak" role="doc-pagebreak"></span></p>
<figure id="P7001011952000000000000000001AC8" class="figure" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001AC8">
<img alt="Illustration of HOL blocking at an input-queued switch." height="594" width="589" aria-describedby="P7001011952000000000000000001ACC" id="P700101195200000000000000000A838" data-uri="P700101195200000000000000000558A" src="../images/4055104008.png"></img>
<figcaption id="P700101195200000000000000000A839" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A839"><header><h1 class="title" id="P700101195200000000000000000A83A" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A83A" epub:type="title"><span class="label">Figure </span><span class="number">4.8</span> HOL blocking at and input-queued switch</h1></header>

</figcaption>
</figure><div class="longdesc" id="P7001011952000000000000000001ACC" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001ACC" aria-hidden="false"><a class="xref" aria-hidden="false" href="../longalt/la_4055104008.xhtml#la_4055104008"><span class="label">Description</span></a></div>
</section>
<section id="P7001011952000000000000000001ACF" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001ACF" class="level3"><header><h1 class="title" id="P700101195200000000000000000A83D" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A83D" epub:type="title">Output Queueing</h1></header>
<p id="P700101195200000000000000000A83E" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A83E">Let’s next consider whether queueing can occur at a switch’s output ports. Suppose that <i>R<sub>switch</sub></i> is again <i>N</i> times faster than <i>R<sub>line</sub></i> and that packets arriving at each of the <i>N</i> input ports are destined to the same output port. In this case, in the time it takes to send a single packet onto the outgoing link, <i>N</i> new packets will arrive at this output port (one from each of the <i>N</i> input ports). Since the output port can transmit only a single packet in a unit of time (the packet transmission time), the <i>N</i> arriving packets will have to queue (wait) for transmission over the outgoing link. Then <i>N</i> more packets can possibly arrive in the time it takes to transmit just one of the <i>N</i> packets that had just previously been queued. And so on. Thus, packet queues can form at the output ports even when the switching fabric is <i>N</i> times faster than the port line speeds. Eventually, the number of queued packets can grow large enough to exhaust available memory at the output port.<span class="pagebreak" title="324" id="P7001011952000000000000000001AD2" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001AD2" epub:type="pagebreak" role="doc-pagebreak"></span></p>
<figure id="P7001011952000000000000000001AD3" class="figure" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001AD3">
<img alt="Illustration of output port queuing." height="499" width="584" aria-describedby="P7001011952000000000000000001AD7" id="P700101195200000000000000000A83F" data-uri="P700101195200000000000000000558B" src="../images/4055104009.png"></img>
<figcaption id="P700101195200000000000000000A840" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A840"><header><h1 class="title" id="P700101195200000000000000000A841" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A841" epub:type="title"><span class="label">Figure </span><span class="number">4.9</span> Output port queueing</h1></header>

</figcaption>
</figure><div class="longdesc" id="P7001011952000000000000000001AD7" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001AD7" aria-hidden="false"><a class="xref" aria-hidden="false" href="../longalt/la_4055104009.xhtml#la_4055104009"><span class="label">Description</span></a></div>
<p id="P700101195200000000000000000A844" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A844">When there is not enough memory to buffer an incoming packet, a decision must be made to either drop the arriving packet (a policy known as <span class="keyword" id="P7001011952000000000000000001ADB" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001ADB"><b>drop-tail</b></span>) or remove one or more already-queued packets to make room for the newly arrived packet. In some cases, it may be advantageous to drop (or mark the header of) a packet <i>before</i> the buffer is full in order to provide a congestion signal to the sender. A number of proactive packet-dropping and -marking policies (which collectively have become known as <span class="keyword" id="P7001011952000000000000000001ADC" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001ADC"><b>active queue management</b> (<b>AQM</b>)</span> algorithms) have been proposed and analyzed <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003A0B" data-foobar="7">[Labrador 1999</a>, <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003951" data-foobar="7">Hollot 2002]</a>. One of the most widely studied and implemented AQM algorithms is the <span class="keyword" id="P7001011952000000000000000001ADD" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001ADD"><b>Random Early Detection</b> (<b>RED</b>)</span> algorithm <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003884" data-foobar="7">[Christiansen 2001</a>; <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003906" data-foobar="7">Floyd 2016]</a>.</p>
<p id="P700101195200000000000000000A845" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A845">Output port queuing is illustrated in <a class="xref" href="#P7001011952000000000000000001AD3" data-foobar="1"><span class="label">Figure</span> <span class="number">4.9</span></a>. At time <i>t,</i> a packet has arrived at each of the incoming input ports, each destined for the uppermost outgoing port. Assuming identical line speeds and a switch operating at three times the line speed, one time unit later (that is, in the time needed to receive or send a packet), all three original packets have been transferred to the outgoing port and are queued awaiting transmission. In the next time unit, one of these three packets will have been transmitted over the outgoing link. In our example, two <i>new</i> packets have arrived at the incoming side of the switch; one of these packets is destined for this uppermost output port. A consequence <span class="pagebreak" title="325" id="P7001011952000000000000000001ADF" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001ADF" epub:type="pagebreak" role="doc-pagebreak"></span>of such queuing is that a <span class="keyword" id="P7001011952000000000000000001AE0" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001AE0"><b>packet scheduler</b></span> at the output port must choose one packet, among those queued, for transmission—a topic we’ll cover in the following section.</p>
<p id="P700101195200000000000000000A846" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A846">Given that router buffers are needed to absorb the fluctuations in traffic load, a natural question to ask is how <i>much</i> buffering is required. For many years, the rule of thumb <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003B79" data-foobar="7">[RFC 3439]</a> for buffer sizing was that the amount of buffering <i>(B)</i> should be equal to an average round-trip time (<i>RTT</i>, say 250 msec) times the link capacity <i>(C)</i>. This result is based on an analysis of the queueing dynamics of a relatively small number of TCP flows <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003C62" data-foobar="7">[Villamizar 1994]</a>. Thus, a 10 Gbps link with an RTT of 250 msec would need an amount of buffering equal to <i>B 5 RTT</i> · <i>C</i> 5 2.5 Gbits of buffers. More recent theoretical and experimental efforts <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P700101195200000000000000000380F" data-foobar="7">[Appenzeller 2004]</a>, however, suggest that when there are a large number of TCP flows (<i>N</i>) passing through a link, the amount of buffering needed is <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="148" altimg-height="25" altimg="../images/ch04math01.png"><m:mrow><m:mi>B</m:mi><m:mo>=</m:mo><m:mi>R</m:mi><m:mi>T</m:mi><m:mi>I</m:mi><m:mo>⋅</m:mo><m:mi>C</m:mi><m:mo>/</m:mo><m:msqrt><m:mi>N</m:mi></m:msqrt><m:mo>.</m:mo></m:mrow></m:math></span> With a large number of flows typically passing through large backbone router links (see, e.g., <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003913" data-foobar="7">[Fraleigh 2003]</a>), the value of <i>N</i> can be large, with the decrease in needed buffer size becoming quite significant. <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P700101195200000000000000000380F" data-foobar="7">[Appenzeller 2004</a>; <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003C81" data-foobar="7">Wischik 2005</a>; <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P700101195200000000000000000382F" data-foobar="7">Beheshti 2008]</a> provide very readable discussions of the buffer-sizing problem from a theoretical, implementation, and operational standpoint.</p>
</section>
</section>
<section id="P7001011952000000000000000001AE2" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001AE2" class="level2"><header><h1 class="title" id="P700101195200000000000000000A847" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A847" epub:type="title"><span class="number">4.2.5</span> Packet Scheduling</h1></header>
<p id="P700101195200000000000000000A848" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A848">Let’s now return to the question of determining the order in which queued packets are transmitted over an outgoing link. Since you yourself have undoubtedly had to wait in long lines on many occasions and observed how waiting customers are served, you’re no doubt familiar with many of the queueing disciplines commonly used in routers. There is first-come-first-served (FCFS, also known as first-in-first-out, FIFO). The British are famous for patient and orderly FCFS queueing at bus stops and in the marketplace (“Oh, are you queueing?”). Other countries operate on a priority basis, with one class of waiting customers given priority service over other waiting customers. There is also round-robin queueing, where customers are again divided into classes (as in priority queueing) but each class of customer is given service in turn.</p>
<section id="P7001011952000000000000000001AE5" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001AE5" class="level3"><header><h1 class="title" id="P700101195200000000000000000A849" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A849" epub:type="title">First-in-First-Out (FIFO)</h1></header>
<p id="P700101195200000000000000000A84A" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A84A"><a class="xref" href="#P7001011952000000000000000001AEA" data-foobar="1"><span class="label">Figure</span> <span class="number">4.10</span></a> shows the queuing model abstraction for the FIFO link-scheduling discipline. Packets arriving at the link output queue wait for transmission if the link is currently busy transmitting another packet. If there is not sufficient buffering space to hold the arriving packet, the queue’s packet-discarding policy then determines whether the packet will be dropped (lost) or whether other packets will be removed from the queue to make space for the arriving packet, as discussed above. In our discussion below, we’ll ignore packet discard. When a packet is completely transmitted over the outgoing link (that is, receives service) it is removed from the queue.</p>
<p id="P700101195200000000000000000A84B" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A84B">The FIFO (also known as first-come-first-served, or FCFS) scheduling discipline selects packets for link transmission in the same order in which they arrived at the output link queue. We’re all familiar with FIFO queuing from service centers, where<span class="pagebreak" title="326" id="P7001011952000000000000000001AE9" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001AE9" epub:type="pagebreak" role="doc-pagebreak"></span></p>
<figure id="P7001011952000000000000000001AEA" class="figure" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001AEA">
<img alt="Illustration of FIFO queuing abstraction." height="174" width="483" aria-describedby="P7001011952000000000000000001AEE" id="P700101195200000000000000000A84C" data-uri="P700101195200000000000000000558C" src="../images/4055104010.png"></img>
<figcaption id="P700101195200000000000000000A84D" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A84D"><header><h1 class="title" id="P700101195200000000000000000A84E" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A84E" epub:type="title"><span class="label">Figure </span><span class="number">4.10</span> FIFO queueing abstraction</h1></header>

</figcaption>
</figure><div class="longdesc" id="P7001011952000000000000000001AEE" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001AEE" aria-hidden="false"><a class="xref" aria-hidden="false" href="../longalt/la_4055104010.xhtml#la_4055104010"><span class="label">Description</span></a></div>
<p class="continued" id="P700101195200000000000000000A850" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A850">arriving customers join the back of the single waiting line, remain in order, and are then served when they reach the front of the line. <a class="xref" href="#P7001011952000000000000000001AF4" data-foobar="1"><span class="label">Figure</span> <span class="number">4.11</span></a> shows the FIFO queue in operation. Packet arrivals are indicated by numbered arrows above the upper timeline, with the number indicating the order in which the packet arrived. Individual packet departures are shown below the lower timeline. The time that a packet spends in service (being transmitted) is indicated by the shaded rectangle between the two timelines. In our examples here, let’s assume that each packet takes three units of time to be transmitted. Under the FIFO discipline, packets leave in the same order in which they arrived. Note that after the departure of packet 4, the link remains idle (since packets 1 through 4 have been transmitted and removed from the queue) until the arrival of packet 5.</p>
</section>
<section id="P7001011952000000000000000001AF1" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001AF1" class="level3"><header><h1 class="title" id="P700101195200000000000000000A851" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A851" epub:type="title">Priority Queuing</h1></header>
<p id="P700101195200000000000000000A852" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A852">Under priority queuing, packets arriving at the output link are classified into priority classes upon arrival at the queue, as shown in <a class="xref" href="#P7001011952000000000000000001AFB" data-foobar="1"><span class="label">Figure</span> <span class="number">4.12</span></a>. In practice, a network operator may configure a queue so that packets carrying network management information (e.g., as indicated by the source or destination TCP/UDP port number) receive priority over user traffic; additionally, real-time voice-over-IP packets might receive priority over non-real traffic such as SMTP or IMAP e-mail packets. Each</p>
<figure id="P7001011952000000000000000001AF4" class="figure" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001AF4">
<img alt="The FIFO queue in operation." height="251" width="774" aria-describedby="P7001011952000000000000000001AF8" id="P700101195200000000000000000A853" data-uri="P700101195200000000000000000558D" src="../images/4055104011.png"></img>
<figcaption id="P700101195200000000000000000A854" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A854"><header><h1 class="title" id="P700101195200000000000000000A855" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A855" epub:type="title"><span class="label">Figure </span><span class="number">4.11</span> The FIFO queue in operation</h1></header>

</figcaption>
</figure><div class="longdesc" id="P7001011952000000000000000001AF8" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001AF8" aria-hidden="false"><a class="xref" aria-hidden="false" href="../longalt/la_4055104011.xhtml#la_4055104011"><span class="label">Description</span></a></div>
<figure id="P7001011952000000000000000001AFB" class="figure" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001AFB">
<img alt="Illustration of the priority queuing model." height="255" width="602" aria-describedby="P7001011952000000000000000001B00" id="P700101195200000000000000000A858" data-uri="P700101195200000000000000000558E" src="../images/4055104012.png"></img>
<figcaption id="P700101195200000000000000000A859" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A859"><header><h1 class="title" id="P700101195200000000000000000A85A" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A85A" epub:type="title"><span class="pagebreak" title="327" id="P7001011952000000000000000001AFF" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001AFF" epub:type="pagebreak" role="doc-pagebreak"></span><span class="label">Figure </span><span class="number">4.12</span> The priority queueing model</h1></header>

</figcaption>
</figure><div class="longdesc" id="P7001011952000000000000000001B00" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001B00" aria-hidden="false"><a class="xref" aria-hidden="false" href="../longalt/la_4055104012.xhtml#la_4055104012"><span class="label">Description</span></a></div>
<p class="continued" id="P700101195200000000000000000A85C" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A85C">priority class typically has its own queue. When choosing a packet to transmit, the priority queuing discipline will transmit a packet from the highest priority class that has a nonempty queue (that is, has packets waiting for transmission). The choice among packets in the same priority class is typically done in a FIFO manner.</p>
<p id="P700101195200000000000000000A85D" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A85D"><a class="xref" href="#P7001011952000000000000000001B05" data-foobar="1"><span class="label">Figure</span> <span class="number">4.13</span></a> illustrates the operation of a priority queue with two priority classes. Packets 1, 3, and 4 belong to the high-priority class, and packets 2 and 5 belong to the low-priority class. Packet 1 arrives and, finding the link idle, begins transmission. During the transmission of packet 1, packets 2 and 3 arrive and are queued in the low- and high-priority queues, respectively. After the transmission of packet 1, packet 3 (a high-priority packet) is selected for transmission over packet 2 (which, even though it arrived earlier, is a low-priority packet). At the end of the transmission of packet 3, packet 2 then begins transmission. Packet 4 (a high-priority packet) arrives during the transmission of packet 2 (a low-priority packet). Under a <span class="keyword" id="P7001011952000000000000000001B04" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001B04"><b>non-preemptive priority queuing</b></span> discipline, the transmission of a packet is not interrupted once it has</p>
<figure id="P7001011952000000000000000001B05" class="figure" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001B05">
<img alt="Illustration of the priority queue in operation." height="252" width="774" aria-describedby="P7001011952000000000000000001B09" id="P700101195200000000000000000A85E" data-uri="P700101195200000000000000000558F" src="../images/4055104013.png"></img>
<figcaption id="P700101195200000000000000000A85F" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A85F"><header><h1 class="title" id="P700101195200000000000000000A860" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A860" epub:type="title"><span class="label">Figure </span><span class="number">4.13</span> The priority queue in operation</h1></header>

</figcaption>
</figure><div class="longdesc" id="P7001011952000000000000000001B09" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001B09" aria-hidden="false"><a class="xref" aria-hidden="false" href="../longalt/la_4055104013.xhtml#la_4055104013"><span class="label">Description</span></a></div>
<figure id="P7001011952000000000000000001B0C" class="figure" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001B0C">
<img alt="Illustration of the two-class robin queue in operation." height="251" width="774" aria-describedby="P7001011952000000000000000001B11" id="P700101195200000000000000000A863" data-uri="P7001011952000000000000000005590" src="../images/4055104014.png"></img>
<figcaption id="P700101195200000000000000000A864" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A864"><header><h1 class="title" id="P700101195200000000000000000A865" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A865" epub:type="title"><span class="pagebreak" title="328" id="P7001011952000000000000000001B10" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001B10" epub:type="pagebreak" role="doc-pagebreak"></span><span class="label">Figure </span><span class="number">4.14</span> The two-class robin queue in operation</h1></header>

</figcaption>
</figure><div class="longdesc" id="P7001011952000000000000000001B11" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001B11" aria-hidden="false"><a class="xref" aria-hidden="false" href="../longalt/la_4055104014.xhtml#la_4055104014"><span class="label">Description</span></a></div>
<p class="continued" id="P700101195200000000000000000A867" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A867">begun. In this case, packet 4 queues for transmission and begins being transmitted after the transmission of packet 2 is completed.</p>
</section>
<section id="P7001011952000000000000000001B14" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001B14" class="level3"><header><h1 class="title" id="P700101195200000000000000000A868" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A868" epub:type="title">Round Robin and Weighted Fair Queuing (WFQ)</h1></header>
<p id="P700101195200000000000000000A869" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A869">Under the round robin queuing discipline, packets are sorted into classes as with priority queuing. However, rather than there being a strict service priority among classes, a round robin scheduler alternates service among the classes. In the simplest form of round robin scheduling, a class 1 packet is transmitted, followed by a class 2 packet, followed by a class 1 packet, followed by a class 2 packet, and so on. A so-called <span class="keyword" id="P7001011952000000000000000001B17" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001B17"><b>work-conserving queuing</b></span> discipline will never allow the link to remain idle whenever there are packets (of any class) queued for transmission. A work-conserving round robin discipline that looks for a packet of a given class but finds none will immediately check the next class in the round robin sequence.</p>
<p id="P700101195200000000000000000A86A" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A86A"><a class="xref" href="#P7001011952000000000000000001B0C" data-foobar="1"><span class="label">Figure</span> <span class="number">4.14</span></a> illustrates the operation of a two-class round robin queue. In this example, packets 1, 2, and 4 belong to class 1, and packets 3 and 5 belong to the second class. Packet 1 begins transmission immediately upon arrival at the output queue. Packets 2 and 3 arrive during the transmission of packet 1 and thus queue for transmission. After the transmission of packet 1, the link scheduler looks for a class 2 packet and thus transmits packet 3. After the transmission of packet 3, the scheduler looks for a class 1 packet and thus transmits packet 2. After the transmission of packet 2, packet 4 is the only queued packet; it is thus transmitted immediately after packet 2.</p>
<p id="P700101195200000000000000000A86B" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A86B">A generalized form of round robin queuing that has been widely implemented in routers is the so-called <span class="keyword" id="P7001011952000000000000000001B1A" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001B1A"><b>weighted fair queuing (WFQ) discipline</b></span> <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P70010119520000000000000000038C0" data-foobar="7">[Demers 1990</a>; <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003A98" data-foobar="7">Parekh 1993</a>; <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003898" data-foobar="7">Cisco QoS 2016]</a>. WFQ is illustrated in <a class="xref" href="#P7001011952000000000000000001B1C" data-foobar="1"><span class="label">Figure</span> <span class="number">4.15</span></a>. Here, arriving packets are classified and queued in the appropriate per-class waiting area. As in round robin scheduling, a WFQ scheduler will serve classes in a circular manner—first serving class 1, then serving class 2, then serving class 3, and then (assuming there are three classes) repeating the service pattern. WFQ is also a work-conserving<span class="pagebreak" title="329" id="P7001011952000000000000000001B1B" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001B1B" epub:type="pagebreak" role="doc-pagebreak"></span></p>
<figure id="P7001011952000000000000000001B1C" class="figure" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001B1C">
<img alt="Illustration of weighted fair queuing." height="261" width="634" aria-describedby="P7001011952000000000000000001B20" id="P700101195200000000000000000A86C" data-uri="P7001011952000000000000000005591" src="../images/4055104015.png"></img>
<figcaption id="P700101195200000000000000000A86D" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A86D"><header><h1 class="title" id="P700101195200000000000000000A86E" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A86E" epub:type="title"><span class="label">Figure </span><span class="number">4.15</span> Weighted fair queueing</h1></header>

</figcaption>
</figure><div class="longdesc" id="P7001011952000000000000000001B20" data-uri="M04_KURO4140_07_SE_C04.xhtml#P7001011952000000000000000001B20" aria-hidden="false"><a class="xref" aria-hidden="false" href="../longalt/la_4055104015.xhtml#la_4055104015"><span class="label">Description</span></a></div>
<p class="continued" id="P700101195200000000000000000A870" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A870">queuing discipline and thus will immediately move on to the next class in the service sequence when it finds an empty class queue.</p>
<p id="P700101195200000000000000000A871" data-uri="M04_KURO4140_07_SE_C04.xhtml#P700101195200000000000000000A871">WFQ differs from round robin in that each class may receive a differential amount of service in any interval of time. Specifically, each class, <i>i</i>, is assigned a weight, <i>w<sub>i</sub></i>. Under WFQ, during any interval of time during which there are class <i>i</i> packets to send, class <i>i</i> will then be guaranteed to receive a fraction of service equal to <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="82" altimg-height="21" altimg="../images/ch04math02.png"><m:mrow><m:mrow><m:mrow><m:msub><m:mi>w</m:mi><m:mi>i</m:mi></m:msub></m:mrow><m:mo>/</m:mo><m:mrow><m:mrow><m:mo>(</m:mo><m:mrow><m:mstyle displaystyle="true"><m:mo>∑</m:mo><m:mrow><m:msub><m:mi>w</m:mi><m:mi>j</m:mi></m:msub></m:mrow></m:mstyle></m:mrow><m:mo>)</m:mo></m:mrow></m:mrow></m:mrow><m:mo>,</m:mo></m:mrow></m:math></span> where the sum in the denominator is taken over all classes that also have packets queued for transmission. In the worst case, even if all classes have queued packets, class <i>i</i> will still be guaranteed to receive a fraction <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="80" altimg-height="21" altimg="../images/ch04math03.png"><m:mrow><m:mrow><m:mrow><m:msub><m:mi>w</m:mi><m:mi>i</m:mi></m:msub></m:mrow><m:mo>/</m:mo><m:mrow><m:mrow><m:mo>(</m:mo><m:mrow><m:mstyle displaystyle="true"><m:mo>∑</m:mo><m:mrow><m:msub><m:mi>w</m:mi><m:mi>j</m:mi></m:msub></m:mrow></m:mstyle></m:mrow><m:mo>)</m:mo></m:mrow></m:mrow></m:mrow></m:mrow></m:math></span> of the bandwidth, where in this worst case the sum in the denominator is over <i>all</i> classes. Thus, for a link with transmission rate <i>R</i>, class <i>i</i> will always achieve a throughput of at least <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="109" altimg-height="20" altimg="../images/ch04math04.png"><m:mrow><m:mi>R</m:mi><m:mo>⋅</m:mo><m:mrow><m:mrow><m:msub><m:mi>w</m:mi><m:mi>i</m:mi></m:msub></m:mrow><m:mo>/</m:mo><m:mrow><m:mrow><m:mo>(</m:mo><m:mrow><m:mstyle displaystyle="true"><m:mo>∑</m:mo><m:mrow><m:msub><m:mi>w</m:mi><m:mi>j</m:mi></m:msub></m:mrow></m:mstyle></m:mrow><m:mo>)</m:mo></m:mrow></m:mrow></m:mrow><m:mo>.</m:mo></m:mrow></m:math></span> Our description of WFQ has been idealized, as we have not considered the fact that packets are discrete and a packet’s transmission will not be interrupted to begin transmission of another packet; <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P70010119520000000000000000038C0" data-foobar="7">[Demers 1990</a>; <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003A98" data-foobar="7">Parekh 1993]</a> discuss this packetization issue.</p>
</section>
</section>
</section></body></html>