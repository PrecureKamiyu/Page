<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>12.6  Disk-Block Access</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part236.htm">&lt; 上一个</a><span> | </span><a href="../database.html">内容</a><span> | </span><a href="part238.htm">下一个 &gt;</a></p><p class="s316" style="padding-top: 6pt;padding-left: 72pt;text-indent: 0pt;text-align: left;">12.6  <span style=" color: #00AEEF;">Disk-Block Access</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s15" style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">Requests for disk <span class="s16">I/O </span>are generated by the database system, with the query processing subsystem responsible for most of the disk <span class="s16">I/O</span>. Each request specifies a disk identifier and a logical block number on the disk; in case database data are stored in operating</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">system ﬁles, the request instead speciﬁes the ﬁle identiﬁer and a block number within the ﬁle. Data are transferred between disk and main memory in units of blocks.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">As we saw earlier, a sequence of requests for blocks from disk may be classiﬁed as a sequential access pattern or a random access pattern. In a <i>sequential access </i>pattern, successive requests are for successive block numbers, which are on the same track, or on adjacent tracks. In contrast, in a <i>random access </i>pattern, successive requests are for blocks that are randomly located on disk. Each such request would require a seek, resulting in a longer access time, and a lower number of random <span class="s44">I/O </span>operations per second.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">A number of techniques have been developed for improving the speed of access to blocks, by minimizing the number of accesses, and in particular minimizing the number of random accesses. We describe these techniques below. Reducing the number of random accesses is very important for data stored on magnetic disks; <span class="s44">SSDs </span>support much faster random access than do magnetic disks, so the impact of random access is less with <span class="s44">SSDs</span>, but data access from <span class="s44">SSDs </span>can still beneﬁt from some of the techniques described below.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s39" style="padding-left: 107pt;text-indent: -16pt;text-align: justify;">• <span class="s63">Buﬀering</span><span class="p">. Blocks that are read from disk are stored temporarily in an in-memory buﬀer, to satisfy future requests. Buﬀering is done by both the operating system and the database system. Database buﬀering is discussed in more detail in Section 13.5.</span></p><p class="s63" style="padding-top: 3pt;padding-left: 107pt;text-indent: -16pt;text-align: justify;"><span class="s39">• </span>Read-ahead<span class="p">. When a disk block is accessed, consecutive blocks from the same track are read into an in-memory buﬀer even if there is no pending request for the blocks. In the case of sequential access, such </span>read-ahead <span class="p">ensures that many blocks are already in memory when they are requested, and it minimizes the time wasted in disk seeks and rotational latency per block read. Operating systems also routinely perform read-ahead for consecutive blocks of an operating system ﬁle. Read-ahead is, however, not very useful for random block accesses.</span></p><p class="s63" style="padding-top: 3pt;padding-left: 107pt;text-indent: -16pt;text-align: justify;"><span class="s39">• </span>Scheduling<span class="p">. If several blocks from a cylinder need to be transferred from disk to main memory, we may be able to save access time by requesting the blocks in the order in which they will pass under the heads. If the desired blocks are on diﬀer- ent cylinders, it is advantageous to request the blocks in an order that minimizes disk-arm movement. </span>Disk-arm–scheduling <span class="p">algorithms attempt to order accesses to tracks in a fashion that increases the number of accesses that can be processed. A commonly used algorithm is the </span>elevator algorithm<span class="p">, which works in the same way many elevators do. Suppose that, initially, the arm is moving from the inner- most track toward the outside of the disk. Under the elevator algorithm’s control, for each track for which there is an access request, the arm stops at that track, services requests for the track, and then continues moving outward until there are no waiting requests for tracks farther out. At this point, the arm changes direction and moves toward the inside, again stopping at each track for which there is a re-</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 139pt;text-indent: 0pt;text-align: justify;">quest, until it reaches a track where there is no request for tracks farther toward the center. Then, it reverses direction and starts a new cycle.</p><p style="padding-left: 139pt;text-indent: 13pt;text-align: justify;">Disk controllers usually perform the task of reordering read requests to improve performance, since they are intimately aware of the organization of blocks on disk, of the rotational position of the disk platters, and of the position of the disk arm. To enable such reordering, the disk controller interface must allow multiple requests to be added to a queue; results may be returned in a diﬀerent order from the request order.</p><p class="s39" style="padding-top: 3pt;padding-left: 139pt;text-indent: -16pt;text-align: justify;">• <span class="s63">File organization</span><span class="p">. To reduce block-access time, we can organize blocks on disk in a way that corresponds closely to the way we expect data to be accessed. For exam- ple, if we expect a ﬁle to be accessed sequentially, then we should ideally keep all the blocks of the ﬁle sequentially on adjacent cylinders. Modern disks hide the ex- act block location from the operating system but use a logical numbering of blocks that gives consecutive numbers to blocks that are adjacent to each other. By allo- cating consecutive blocks of a ﬁle to disk blocks that are consecutively numbered, operating systems ensure that ﬁles are stored sequentially.</span></p><p style="padding-left: 139pt;text-indent: 14pt;text-align: justify;">Storing a large ﬁle in a single long sequence of consecutive blocks poses chal- lenges to disk block allocation; instead, operating systems allocate some number of consecutive blocks (an <span class="s63">extent</span>) at a time to a ﬁle. Diﬀerent extents allocated to a ﬁle may not be adjacent to each other on disk. Sequential access to the ﬁle needs one seek per extent, instead of one seek per block if blocks are randomly allocated; with large enough extents, the cost of seeks relative to data transfer costs can be minimized.</p><p style="padding-left: 139pt;text-indent: 14pt;text-align: justify;">Over time, a sequential ﬁle that has multiple small appends may become <span class="s63">frag- mented</span>; that is, its blocks become scattered all over the disk. To reduce fragmen- tation, the system can make a backup copy of the data on disk and restore the entire disk. The restore operation writes back the blocks of each ﬁle contiguously (or nearly so). Some systems (such as diﬀerent versions of the <span class="s44">W</span>indows operat- ing system) have utilities that scan the disk and then move blocks to decrease the fragmentation. The performance increases realized from these techniques can be quite signiﬁcant.</p><p class="s39" style="padding-top: 4pt;padding-left: 139pt;text-indent: -16pt;text-align: justify;">• <span class="s63">Non-volatile write buﬀers</span><span class="p">. Since the contents of main memory are lost in a power failure, information about database updates has to be recorded on disk to sur- vive possible system crashes. For this reason, the performance of update-intensive database applications, such as transaction-processing systems, is heavily depen- dent on the latency of disk writes.</span></p><p style="padding-left: 139pt;text-indent: 16pt;text-align: justify;">We can use <i>non-volatile random-access memory </i>(<span class="s44">NVRAM</span>) to speed up disk writes. The contents of <span class="s44">NVRAM </span>are not lost in power failure. <span class="s44">NVRAM </span>was im- plemented using battery-backed-up <span class="s44">RAM </span>in earlier days, but ﬂash memory is cur- rently the primary medium for non-volatile write buﬀering. The idea is that, when the database system (or the operating system) requests that a block be written to disk, the disk controller writes the block to a <span class="s63">non-volatile write buﬀer </span>and imme-</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 107pt;text-indent: 0pt;text-align: justify;"><a name="bookmark261">diately notiﬁes the operating system that the write completed successfully. The controller can subsequently write the data to their destination on disk in a way that minimizes disk arm movement, using the elevator algorithm, for example. If such write reordering is done without using non-volatile write buﬀers, the database state may become inconsistent in the event of a system crash; recovery algorithms that we study later in Chapter 19 depend on writes being written in the speciﬁed order. When the database system requests a block write, it notices a delay only if the </a><span class="s44">NVRAM </span>buﬀer is full. On recovery from a system crash, any pending buﬀered writes in the <span class="s44">NVRAM </span>are written back to the disk. <span class="s44">NVRAM </span>buﬀers are found in certain high-end disks, but are more frequently found in <span class="s44">RAID </span>controllers.<a name="bookmark296">&zwnj;</a></p><p style="padding-top: 8pt;padding-left: 88pt;text-indent: 17pt;text-align: justify;">In addition to the above low-level optimizations, optimizations to minimize random accesses can be done at a higher level, by clever design of query processing algorithms. We study eﬃcient query processing techniques in Chapter 15.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part236.htm">&lt; 上一个</a><span> | </span><a href="../database.html">内容</a><span> | </span><a href="part238.htm">下一个 &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
