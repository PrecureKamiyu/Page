<?xml version="1.0" encoding="utf-8"?><html xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:svg="http://www.w3.org/2000/svg" xmlns:epub="http://www.idpf.org/2007/ops" xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" epub:prefix="index: http://www.index.com/"><head>
<meta name="dcterms.conformsTo" content="PXE Basic 1.0"></meta>
<meta name="generator" content="PXE Tools version 1.39.109"></meta>
<!--Created by pxe.pl for standard version PXE Basic 1.0,data-profile-product=standard by PXE Tools 1.39.109, partial=false-->
<title>6.3 Multiple Access Links and Protocols</title><link rel="alternate stylesheet" type="text/css" title="sepia" href="../css/sepia.css"></link><link rel="alternate stylesheet" type="text/css" title="night" href="../css/night.css"></link><link rel="stylesheet" type="text/css" title="day" href="../css/main.css"></link><link rel="stylesheet" type="text/css" title="day" href="../css/print.css"></link>
<script src="js/format_lg_obj.js"></script>
</head><body epub:type="bodymatter">
<section id="P700101195200000000000000000245F" class="level1"><header><h1 class="title" id="P700101195200000000000000000AF8C" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AF8C" epub:type="title"><span class="number">6.3</span> Multiple Access Links and Protocols</h1></header>
<p id="P700101195200000000000000000AF8D" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AF8D">In the introduction to this chapter, we noted that there are two types of network links: point-to-point links and broadcast links. A <span class="keyword" id="P7001011952000000000000000002462" data-uri="M06_KURO4140_07_SE_C06.xhtml#P7001011952000000000000000002462"><b>point-to-point link</b></span> consists of a single sender at one end of the link and a single receiver at the other end of the link. Many link-layer protocols have been designed for point-to-point links; the point-to-point protocol (PPP) and high-level data link control (HDLC) are two such protocols. The second type of link, a <span class="keyword" id="P7001011952000000000000000002463" data-uri="M06_KURO4140_07_SE_C06.xhtml#P7001011952000000000000000002463"><b>broadcast link</b></span>, can have multiple sending and receiving nodes all connected to the same, single, shared broadcast channel. The term <i>broadcast</i> is used here because when any one node transmits a frame, the channel broadcasts the frame and each of the other nodes receives a copy. Ethernet and wireless LANs are examples of broadcast link-layer technologies. In this section we’ll take a step back from specific link-layer protocols and first examine a problem of central importance to the link layer: how to coordinate the access of multiple sending and receiving nodes to a shared broadcast channel—the <span class="keyword" id="P7001011952000000000000000002464" data-uri="M06_KURO4140_07_SE_C06.xhtml#P7001011952000000000000000002464"><b>multiple access problem</b></span>. Broadcast channels are often used in LANs, networks that are geographically concentrated in a single building (or on a corporate or university campus). Thus, we’ll look at how multiple access channels are used in LANs at the end of this section.</p>
<p id="P700101195200000000000000000AF8E" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AF8E">We are all familiar with the notion of broadcasting—television has been using it since its invention. But traditional television is a one-way broadcast (that is, one fixed node transmitting to many receiving nodes), while nodes on a computer network broadcast channel can both send and receive. Perhaps a more apt human analogy for a broadcast channel is a cocktail party, where many people gather in a large room (the air providing the broadcast medium) to talk and listen. A second good analogy is something many readers will be familiar with—a classroom—where teacher(s) and student(s) similarly share the same, single, broadcast medium. A central problem in <span class="pagebreak" title="452" id="P7001011952000000000000000002466" data-uri="M06_KURO4140_07_SE_C06.xhtml#P7001011952000000000000000002466" epub:type="pagebreak" role="doc-pagebreak"></span>both scenarios is that of determining who gets to talk (that is, transmit into the channel) and when. As humans, we’ve evolved an elaborate set of protocols for sharing the broadcast channel:</p>
<ul class="ul_none" id="P700101195200000000000000000AF8F" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AF8F">
<li id="P700101195200000000000000000AF90" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AF90"><p id="P700101195200000000000000000AF91" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AF91">“Give everyone a chance to speak.”</p></li>
<li id="P700101195200000000000000000AF92" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AF92"><p id="P700101195200000000000000000AF93" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AF93">“Don’t speak until you are spoken to.”</p></li>
<li id="P700101195200000000000000000AF94" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AF94"><p id="P700101195200000000000000000AF95" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AF95">“Don’t monopolize the conversation.”</p></li>
<li id="P700101195200000000000000000AF96" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AF96"><p id="P700101195200000000000000000AF97" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AF97">“Raise your hand if you have a question.”</p></li>
<li id="P700101195200000000000000000AF98" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AF98"><p id="P700101195200000000000000000AF99" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AF99">“Don’t interrupt when someone is speaking.”</p></li>
<li id="P700101195200000000000000000AF9A" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AF9A"><p id="P700101195200000000000000000AF9B" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AF9B">“Don’t fall asleep when someone is talking.”</p></li>
</ul>
<p id="P700101195200000000000000000AF9C" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AF9C">Computer networks similarly have protocols—so-called <span class="keyword" id="P7001011952000000000000000002475" data-uri="M06_KURO4140_07_SE_C06.xhtml#P7001011952000000000000000002475"><b>multiple access ­protocols</b></span>—by which nodes regulate their transmission into the shared broadcast channel. As shown in <a class="xref" href="#P7001011952000000000000000002476" data-foobar="1"><span class="label">Figure</span> <span class="number">6.8</span></a>, multiple access protocols are needed in a wide variety of network settings, including both wired and wireless access networks, and satellite networks. Although technically each node accesses the broadcast channel through its adapter, in this section we will refer to the <i>node</i> as the sending and</p>
<figure id="P7001011952000000000000000002476" class="figure" data-uri="M06_KURO4140_07_SE_C06.xhtml#P7001011952000000000000000002476">
<img alt="Illustration of various multiple access channels." height="531" width="668" aria-describedby="P700101195200000000000000000247A" id="P700101195200000000000000000AF9D" data-uri="P70010119520000000000000000055CB" src="../images/4055106008.png"></img>
<figcaption id="P700101195200000000000000000AF9E" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AF9E"><header><h1 class="title" id="P700101195200000000000000000AF9F" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AF9F" epub:type="title"><span class="label">Figure </span> <span class="number">6.8</span> Various multiple access channels</h1></header>

</figcaption>
</figure><div class="longdesc" id="P700101195200000000000000000247A" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000247A" aria-hidden="false"><a class="xref" aria-hidden="false" href="../longalt/la_4055106008.xhtml#la_4055106008"><span class="label">Description</span></a></div>
<p class="continued" id="P700101195200000000000000000AFA1" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFA1"><span class="pagebreak" title="453" id="P700101195200000000000000000247D" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000247D" epub:type="pagebreak" role="doc-pagebreak"></span>receiving device. In practice, hundreds or even thousands of nodes can directly communicate over a broadcast channel.</p>
<p id="P700101195200000000000000000AFA2" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFA2">Because all nodes are capable of transmitting frames, more than two nodes can transmit frames at the same time. When this happens, all of the nodes receive multiple frames at the same time; that is, the transmitted frames <span class="keyword" id="P700101195200000000000000000247F" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000247F"><b>collide</b></span> at all of the receivers. Typically, when there is a collision, none of the receiving nodes can make any sense of any of the frames that were transmitted; in a sense, the signals of the colliding frames become inextricably tangled together. Thus, all the frames involved in the collision are lost, and the broadcast channel is wasted during the collision interval. Clearly, if many nodes want to transmit frames frequently, many transmissions will result in collisions, and much of the bandwidth of the broadcast channel will be wasted.</p>
<p id="P700101195200000000000000000AFA3" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFA3">In order to ensure that the broadcast channel performs useful work when multiple nodes are active, it is necessary to somehow coordinate the transmissions of the active nodes. This coordination job is the responsibility of the multiple access protocol. Over the past 40 years, thousands of papers and hundreds of PhD dissertations have been written on multiple access protocols; a comprehensive survey of the first 20 years of this body of work is <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003BD3" data-foobar="7">[Rom 1990]</a>. Furthermore, active research in multiple access protocols continues due to the continued emergence of new types of links, particularly new wireless links.</p>
<p id="P700101195200000000000000000AFA4" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFA4">Over the years, dozens of multiple access protocols have been implemented in a variety of link-layer technologies. Nevertheless, we can classify just about any multiple access protocol as belonging to one of three categories: <span class="keyword" id="P7001011952000000000000000002482" data-uri="M06_KURO4140_07_SE_C06.xhtml#P7001011952000000000000000002482"><b>channel partitioning protocols</b></span>, <span class="keyword" id="P7001011952000000000000000002483" data-uri="M06_KURO4140_07_SE_C06.xhtml#P7001011952000000000000000002483"><b>random access protocols</b></span>, and <span class="keyword" id="P7001011952000000000000000002484" data-uri="M06_KURO4140_07_SE_C06.xhtml#P7001011952000000000000000002484"><b>taking-turns protocols</b></span>. We’ll cover these categories of multiple access protocols in the following three subsections.</p>
<p id="P700101195200000000000000000AFA5" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFA5">Let’s conclude this overview by noting that, ideally, a multiple access protocol for a broadcast channel of rate <i>R</i> bits per second should have the following desirable characteristics:</p>
<ol id="P700101195200000000000000000AFA6" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFA6">
<li id="P700101195200000000000000000AFA7" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFA7"><p id="P700101195200000000000000000AFA8" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFA8">When only one node has data to send, that node has a throughput of <i>R</i> bps.</p></li>
<li id="P700101195200000000000000000AFA9" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFA9"><p id="P700101195200000000000000000AFAA" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFAA">When <i>M</i> nodes have data to send, each of these nodes has a throughput of <i>R</i>/<i>M</i> bps. This need not necessarily imply that each of the <i>M</i> nodes always has an instantaneous rate of <i>R</i>/<i>M</i>, but rather that each node should have an average transmission rate of <i>R</i>/<i>M</i> over some suitably defined interval of time.</p></li>
<li id="P700101195200000000000000000AFAB" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFAB"><p id="P700101195200000000000000000AFAC" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFAC">The protocol is decentralized; that is, there is no master node that represents a single point of failure for the network.</p></li>
<li id="P700101195200000000000000000AFAD" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFAD"><p id="P700101195200000000000000000AFAE" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFAE">The protocol is simple, so that it is inexpensive to implement.</p></li>
</ol>
<section id="P700101195200000000000000000248F" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000248F" class="level2"><header><h1 class="title" id="P700101195200000000000000000AFAF" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFAF" epub:type="title"><span class="number">6.3.1</span> Channel Partitioning Protocols</h1></header>
<p id="P700101195200000000000000000AFB0" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFB0">Recall from our early discussion back in <a class="xref" href="fileP7001011952000000000000000000542.xhtml#P7001011952000000000000000000542" data-foobar="7"><span class="label">Section</span> <span class="number">1.3</span></a> that time-division ­multiplexing (TDM) and frequency-division multiplexing (FDM) are two techniques that can<span class="pagebreak" title="454" id="P7001011952000000000000000002492" data-uri="M06_KURO4140_07_SE_C06.xhtml#P7001011952000000000000000002492" epub:type="pagebreak" role="doc-pagebreak"></span></p>
<figure id="P7001011952000000000000000002493" class="figure" data-uri="M06_KURO4140_07_SE_C06.xhtml#P7001011952000000000000000002493">
<img alt="A four-node TDM and FDM example." height="403" width="472" aria-describedby="P7001011952000000000000000002497" id="P700101195200000000000000000AFB1" data-uri="P70010119520000000000000000055CC" src="../images/4055106009.png"></img>
<figcaption id="P700101195200000000000000000AFB2" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFB2"><header><h1 class="title" id="P700101195200000000000000000AFB3" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFB3" epub:type="title"><span class="label">Figure </span> <span class="number">6.9</span> A four-node TDM and FDM example</h1></header>

</figcaption>
</figure><div class="longdesc" id="P7001011952000000000000000002497" data-uri="M06_KURO4140_07_SE_C06.xhtml#P7001011952000000000000000002497" aria-hidden="false"><a class="xref" aria-hidden="false" href="../longalt/la_4055106009.xhtml#la_4055106009"><span class="label">Description</span></a></div>
<p class="continued" id="P700101195200000000000000000AFB7" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFB7">be used to partition a broadcast channel’s bandwidth among all nodes sharing that channel. As an example, suppose the channel supports <i>N</i> nodes and that the transmission rate of the channel is <i>R</i> bps. TDM divides time into <span class="keyword" id="P700101195200000000000000000249C" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000249C"><b>time frames</b></span> and further divides each time frame into <i>N</i> <span class="keyword" id="P700101195200000000000000000249D" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000249D"><b>time slots</b></span>. (The TDM time frame should not be confused with the link-layer unit of data exchanged between sending and receiving adapters, which is also called a frame. In order to reduce confusion, in this subsection we’ll refer to the link-layer unit of data exchanged as a packet.) Each time slot is then assigned to one of the <i>N</i> nodes. Whenever a node has a packet to send, it transmits the packet’s bits during its assigned time slot in the revolving TDM frame. Typically, slot sizes are chosen so that a single packet can be transmitted during a slot time. <a class="xref" href="#P7001011952000000000000000002493" data-foobar="1"><span class="label">Figure</span> <span class="number">6.9</span></a> shows a simple four-node TDM example. Returning to our cocktail party analogy, a TDM-regulated cocktail party would allow one partygoer to speak for a fixed period of time, then allow another partygoer to speak for the same amount of time, and so on. Once everyone had had a chance to talk, the ­pattern would repeat.</p>
<p id="P700101195200000000000000000AFB8" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFB8">TDM is appealing because it eliminates collisions and is perfectly fair: Each node gets a dedicated transmission rate of <i>R</i>/<i>N</i> bps during each frame time. However, it has two major drawbacks. First, a node is limited to an average rate of <i>R</i>/<i>N</i> bps even when it is the only node with packets to send. A second drawback is that a node must always wait for its turn in the transmission sequence—again, even when it is the only node with a frame to send. Imagine the partygoer who is the only one with anything to say (and imagine that this is the even rarer circumstance where everyone <span class="pagebreak" title="455" id="P700101195200000000000000000249F" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000249F" epub:type="pagebreak" role="doc-pagebreak"></span>wants to hear what that one person has to say). Clearly, TDM would be a poor choice for a multiple access protocol for this particular party.</p>
<p id="P700101195200000000000000000AFB9" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFB9">While TDM shares the broadcast channel in time, FDM divides the <i>R</i> bps channel into different frequencies (each with a bandwidth of <i>R</i>/<i>N</i>) and assigns each frequency to one of the <i>N</i> nodes. FDM thus creates <i>N</i> smaller channels of <i>R</i>/<i>N</i> bps out of the single, larger <i>R</i> bps channel. FDM shares both the advantages and drawbacks of TDM. It avoids collisions and divides the bandwidth fairly among the <i>N</i> nodes. However, FDM also shares a principal disadvantage with TDM—a node is limited to a bandwidth of <i>R</i>/<i>N</i>, even when it is the only node with packets to send.</p>
<p id="P700101195200000000000000000AFBA" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFBA">A third channel partitioning protocol is <span class="keyword" id="P70010119520000000000000000024A2" data-uri="M06_KURO4140_07_SE_C06.xhtml#P70010119520000000000000000024A2"><b>code division multiple access (CDMA)</b></span>. While TDM and FDM assign time slots and frequencies, respectively, to the nodes, CDMA assigns a different <i>code</i> to each node. Each node then uses its unique code to encode the data bits it sends. If the codes are chosen carefully, CDMA networks have the wonderful property that different nodes can transmit <i>simultaneously</i> and yet have their respective receivers correctly receive a sender’s encoded data bits (assuming the receiver knows the sender’s code) in spite of interfering transmissions by other nodes. CDMA has been used in military systems for some time (due to its anti-jamming properties) and now has widespread civilian use, particularly in cellular telephony. Because CDMA’s use is so tightly tied to wireless channels, we’ll save our discussion of the technical details of CDMA until <a class="xref" href="fileP70010119520000000000000000028C7.xhtml#P70010119520000000000000000028C7" data-foobar="7"><span class="label">Chapter</span> <span class="number">7</span></a>. For now, it will suffice to know that CDMA codes, like time slots in TDM and frequencies in FDM, can be allocated to the multiple access channel users.</p>
</section>
<section id="P70010119520000000000000000024A3" data-uri="M06_KURO4140_07_SE_C06.xhtml#P70010119520000000000000000024A3" class="level2"><header><h1 class="title" id="P700101195200000000000000000AFBB" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFBB" epub:type="title"><span class="number">6.3.2</span> Random Access Protocols</h1></header>
<p id="P700101195200000000000000000AFBC" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFBC">The second broad class of multiple access protocols are random access protocols. In a random access protocol, a transmitting node always transmits at the full rate of the channel, namely, <i>R</i> bps. When there is a collision, each node involved in the collision repeatedly retransmits its frame (that is, packet) until its frame gets through without a collision. But when a node experiences a collision, it doesn’t necessarily retransmit the frame right away. <i>Instead it waits a random delay before retransmitting the frame</i>. Each node involved in a collision chooses independent random delays. Because the random delays are independently chosen, it is possible that one of the nodes will pick a delay that is sufficiently less than the delays of the other colliding nodes and will therefore be able to sneak its frame into the channel without a collision.</p>
<p id="P700101195200000000000000000AFBD" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFBD">There are dozens if not hundreds of random access protocols described in the literature <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003BD3" data-foobar="7">[Rom 1990</a>; <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003837" data-foobar="7">Bertsekas 1991]</a>. In this section we’ll describe a few of the most commonly used random access protocols—the ALOHA protocols <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P70010119520000000000000000037E8" data-foobar="7">[Abramson 1970</a>; <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P70010119520000000000000000037EA" data-foobar="7">Abramson 1985</a>; <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P70010119520000000000000000037EC" data-foobar="7">Abramson 2009]</a> and the carrier sense multiple access (CSMA) protocols <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P70010119520000000000000000039EC" data-foobar="7">[Kleinrock 1975b]</a>. Ethernet <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003A4C" data-foobar="7">[Metcalfe 1976]</a> is a popular and widely deployed CSMA protocol.</p>
<section id="P70010119520000000000000000024A7" data-uri="M06_KURO4140_07_SE_C06.xhtml#P70010119520000000000000000024A7" class="level3"><header><h1 class="title" id="P700101195200000000000000000AFBE" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFBE" epub:type="title"><span class="pagebreak" title="456" id="P70010119520000000000000000024A9" data-uri="M06_KURO4140_07_SE_C06.xhtml#P70010119520000000000000000024A9" epub:type="pagebreak" role="doc-pagebreak"></span>Slotted ALOHA</h1></header>
<p id="P700101195200000000000000000AFBF" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFBF">Let’s begin our study of random access protocols with one of the simplest random access protocols, the slotted ALOHA protocol. In our description of slotted ALOHA, we assume the following:</p>
<ul id="P700101195200000000000000000AFC0" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFC0">
<li id="P700101195200000000000000000AFC1" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFC1"><p id="P700101195200000000000000000AFC2" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFC2">All frames consist of exactly <i>L</i> bits.</p></li>
<li id="P700101195200000000000000000AFC3" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFC3"><p id="P700101195200000000000000000AFC4" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFC4">Time is divided into slots of size <i>L</i>/<i>R</i> seconds (that is, a slot equals the time to transmit one frame).</p></li>
<li id="P700101195200000000000000000AFC5" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFC5"><p id="P700101195200000000000000000AFC6" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFC6">Nodes start to transmit frames only at the beginnings of slots.</p></li>
<li id="P700101195200000000000000000AFC7" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFC7"><p id="P700101195200000000000000000AFC8" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFC8">The nodes are synchronized so that each node knows when the slots begin.</p></li>
<li id="P700101195200000000000000000AFC9" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFC9"><p id="P700101195200000000000000000AFCA" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFCA">If two or more frames collide in a slot, then all the nodes detect the collision event before the slot ends.</p></li>
</ul>
<p class="continued" id="P700101195200000000000000000AFCB" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFCB">Let <i>p</i> be a probability, that is, a number between 0 and 1. The operation of slotted ALOHA in each node is simple:</p>
<ul id="P700101195200000000000000000AFCC" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFCC">
<li id="P700101195200000000000000000AFCD" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFCD"><p id="P700101195200000000000000000AFCE" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFCE">When the node has a fresh frame to send, it waits until the beginning of the next slot and transmits the entire frame in the slot.</p></li>
<li id="P700101195200000000000000000AFCF" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFCF"><p id="P700101195200000000000000000AFD0" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFD0">If there isn’t a collision, the node has successfully transmitted its frame and thus need not consider retransmitting the frame. (The node can prepare a new frame for transmission, if it has one.)</p></li>
<li id="P700101195200000000000000000AFD1" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFD1"><p id="P700101195200000000000000000AFD2" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFD2">If there is a collision, the node detects the collision before the end of the slot. The node retransmits its frame in each subsequent slot with probability <i>p</i> until the frame is transmitted without a collision.</p></li>
</ul>
<p id="P700101195200000000000000000AFD3" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFD3">By retransmitting with probability <i>p</i>, we mean that the node effectively tosses a biased coin; the event heads corresponds to “retransmit,” which occurs with probability <i>p</i>. The event tails corresponds to “skip the slot and toss the coin again in the next slot”; this occurs with probability <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="61" altimg-height="17" altimg="../images/ch06math23.png"><m:mrow><m:mrow><m:mo>(</m:mo><m:mrow><m:mn>1</m:mn><m:mo>−</m:mo><m:mi>p</m:mi></m:mrow><m:mo>)</m:mo></m:mrow></m:mrow></m:math></span>. All nodes involved in the collision toss their coins independently.</p>
<p id="P700101195200000000000000000AFD4" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFD4">Slotted ALOHA would appear to have many advantages. Unlike channel partitioning, slotted ALOHA allows a node to transmit continuously at the full rate, <i>R</i>, when that node is the only active node. (A node is said to be active if it has frames to send.) Slotted ALOHA is also highly decentralized, because each node detects collisions and independently decides when to retransmit. (Slotted ALOHA does, however, require the slots to be synchronized in the nodes; shortly we’ll discuss an unslotted version of the ALOHA protocol, as well as CSMA protocols, none of which require such synchronization.) Slotted ALOHA is also an extremely simple protocol.</p>
<p id="P700101195200000000000000000AFD5" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFD5">Slotted ALOHA works well when there is only one active node, but how ­efficient is it when there are multiple active nodes? There are two possible efficiency<span class="pagebreak" title="457" id="P70010119520000000000000000024C1" data-uri="M06_KURO4140_07_SE_C06.xhtml#P70010119520000000000000000024C1" epub:type="pagebreak" role="doc-pagebreak"></span></p>
<figure id="P70010119520000000000000000024C2" class="figure" data-uri="M06_KURO4140_07_SE_C06.xhtml#P70010119520000000000000000024C2">
<img alt="Nodes 1, 2, and 3 collide in the first slot. Node 2 finally succeeds in the fourth slot, node 1 in the eighth slot, and node 3 in the ninth slot." height="346" width="670" aria-describedby="P70010119520000000000000000024C6" id="P700101195200000000000000000AFD6" data-uri="P70010119520000000000000000055CD" src="../images/4055106010.png"></img>
<figcaption id="P700101195200000000000000000AFD7" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFD7"><header><h1 class="title" id="P700101195200000000000000000AFD8" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFD8" epub:type="title"><span class="label">Figure </span> <span class="number">6.10</span> Nodes 1, 2, and 3 collide in the first slot. Node 2 finally succeeds in the fourth slot, node 1 in the eighth slot, and node 3 in the ninth slot</h1></header>

</figcaption>
</figure><div class="longdesc" id="P70010119520000000000000000024C6" data-uri="M06_KURO4140_07_SE_C06.xhtml#P70010119520000000000000000024C6" aria-hidden="false"><a class="xref" aria-hidden="false" href="../longalt/la_4055106010.xhtml#la_4055106010"><span class="label">Description</span></a></div>
<p class="continued" id="P700101195200000000000000000AFEE" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFEE">concerns here. First, as shown in <a class="xref" href="#P70010119520000000000000000024C2" data-foobar="1"><span class="label">Figure</span> <span class="number">6.10</span></a>, when there are multiple active nodes, a certain fraction of the slots will have collisions and will therefore be “wasted.” The second concern is that another fraction of the slots will be <i>empty</i> because all active nodes refrain from transmitting as a result of the probabilistic transmission policy. The only “unwasted” slots will be those in which exactly one node transmits. A slot in which exactly one node transmits is said to be a <span class="keyword" id="P70010119520000000000000000024DD" data-uri="M06_KURO4140_07_SE_C06.xhtml#P70010119520000000000000000024DD"><b>successful slot</b></span>. The <span class="keyword" id="P70010119520000000000000000024DE" data-uri="M06_KURO4140_07_SE_C06.xhtml#P70010119520000000000000000024DE"><b>efficiency</b></span> of a slotted multiple access protocol is defined to be the long-run fraction of successful slots in the case when there are a large number of active nodes, each always having a large number of frames to send. Note that if no form of access control were used, and each node were to immediately retransmit after each collision, the efficiency would be zero. Slotted ALOHA clearly increases the efficiency beyond zero, but by how much?</p>
<p id="P700101195200000000000000000AFEF" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFEF">We now proceed to outline the derivation of the maximum efficiency of slotted ALOHA. To keep this derivation simple, let’s modify the protocol a little and assume that each node attempts to transmit a frame in each slot with probability <i>p</i>. (That is, we assume that each node always has a frame to send and that the node transmits with probability <i>p</i> for a fresh frame as well as for a frame that has already suffered a collision.) Suppose there are <i>N</i> nodes. Then the probability that a given slot is a successful slot is the probability that one of the nodes transmits and that the remaining <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="51" altimg-height="14" altimg="../images/ch06math24.png"><m:mrow><m:mi>N</m:mi><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:math></span> nodes do not transmit. The probability that a given node transmits is <i>p;</i> the probability that the remaining nodes do not transmit is <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="87" altimg-height="21" altimg="../images/ch06math25.png"><m:mrow><m:msup><m:mrow><m:mrow><m:mo>(</m:mo><m:mrow><m:mn>1</m:mn><m:mo>−</m:mo><m:mi>p</m:mi></m:mrow><m:mo>)</m:mo></m:mrow></m:mrow><m:mrow><m:mi>N</m:mi><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:msup></m:mrow></m:math></span>. Therefore the probability a given node has a success is <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="99" altimg-height="21" altimg="../images/ch06math26.png"><m:mrow><m:mi>p</m:mi><m:msup><m:mrow><m:mrow><m:mo>(</m:mo><m:mrow><m:mn>1</m:mn><m:mo>−</m:mo><m:mi>p</m:mi></m:mrow><m:mo>)</m:mo></m:mrow></m:mrow><m:mrow><m:mi>N</m:mi><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:msup></m:mrow></m:math></span>. Because there are <i>N</i> nodes, the probability that any one of the <i>N</i> nodes has a success is <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="110" altimg-height="21" altimg="../images/ch06math27.png"><m:mrow><m:mi>N</m:mi><m:mi>p</m:mi><m:msup><m:mrow><m:mrow><m:mo>(</m:mo><m:mrow><m:mn>1</m:mn><m:mo>−</m:mo><m:mi>p</m:mi></m:mrow><m:mo>)</m:mo></m:mrow></m:mrow><m:mrow><m:mi>N</m:mi><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:msup></m:mrow></m:math></span>.</p>
<p id="P700101195200000000000000000AFF0" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFF0"><span class="pagebreak" title="458" id="P70010119520000000000000000024E1" data-uri="M06_KURO4140_07_SE_C06.xhtml#P70010119520000000000000000024E1" epub:type="pagebreak" role="doc-pagebreak"></span>Thus, when there are <i>N</i> active nodes, the efficiency of slotted ALOHA is <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="112" altimg-height="21" altimg="../images/ch06math28.png"><m:mrow><m:mi>N</m:mi><m:mi>p</m:mi><m:msup><m:mrow><m:mrow><m:mo>(</m:mo><m:mrow><m:mn>1</m:mn><m:mo>−</m:mo><m:mi>p</m:mi></m:mrow><m:mo>)</m:mo></m:mrow></m:mrow><m:mrow><m:mi>N</m:mi><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:msup></m:mrow></m:math></span>. To obtain the <i>maximum</i> efficiency for <i>N</i> active nodes, we have to find the <i>p</i>* that maximizes this expression. (See the homework problems for a general outline of this derivation.) And to obtain the maximum efficiency for a large number of active nodes, we take the limit of <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="132" altimg-height="20" altimg="../images/ch06math29.png"><m:mrow><m:mi>N</m:mi><m:mi>p</m:mi><m:mo>*</m:mo><m:msup><m:mrow><m:mrow><m:mo>(</m:mo><m:mrow><m:mn>1</m:mn><m:mo>−</m:mo><m:mi>p</m:mi><m:mo>*</m:mo></m:mrow><m:mo>)</m:mo></m:mrow></m:mrow><m:mrow><m:mi>N</m:mi><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:msup></m:mrow></m:math></span> as <i>N</i> approaches infinity. (Again, see the homework problems.) After performing these calculations, we’ll find that the maximum efficiency of the protocol is given by <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="80" altimg-height="13" altimg="../images/ch06math30.png"><m:mrow><m:mn>1</m:mn><m:mo>/</m:mo><m:mi>e</m:mi><m:mo>=</m:mo><m:mn>0.37</m:mn></m:mrow></m:math></span>. That is, when a large number of nodes have many frames to transmit, then (at best) only 37 percent of the slots do useful work. Thus the effective transmission rate of the channel is not <i>R</i> bps but only 0.37 <i>R</i> bps! A similar analysis also shows that 37 percent of the slots go empty and 26 percent of slots have collisions. Imagine the poor network administrator who has purchased a 100-Mbps slotted ALOHA system, expecting to be able to use the network to transmit data among a large number of users at an aggregate rate of, say, 80 Mbps! Although the channel is capable of transmitting a given frame at the full channel rate of 100 Mbps, in the long run, the successful throughput of this channel will be less than 37 Mbps.</p>
</section>
<section id="P70010119520000000000000000024E2" data-uri="M06_KURO4140_07_SE_C06.xhtml#P70010119520000000000000000024E2" class="level3"><header><h1 class="title" id="P700101195200000000000000000AFF1" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFF1" epub:type="title">ALOHA</h1></header>
<p id="P700101195200000000000000000AFF2" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFF2">The slotted ALOHA protocol required that all nodes synchronize their transmissions to start at the beginning of a slot. The first ALOHA protocol <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P70010119520000000000000000037E8" data-foobar="7">[Abramson 1970]</a> was actually an unslotted, fully decentralized protocol. In pure ALOHA, when a frame first arrives (that is, a network-layer datagram is passed down from the network layer at the sending node), the node immediately transmits the frame in its entirety into the broadcast channel. If a transmitted frame experiences a collision with one or more other transmissions, the node will then immediately (after completely transmitting its collided frame) retransmit the frame with probability <i>p</i>. Otherwise, the node waits for a frame transmission time. After this wait, it then transmits the frame with probability <i>p</i>, or waits (remaining idle) for another frame time with probability 1 – <i>p</i>.</p>
<p id="P700101195200000000000000000AFF3" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFF3">To determine the maximum efficiency of pure ALOHA, we focus on an individual node. We’ll make the same assumptions as in our slotted ALOHA analysis and take the frame transmission time to be the unit of time. At any given time, the probability that a node is transmitting a frame is <i>p</i>. Suppose this frame begins transmission at time <i>t</i><sub>0</sub>. As shown in <a class="xref" href="#P70010119520000000000000000024E7" data-foobar="1"><span class="label">Figure</span> <span class="number">6.11</span></a>, in order for this frame to be successfully transmitted, no other nodes can begin their transmission in the interval of time <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="83" altimg-height="17" altimg="../images/ch06math31.png"><m:mrow><m:mrow><m:mo>[</m:mo> <m:mrow><m:msub><m:mi>t</m:mi><m:mn>0</m:mn></m:msub><m:mo>−</m:mo><m:mn>1</m:mn><m:mo>,</m:mo><m:msub><m:mi>t</m:mi><m:mn>0</m:mn></m:msub></m:mrow><m:mo>]</m:mo></m:mrow></m:mrow></m:math></span>. Such a transmission would overlap with the beginning of the transmission of node <i>i</i>’s frame. The probability that all other nodes do not begin a transmission in this interval is <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="88" altimg-height="20" altimg="../images/ch06math32.png"><m:mrow><m:msup><m:mrow><m:mrow><m:mo>(</m:mo><m:mrow><m:mn>1</m:mn><m:mo>−</m:mo><m:mi>p</m:mi></m:mrow><m:mo>)</m:mo></m:mrow></m:mrow><m:mrow><m:mi>N</m:mi><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:msup></m:mrow></m:math></span>. Similarly, no other node can begin a transmission while node <i>i</i> is transmitting, as such a transmission would overlap with the latter part of node <i>i</i>’s transmission. The probability that all other nodes do not begin a transmission in this interval is also <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="88" altimg-height="21" altimg="../images/ch06math33.png"><m:mrow><m:msup><m:mrow><m:mrow><m:mo>(</m:mo><m:mrow><m:mn>1</m:mn><m:mo>−</m:mo><m:mi>p</m:mi></m:mrow><m:mo>)</m:mo></m:mrow></m:mrow><m:mrow><m:mi>N</m:mi><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:msup></m:mrow></m:math></span>. Thus, the probability that a given node has a successful transmission is <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="115" altimg-height="25" altimg="../images/ch06math34.png"><m:mrow><m:mi>p</m:mi><m:msup><m:mrow><m:mrow><m:mo>(</m:mo><m:mrow><m:mn>1</m:mn><m:mo>−</m:mo><m:mi>p</m:mi></m:mrow><m:mo>)</m:mo></m:mrow></m:mrow><m:mrow><m:mn>2</m:mn><m:mrow><m:mo>(</m:mo><m:mrow><m:mi>N</m:mi><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow><m:mo>)</m:mo></m:mrow></m:mrow></m:msup></m:mrow></m:math></span>. By taking limits as in the slotted ALOHA case, we find that the maximum efficiency of the pure ALOHA protocol is only 1/(2<i>e</i>)—exactly half that of slotted ALOHA. This then is the price to be paid for a fully decentralized ALOHA protocol.<span class="pagebreak" title="459" id="P70010119520000000000000000024E6" data-uri="M06_KURO4140_07_SE_C06.xhtml#P70010119520000000000000000024E6" epub:type="pagebreak" role="doc-pagebreak"></span></p>
<figure id="P70010119520000000000000000024E7" class="figure" data-uri="M06_KURO4140_07_SE_C06.xhtml#P70010119520000000000000000024E7">
<img alt="Illustration of interfering transmissions in pure ALOHA." height="279" width="668" aria-describedby="P70010119520000000000000000024EB" id="P700101195200000000000000000AFF4" data-uri="P70010119520000000000000000055CE" src="../images/4055106011.png"></img>
<figcaption id="P700101195200000000000000000AFF5" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFF5"><header><h1 class="title" id="P700101195200000000000000000AFF6" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFF6" epub:type="title"><span class="label">Figure </span> <span class="number">6.11</span> Interfering transmissions in pure ALOHA</h1></header>

</figcaption>
</figure><div class="longdesc" id="P70010119520000000000000000024EB" data-uri="M06_KURO4140_07_SE_C06.xhtml#P70010119520000000000000000024EB" aria-hidden="false"><a class="xref" aria-hidden="false" href="../longalt/la_4055106011.xhtml#la_4055106011"><span class="label">Description</span></a></div>
</section>
<section id="P70010119520000000000000000024ED" data-uri="M06_KURO4140_07_SE_C06.xhtml#P70010119520000000000000000024ED" class="level3"><header><h1 class="title" id="P700101195200000000000000000AFF8" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFF8" epub:type="title">Carrier Sense Multiple Access (CSMA)</h1></header>
<p id="P700101195200000000000000000AFF9" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFF9">In both slotted and pure ALOHA, a node’s decision to transmit is made independently of the activity of the other nodes attached to the broadcast channel. In particular, a node neither pays attention to whether another node happens to be transmitting when it begins to transmit, nor stops transmitting if another node begins to interfere with its transmission. In our cocktail party analogy, ALOHA protocols are quite like a boorish partygoer who continues to chatter away regardless of whether other people are talking. As humans, we have human protocols that allow us not only to behave with more civility, but also to decrease the amount of time spent “colliding” with each other in conversation and, consequently, to increase the amount of data we exchange in our conversations. Specifically, there are two important rules for polite human conversation:</p>
<ul id="P700101195200000000000000000AFFA" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFFA">
<li id="P700101195200000000000000000AFFB" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFFB"><p id="P700101195200000000000000000AFFC" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFFC"><span class="leadin">Listen before speaking.</span> If someone else is speaking, wait until they are finished. In the networking world, this is called <span class="keyword" id="P70010119520000000000000000024F3" data-uri="M06_KURO4140_07_SE_C06.xhtml#P70010119520000000000000000024F3"><b>carrier sensing</b></span>—a node listens to the channel before transmitting. If a frame from another node is currently being transmitted into the channel, a node then waits until it detects no transmissions for a short amount of time and then begins transmission.</p></li>
<li id="P700101195200000000000000000AFFD" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFFD"><p id="P700101195200000000000000000AFFE" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFFE"><span class="leadin">If someone else begins talking at the same time, stop talking.</span> In the networking world, this is called <span class="keyword" id="P70010119520000000000000000024F6" data-uri="M06_KURO4140_07_SE_C06.xhtml#P70010119520000000000000000024F6"><b>collision detection</b></span>—a transmitting node listens to the channel while it is transmitting. If it detects that another node is transmitting an interfering frame, it stops transmitting and waits a random amount of time before repeating the sense-and-transmit-when-idle cycle.</p></li>
</ul>
<p id="P700101195200000000000000000AFFF" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000AFFF">These two rules are embodied in the family of <span class="keyword" id="P70010119520000000000000000024F8" data-uri="M06_KURO4140_07_SE_C06.xhtml#P70010119520000000000000000024F8"><b>carrier sense multiple access (CSMA)</b></span> and <span class="keyword" id="P70010119520000000000000000024F9" data-uri="M06_KURO4140_07_SE_C06.xhtml#P70010119520000000000000000024F9"><b>CSMA with collision detection (CSMA/CD)</b></span> protocols <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P70010119520000000000000000039EC" data-foobar="7">[Kleinrock 1975b</a>; <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003A4C" data-foobar="7">Metcalfe 1976</a>; <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003A18" data-foobar="7">Lam 1980</a>; <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003BD3" data-foobar="7">Rom 1990]</a>. Many variations on CSMA and</p>
<aside class="sidebar" id="P70010119520000000000000000024FA" data-uri="M06_KURO4140_07_SE_C06.xhtml#P70010119520000000000000000024FA"><header><h1 class="title" id="P700101195200000000000000000B000" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B000" epub:type="title"><span class="pagebreak" title="460" id="P70010119520000000000000000024FC" data-uri="M06_KURO4140_07_SE_C06.xhtml#P70010119520000000000000000024FC" epub:type="pagebreak" role="doc-pagebreak"></span><span class="label">CASE HISTORY </span></h1></header>
<section id="P70010119520000000000000000024FD" data-uri="M06_KURO4140_07_SE_C06.xhtml#P70010119520000000000000000024FD"><header><h1 class="title" id="P700101195200000000000000000B001" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B001" epub:type="title">NORM ABRAMSON AND ALOHANET</h1></header>
<p id="P700101195200000000000000000B002" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B002">Norm Abramson, a PhD engineer, had a passion for surfing and an interest in packet switching. This combination of interests brought him to the University of Hawaii in 1969. Hawaii consists of many mountainous islands, making it difficult to install and operate land-based networks. When not surfing, Abramson thought about how to design a network that does packet switching over radio. The network he designed had one central host and several secondary nodes scattered over the Hawaiian Islands. The network had two channels, each using a different frequency band. The downlink channel broadcasted packets from the central host to the secondary hosts; and the upstream channel sent packets from the secondary hosts to the central host. In addition to sending informational packets, the central host also sent on the downstream channel an acknowledgment for each packet successfully received from the secondary hosts.</p>
<p id="P700101195200000000000000000B003" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B003">Because the secondary hosts transmitted packets in a decentralized fashion, collisions on the upstream channel inevitably occurred. This observation led Abramson to devise the pure ALOHA protocol, as described in this chapter. In 1970, with continued funding from ARPA, Abramson connected his ALOHAnet to the ARPAnet. Abramson’s work is important not only because it was the first example of a radio packet network, but also because it inspired Bob Metcalfe. A few years later, Metcalfe modified the ALOHA protocol to create the CSMA/CD protocol and the Ethernet LAN.</p>
</section>
</aside>
<p class="continued" id="P700101195200000000000000000B004" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B004">CSMA/CD have been proposed. Here, we’ll consider a few of the most important, and fundamental, characteristics of CSMA and CSMA/CD.</p>
<p id="P700101195200000000000000000B005" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B005">The first question that you might ask about CSMA is why, if all nodes perform carrier sensing, do collisions occur in the first place? After all, a node will refrain from transmitting whenever it senses that another node is transmitting. The answer to the question can best be illustrated using space-time diagrams <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003A58" data-foobar="7">[Molle 1987]</a>. ­<a class="xref" href="#P7001011952000000000000000002505" data-foobar="1"><span class="label">Figure</span> <span class="number">6.12</span></a> shows a space-time diagram of four nodes (A, B, C, D) attached to a linear broadcast bus. The horizontal axis shows the position of each node in space; the vertical axis represents time.</p>
<p id="P700101195200000000000000000B006" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B006">At time <i>t</i><sub>0</sub>, node B senses the channel is idle, as no other nodes are currently transmitting. Node B thus begins transmitting, with its bits propagating in both directions along the broadcast medium. The downward propagation of B’s bits in <a class="xref" href="#P7001011952000000000000000002505" data-foobar="1"><span class="label">Figure</span> <span class="number">6.12</span></a> with increasing time indicates that a nonzero amount of time is needed for B’s bits actually to propagate (albeit at near the speed of light) along the broadcast medium. At time <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="81" altimg-height="17" altimg="../images/ch06math35.png"><m:mrow><m:msub><m:mi>t</m:mi><m:mn>1</m:mn></m:msub><m:mrow><m:mo>(</m:mo><m:mrow><m:msub><m:mi>t</m:mi><m:mn>1</m:mn></m:msub><m:mo>&gt;</m:mo><m:msub><m:mi>t</m:mi><m:mn>0</m:mn></m:msub></m:mrow><m:mo>)</m:mo></m:mrow></m:mrow></m:math></span>, node D has a frame to send. Although node B is currently transmitting at time <i>t</i><sub>1</sub>, the bits being transmitted by B have yet to reach D, and thus D senses<span class="pagebreak" title="461" id="P7001011952000000000000000002504" data-uri="M06_KURO4140_07_SE_C06.xhtml#P7001011952000000000000000002504" epub:type="pagebreak" role="doc-pagebreak"></span></p>
<figure id="P7001011952000000000000000002505" class="figure" data-uri="M06_KURO4140_07_SE_C06.xhtml#P7001011952000000000000000002505">
<img alt="Space-time diagram of two CSMA nodes with colliding transmissions." height="575" width="521" aria-describedby="P7001011952000000000000000002509" id="P700101195200000000000000000B007" data-uri="P70010119520000000000000000055CF" src="../images/4055106012.png"></img>
<figcaption id="P700101195200000000000000000B008" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B008"><header><h1 class="title" id="P700101195200000000000000000B009" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B009" epub:type="title"><span class="label">Figure </span> <span class="number">6.12</span> Space-time diagram of two CSMA nodes with colliding transmissions</h1></header>

</figcaption>
</figure><div class="longdesc" id="P7001011952000000000000000002509" data-uri="M06_KURO4140_07_SE_C06.xhtml#P7001011952000000000000000002509" aria-hidden="false"><a class="xref" aria-hidden="false" href="../longalt/la_4055106012.xhtml#la_4055106012"><span class="label">Description</span></a></div>
<p class="continued" id="P700101195200000000000000000B00C" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B00C">the channel idle at <i>t</i><sub>1</sub>. In accordance with the CSMA protocol, D thus begins transmitting its frame. A short time later, B’s transmission begins to interfere with D’s transmission at D. From <a class="xref" href="#P7001011952000000000000000002505" data-foobar="1"><span class="label">Figure</span> <span class="number">6.12</span></a>, it is evident that the end-to-end <span class="keyword" id="P700101195200000000000000000250D" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000250D"><b>channel propagation delay</b></span> of a broadcast channel—the time it takes for a signal to propagate from one of the nodes to another—will play a crucial role in determining its performance. The longer this propagation delay, the larger the chance that a carrier-sensing node is not yet able to sense a transmission that has already begun at another node in the network.</p>
</section>
<section id="P700101195200000000000000000250E" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000250E" class="level3"><header><h1 class="title" id="P700101195200000000000000000B00D" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B00D" epub:type="title">Carrier Sense Multiple Access with Collision Dection (CSMA/CD)</h1></header>
<p id="P700101195200000000000000000B00E" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B00E">In <a class="xref" href="#P7001011952000000000000000002505" data-foobar="1"><span class="label">Figure</span> <span class="number">6.12</span></a>, nodes do not perform collision detection; both B and D continue to transmit their frames in their entirety even though a collision has occurred. When a node performs collision detection, it ceases transmission as soon as it detects a collision. <a class="xref" href="#P7001011952000000000000000002512" data-foobar="1"><span class="label">Figure</span> <span class="number">6.13</span></a> shows the same scenario as in <a class="xref" href="#P7001011952000000000000000002505" data-foobar="1"><span class="label">Figure</span> <span class="number">6.12</span></a>, except that the two<span class="pagebreak" title="462" id="P7001011952000000000000000002511" data-uri="M06_KURO4140_07_SE_C06.xhtml#P7001011952000000000000000002511" epub:type="pagebreak" role="doc-pagebreak"></span></p>
<figure id="P7001011952000000000000000002512" class="figure" data-uri="M06_KURO4140_07_SE_C06.xhtml#P7001011952000000000000000002512">
<img alt="Illustration of CSMA with collision detection." height="578" width="521" aria-describedby="P7001011952000000000000000002516" id="P700101195200000000000000000B00F" data-uri="P70010119520000000000000000055D0" src="../images/4055106013.png"></img>
<figcaption id="P700101195200000000000000000B010" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B010"><header><h1 class="title" id="P700101195200000000000000000B011" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B011" epub:type="title"><span class="label">Figure </span> <span class="number">6.13</span> CSMA with collision detection</h1></header>

</figcaption>
</figure><div class="longdesc" id="P7001011952000000000000000002516" data-uri="M06_KURO4140_07_SE_C06.xhtml#P7001011952000000000000000002516" aria-hidden="false"><a class="xref" aria-hidden="false" href="../longalt/la_4055106013.xhtml#la_4055106013"><span class="label">Description</span></a></div>
<p class="continued" id="P700101195200000000000000000B013" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B013">nodes each abort their transmission a short time after detecting a collision. Clearly, adding collision detection to a multiple access protocol will help protocol performance by not transmitting a useless, damaged (by interference with a frame from another node) frame in its entirety.</p>
<p id="P700101195200000000000000000B014" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B014">Before analyzing the CSMA/CD protocol, let us now summarize its operation from the perspective of an adapter (in a node) attached to a broadcast channel:</p>
<ol id="P700101195200000000000000000B015" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B015">
<li id="P700101195200000000000000000B016" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B016"><p id="P700101195200000000000000000B017" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B017">The adapter obtains a datagram from the network layer, prepares a link-layer frame, and puts the frame adapter buffer.</p></li>
<li id="P700101195200000000000000000B018" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B018"><p id="P700101195200000000000000000B019" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B019">If the adapter senses that the channel is idle (that is, there is no signal energy entering the adapter from the channel), it starts to transmit the frame. If, on the other hand, the adapter senses that the channel is busy, it waits until it senses no signal energy and then starts to transmit the frame.</p></li>
<li id="P700101195200000000000000000B01A" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B01A"><p id="P700101195200000000000000000B01B" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B01B">While transmitting, the adapter monitors for the presence of signal energy coming from other adapters using the broadcast channel.</p></li>
<li id="P700101195200000000000000000B01C" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B01C"><p id="P700101195200000000000000000B01D" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B01D"><span class="pagebreak" title="463" id="P7001011952000000000000000002523" data-uri="M06_KURO4140_07_SE_C06.xhtml#P7001011952000000000000000002523" epub:type="pagebreak" role="doc-pagebreak"></span>If the adapter transmits the entire frame without detecting signal energy from other adapters, the adapter is finished with the frame. If, on the other hand, the adapter detects signal energy from other adapters while transmitting, it aborts the transmission (that is, it stops transmitting its frame).</p></li>
<li id="P700101195200000000000000000B01E" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B01E"><p id="P700101195200000000000000000B01F" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B01F">After aborting, the adapter waits a random amount of time and then returns to step 2.</p></li>
</ol>
<p id="P700101195200000000000000000B020" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B020">The need to wait a random (rather than fixed) amount of time is hopefully clear—if two nodes transmitted frames at the same time and then both waited the same fixed amount of time, they’d continue colliding forever. But what is a good interval of time from which to choose the random backoff time? If the interval is large and the number of colliding nodes is small, nodes are likely to wait a large amount of time (with the channel remaining idle) before repeating the sense-and-transmit-when-idle step. On the other hand, if the interval is small and the number of colliding nodes is large, it’s likely that the chosen random values will be nearly the same, and transmitting nodes will again collide. What we’d like is an interval that is short when the number of colliding nodes is small, and long when the number of colliding nodes is large.</p>
<p id="P700101195200000000000000000B021" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B021">The <span class="keyword" id="P7001011952000000000000000002528" data-uri="M06_KURO4140_07_SE_C06.xhtml#P7001011952000000000000000002528"><b>binary exponential backoff</b></span> algorithm, used in Ethernet as well as in DOCSIS cable network multiple access protocols <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P70010119520000000000000000038D2" data-foobar="7">[DOCSIS 2011]</a>, elegantly solves this problem. Specifically, when transmitting a frame that has already experienced <i>n</i> collisions, a node chooses the value of <i>K</i> at random from <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="153" altimg-height="18" altimg="../images/ch06math36.png"><m:mrow><m:mrow><m:mo>{</m:mo> <m:mrow><m:mn>0</m:mn><m:mo>,</m:mo><m:mn>1</m:mn><m:mo>,</m:mo><m:mn>2</m:mn><m:mo>,</m:mo><m:mo>…</m:mo><m:msup><m:mn>2</m:mn><m:mi>n</m:mi></m:msup><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow><m:mo>}</m:mo></m:mrow></m:mrow></m:math></span>. Thus, the more collisions experienced by a frame, the larger the interval from which <i>K</i> is chosen. For Ethernet, the actual amount of time a node waits is <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="57" altimg-height="13" altimg="../images/ch06math37.png"><m:mrow><m:mtext>K</m:mtext><m:mo>⋅</m:mo><m:mn>512</m:mn></m:mrow></m:math></span> bit times (i.e., <i>K</i> times the amount of time needed to send 512 bits into the Ethernet) and the maximum value that <i>n</i> can take is capped at 10.</p>
<p id="P700101195200000000000000000B022" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B022">Let’s look at an example. Suppose that a node attempts to transmit a frame for the first time and while transmitting it detects a collision. The node then chooses <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="56" altimg-height="13" altimg="../images/ch06math38.png"><m:mrow><m:mi>K</m:mi><m:mo>=</m:mo><m:mn>0</m:mn></m:mrow></m:math></span> with probability 0.5 or chooses <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="52" altimg-height="13" altimg="../images/ch06math39.png"><m:mrow><m:mi>K</m:mi><m:mo>=</m:mo><m:mn>1</m:mn></m:mrow></m:math></span> with probability 0.5. If the node chooses <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="51" altimg-height="13" altimg="../images/ch06math40.png"><m:mrow><m:mi>K</m:mi><m:mo>=</m:mo><m:mn>0</m:mn></m:mrow></m:math></span>, then it immediately begins sensing the channel. If the node chooses <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="52" altimg-height="13" altimg="../images/ch06math41.png"><m:mrow><m:mi>K</m:mi><m:mo>=</m:mo><m:mn>1</m:mn></m:mrow></m:math></span>, it waits 512 bit times (e.g., 5.12 microseconds for a 100 Mbps Ethernet) before beginning the sense-and-transmit-when-idle cycle. After a second collision, <i>K</i> is chosen with equal probability from {0,1,2,3}. After three collisions, <i>K</i> is chosen with equal probability from {0,1,2,3,4,5,6,7}. After 10 or more collisions, <i>K</i> is chosen with equal probability from {0,1,2,…, 1023}. Thus, the size of the sets from which <i>K</i> is chosen grows exponentially with the number of collisions; for this reason this algorithm is referred to as binary exponential backoff.</p>
<p id="P700101195200000000000000000B023" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B023">We also note here that each time a node prepares a new frame for transmission, it runs the CSMA/CD algorithm, not taking into account any collisions that may have occurred in the recent past. So it is possible that a node with a new frame will immediately be able to sneak in a successful transmission while several other nodes are in the exponential backoff state.</p>
</section>
<section id="P700101195200000000000000000252B" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000252B" class="level3"><header><h1 class="title" id="P700101195200000000000000000B024" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B024" epub:type="title"><span class="pagebreak" title="464" id="P700101195200000000000000000252D" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000252D" epub:type="pagebreak" role="doc-pagebreak"></span>CSMA/CD Efficiency</h1></header>
<p id="P700101195200000000000000000B025" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B025">When only one node has a frame to send, the node can transmit at the full channel rate (e.g., for Ethernet typical rates are 10 Mbps, 100 Mbps, or 1 Gbps). However, if many nodes have frames to transmit, the effective transmission rate of the channel can be much less. We define the <span class="keyword" id="P700101195200000000000000000252F" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000252F"><b>efficiency of CSMA/CD</b></span> to be the long-run fraction of time during which frames are being transmitted on the channel without collisions when there is a large number of active nodes, with each node having a large number of frames to send. In order to present a closed-form approximation of the efficiency of Ethernet, let <i>d</i><sub>prop</sub> denote the maximum time it takes signal energy to propagate between any two adapters. Let <i>d</i><sub>trans</sub> be the time to transmit a maximum-size frame (approximately 1.2 msecs for a 10 Mbps Ethernet). A derivation of the efficiency of CSMA/CD is beyond the scope of this book (see <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003A18" data-foobar="7">[Lam 1980]</a> and <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003837" data-foobar="7">[Bertsekas 1991]</a>). Here we simply state the following approximation:</p>
<div class="informalequation" id="P7001011952000000000000000002530" data-uri="M06_KURO4140_07_SE_C06.xhtml#P7001011952000000000000000002530"><m:math display="block" alttext="" data-uri="" altimg-width="239" altimg-height="47" altimg="../images/ch06math42.png"><m:mrow><m:mtext>Efficiency</m:mtext><m:mo>=</m:mo><m:mfrac><m:mn>1</m:mn><m:mrow><m:mrow><m:mrow><m:mn>1</m:mn><m:mo>+</m:mo><m:mn>5</m:mn><m:msub><m:mi>d</m:mi><m:mrow><m:mtext>prop</m:mtext></m:mrow></m:msub></m:mrow><m:mo>/</m:mo><m:mrow><m:msub><m:mi>d</m:mi><m:mrow><m:mtext>trans</m:mtext></m:mrow></m:msub></m:mrow></m:mrow></m:mrow></m:mfrac></m:mrow></m:math></div>
<p class="continued" id="P700101195200000000000000000B026" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B026">We see from this formula that as <i>d</i><sub>prop</sub> approaches 0, the efficiency approaches 1. This matches our intuition that if the propagation delay is zero, colliding nodes will abort immediately without wasting the channel. Also, as <i>d</i><sub>trans</sub> becomes very large, efficiency approaches 1. This is also intuitive because when a frame grabs the channel, it will hold on to the channel for a very long time; thus, the channel will be doing productive work most of the time.</p>
</section>
</section>
<section id="P7001011952000000000000000002532" data-uri="M06_KURO4140_07_SE_C06.xhtml#P7001011952000000000000000002532" class="level2"><header><h1 class="title" id="P700101195200000000000000000B027" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B027" epub:type="title"><span class="number">6.3.3</span> Taking-Turns Protocols</h1></header>
<p id="P700101195200000000000000000B028" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B028">Recall that two desirable properties of a multiple access protocol are (1) when only one node is active, the active node has a throughput of <i>R</i> bps, and (2) when <i>M</i> nodes are active, then each active node has a throughput of nearly <i>R</i>/<i>M</i> bps. The ALOHA and CSMA protocols have this first property but not the second. This has motivated researchers to create another class of protocols—the <span class="keyword" id="P7001011952000000000000000002535" data-uri="M06_KURO4140_07_SE_C06.xhtml#P7001011952000000000000000002535"><b>taking-turns protocols</b></span>. As with random access protocols, there are dozens of taking-turns protocols, and each one of these protocols has many variations. We’ll discuss two of the more important protocols here. The first one is the <span class="keyword" id="P7001011952000000000000000002536" data-uri="M06_KURO4140_07_SE_C06.xhtml#P7001011952000000000000000002536"><b>polling protocol</b></span>. The polling protocol requires one of the nodes to be designated as a master node. The master node <span class="keyword" id="P7001011952000000000000000002537" data-uri="M06_KURO4140_07_SE_C06.xhtml#P7001011952000000000000000002537"><b>polls</b></span> each of the nodes in a round-robin fashion. In particular, the master node first sends a message to node 1, saying that it (node 1) can transmit up to some maximum number of frames. After node 1 transmits some frames, the master node tells node 2 it (node 2) can transmit up to the maximum number of frames. (The master node can determine when a node has finished sending its frames by observing the lack of a signal on the channel.) The procedure continues in this manner, with the master node polling each of the nodes in a cyclic manner.</p>
<p id="P700101195200000000000000000B029" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B029">The polling protocol eliminates the collisions and empty slots that plague random access protocols. This allows polling to achieve a much higher efficiency. But <span class="pagebreak" title="465" id="P7001011952000000000000000002539" data-uri="M06_KURO4140_07_SE_C06.xhtml#P7001011952000000000000000002539" epub:type="pagebreak" role="doc-pagebreak"></span>it also has a few drawbacks. The first drawback is that the protocol introduces a polling delay—the amount of time required to notify a node that it can transmit. If, for example, only one node is active, then the node will transmit at a rate less than <i>R</i> bps, as the master node must poll each of the inactive nodes in turn each time the active node has sent its maximum number of frames. The second drawback, which is potentially more serious, is that if the master node fails, the entire channel becomes inoperative. The 802.15 protocol and the Bluetooth protocol we will study in <a class="xref" href="#P700101195200000000000000000245F" data-foobar="1"><span class="label">Section</span> <span class="number">6.3</span></a> are examples of polling protocols.</p>
<p id="P700101195200000000000000000B02A" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B02A">The second taking-turns protocol is the <span class="keyword" id="P700101195200000000000000000253B" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000253B"><b>token-passing protocol</b></span>. In this protocol there is no master node. A small, special-purpose frame known as a <span class="keyword" id="P700101195200000000000000000253C" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000253C"><b>token</b></span> is exchanged among the nodes in some fixed order. For example, node 1 might always send the token to node 2, node 2 might always send the token to node 3, and node <i>N</i> might always send the token to node 1. When a node receives a token, it holds onto the token only if it has some frames to transmit; otherwise, it immediately forwards the token to the next node. If a node does have frames to transmit when it receives the token, it sends up to a maximum number of frames and then forwards the token to the next node. Token passing is decentralized and highly efficient. But it has its problems as well. For example, the failure of one node can crash the entire channel. Or if a node accidentally neglects to release the token, then some recovery procedure must be invoked to get the token back in circulation. Over the years many token-passing protocols have been developed, including the fiber distributed data interface (FDDI) protocol <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P70010119520000000000000000039B8" data-foobar="7">[Jain 1994]</a> and the IEEE 802.5 token ring protocol <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003989" data-foobar="7">[IEEE 802.5 2012]</a>, and each one had to address these as well as other sticky issues.</p>
</section>
<section id="P700101195200000000000000000253D" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000253D" class="level2"><header><h1 class="title" id="P700101195200000000000000000B02B" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B02B" epub:type="title"><span class="number">6.3.4</span> DOCSIS: The Link-Layer Protocol for Cable Internet Access</h1></header>
<p id="P700101195200000000000000000B02C" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B02C">In the previous three subsections, we’ve learned about three broad classes of multiple access protocols: channel partitioning protocols, random access protocols, and taking turns protocols. A cable access network will make for an excellent case study here, as we’ll find aspects of <i>each</i> of these three classes of multiple access protocols with the cable access network!</p>
<p id="P700101195200000000000000000B02D" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B02D">Recall from <a class="xref" href="fileP70010119520000000000000000004B3.xhtml#P70010119520000000000000000004CB" data-foobar="7"><span class="label">Section</span> <span class="number">1.2.1</span></a> that a cable access network typically connects several thousand residential cable modems to a cable modem termination system (CMTS) at the cable network headend. The Data-Over-Cable Service Interface Specifications (DOCSIS) <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P70010119520000000000000000038D2" data-foobar="7">[DOCSIS 2011]</a> specifies the cable data network architecture and its protocols. DOCSIS uses FDM to divide the downstream (CMTS to modem) and upstream (modem to CMTS) network segments into multiple frequency channels. Each downstream channel is 6 MHz wide, with a maximum throughput of approximately 40 Mbps per channel (although this data rate is seldom seen at a cable modem in practice); each upstream channel has a maximum channel width of 6.4 MHz, and a maximum upstream throughput of approximately 30 Mbps. Each upstream and<span class="pagebreak" title="466" id="P7001011952000000000000000002541" data-uri="M06_KURO4140_07_SE_C06.xhtml#P7001011952000000000000000002541" epub:type="pagebreak" role="doc-pagebreak"></span></p>
<figure id="P7001011952000000000000000002542" class="figure" data-uri="M06_KURO4140_07_SE_C06.xhtml#P7001011952000000000000000002542">
<img alt="Illustration of upstream and downstream channels between CMTS and cable modems." height="344" width="673" aria-describedby="P7001011952000000000000000002546" id="P700101195200000000000000000B02E" data-uri="P70010119520000000000000000055D1" src="../images/4055106014.png"></img>
<figcaption id="P700101195200000000000000000B02F" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B02F"><header><h1 class="title" id="P700101195200000000000000000B030" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B030" epub:type="title"><span class="label">Figure </span> <span class="number">6.14</span> Upstream and downstream channels between CMTS and cable modems</h1></header>

</figcaption>
</figure><div class="longdesc" id="P7001011952000000000000000002546" data-uri="M06_KURO4140_07_SE_C06.xhtml#P7001011952000000000000000002546" aria-hidden="false"><a class="xref" aria-hidden="false" href="../longalt/la_4055106014.xhtml#la_4055106014"><span class="label">Description</span></a></div>
<p class="continued" id="P700101195200000000000000000B032" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B032">downstream channel is a broadcast channel. Frames transmitted on the downstream channel by the CMTS are received by all cable modems receiving that channel; since there is just a single CMTS transmitting into the downstream channel, however, there is no multiple access problem. The upstream direction, however, is more interesting and technically challenging, since multiple cable modems share the same upstream channel (frequency) to the CMTS, and thus collisions can potentially occur.</p>
<p id="P700101195200000000000000000B033" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B033">As illustrated in <a class="xref" href="#P7001011952000000000000000002542" data-foobar="1"><span class="label">Figure</span> <span class="number">6.14</span></a>, each upstream channel is divided into intervals of time (TDM-like), each containing a sequence of mini-slots during which cable modems can transmit to the CMTS. The CMTS explicitly grants permission to individual cable modems to transmit during specific mini-slots. The CMTS accomplishes this by sending a control message known as a MAP message on a downstream channel to specify which cable modem (with data to send) can transmit during which mini-slot for the interval of time specified in the control message. Since mini-slots are explicitly allocated to cable modems, the CMTS can ensure there are no colliding transmissions during a mini-slot.</p>
<p id="P700101195200000000000000000B034" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B034">But how does the CMTS know which cable modems have data to send in the first place? This is accomplished by having cable modems send mini-slot-request frames to the CMTS during a special set of interval mini-slots that are dedicated for this purpose, as shown in <a class="xref" href="#P7001011952000000000000000002542" data-foobar="1"><span class="label">Figure</span> <span class="number">6.14</span></a>. These mini-slot-request frames are transmitted in a random access manner and so may collide with each other. A cable modem can neither sense whether the upstream channel is busy nor detect collisions. Instead, the cable modem infers that its mini-slot-request frame experienced a collision if it does not receive a response to the requested allocation in the next downstream control message. When a collision is inferred, a cable modem uses binary exponential <span class="pagebreak" title="467" id="P700101195200000000000000000254B" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000254B" epub:type="pagebreak" role="doc-pagebreak"></span>backoff to defer the retransmission of its mini-slot-request frame to a future time slot. When there is little traffic on the upstream channel, a cable modem may actually transmit data frames during slots nominally assigned for mini-slot-request frames (and thus avoid having to wait for a mini-slot assignment).</p>
<p id="P700101195200000000000000000B035" data-uri="M06_KURO4140_07_SE_C06.xhtml#P700101195200000000000000000B035">A cable access network thus serves as a terrific example of multiple access protocols in action—FDM, TDM, random access, and centrally allocated time slots all within one network!</p>
</section>
</section></body></html>