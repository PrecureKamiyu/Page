<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xmlns:mml="http://www.w3.org/1998/Math/MathML" lang="EN" xml:lang="en"><head><meta content="text/html; charset=utf-8" http-equiv="default-style"/><title>The Art of Multiprocessor Programming</title><link href="Elsevier_eBook.css" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:4f1c4a5b-a3e2-48ff-98f3-ff17812cd57a" name="Adept.expected.resource"/></head><body><section epub:type="preface" role="doc-preface"><div id="CN"/><div aria-label="Page xv" epub:type="pagebreak" id="page_xv" role="doc-pagebreak"/><h1 class="fmtitle" id="ti0010">Preface</h1><p class="textfl" id="p0010"/><p class="text" id="p0015">In the decade since the first edition, this book has become a staple of undergraduate and graduate courses at universities around the world. It has also found a home on the bookshelves of practitioners at companies large and small. The audience for the book has, in turn, advanced the state of the art in multiprocessor programming. In this second edition, we aim to continue this “virtuous cycle” by providing new and updated content. Our goal is the same as with the first edition: to provide a textbook for a senior-level undergraduate course and a reference for practitioners.</p><section><h2 class="h1hd" id="s0010"><a id="st0010"/>Organization</h2><p class="textfl" id="p0020">The first part of this book covers the <i>principles</i> of concurrent programming, showing how to <i>think</i> as a concurrent programmer, developing fundamental skills such as understanding when operations “happen,” considering all possible interleavings, and identifying impediments to progress. Like many skills—driving a car, cooking a meal, or appreciating caviar—thinking concurrently must be cultivated, and it can be learned with moderate effort. Readers who want to start programming right away may skip most of this section but should still read Chapters <a href="B9780124159501000112.xhtml">2</a> and <a href="B9780124159501000124.xhtml">3</a>, which cover the basic ideas necessary to understand the rest of the book.</p><p class="text" id="p0025">We first look at the classic <i>mutual exclusion</i> problem (Chapter <a href="B9780124159501000112.xhtml">2</a>). This chapter is essential for understanding why concurrent programming is a challenge. It covers basic concepts such as fairness and deadlock. We then ask what it means for a concurrent program to be correct (Chapter <a href="B9780124159501000124.xhtml">3</a>). We consider several alternative conditions and the circumstances under which one might want to use each one. We examine the properties of <i>shared memory</i> essential to concurrent computation (Chapter <a href="B9780124159501000136.xhtml">4</a>), and we look at the kinds of synchronization primitives needed to implement highly concurrent data structures (Chapters <a href="B9780124159501000148.xhtml">5</a> and <a href="B978012415950100015X.xhtml">6</a>).</p><p class="text" id="p0030">We think it is essential that anyone who wants to become truly skilled in the art of multiprocessor programming spend time solving the problems presented in the first part of this book. Although these problems are idealized, they distill the kind of thinking necessary to write effective multiprocessor programs. Most importantly, they distill the style of thinking necessary to avoid the common mistakes committed by nearly all novice programmers when they first encounter concurrency.</p><p class="text" id="p0035">The second part of the book describes the <i>practice</i> of concurrent programming. For most of this part, we give examples in Java to avoid getting mired in low-level details. However, we have expanded this edition to include discussion of some low-level issues that are essential to understanding multiprocessor systems and how to program them effectively. We use examples in C++ to illustrate these issues.</p><p class="text" id="p0040"><span aria-label="Page xvi" epub:type="pagebreak" id="page_xvi" role="doc-pagebreak"/>Each chapter has a secondary theme, illustrating either a particular programming pattern or an algorithmic technique. Chapter <a href="B9780124159501000173.xhtml">7</a> covers spin locks and contention, and introduces the importance of the underlying architecture: spin lock performance cannot be understood without understanding the multiprocessor memory hierarchy. Chapter <a href="B9780124159501000185.xhtml">8</a> covers monitor locks and waiting, a common synchronization idiom.</p><p class="text" id="p0045">Several chapters cover concurrent data structures. Linked lists, which illustrate different kinds of synchronization patterns, from coarse-grained locking to fine-grained locking to lock-free structures, are covered in Chapter <a href="B9780124159501000197.xhtml">9</a>. This chapter should be read before the remaining chapters, which depend on it. First-in-first-out (FIFO) queues illustrate the “ABA problem” that arises when using atomic synchronization primitives (Chapter <a href="B9780124159501000203.xhtml">10</a>); stacks illustrate an important synchronization pattern called <i>elimination</i> (Chapter <a href="B9780124159501000215.xhtml">11</a>); hash maps show how an algorithm can exploit natural parallelism (Chapter <a href="B9780124159501000239.xhtml">13</a>); skip lists illustrate efficient parallel search (Chapter <a href="B9780124159501000240.xhtml">14</a>); priority queues illustrate how one can sometimes relax correctness guarantees to enhance performance (Chapter <a href="B9780124159501000252.xhtml">15</a>).</p><p class="text" id="p0050">We also consider other fundamental problems in concurrent computing. Chapter <a href="B9780124159501000227.xhtml">12</a> describes counting and sorting, two classic problems with nuanced concurrent solutions. Breaking a program into parallelizable tasks and organizing their execution is an essential skill for concurrent programming, and we consider several ways to do this, including work stealing and distribution (Chapter <a href="B9780124159501000264.xhtml">16</a>), data parallelism (Chapter <a href="B9780124159501000276.xhtml">17</a>), barriers (Chapter <a href="B9780124159501000288.xhtml">18</a>), and transactional programming (Chapter <a href="B9780124159501000306.xhtml">20</a>). Memory management is another fundamental challenge for concurrent programs, and we discuss how to manually reclaim memory in Chapter <a href="B978012415950100029X.xhtml">19</a>. Because Java provides automatic memory management, we use C++ to illustrate these issues.</p><p class="text" id="p0055">Much of these latter chapters are new to this edition: Chapters <a href="B9780124159501000276.xhtml">17</a> and <a href="B978012415950100029X.xhtml">19</a> are completely new, and Chapters <a href="B9780124159501000264.xhtml">16</a> and <a href="B9780124159501000306.xhtml">20</a> have been substantially updated from the first edition. In particular, Chapter <a href="B9780124159501000306.xhtml">20</a> now covers hardware primitives for transactional programming as well as software strategies, and the examples have been recast in C++ to allow us to focus on lower-level mechanisms.</p><p class="text" id="p0060"/><p class="quote" id="sp0010"><i>In theory, there is no difference between theory and practice. In practice, there is.</i></p><p class="textfl"/><p class="text" id="p0065">Although the origin of this quote is uncertain, it is relevant to the subject of this book. For the greatest benefit, a reader must supplement learning the conceptual material presented in this book with actual experience programming real multiprocessor systems.<span aria-label="Page xvii" epub:type="pagebreak" id="page_xvii" role="doc-pagebreak"/></p></section><section><h2 class="h1hd" id="s0015"><a id="st0015"/>Prerequisites</h2><p class="textfl" id="p0070">The prerequisites for the second edition are largely the same as for the first. To understand the algorithms and their properties, readers will need some knowledge of discrete mathematics, especially “big-O” notation and what it means for a problem to be NP-complete, and data structures such as stacks, queues, lists, balanced trees, and hash tables. It is also helpful to be familiar with elementary computer architecture and system constructs such as processors, threads, and caches. While a course on operating systems or computer organization would suffice, neither is necessary; dozens of universities have used this book successfully without either prerequisite.</p><p class="text" id="p0075">A basic understanding of Java or C++ is needed to follow the examples. When we require advanced language features or advanced understanding of hardware, we provide an explanation first. More details about programming language constructs and multiprocessor hardware architectures are covered in Appendix <a href="B9780124159501000318.xhtml">A</a> and Appendix <a href="B978012415950100032X.xhtml">B</a>, respectively.</p></section></section></body></html>