<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xmlns:mml="http://www.w3.org/1998/Math/MathML" lang="EN" xml:lang="en"><head><meta content="text/html; charset=utf-8" http-equiv="default-style"/><title>The Art of Multiprocessor Programming</title><link href="Elsevier_eBook.css" rel="stylesheet" type="text/css"/><link href="math.css" rel="stylesheet" type="text/css"/><link href="media.css" media="only screen" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:4f1c4a5b-a3e2-48ff-98f3-ff17812cd57a" name="Adept.expected.resource"/></head><body><section epub:type="chapter" role="doc-chapter"><div aria-label="Page 147" epub:type="pagebreak" id="page_147" role="doc-pagebreak"/><div id="CN"><a id="c0010tit1"/></div><header><hgroup><h1 class="chaptitle" id="c0010tit">Chapter 7: Spin locks and contention</h1></hgroup><section epub:type="preamble"><div class="abstract"><h2 class="h1hd" id="ab0010"><a id="st0010"/>Abstract</h2><p class="abspara">This chapter begins our study of practical concurrency by exploring the impact of system architecture on the performance of spin locks. Understanding the memory hierarchy and how processors communicate is critical to being able to write effective concurrent programs. We examine how to exploit knowledge of the architecture to design locking algorithms that reduce contention and so improve performance.</p></div></section><section id="ks0010"><h3 class="h2hd" id="st0015">Keywords</h3><p class="keywords">mutual exclusion; spin lock; contention; exponential back-off; queue lock; hierarchical lock; cohort lock; fast path</p></section></header><p class="textfl" id="p0010">When writing programs for uniprocessors, it is usually safe to ignore the underlying system's architectural details. Unfortunately, multiprocessor programming has yet to reach that state; for now, it is crucial to understand the underlying machine architecture. The goal of this chapter is to explain how architecture affects performance, and how to exploit this knowledge to write efficient concurrent programs. We revisit the familiar mutual exclusion problem, this time with the aim of devising mutual exclusion protocols that work well with today's multiprocessors.</p><p class="text" id="p0015">Any mutual exclusion protocol poses the question: “What do you do if you cannot acquire the lock?” There are two alternatives. If you keep trying, the lock is called a <i>spin lock</i>, and repeatedly testing the lock is called <i>spinning</i>, or <i>busy-waiting</i>. The <img alt="Image" height="9" src="images/B9780124159501000173/fx001.jpg" width="38"/> and <img alt="Image" height="11" src="images/B9780124159501000173/fx002.jpg" width="39"/> algorithms are spin locks. Spinning makes sense when you expect the lock delay to be short (and only on multiprocessors, of course). The alternative is to suspend yourself and ask the operating system to schedule another thread on your processor, which is sometimes called <i>blocking</i>. Because switching from one thread to another is expensive, blocking makes sense only if you expect the lock delay to be long. Many operating systems mix both strategies, spinning for a short time and then blocking. Both spinning and blocking are important techniques. In this chapter, we turn our attention to locks that use spinning.</p><section><h2 class="h1hd" id="s0010"><a id="st0020"/>7.1 Welcome to the real world</h2><p class="textfl" id="p0020">We approach real-world mutual exclusion via the <img alt="Image" height="9" src="images/B9780124159501000173/fx003.jpg" width="25"/> interface from the <span class="sans-serif">java.util.concurrent.locks</span> package. For now, we consider only the two principal methods, <img alt="Image" height="9" src="images/B9780124159501000173/fx004.jpg" width="25"/>() and <img alt="Image" height="9" src="images/B9780124159501000173/fx005.jpg" width="39"/>(). As mentioned in Pragma <a href="B9780124159501000112.xhtml">2.2.1</a>, these methods are often used in the following structured way:</p><p class="text" id="p0025"/><div class="pageavoid"><figure class="fig" id="f0010"><img alt="Image" class="img" height="142" src="images/B9780124159501000173/fx006.jpg" width="344"/></figure></div><p class="textfl"><span aria-label="Page 148" epub:type="pagebreak" id="page_148" role="doc-pagebreak"/></p><p class="text" id="p0030">We create a new <img alt="Image" height="9" src="images/B9780124159501000173/fx003.jpg" width="25"/> object called <img alt="Image" height="8" src="images/B9780124159501000173/fx007.jpg" width="33"/> (line 1). Because <img alt="Image" height="9" src="images/B9780124159501000173/fx003.jpg" width="25"/> is an interface and not a class, we cannot create <img alt="Image" height="9" src="images/B9780124159501000173/fx003.jpg" width="25"/> objects directly. Instead, we create an object that <i>implements</i> the <img alt="Image" height="9" src="images/B9780124159501000173/fx003.jpg" width="25"/> interface. (The <span class="sans-serif">java.util.concurrent.locks</span> package includes several classes that implement <img alt="Image" height="9" src="images/B9780124159501000173/fx003.jpg" width="25"/>, and we provide others in this chapter.) Next, we acquire the lock (line 3), and enter the critical section in a <img alt="Image" height="11" src="images/B9780124159501000173/fx008.jpg" width="19"/> block (line 4). The <img alt="Image" height="11" src="images/B9780124159501000173/fx009.jpg" width="46"/> block (line 6) ensures that no matter what, the lock is released when control leaves the critical section. We do not put the <img alt="Image" height="9" src="images/B9780124159501000173/fx004.jpg" width="25"/>() call inside the <img alt="Image" height="11" src="images/B9780124159501000173/fx008.jpg" width="19"/> block, because the <img alt="Image" height="9" src="images/B9780124159501000173/fx004.jpg" width="25"/>() call might throw an exception before acquiring the lock, causing the <img alt="Image" height="11" src="images/B9780124159501000173/fx009.jpg" width="46"/> block to call <img alt="Image" height="9" src="images/B9780124159501000173/fx005.jpg" width="39"/>() when the lock has not actually been acquired. (Java does not permit instructions to be executed between program lines, so once line 3 is completed and the lock is taken, the thread is in the <img alt="Image" height="11" src="images/B9780124159501000173/fx008.jpg" width="19"/> block.)</p><p class="text" id="p0035">Why not use one of the <img alt="Image" height="9" src="images/B9780124159501000173/fx003.jpg" width="25"/> algorithms studied in Chapter <a href="B9780124159501000112.xhtml">2</a>, such as <img alt="Image" height="9" src="images/B9780124159501000173/fx001.jpg" width="38"/> or <img alt="Image" height="11" src="images/B9780124159501000173/fx002.jpg" width="39"/>? One reason is the space lower bound proved in Chapter <a href="B9780124159501000112.xhtml">2</a>: No matter what we do, mutual exclusion using reads and writes requires space linear in <i>n</i>, the number of threads that potentially access the location. It gets worse.</p><p class="text" id="p0040">Consider, for example, the two-thread <img alt="Image" height="9" src="images/B9780124159501000173/fx010.jpg" width="51"/> lock algorithm of Chapter <a href="B9780124159501000112.xhtml">2</a>, presented again in <a href="#f0015" id="cf0010">Fig. 7.1</a>. There are two threads, with IDs 0 and 1. When thread <i>A</i> wants to acquire the lock, it sets <img alt="Image" height="10" src="images/B9780124159501000173/fx011.jpg" width="23"/><span class="hiddenClass"><mml:math><mml:mo stretchy="false">[</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000173/si1.png" style="vertical-align:middle" width="23"/></span> to <i>true</i>, sets <img alt="Image" height="9" src="images/B9780124159501000173/fx012.jpg" width="39"/> to <i>A</i>, and tests <img alt="Image" height="9" src="images/B9780124159501000173/fx012.jpg" width="39"/> and <img alt="Image" height="10" src="images/B9780124159501000173/fx011.jpg" width="23"/><span class="hiddenClass"><mml:math><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo linebreak="badbreak" linebreakstyle="after">−</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000173/si2.png" style="vertical-align:middle" width="50"/></span>. As long as <img alt="Image" height="9" src="images/B9780124159501000173/fx012.jpg" width="39"/> is <i>A</i> and <img alt="Image" height="10" src="images/B9780124159501000173/fx011.jpg" width="23"/><span class="hiddenClass"><mml:math><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo linebreak="badbreak" linebreakstyle="after">−</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000173/si2.png" style="vertical-align:middle" width="50"/></span> is <i>true</i>, the thread spins, repeating the test. Once either <img alt="Image" height="9" src="images/B9780124159501000173/fx012.jpg" width="39"/> is not <i>A</i> or <img alt="Image" height="10" src="images/B9780124159501000173/fx011.jpg" width="23"/><span class="hiddenClass"><mml:math><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo linebreak="badbreak" linebreakstyle="after">−</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000173/si2.png" style="vertical-align:middle" width="50"/></span> is <i>false</i>, the thread enters the critical section, setting <img alt="Image" height="10" src="images/B9780124159501000173/fx011.jpg" width="23"/><span class="hiddenClass"><mml:math><mml:mo stretchy="false">[</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000173/si1.png" style="vertical-align:middle" width="23"/></span> to <i>false</i> as it leaves. We know from Chapter <a href="B9780124159501000112.xhtml">2</a> that the <img alt="Image" height="9" src="images/B9780124159501000173/fx010.jpg" width="51"/> lock provides starvation-free mutual exclusion.</p><div class="pageavoid"><figure class="fig" id="f0015"><img alt="Image" height="174" src="images/B9780124159501000173/gr001.jpg" width="297"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.1</span> The <img alt="Image" height="9" src="images/B9780124159501000173/fx010.jpg" width="51"/> class (Chapter <a href="B9780124159501000112.xhtml">2</a>): the order of reads and writes in lines 7–9 is crucial to providing mutual exclusion.</div></figcaption></figure></div><p class="text" id="p0045">Suppose we write a simple concurrent program in which each of the threads repeatedly acquires the <img alt="Image" height="9" src="images/B9780124159501000173/fx010.jpg" width="51"/> lock, increments a shared counter, and then releases the lock. We run it on a multiprocessor, where each thread executes this acquire–increment–release cycle, say, half a million times. On most modern architectures, the threads finish quickly. Alarmingly, however, we may discover that the counter's final value may be slightly <span aria-label="Page 149" epub:type="pagebreak" id="page_149" role="doc-pagebreak"/>off from the expected million mark. Proportionally, the error may be tiny, but why is there any error at all? Somehow, it must be that both threads are occasionally in the critical section at the same time, even though we have proved that this cannot happen. To quote Sherlock Holmes: </p><p class="quote" id="sp0180"><i>How often have I said to you that when you have eliminated the impossible, whatever remains, however improbable, must be the truth?</i></p><p class="textfl"/><p class="text" id="p0050">Our proof fails, not because there is anything wrong with our logic, but because our assumptions about the real world are mistaken.</p><p class="text" id="p0055">When programming our multiprocessor, we implicitly assumed that read–write operations are atomic, that is, they are linearizable to some sequential execution, or at the very least, that they are sequentially consistent. (Recall that linearizability implies sequential consistency.) As we saw in Chapter <a href="B9780124159501000124.xhtml">3</a>, sequential consistency implies that there is some global order on all operations in which each thread's operations take effect as ordered by its program. When we proved the <img alt="Image" height="9" src="images/B9780124159501000173/fx010.jpg" width="51"/> lock correct, we relied, without calling attention to it, on the assumption that memory is sequentially consistent. In particular, mutual exclusion depends on the order of the steps in lines 7–9 of <a href="#f0015" id="cf0015">Fig. 7.1</a>. Our proof that the <img alt="Image" height="9" src="images/B9780124159501000173/fx010.jpg" width="51"/> lock provides mutual exclusion implicitly relied on the assumption that any two memory accesses by the same thread, even to separate variables, take effect in program order. Specifically, <i>B</i>'s write to <img alt="Image" height="10" src="images/B9780124159501000173/fx011.jpg" width="23"/><span class="hiddenClass"><mml:math><mml:mo stretchy="false">[</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000173/si3.png" style="vertical-align:middle" width="24"/></span> must take effect before its write to <img alt="Image" height="9" src="images/B9780124159501000173/fx012.jpg" width="39"/> (Eq. <a href="B9780124159501000112.xhtml">(2.3.2)</a>) and <i>A</i>'s write to <img alt="Image" height="9" src="images/B9780124159501000173/fx012.jpg" width="39"/> must take effect before its read of <img alt="Image" height="10" src="images/B9780124159501000173/fx011.jpg" width="23"/><span class="hiddenClass"><mml:math><mml:mo stretchy="false">[</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000173/si3.png" style="vertical-align:middle" width="24"/></span> (Eq. <a href="B9780124159501000112.xhtml">(2.3.4)</a>).</p><p class="text" id="p0060">Unfortunately, modern multiprocessors, and programming languages for modern multiprocessors, typically do not provide sequentially consistent memory, nor do they necessarily guarantee program order among reads and writes by a given thread.</p><p class="text" id="p0065">Why not? The first culprits are compilers that reorder instructions to enhance performance. It is possible that the order of writes by thread <i>B</i> of <img alt="Image" height="10" src="images/B9780124159501000173/fx011.jpg" width="23"/><span class="hiddenClass"><mml:math><mml:mo stretchy="false">[</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000173/si3.png" style="vertical-align:middle" width="24"/></span> and <img alt="Image" height="9" src="images/B9780124159501000173/fx012.jpg" width="39"/> will be reversed by the compiler, invalidating Eq. <a href="B9780124159501000112.xhtml">(2.3.2)</a>. In addition, if a thread reads a variable repeatedly without writing it, a compiler may eliminate all but the first read of the variable, using the value read the first time for all subsequent reads. For example, the loop on line 9 of <a href="#f0015" id="cf0020">Fig. 7.1</a> may be replaced with a conditional statement that spins forever if the thread may not immediately enter the critical section.</p><p class="text" id="p0070">A second culprit is the multiprocessor hardware itself. (Appendix <a href="B978012415950100032X.xhtml">B</a> has a more extensive discussion of the multiprocessor architecture issues raised in this chapter.) Hardware vendors make no secret of the fact that writes to multiprocessor memory do not necessarily take effect when they are issued, because in most programs the vast majority of writes do not <i>need</i> to take effect in shared memory right away. On many multiprocessor architectures, writes to shared memory are buffered in a special <i>write buffer</i> (sometimes called a <i>store buffer</i>), to be written to memory only when needed. If thread <i>A</i>'s write to <img alt="Image" height="9" src="images/B9780124159501000173/fx012.jpg" width="39"/> is delayed in a write buffer, it may arrive in memory only after <i>A</i> reads <img alt="Image" height="10" src="images/B9780124159501000173/fx011.jpg" width="23"/><span class="hiddenClass"><mml:math><mml:mo stretchy="false">[</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000173/si3.png" style="vertical-align:middle" width="24"/></span>, invalidating Eq. <a href="B9780124159501000112.xhtml">(2.3.4)</a>.</p><p class="text" id="p0075">How then does one program multiprocessors, given such weak memory consistency guarantees? To prevent the reordering of operations resulting from write buffering, modern architectures provide a special <i>memory barrier</i> instruction (sometimes called a <span aria-label="Page 150" epub:type="pagebreak" id="page_150" role="doc-pagebreak"/><i>memory fence</i>) that forces outstanding operations to take effect. Synchronization methods such as <img alt="Image" height="11" src="images/B9780124159501000173/fx013.jpg" width="59"/>() and <img alt="Image" height="12" src="images/B9780124159501000173/fx014.jpg" width="97"/> of <img alt="Image" height="11" src="images/B9780124159501000173/fx015.jpg" width="87"/>, include a memory barrier on many architectures, as do <img alt="Image" height="9" src="images/B9780124159501000173/fx016.jpg" width="31"/> and <img alt="Image" height="9" src="images/B9780124159501000173/fx017.jpg" width="39"/> to <img alt="Image" height="9" src="images/B9780124159501000173/fx018.jpg" width="53"/> fields. It is the programmer's responsibility to know where memory barriers are needed (e.g., the <img alt="Image" height="9" src="images/B9780124159501000173/fx010.jpg" width="51"/> lock can be fixed by placing a barrier immediately before each read, and how to insert them. We discuss how to do this for Java in the next section.</p><p class="text" id="p0080">Not surprisingly, memory barriers are expensive, so we want to minimize their use. Because operations such as <img alt="Image" height="11" src="images/B9780124159501000173/fx013.jpg" width="59"/>() and <img alt="Image" height="12" src="images/B9780124159501000173/fx014.jpg" width="97"/> have higher consensus numbers than <img alt="Image" height="9" src="images/B9780124159501000173/fx016.jpg" width="31"/> and <img alt="Image" height="9" src="images/B9780124159501000173/fx017.jpg" width="39"/>, and can be used in a straightforward way to reach a kind of consensus on who can and cannot enter the critical section, it may be sensible to design mutual exclusion algorithms that use these operations directly.</p></section><section><h2 class="h1hd" id="s0015"><a id="st0025"/>7.2 Volatile fields and atomic objects</h2><p class="textfl" id="p0085">As a rule of thumb, any object field, accessed by concurrent threads, that is not protected by a critical section should be declared <img alt="Image" height="9" src="images/B9780124159501000173/fx018.jpg" width="53"/>. Without such a declaration, that field will not act like an atomic register: Reads may return stale values, and writes may be delayed.</p><p class="text" id="p0090">A <img alt="Image" height="9" src="images/B9780124159501000173/fx018.jpg" width="53"/> declaration does not make compound operations atomic: If <i>x</i> is a volatile variable, then the expression <i>x</i>++ will not necessarily increment <i>x</i> if concurrent threads can modify <i>x</i>. For tasks such as these, the <span class="sans-serif">java.util.concurrent.atomic</span> package provides classes such as <img alt="Image" height="9" src="images/B9780124159501000173/fx019.jpg" width="120"/> or <img alt="Image" height="11" src="images/B9780124159501000173/fx015.jpg" width="87"/> that provide many useful atomic operations.</p><p class="text" id="p0095">In earlier chapters, we did not put <img alt="Image" height="9" src="images/B9780124159501000173/fx018.jpg" width="53"/> declarations in our pseudocode because we assumed memory was linearizable. From now on, however, we assume the Java memory model, and so we put <img alt="Image" height="9" src="images/B9780124159501000173/fx018.jpg" width="53"/> declarations where they are needed. The Java memory model is described in more detail in Appendix <a href="B9780124159501000318.xhtml">A.3</a>.</p></section><section><h2 class="h1hd" id="s0020"><a id="st0030"/>7.3 Test-and-set locks</h2><p class="textfl" id="p0100">The principal synchronization instruction on many early multiprocessor architectures was the <i>test-and-set</i> instruction. It operates on a single memory word (or byte) that may be either <i>true</i> or <i>false</i>. The test-and-set instruction, which has consensus number two, atomically stores <i>true</i> in the word and returns that word's previous value; that is, it <i>swaps</i> the value <i>true</i> for the word's current value. At first glance, test-and-set seems ideal for implementing a spin lock: The lock is free when the word's value is <i>false</i>, and busy when it is <i>true</i>. The <img alt="Image" height="9" src="images/B9780124159501000173/fx004.jpg" width="25"/>() method repeatedly applies test-and-set to the word until it returns <i>false</i> (i.e., until the lock is free). The <img alt="Image" height="9" src="images/B9780124159501000173/fx005.jpg" width="39"/>() method simply writes the value <i>false</i> to it.</p><p class="text" id="p0105">The <img alt="Image" height="9" src="images/B9780124159501000173/fx020.jpg" width="46"/> class in <a href="#f0020" id="cf0025">Fig. 7.2</a> implements this lock in Java using the <img alt="Image" height="9" src="images/B9780124159501000173/fx021.jpg" width="86"/> class in the <span class="sans-serif">java.util.concurrent</span> package. This class stores a Boolean value, and it provides a <img alt="Image" height="8" src="images/B9780124159501000173/fx022.jpg" width="18"/>(<i>b</i>) method to replace the <span aria-label="Page 151" epub:type="pagebreak" id="page_151" role="doc-pagebreak"/>stored value with value <i>b</i>, and a <img alt="Image" height="11" src="images/B9780124159501000173/fx013.jpg" width="59"/>(<i>b</i>) that atomically replaces the current value with <i>b</i> and returns the previous value. The test-and-set instruction is equivalent to <img alt="Image" height="11" src="images/B9780124159501000173/fx013.jpg" width="59"/><span class="hiddenClass"><mml:math><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000173/si4.png" style="vertical-align:middle" width="43"/></span>. (We follow common practice by using test-and-set in prose, but we use <img alt="Image" height="11" src="images/B9780124159501000173/fx013.jpg" width="59"/><span class="hiddenClass"><mml:math><mml:mo stretchy="false">(</mml:mo><mml:mtext mathvariant="italic">true</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000173/si5.png" style="vertical-align:middle" width="39"/></span> in our code examples to be compatible with Java.)</p><div class="pageavoid"><figure class="fig" id="f0020"><img alt="Image" height="142" src="images/B9780124159501000173/gr002.jpg" width="312"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.2</span> The <img alt="Image" height="9" src="images/B9780124159501000173/fx020.jpg" width="46"/> class.</div></figcaption></figure></div><p class="text" id="p0110">Now consider <img alt="Image" height="9" src="images/B9780124159501000173/fx023.jpg" width="52"/> (<a href="#f0025" id="cf0030">Fig. 7.3</a>), a variant of the <img alt="Image" height="9" src="images/B9780124159501000173/fx020.jpg" width="46"/> algorithm called a <i>test-and-test-and-set</i> lock. In this algorithm, a thread reads the lock to check that it is free <i>before</i> performing the test-and-set. If the lock is not free, the thread repeatedly reads the lock until it is (i.e., until <img alt="Image" height="11" src="images/B9780124159501000173/fx024.jpg" width="19"/>() returns <i>false</i>), and only after that does the thread apply test-and-set. From the point of view of correctness, <img alt="Image" height="9" src="images/B9780124159501000173/fx020.jpg" width="46"/> and <img alt="Image" height="9" src="images/B9780124159501000173/fx023.jpg" width="52"/> are equivalent: Each guarantees deadlock-free mutual exclusion. Under the simple model we have been using so far, there should be no difference between these two algorithms.</p><div class="pageavoid"><figure class="fig" id="f0025"><img alt="Image" height="208" src="images/B9780124159501000173/gr003.jpg" width="315"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.3</span> The <img alt="Image" height="9" src="images/B9780124159501000173/fx023.jpg" width="52"/> class.</div></figcaption></figure></div><p class="text" id="p0115">How do they compare on a real multiprocessor? Experiments that measure the elapsed time for <i>n</i> threads to execute a short critical section a fixed total number of times invariably yield results that look like <a href="#f0030" id="cf0035">Fig. 7.4</a>. <span aria-label="Page 152" epub:type="pagebreak" id="page_152" role="doc-pagebreak"/>Each data point represents the same amount of work, so in the absence of contention effects, all curves would be flat. The top curve is the <img alt="Image" height="9" src="images/B9780124159501000173/fx020.jpg" width="46"/>, the middle curve is the <img alt="Image" height="9" src="images/B9780124159501000173/fx023.jpg" width="52"/>, and the bottom curve shows the time that would be needed if the threads did not interfere at all. The difference is dramatic: The <img alt="Image" height="9" src="images/B9780124159501000173/fx020.jpg" width="46"/> performs very poorly; the <img alt="Image" height="9" src="images/B9780124159501000173/fx023.jpg" width="52"/> performance, while substantially better, still falls far short of the ideal.</p><div class="pageavoid"><figure class="fig" id="f0030"><img alt="Image" height="246" src="images/B9780124159501000173/gr004.jpg" width="219"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.4</span> Schematic performance of a <img alt="Image" height="9" src="images/B9780124159501000173/fx020.jpg" width="46"/>, a <img alt="Image" height="9" src="images/B9780124159501000173/fx023.jpg" width="52"/>, and an ideal lock with no overhead.</div></figcaption></figure></div><p class="text" id="p0120">To understand these results, we must study the architecture of modern multiprocessors. First, a word of caution: Modern multiprocessors have a variety of architectures, so we must be careful about overgeneralizing. Nevertheless, (almost) all modern architectures have similar issues concerning caching and locality. The details differ, but the principles remain the same.</p><p class="text" id="p0125">For simplicity, we consider a typical multiprocessor architecture in which processors communicate by a shared broadcast medium called a <i>bus</i>. The memory typically also resides in nodes connected to the bus, each with its own <i>memory controller</i>. The processors and memory controllers can broadcast on the bus, but only one at a time. All processors and memory controllers can listen at the same time. Bus-based architectures are common today because they are easy to build, but they do not scale well to many processors; the bus becomes a point of contention.</p><p class="text" id="p0130">Each processor has a <i>cache</i>, a small high-speed memory in which it keeps data likely to be of interest. Memory access typically takes orders of magnitude longer than access to the cache. Technology trends are not helping: Memory access time is unlikely to catch up with processor cycle time in the near future, so cache performance is critical to the overall performance of a multiprocessor.</p><p class="text" id="p0135">A processor's cache contains copies of memory locations, along with their addresses. These copies are maintained by a <i>cache coherence protocol</i>, and may be <i>shared</i> or <i>exclusive</i>. As the name suggests, if any processor has an exclusive <span aria-label="Page 153" epub:type="pagebreak" id="page_153" role="doc-pagebreak"/>copy of a memory location, then no other processor has a copy of that location, shared or exclusive.</p><p class="text" id="p0140">When accessing a memory location, a processor first checks whether its cache has a copy of that location. If it is writing the location, the copy must be exclusive. If the cache has the location's current data, then we say that the processor <i>hits</i> in its cache. In this case, the processor may read or write the copy in its cache immediately. Otherwise, the processor has a <i>cache miss</i>, and it requests a copy by broadcasting the address of the location on the bus. The other processors (and the memory controllers) <i>snoop</i> on the bus. If some processor has an exclusive copy of the location in its cache, it responds by broadcasting the address and value (making its copy shared). Otherwise, the memory controller responsible for that location responds. If the request was to write the location, then all previous copies are <i>invalidated</i>, so that the requester has an exclusive copy of that location.</p><p class="text" id="p0145">We now consider how the simple <img alt="Image" height="9" src="images/B9780124159501000173/fx020.jpg" width="46"/> algorithm performs on this architecture: Because <img alt="Image" height="11" src="images/B9780124159501000173/fx013.jpg" width="59"/>() may write the location, a thread must request an exclusive copy of the lock whenever it calls <img alt="Image" height="11" src="images/B9780124159501000173/fx013.jpg" width="59"/>(), unless its processor's cache already has such a copy. This request forces other processors to invalidate their cached copies of the lock. If multiple threads are spinning on the lock, almost every call to <img alt="Image" height="11" src="images/B9780124159501000173/fx013.jpg" width="59"/>() will result in a cache miss and a request on the bus to fetch the (unchanged) value. Compounding the injury, when the thread holding the lock tries to release it, it may be delayed because the bus is monopolized by the spinners. Indeed, because all threads use the bus to communicate with memory, even threads not waiting for the lock may be delayed. We now understand why the <img alt="Image" height="9" src="images/B9780124159501000173/fx020.jpg" width="46"/> performs so poorly.</p><p class="text" id="p0150">Now consider the behavior of the <img alt="Image" height="9" src="images/B9780124159501000173/fx023.jpg" width="52"/> algorithm while the lock is held by a thread <i>A</i>. The first time thread <i>B</i> reads the lock, it has a cache miss, forcing <i>B</i> to block while the value is loaded into <i>B</i>'s cache. However, because <i>B</i> is only reading the lock, it only requests a shared copy, which is stored in its processor's cache. As long as <i>A</i> holds the lock, <i>B</i> repeatedly rereads the value, but hits in its cache every time. <i>B</i> produces no bus traffic after its first request, and does not slow down other threads' memory accesses.</p><p class="text" id="p0155">The situation deteriorates, however, when the lock holder <i>A</i> releases the lock by writing <i>false</i> to the lock's <span class="sans-serif">state</span> variable. Because the lock is now shared with all the threads spinning on it, this write causes a cache miss, resulting in a request on the bus for an exclusive copy of the lock. This request invalidates the cached copies of the spinning threads. Each one has a cache miss and rereads the new value, and they all (more or less simultaneously) call <img alt="Image" height="11" src="images/B9780124159501000173/fx013.jpg" width="59"/>() to acquire the lock. The first to succeed invalidates the others, which must then reread the value, causing a storm of bus traffic. Eventually, the threads settle down once again to local spinning.</p><p class="text" id="p0160">This notion of <i>local spinning</i>, where threads repeatedly reread cached values instead of repeatedly using the bus, is an important principle critical to the design of efficient spin locks.<span aria-label="Page 154" epub:type="pagebreak" id="page_154" role="doc-pagebreak"/></p></section><section><h2 class="h1hd" id="s0025"><a id="st0035"/>7.4 Exponential back-off</h2><p class="textfl" id="p0165">We now consider how to improve the <img alt="Image" height="9" src="images/B9780124159501000173/fx023.jpg" width="52"/> algorithm by reducing the bus traffic induced when a thread releases the lock and many threads are waiting to acquire it. First, some terminology: <i>Contention</i> on a lock occurs when multiple threads try to acquire the lock at the same time. <i>High contention</i> means there are many such threads; <i>low contention</i> means there are few. As discussed above, attempting to acquire a highly contended lock is a bad idea: Such an attempt contributes to bus traffic (making the traffic jam worse) at a time when the thread's chances of acquiring the lock are slim. Instead, it is more effective for the thread to <i>back off</i> for some duration, giving the competing threads a chance to finish.</p><p class="text" id="p0170">Recall that in the <img alt="Image" height="9" src="images/B9780124159501000173/fx023.jpg" width="52"/> class, the <img alt="Image" height="9" src="images/B9780124159501000173/fx004.jpg" width="25"/>() method takes two steps: It repeatedly reads the lock until the lock is free, and then it attempts to acquire the lock by calling <img alt="Image" height="11" src="images/B9780124159501000173/fx013.jpg" width="59"/><span class="hiddenClass"><mml:math><mml:mo stretchy="false">(</mml:mo><mml:mtext mathvariant="italic">true</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000173/si5.png" style="vertical-align:middle" width="39"/></span>. Here is a key observation: If a thread fails to acquire the lock in the second step, then some other thread must have acquired the lock between the first and second step, so most likely there is high contention for that lock. Here is a simple approach: Whenever a thread sees the lock has become free but fails to acquire it, it backs off before retrying. To ensure that competing threads do not fall into lockstep, each backing off and then trying again to acquire the lock at the same time, the thread backs off for a random duration.</p><p class="text" id="p0175">For how long should the thread back off before retrying? A good rule of thumb is that the larger the number of unsuccessful tries, the higher the likely contention, so the longer the thread should back off. To incorporate this rule, each time a thread tries and fails to get the lock, it doubles the expected back-off time, up to a fixed maximum.</p><p class="text" id="p0180">Because backing off is common to several locking algorithms, we encapsulate this logic in a simple <img alt="Image" height="9" src="images/B9780124159501000173/fx025.jpg" width="46"/> class, shown in <a href="#f0035" id="cf0040">Fig. 7.5</a>. The constructor takes two arguments: <img alt="Image" height="11" src="images/B9780124159501000173/fx026.jpg" width="53"/> is the initial minimum delay (it makes no sense for the thread to back off for too short a duration), and <img alt="Image" height="11" src="images/B9780124159501000173/fx027.jpg" width="53"/> is the final maximum delay (a final limit is necessary to prevent unlucky threads from backing off for much too long). The <img alt="Image" height="9" src="images/B9780124159501000173/fx028.jpg" width="31"/> field controls the current delay limit. The <img alt="Image" height="9" src="images/B9780124159501000173/fx029.jpg" width="46"/>() method computes a random delay between zero and the current limit, and blocks the thread for that duration before returning. It doubles the limit for the next back-off, up to <img alt="Image" height="11" src="images/B9780124159501000173/fx027.jpg" width="53"/>.</p><div class="pageavoid"><figure class="fig" id="f0035"><img alt="Image" height="224" src="images/B9780124159501000173/gr005.jpg" width="374"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.5</span> The <img alt="Image" height="9" src="images/B9780124159501000173/fx025.jpg" width="46"/> class: adaptive back-off logic. To ensure that concurrently contending threads do not repeatedly try to acquire the lock at the same time, threads back off for a random duration. Each time the thread tries and fails to get the lock, it doubles the expected time to back off, up to a fixed maximum.</div></figcaption></figure></div><p class="text" id="p0185"><a href="#f0040" id="cf0045">Fig. 7.6</a> shows the <img alt="Image" height="9" src="images/B9780124159501000173/fx030.jpg" width="72"/> class. It uses a <img alt="Image" height="9" src="images/B9780124159501000173/fx025.jpg" width="46"/> object whose minimum and maximum back-off durations are governed by the constants chosen for <img alt="Image" height="13" src="images/B9780124159501000173/fx031.jpg" width="59"/> and <img alt="Image" height="13" src="images/B9780124159501000173/fx032.jpg" width="59"/>. Note that the thread backs off only when it fails to acquire a lock that it had immediately before observed to be free. Observing that the lock is held by another thread says nothing about the level of contention.</p><div class="pageavoid"><figure class="fig" id="f0040"><img alt="Image" height="322" src="images/B9780124159501000173/gr006.jpg" width="364"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.6</span> The exponential back-off lock. Whenever the thread fails to acquire a lock that became free, it backs off before retrying.</div></figcaption></figure></div><p class="text" id="p0190">The <img alt="Image" height="9" src="images/B9780124159501000173/fx030.jpg" width="72"/> is easy to implement, and typically performs significantly better than <img alt="Image" height="9" src="images/B9780124159501000173/fx020.jpg" width="46"/> and <img alt="Image" height="9" src="images/B9780124159501000173/fx023.jpg" width="52"/> on many architectures. Unfortunately, its performance is sensitive to the choice of <img alt="Image" height="13" src="images/B9780124159501000173/fx031.jpg" width="59"/> and <img alt="Image" height="13" src="images/B9780124159501000173/fx032.jpg" width="59"/> values. To deploy this lock on a particular architecture, it is easy to experiment with different values, and to choose the ones that work best. Experience shows, however, that these optimal values are sensitive to the number of processors and their speed, so it is not easy to tune <img alt="Image" height="9" src="images/B9780124159501000173/fx030.jpg" width="72"/> to be portable across a range of different <span aria-label="Page 155" epub:type="pagebreak" id="page_155" role="doc-pagebreak"/>machines.<span aria-label="Page 156" epub:type="pagebreak" id="page_156" role="doc-pagebreak"/></p><p class="text" id="p0195">One drawback of <img alt="Image" height="9" src="images/B9780124159501000173/fx030.jpg" width="72"/> is that it underutilizes the critical section when the lock is contended: Because threads back off when they notice contention, when a thread releases the lock, there may be some delay before another thread attempts to acquire it, even though many threads are waiting to acquire the lock. Indeed, because threads back off for longer at higher contention, this effect is more pronounced at higher levels of contention.</p><p class="text" id="p0200">Finally, the <img alt="Image" height="9" src="images/B9780124159501000173/fx030.jpg" width="72"/> can be unfair, allowing one thread to acquire the lock many times while other threads are waiting. <img alt="Image" height="9" src="images/B9780124159501000173/fx020.jpg" width="46"/> and <img alt="Image" height="9" src="images/B9780124159501000173/fx023.jpg" width="52"/> may also be unfair, but <img alt="Image" height="9" src="images/B9780124159501000173/fx030.jpg" width="72"/> exacerbates this problem because the thread that just released the lock might never notice that the lock is contended, and so not back off at all.</p><p class="text" id="p0205">Although this unfairness has obvious negative consequences, including the possibility of starving other threads, it also has some positive consequences: Because a lock often protects accesses to some shared data structure, which is also cached, granting repeated access to the same thread without intervening accesses by threads at different processors reduces cache misses due to accesses to this data structure, and so reduces bus traffic and avoids the latency of communication. For longer critical sections, this effect can be more significant than the effect of reduced contention on the lock itself. So there is a tension between fairness and performance.</p></section><section><h2 class="h1hd" id="s0030"><a id="st0040"/>7.5 Queue locks</h2><p class="textfl" id="p0210">We now explore a different approach to implementing scalable spin locks, one that is slightly more complicated than back-off locks, but inherently more portable, and avoids or ameliorates many of the problems of back-off locks. The idea is to have threads waiting to acquire the lock form a <i>queue</i>. In a queue, each thread can discover when its turn has arrived by checking whether its predecessor has finished. Cache-coherence traffic is reduced by having each thread spin on a different location. A queue also allows better utilization of the critical section, since there is no need to guess when to attempt to access it: Each thread is notified directly by its predecessor in the queue. Finally, a queue provides first-come-first-served fairness, the same high degree of fairness achieved by the <img alt="Image" height="11" src="images/B9780124159501000173/fx002.jpg" width="39"/> algorithm. We now explore different ways to implement <i>queue locks</i>, a family of locking algorithms that exploit these insights.</p><section><h3 class="h2hd" id="s0035"><a id="st0045"/>7.5.1 Array-based locks</h3><p class="textfl" id="p0215"><a href="#f0045" id="cf0050">Fig. 7.7</a> shows the <img alt="Image" height="9" src="images/B9780124159501000173/fx033.jpg" width="33"/>,<sup><a epub:type="noteref" href="#fn001" id="cf0055" role="doc-noteref">1</a></sup> a simple array-based queue lock. The threads share an <img alt="Image" height="11" src="images/B9780124159501000173/fx015.jpg" width="87"/> <img alt="Image" height="9" src="images/B9780124159501000173/fx034.jpg" width="23"/> field, initially zero. To acquire the lock, each thread atomically increments <img alt="Image" height="9" src="images/B9780124159501000173/fx034.jpg" width="23"/> (line 17). Call the resulting value the thread's <i>slot</i>. The slot is used as an index into a Boolean <img alt="Image" height="11" src="images/B9780124159501000173/fx035.jpg" width="25"/> array.</p><div class="pageavoid"><figure class="fig" id="f0045"><img alt="Image" height="421" src="images/B9780124159501000173/gr007.jpg" width="412"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.7</span> Array-based queue lock.</div></figcaption></figure></div><p class="text" id="p0220">If <img alt="Image" height="10" src="images/B9780124159501000173/fx011.jpg" width="23"/><span class="hiddenClass"><mml:math><mml:mo stretchy="false">[</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000173/si6.png" style="vertical-align:middle" width="20"/></span> is <i>true</i>, then the thread with slot <i>j</i> has permission to acquire the lock. Initially, <img alt="Image" height="10" src="images/B9780124159501000173/fx011.jpg" width="23"/>[0] is <i>true</i>. To acquire the lock, a thread spins until the flag <span aria-label="Page 157" epub:type="pagebreak" id="page_157" role="doc-pagebreak"/>at its slot becomes <i>true</i> (line 19). To release the lock, the thread sets the flag at its slot to <i>false</i> (line 23), and sets the flag at the next slot to <i>true</i> (line 24). All arithmetic is modulo <i>n</i>, where <i>n</i> is at least as large as the maximum number of concurrent threads.</p><p class="text" id="p0225">In the <img alt="Image" height="9" src="images/B9780124159501000173/fx033.jpg" width="33"/> algorithm, <img alt="Image" height="11" src="images/B9780124159501000173/fx036.jpg" width="73"/> is a <i>thread-local</i> variable (see Appendix <a href="B9780124159501000318.xhtml">A</a>). Thread-local variables differ from their regular counterparts in that each thread has its own, independently initialized copy of each variable. Thread-local variables need not be stored in shared memory, do not require synchronization, and do not generate any coherence traffic since they are accessed by only one thread. The value of a thread-local variable is accessed by <img alt="Image" height="11" src="images/B9780124159501000173/fx024.jpg" width="19"/>() and <img alt="Image" height="8" src="images/B9780124159501000173/fx022.jpg" width="18"/>() methods.</p><p class="text" id="p0230">The <img alt="Image" height="10" src="images/B9780124159501000173/fx011.jpg" width="23"/>[] array, on the other hand, is shared.<sup><a epub:type="noteref" href="#fn002" id="cf0065" role="doc-noteref">2</a></sup> However, contention on the array locations is minimized since each thread, at any given time, spins on its locally cached copy of a single array location, greatly reducing invalidation <span aria-label="Page 158" epub:type="pagebreak" id="page_158" role="doc-pagebreak"/>traffic.<span aria-label="Page 159" epub:type="pagebreak" id="page_159" role="doc-pagebreak"/></p><p class="text" id="p0235">Contention may still occur because of a phenomenon called <i>false sharing</i>, which occurs when adjacent data items (such as array elements) share a single cache line. A write to one item invalidates that item's cache line, which causes invalidation traffic to processors that are spinning on nearby unchanged items that happen to fall in the same cache line. In the example in part (a) of <a href="#f0050" id="cf0070">Fig. 7.8</a>, threads accessing the eight <img alt="Image" height="9" src="images/B9780124159501000173/fx033.jpg" width="33"/> locations may suffer unnecessary invalidations because the locations were all cached in the same two four-word lines.</p><div class="pageavoid"><figure class="fig" id="f0050"><img alt="Image" height="597" src="images/B9780124159501000173/gr008.jpg" width="497"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.8</span> The <img alt="Image" height="9" src="images/B9780124159501000173/fx033.jpg" width="33"/> with padding to avoid false sharing. In part (a), the <img alt="Image" height="9" src="images/B9780124159501000173/fx033.jpg" width="33"/> has eight slots which are accessed via a modulo 8 counter. Array entries are typically mapped into cache lines consecutively. As illustrated, when thread <i>A</i> changes the status of its entry, thread <i>B</i>, whose entry is mapped to the same cache line <i>k</i>, incurs a false invalidation. In part (b), each location is padded so it is 4 apart from the others with a modulo 32 counter. Even if array entries are mapped consecutively, the entry for <i>B</i> is mapped to a different cache line from that of <i>A</i>, so <i>B</i>'s entry is not invalidated when <i>A</i> invalidates its entry.</div></figcaption></figure></div><p class="text" id="p0240">One way to avoid false sharing is to <i>pad</i> array elements so that distinct elements are mapped to distinct cache lines. Padding is easier in low-level languages like C or C++, where the programmer has direct control over the layout of objects in memory. In the example in part (b) of <a href="#f0050" id="cf0075">Fig. 7.8</a>, we pad the eight original <img alt="Image" height="9" src="images/B9780124159501000173/fx033.jpg" width="33"/> locations by increasing the lock array size four-fold, and placing the locations four words apart so that no two locations can fall in the same cache line. (We increment from one location <i>i</i> to the next by computing <span class="hiddenClass"><mml:math><mml:mn>4</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo linebreak="badbreak" linebreakstyle="after">+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">mod</mml:mi></mml:mrow><mml:mspace width="0.25em"/><mml:mn>32</mml:mn></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000173/si7.png" style="vertical-align:middle" width="107"/></span> instead of <span class="hiddenClass"><mml:math><mml:mi>i</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">+</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">mod</mml:mi></mml:mrow><mml:mspace width="0.25em"/><mml:mn>8</mml:mn></mml:math></span><span><img alt="Image" height="13" src="images/B9780124159501000173/si8.png" style="vertical-align:middle" width="77"/></span>.)</p><p class="text" id="p0245">The <img alt="Image" height="9" src="images/B9780124159501000173/fx033.jpg" width="33"/> improves on <img alt="Image" height="9" src="images/B9780124159501000173/fx030.jpg" width="72"/>: it reduces invalidations to a minimum and minimizes the interval between when a lock is freed by one thread and when it is acquired by another. Unlike the <img alt="Image" height="9" src="images/B9780124159501000173/fx020.jpg" width="46"/> and <img alt="Image" height="9" src="images/B9780124159501000173/fx030.jpg" width="72"/>, this algorithm guarantees that no starvation occurs, and provides first-come-first-served fairness.</p><p class="text" id="p0250">Unfortunately, the <img alt="Image" height="9" src="images/B9780124159501000173/fx033.jpg" width="33"/> lock is not space-efficient. It requires a known bound <i>n</i> on the maximum number of concurrent threads, and it allocates an array of that size per lock. Synchronizing <i>L</i> distinct objects requires <span class="hiddenClass"><mml:math><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>L</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000173/si9.png" style="vertical-align:middle" width="45"/></span> space, even if a thread accesses only one lock at a time.</p></section><section><h3 class="h2hd" id="s0040"><a id="st0050"/>7.5.2 The CLH queue lock</h3><p class="textfl" id="p0255">We now turn our attention to a different style of queue lock, the <img alt="Image" height="9" src="images/B9780124159501000173/fx037.jpg" width="46"/> (<a href="#f0055" id="cf0080">Fig. 7.9</a>). This class records each thread's status in a <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> object, which has a Boolean <img alt="Image" height="9" src="images/B9780124159501000173/fx039.jpg" width="38"/> field. If that field is <i>true</i>, then the corresponding thread has either acquired the lock or is waiting for the lock. If that field is <i>false</i>, then the thread has released the lock. The lock itself is represented as a virtual linked list of <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> objects. We use the term “virtual” because the list is implicit: Each thread refers to its predecessor through a thread-local <img alt="Image" height="11" src="images/B9780124159501000173/fx040.jpg" width="25"/> variable. The public <img alt="Image" height="9" src="images/B9780124159501000173/fx034.jpg" width="23"/> field is an <img alt="Image" height="11" src="images/B9780124159501000173/fx041.jpg" width="147"/> to the node most recently added to the queue.</p><div class="pageavoid"><figure class="fig" id="f0055"><img alt="Image" height="536" src="images/B9780124159501000173/gr009.jpg" width="326"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.9</span> The <img alt="Image" height="9" src="images/B9780124159501000173/fx037.jpg" width="46"/> class.</div></figcaption></figure></div><p class="text" id="p0260">To acquire the lock, a thread sets the <img alt="Image" height="9" src="images/B9780124159501000173/fx039.jpg" width="38"/> field of its <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> to <i>true</i>, indicating that the thread is not ready to release the lock. The thread applies <img alt="Image" height="11" src="images/B9780124159501000173/fx013.jpg" width="59"/>() to the <img alt="Image" height="9" src="images/B9780124159501000173/fx034.jpg" width="23"/> field to make its own node the tail of the queue, simultaneously acquiring a reference to its predecessor's <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/>. The thread then spins on the predecessor's <img alt="Image" height="9" src="images/B9780124159501000173/fx039.jpg" width="38"/> field until the predecessor releases the lock. To release the lock, the thread sets its node's <img alt="Image" height="9" src="images/B9780124159501000173/fx039.jpg" width="38"/> field to <i>false</i>. It then reuses its predecessor's <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> as its new node for future lock accesses. It can do so because at this point the thread's predecessor's <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> is no longer used by the predecessor. It cannot use its old <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> because that node could be referenced both by the thread's successor and by the <img alt="Image" height="9" src="images/B9780124159501000173/fx034.jpg" width="23"/>. Although we do not do so in our implementation, it is possible to recycle nodes so that if there are <i>L</i> locks and each thread accesses at most one lock at a time, then <span aria-label="Page 160" epub:type="pagebreak" id="page_160" role="doc-pagebreak"/>the <img alt="Image" height="9" src="images/B9780124159501000173/fx037.jpg" width="46"/> class needs only <span class="hiddenClass"><mml:math><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>L</mml:mi><mml:mo linebreak="badbreak" linebreakstyle="after">+</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000173/si10.png" style="vertical-align:middle" width="64"/></span> space, as compared with <span class="hiddenClass"><mml:math><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>L</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000173/si9.png" style="vertical-align:middle" width="45"/></span> for the <img alt="Image" height="9" src="images/B9780124159501000173/fx033.jpg" width="33"/> class.<sup><a epub:type="noteref" href="#fn003" id="cf0085" role="doc-noteref">3</a></sup> <a href="#f0060" id="cf0090">Fig. 7.10</a> shows a typical <img alt="Image" height="9" src="images/B9780124159501000173/fx037.jpg" width="46"/> execution.</p><div class="pageavoid"><figure class="fig" id="f0060"><img alt="Image" height="296" src="images/B9780124159501000173/gr010.jpg" width="497"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.10</span> <img alt="Image" height="9" src="images/B9780124159501000173/fx037.jpg" width="46"/> class: lock acquisition and release. Initially the <img alt="Image" height="9" src="images/B9780124159501000173/fx034.jpg" width="23"/> field refers to a <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> whose <img alt="Image" height="9" src="images/B9780124159501000173/fx039.jpg" width="38"/> field is <i>false</i>. Thread <i>A</i> then applies <img alt="Image" height="11" src="images/B9780124159501000173/fx013.jpg" width="59"/>() to the <img alt="Image" height="9" src="images/B9780124159501000173/fx034.jpg" width="23"/> field to insert its <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> at the tail of the queue, simultaneously acquiring a reference to its predecessor's <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/>. Next, <i>B</i> does the same to insert its <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> at the tail of the queue. <i>A</i> then releases the lock by setting its node's <img alt="Image" height="9" src="images/B9780124159501000173/fx039.jpg" width="38"/> field to <i>false</i>. It then recycles the <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> referenced by <img alt="Image" height="11" src="images/B9780124159501000173/fx040.jpg" width="25"/> for future lock accesses.</div></figcaption></figure></div><p class="text" id="p0265">Like the <img alt="Image" height="9" src="images/B9780124159501000173/fx033.jpg" width="33"/>, this algorithm has each thread spin on a distinct location, so when one thread releases its lock, it invalidates only its successor's cache. This algorithm requires much less space than the <img alt="Image" height="9" src="images/B9780124159501000173/fx033.jpg" width="33"/> class, <span aria-label="Page 161" epub:type="pagebreak" id="page_161" role="doc-pagebreak"/>and does not require knowledge of the number of threads that might access the lock. Like the <img alt="Image" height="9" src="images/B9780124159501000173/fx033.jpg" width="33"/> class, it provides first-come-first-served fairness.</p><p class="text" id="p0270">Perhaps the only disadvantage of this lock algorithm is that it performs poorly on cacheless NUMA architectures. Each thread spins waiting for its predecessor's node's <img alt="Image" height="9" src="images/B9780124159501000173/fx039.jpg" width="38"/> field to become <i>false</i>. If this memory location is remote, then performance suffers. On cache-coherent architectures, however, this approach should work well.</p></section><section><h3 class="h2hd" id="s0045"><a id="st0055"/>7.5.3 The MCS queue lock</h3><p class="textfl" id="p0275">The <img alt="Image" height="9" src="images/B9780124159501000173/fx042.jpg" width="46"/> (<a href="#f0065" id="cf0095">Fig. 7.11</a>) is another lock represented as a linked list of <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> objects, where each <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> represents either a lock holder or a thread waiting to acquire the lock. Unlike the <img alt="Image" height="9" src="images/B9780124159501000173/fx037.jpg" width="46"/> class, the list is explicit, not virtual: Instead of embodying the list in thread-local variables, it is embodied in the (globally accessible) <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> objects, via their <img alt="Image" height="8" src="images/B9780124159501000173/fx043.jpg" width="25"/> fields.</p><div class="pageavoid"><figure class="fig" id="f0065"><img alt="Image" height="602" src="images/B9780124159501000173/gr011.jpg" width="339"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.11</span> The <img alt="Image" height="9" src="images/B9780124159501000173/fx042.jpg" width="46"/> class.</div></figcaption></figure></div><p class="text" id="p0280">To acquire the lock, a thread appends its own <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> at the tail of the list (line 14). If the queue was not previously empty, it sets the predecessor's <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/>'s <img alt="Image" height="8" src="images/B9780124159501000173/fx043.jpg" width="25"/> field to refer to its own <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/>. The thread then spins on a (local) <img alt="Image" height="9" src="images/B9780124159501000173/fx039.jpg" width="38"/> field in its own <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> waiting until its predecessor sets this field to <i>false</i> (lines 15–20).</p><p class="text" id="p0285"><span aria-label="Page 162" epub:type="pagebreak" id="page_162" role="doc-pagebreak"/>To release the lock, a thread checks whether its node's <img alt="Image" height="8" src="images/B9780124159501000173/fx043.jpg" width="25"/> field is <i>null</i> (line 24). If so, then either no other thread is contending for the lock, or there is another thread, but it is slow. To distinguish these cases, it applies <img alt="Image" height="11" src="images/B9780124159501000173/fx044.jpg" width="86"/><span class="hiddenClass"><mml:math><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo>,</mml:mo><mml:mtext mathvariant="italic">null</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="15" src="images/B9780124159501000173/si11.png" style="vertical-align:middle" width="54"/></span> to the <img alt="Image" height="9" src="images/B9780124159501000173/fx034.jpg" width="23"/> field, where <i>q</i> is the thread's node. If the call succeeds, then no other thread is trying to acquire the lock, so the thread just returns. Otherwise, another <span aria-label="Page 163" epub:type="pagebreak" id="page_163" role="doc-pagebreak"/>(slow) thread is trying to acquire the lock, so the thread spins waiting for the other thread to finish adding its node to the queue (line 28). Once the successor appears (or if it was there at the beginning), the thread sets its successor's <img alt="Image" height="9" src="images/B9780124159501000173/fx039.jpg" width="38"/> field to <i>false</i>, indicating that the lock is now free. At this point, no other thread can access this <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/>, and so it can be reused. <a href="#f0070" id="cf0100">Fig. 7.12</a> shows an example execution of the <img alt="Image" height="9" src="images/B9780124159501000173/fx045.jpg" width="46"/>.</p><div class="pageavoid"><figure class="fig" id="f0070"><img alt="Image" height="268" src="images/B9780124159501000173/gr012.jpg" width="497"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.12</span> A lock acquisition and release in an <img alt="Image" height="9" src="images/B9780124159501000173/fx042.jpg" width="46"/>. (a) Initially the <img alt="Image" height="9" src="images/B9780124159501000173/fx034.jpg" width="23"/> is <i>null</i>. (b) To acquire the lock, thread <i>A</i> places its own <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> at the tail of the list and since it has no predecessor, it enters the critical section. (c) Thread <i>B</i> enqueues its own <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> at the tail of the list and modifies its predecessor's <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> to refer back to its own. Thread <i>B</i> then spins on its <img alt="Image" height="9" src="images/B9780124159501000173/fx039.jpg" width="38"/> field waiting until <i>A</i>, its predecessor, sets this field from <i>true</i> to <i>false</i>. Thread <i>C</i> repeats this sequence. (d) To release the lock, <i>A</i> follows its <img alt="Image" height="8" src="images/B9780124159501000173/fx043.jpg" width="25"/> field to its successor <i>B</i> and sets <i>B</i>'s <img alt="Image" height="9" src="images/B9780124159501000173/fx039.jpg" width="38"/> field to <i>false</i>. It can now reuse its <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/>.</div></figcaption></figure></div><p class="text" id="p0290">This lock shares the advantages of the <img alt="Image" height="9" src="images/B9780124159501000173/fx037.jpg" width="46"/>, in particular, the property that each lock release invalidates only the successor's cache entry. It is better suited to cacheless NUMA architectures because each thread controls the location on which it spins. Like the <img alt="Image" height="9" src="images/B9780124159501000173/fx037.jpg" width="46"/>, nodes can be recycled so that this lock has space complexity <span class="hiddenClass"><mml:math><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>L</mml:mi><mml:mo linebreak="badbreak" linebreakstyle="after">+</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000173/si10.png" style="vertical-align:middle" width="64"/></span>. One drawback of the <img alt="Image" height="9" src="images/B9780124159501000173/fx042.jpg" width="46"/> algorithm is that releasing a lock requires spinning. Another is that it requires more reads, writes, and <img alt="Image" height="12" src="images/B9780124159501000173/fx014.jpg" width="97"/> calls than the <img alt="Image" height="9" src="images/B9780124159501000173/fx037.jpg" width="46"/> algorithm.<span aria-label="Page 164" epub:type="pagebreak" id="page_164" role="doc-pagebreak"/></p></section></section><section><h2 class="h1hd" id="s0050"><a id="st0060"/>7.6 A queue lock with timeouts</h2><p class="textfl" id="p0295">The Java <img alt="Image" height="9" src="images/B9780124159501000173/fx003.jpg" width="25"/> interface includes a <img alt="Image" height="11" src="images/B9780124159501000173/fx046.jpg" width="46"/>() method that allows the caller to specify a <i>timeout</i>, that is, a maximum duration the caller is willing to wait to acquire the lock. If the timeout expires before the caller acquires the lock, the attempt is abandoned. A Boolean return value indicates whether the lock attempt succeeded. (For an explanation why these methods throw <img alt="Image" height="11" src="images/B9780124159501000173/fx047.jpg" width="132"/>, see <a href="B9780124159501000185.xhtml">Pragma 8.2.1</a>.)</p><p class="text" id="p0300">Abandoning a <img alt="Image" height="9" src="images/B9780124159501000173/fx030.jpg" width="72"/> request is trivial: a thread can simply return from the <img alt="Image" height="11" src="images/B9780124159501000173/fx046.jpg" width="46"/>() call. Responding to a timeout is wait-free, requiring only a constant number of steps. By contrast, timing out any of the queue lock algorithms is far from trivial: if a thread simply returns, the threads queued up behind it will starve.</p><p class="text" id="p0305">Here is a bird's-eye view of a queue lock with timeouts. As in the <img alt="Image" height="9" src="images/B9780124159501000173/fx037.jpg" width="46"/>, the lock is a virtual queue of nodes, and each thread spins on its predecessor's node waiting for the lock to be released. As noted, when a thread times out, it cannot simply abandon its queue node, because its successor will never notice when the lock is released. On the other hand, it seems extremely difficult to unlink a queue node without disrupting concurrent lock releases. Instead, we take a <i>lazy</i> approach: When a thread times out, it marks its node as abandoned. Its successor in the queue, if there is one, notices that the node on which it is spinning has been abandoned, and starts spinning on the abandoned node's predecessor. This approach has the added advantage that the successor can recycle the abandoned node.</p><p class="text" id="p0310"><a href="#f0075" id="cf0105">Fig. 7.13</a> shows the fields, constructor, and <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> class for the <img alt="Image" height="9" src="images/B9780124159501000173/fx048.jpg" width="39"/> (timeout lock) class, a queue lock based on the <img alt="Image" height="9" src="images/B9780124159501000173/fx037.jpg" width="46"/> class that supports wait-free timeout even for threads in the middle of the list of nodes waiting for the lock.</p><div class="pageavoid"><figure class="fig" id="f0075"><img alt="Image" height="273" src="images/B9780124159501000173/gr013.jpg" width="284"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.13</span> <img alt="Image" height="9" src="images/B9780124159501000173/fx048.jpg" width="39"/> class: fields, constructor, and <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> class.</div></figcaption></figure></div><p class="text" id="p0315">When a <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/>'s <img alt="Image" height="11" src="images/B9780124159501000173/fx040.jpg" width="25"/> field is <i>null</i>, the associated thread has either not acquired the lock or has released it. When a <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/>'s <img alt="Image" height="11" src="images/B9780124159501000173/fx040.jpg" width="25"/> field refers to the distinguished static <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> <img alt="Image" height="9" src="images/B9780124159501000173/fx049.jpg" width="59"/>, the associated thread has released the lock. Finally, if the <img alt="Image" height="11" src="images/B9780124159501000173/fx040.jpg" width="25"/> field refers to some other <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/>, the associated thread <span aria-label="Page 165" epub:type="pagebreak" id="page_165" role="doc-pagebreak"/>has abandoned the lock request, so the thread owning the successor node should wait on the abandoned node's predecessor.</p><p class="text" id="p0320"><a href="#f0080" id="cf0110">Fig. 7.14</a> shows the <img alt="Image" height="9" src="images/B9780124159501000173/fx048.jpg" width="39"/> class's <img alt="Image" height="11" src="images/B9780124159501000173/fx046.jpg" width="46"/>() and <img alt="Image" height="9" src="images/B9780124159501000173/fx005.jpg" width="39"/>() methods. The <img alt="Image" height="11" src="images/B9780124159501000173/fx046.jpg" width="46"/>() method creates a new <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> with a <i>null</i> <img alt="Image" height="11" src="images/B9780124159501000173/fx040.jpg" width="25"/> field and appends it to the list as in the <img alt="Image" height="9" src="images/B9780124159501000173/fx037.jpg" width="46"/> class (lines 21–24). If the lock was free (line 25), the thread enters the critical section. Otherwise, it spins waiting for its predecessor's <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/>'s <img alt="Image" height="11" src="images/B9780124159501000173/fx040.jpg" width="25"/> field to change (lines 28–35). If the predecessor thread times out, it sets the <img alt="Image" height="11" src="images/B9780124159501000173/fx040.jpg" width="25"/> field to its own predecessor, and the thread spins instead on the new predecessor. An example of such a sequence appears in <a href="#f0085" id="cf0115">Fig. 7.15</a>. Finally, if the thread itself times out (line 36), it attempts to remove its <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> from the list by applying <img alt="Image" height="12" src="images/B9780124159501000173/fx014.jpg" width="97"/> to the <img alt="Image" height="9" src="images/B9780124159501000173/fx034.jpg" width="23"/> field. If the <img alt="Image" height="12" src="images/B9780124159501000173/fx014.jpg" width="97"/> call fails, indicating that the thread has a successor, the thread sets its <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/>'s <img alt="Image" height="11" src="images/B9780124159501000173/fx040.jpg" width="25"/> field, previously <i>null</i>, to its predecessor's <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/>, indicating that it has abandoned the queue.</p><div class="pageavoid"><figure class="fig" id="f0080"><img alt="Image" height="438" src="images/B9780124159501000173/gr014.jpg" width="503"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.14</span> <img alt="Image" height="9" src="images/B9780124159501000173/fx048.jpg" width="39"/> class: <img alt="Image" height="11" src="images/B9780124159501000173/fx046.jpg" width="46"/>() and <img alt="Image" height="9" src="images/B9780124159501000173/fx005.jpg" width="39"/>() methods.</div></figcaption></figure></div><div class="pageavoid"><figure class="fig" id="f0085"><img alt="Image" height="162" src="images/B9780124159501000173/gr015.jpg" width="497"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.15</span> Timed-out nodes that must be skipped to acquire the <img alt="Image" height="9" src="images/B9780124159501000173/fx048.jpg" width="39"/>. Threads <i>B</i> and <i>D</i> have timed out, redirecting their <img alt="Image" height="11" src="images/B9780124159501000173/fx040.jpg" width="25"/> fields to their predecessors in the list. Thread <i>C</i> notices that <i>B</i>'s field is directed at <i>A</i> and so it starts spinning on <i>A</i>. Similarly, thread <i>E</i> spins waiting for <i>C</i>. When <i>A</i> completes and sets its <img alt="Image" height="11" src="images/B9780124159501000173/fx040.jpg" width="25"/> to <img alt="Image" height="9" src="images/B9780124159501000173/fx049.jpg" width="59"/>, <i>C</i> will access the critical section and upon leaving it will set its <img alt="Image" height="11" src="images/B9780124159501000173/fx040.jpg" width="25"/> to <img alt="Image" height="9" src="images/B9780124159501000173/fx049.jpg" width="59"/>, releasing <i>E</i>.</div></figcaption></figure></div><p class="text" id="p0325">In the <img alt="Image" height="9" src="images/B9780124159501000173/fx005.jpg" width="39"/>() method, a thread uses <img alt="Image" height="12" src="images/B9780124159501000173/fx014.jpg" width="97"/> to check whether it has a successor (line 42), and if so, sets its <span aria-label="Page 166" epub:type="pagebreak" id="page_166" role="doc-pagebreak"/><img alt="Image" height="11" src="images/B9780124159501000173/fx040.jpg" width="25"/> field to <img alt="Image" height="9" src="images/B9780124159501000173/fx049.jpg" width="59"/>. Note that it is not safe to recycle a thread's old node at this point, since the node may be referenced by its immediate successor, or by a chain of such references. The nodes in such a chain can be recycled as soon as a thread skips over the timed-out nodes and enters the critical section.</p><p class="text" id="p0330">The <img alt="Image" height="9" src="images/B9780124159501000173/fx048.jpg" width="39"/> has many of the advantages of the original <img alt="Image" height="9" src="images/B9780124159501000173/fx037.jpg" width="46"/>: local spinning on a cached location and quick detection that the lock is free. It also has the wait-free timeout property of the <img alt="Image" height="9" src="images/B9780124159501000173/fx030.jpg" width="72"/>. However, it has some drawbacks, among them the need to allocate a new node per lock access and the fact that a thread spinning on the lock may have to traverse a chain of timed-out nodes before it can access the critical section.</p></section><section><h2 class="h1hd" id="s0055"><a id="st0065"/>7.7 Hierarchical locks</h2><p class="textfl" id="p0335">Many of today's cache-coherent architectures organize processors into <i>clusters</i>, where communication within a cluster is significantly faster than communication between clusters. For example, a cluster might correspond to a group of processors that share memory through a fast interconnect, or to the threads running on a single core in a multicore architecture. Such systems are called <i>nonuniform memory access</i> (NUMA) systems. On a NUMA system, passing a lock between threads in different clusters (i.e., <i>remote</i> threads) incurs significantly more overhead than passing it between threads in the same cluster (i.e., <i>local</i> threads). This increased overhead is due not only to the increased cost of synchronization on the lock, but also to the cost of transferring the data protected by the lock. We can reduce this overhead by preferentially passing the lock to a local thread rather than a remote one (i.e., to a thread in the same cluster as the thread releasing the lock, rather than to one in a different cluster). Such a lock is called a <i>hierarchical lock</i>.</p><p class="text" id="p0340"><span aria-label="Page 167" epub:type="pagebreak" id="page_167" role="doc-pagebreak"/>We consider an architecture with a two-level memory hierarchy, consisting of clusters of processors, where processors in the same cluster communicate efficiently through a shared cache, and intercluster communication is much more expensive than intracluster communication. For architectures whose memory hierarchy has more than two levels, we can apply the techniques in this section at each boundary between levels in the hierarchy.</p><p class="text" id="p0345">We assume that each cluster has a unique <i>cluster ID</i> known to each thread in the cluster, available via <span class="sans-serif">ThreadID.getCluster()</span>, and that threads do not migrate between clusters. We also assume there is a class <img alt="Image" height="9" src="images/B9780124159501000173/fx050.jpg" width="100"/> (<a href="#f0090" id="cf0120">Fig. 7.16</a>), analogous to <img alt="Image" height="9" src="images/B9780124159501000173/fx051.jpg" width="93"/>, which manages one variable for each cluster, and provides <img alt="Image" height="11" src="images/B9780124159501000173/fx024.jpg" width="19"/>(), <img alt="Image" height="8" src="images/B9780124159501000173/fx022.jpg" width="18"/>(), and <img alt="Image" height="9" src="images/B9780124159501000173/fx052.jpg" width="78"/>() for reading, writing, and initializing these variables.</p><div class="pageavoid"><figure class="fig" id="f0090"><img alt="Image" height="76" src="images/B9780124159501000173/gr016.jpg" width="198"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.16</span> The <span class="sans-serif">ClusterLocal</span> class.</div></figcaption></figure></div><section><h3 class="h2hd" id="s0060"><a id="st0070"/>7.7.1 A hierarchical back-off lock</h3><p class="textfl" id="p0350">Simple back-off locks, such as test-and-set and test-and-test-and-set locks, can easily be adapted to exploit clustering: By increasing the back-off times of threads in different clusters from the thread holding the lock (relative to those of threads in the same cluster), local threads are more likely to acquire the lock than remote threads. To do this, we must record the cluster of the thread that holds the lock. <a href="#f0095" id="cf0125">Fig. 7.17</a> shows the <img alt="Image" height="9" src="images/B9780124159501000173/fx053.jpg" width="46"/> class, a hierarchical back-off lock based on this principle.</p><div class="pageavoid"><figure class="fig" id="f0095"><img alt="Image" height="520" src="images/B9780124159501000173/gr017.jpg" width="354"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.17</span> The <img alt="Image" height="9" src="images/B9780124159501000173/fx053.jpg" width="46"/> class: a hierarchical back-off lock.</div></figcaption></figure></div><p class="text" id="p0355"><img alt="Image" height="9" src="images/B9780124159501000173/fx053.jpg" width="46"/> suffers from some of the same problems as <img alt="Image" height="9" src="images/B9780124159501000173/fx030.jpg" width="72"/>, as described in Section <a href="#s0025" id="cf0130">7.4</a>. These problems may be even worse on NUMA systems because of the greater disparity in communication costs and the longer back-off times for remote threads. For example, longer back-off times increase delays between the release of a lock and its subsequent acquisition, resulting in greater underutilization of the critical section. As before, choosing back-off durations can be difficult, and acquiring or releasing the lock can generate a “storm” of cache-coherence traffic. And as with <img alt="Image" height="9" src="images/B9780124159501000173/fx030.jpg" width="72"/>, the <img alt="Image" height="9" src="images/B9780124159501000173/fx053.jpg" width="46"/> may be <i>too</i> successful at passing the lock among threads in a single cluster, starving remote threads attempting to acquire the lock. In short, the problems with back-off locks that led us to explore queue locks still exist and are more severe on NUMA systems.<span aria-label="Page 168" epub:type="pagebreak" id="page_168" role="doc-pagebreak"/></p></section><section><h3 class="h2hd" id="s0065"><a id="st0075"/>7.7.2 Cohort locks</h3><p class="textfl" id="p0360">We can address these problems by <i>lock cohorting</i>, a simple but effective technique that enables threads in a cluster to pass the lock among themselves without intercluster communication. The set of threads in a single cluster waiting to acquire the lock is called a <i>cohort</i>, and a lock based on this technique is called a <i>cohort lock</i>.</p><p class="text" id="p0365">The key idea of lock cohorting is to use multiple locks to provide exclusion at different levels of the memory hierarchy. In a cohort lock, each cluster has a <i>cluster lock</i>, held by a thread, and the clusters share a <i>global lock</i>, held by a cluster. A thread holds the cohort lock if it holds its cluster lock and its cluster holds the global lock. To acquire the cohort lock, a thread first acquires the lock of its cluster, and then ensures that its cluster holds the global lock. When releasing the cohort lock, the thread checks whether there is any thread in its cohort (i.e., a thread in its cluster is waiting to acquire the lock). If so, the thread releases <span aria-label="Page 169" epub:type="pagebreak" id="page_169" role="doc-pagebreak"/>its cluster lock without releasing the global lock. In this way, the thread in its cluster that next acquires the cluster lock also acquires the cohort lock (since its cluster already holds the global lock) without intercluster communication. If the cohort is empty when a thread releases the lock, it releases both the cluster lock and the global lock. To prevent remote threads from starving, a cohort lock must also have some policy that restricts local threads from passing the lock among themselves indefinitely without releasing the global lock.</p><p class="text" id="p0370">A cohort lock algorithm requires certain properties of its component locks. A thread releasing the lock must be able to detect whether another thread is attempting to acquire its cluster lock, and it must be able to pass ownership of the global lock directly to another thread without releasing it.</p><p class="text" id="p0375">A lock <i>supports cohort detection</i> if it provides a predicate method <img alt="Image" height="9" src="images/B9780124159501000173/fx054.jpg" width="32"/>() with the following meaning: If <img alt="Image" height="9" src="images/B9780124159501000173/fx054.jpg" width="32"/>() returns <i>false</i> when called by the thread holding a lock, then another thread is attempting to acquire that lock. The converse need not hold: If <img alt="Image" height="9" src="images/B9780124159501000173/fx054.jpg" width="32"/>() returns <i>true</i>, there may be another thread attempting to acquire the lock, but such false positives should be rare. <a href="#f0100" id="cf0135">Fig. 7.18</a> shows an interface for a lock that supports cohort detection.</p><div class="pageavoid"><figure class="fig" id="f0100"><img alt="Image" height="43" src="images/B9780124159501000173/gr018.jpg" width="325"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.18</span> Interface for locks that support cohort detection.</div></figcaption></figure></div><p class="text" id="p0380">A lock is <i>thread-oblivious</i> if the thread releasing a thread-oblivious lock need not be the thread that most recently acquired it. The pattern of lock accesses must still be well formed (for example, <img alt="Image" height="9" src="images/B9780124159501000173/fx005.jpg" width="39"/>() may not be invoked when the lock is free).</p><p class="text" id="p0385"><a href="#f0105" id="cf0140">Fig. 7.19</a> shows code for the <img alt="Image" height="9" src="images/B9780124159501000173/fx055.jpg" width="66"/> class, which must be instantiated with a thread-oblivious global lock and a lock that supports cohort detection for each cluster. The global lock must be thread-oblivious because its ownership may be passed implicitly among threads in a cluster, and eventually released by a different thread than the one that acquired the lock.</p><div class="pageavoid"><figure class="fig" id="f0105"><img alt="Image" height="413" src="images/B9780124159501000173/gr019.jpg" width="461"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.19</span> The <img alt="Image" height="9" src="images/B9780124159501000173/fx055.jpg" width="66"/> class.</div></figcaption></figure></div><p class="text" id="p0390">The <img alt="Image" height="9" src="images/B9780124159501000173/fx004.jpg" width="25"/>() function acquires the thread's cluster lock, and then checks whether the lock was passed locally, meaning that its cluster already owns the global lock. If so, it returns immediately. Otherwise, it acquires the global lock before returning.</p><p class="text" id="p0395">The <img alt="Image" height="9" src="images/B9780124159501000173/fx005.jpg" width="39"/>() function first determines whether a local thread is trying to acquire the lock, and if so, whether it should pass the lock locally. The latter decision is made by a “turn arbiter.” We adopt a simple policy of bounding the number of times a thread may be passed locally without releasing the global lock. To emphasize that other policies are possible, we encapsulate the policy in a <img alt="Image" height="9" src="images/B9780124159501000173/fx056.jpg" width="73"/> class, shown in <a href="#f0110" id="cf0145">Fig. 7.20</a>. The <img alt="Image" height="11" src="images/B9780124159501000173/fx057.jpg" width="86"/> field and the arbiter are updated to reflect the decision of whether to pass the lock locally. If the lock is not to be passed locally, both the global lock and the cluster lock are released. Otherwise, only the cluster lock is released.<span aria-label="Page 170" epub:type="pagebreak" id="page_170" role="doc-pagebreak"/></p><div class="pageavoid"><figure class="fig" id="f0110"><img alt="Image" height="257" src="images/B9780124159501000173/gr020.jpg" width="267"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.20</span> <img alt="Image" height="9" src="images/B9780124159501000173/fx056.jpg" width="73"/> class.</div></figcaption></figure></div></section><section><h3 class="h2hd" id="s0070"><a id="st0080"/>7.7.3 A cohort lock implementation</h3><p class="textfl" id="p0400">We now describe a cohort lock implementation that uses <img alt="Image" height="9" src="images/B9780124159501000173/fx030.jpg" width="72"/>, which is thread-oblivious, for the global lock, and a version of <img alt="Image" height="9" src="images/B9780124159501000173/fx042.jpg" width="46"/> modified to provide an <img alt="Image" height="9" src="images/B9780124159501000173/fx054.jpg" width="32"/>() method for the cluster locks. The modified <img alt="Image" height="9" src="images/B9780124159501000173/fx042.jpg" width="46"/> is shown in <a href="#f0115" id="cf0150">Fig. 7.21</a>. The <img alt="Image" height="9" src="images/B9780124159501000173/fx054.jpg" width="32"/>() method simply checks whether the <img alt="Image" height="8" src="images/B9780124159501000173/fx043.jpg" width="25"/> field of the invoking thread's <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> is <i>null</i>. This test provides cohort detection, because whenever the <img alt="Image" height="8" src="images/B9780124159501000173/fx043.jpg" width="25"/> field of a <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> is not <i>null</i>, it points to the <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> of a thread waiting to acquire the lock. <a href="#f0120" id="cf0155">Fig. 7.22</a> shows how to extend <img alt="Image" height="9" src="images/B9780124159501000173/fx055.jpg" width="66"/> to use <img alt="Image" height="9" src="images/B9780124159501000173/fx030.jpg" width="72"/> and the modified <img alt="Image" height="9" src="images/B9780124159501000173/fx042.jpg" width="46"/>. <a href="#f0125" id="cf0160">Fig. 7.23</a> illustrates an execution of this cohort lock.</p><div class="pageavoid"><figure class="fig" id="f0115"><img alt="Image" height="92" src="images/B9780124159501000173/gr021.jpg" width="327"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.21</span> Adding support for cohort detection to <img alt="Image" height="9" src="images/B9780124159501000173/fx042.jpg" width="46"/>.</div></figcaption></figure></div><div class="pageavoid"><figure class="fig" id="f0120"><img alt="Image" height="144" src="images/B9780124159501000173/gr022.jpg" width="491"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.22</span> <img alt="Image" height="9" src="images/B9780124159501000173/fx058.jpg" width="133"/> class.</div></figcaption></figure></div><div class="pageavoid"><figure class="fig" id="f0125"><img alt="Image" height="506" src="images/B9780124159501000173/gr023.jpg" width="496"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.23</span> An example execution of <img alt="Image" height="9" src="images/B9780124159501000173/fx058.jpg" width="133"/>.</div></figcaption></figure></div><p class="text" id="p0405"><img alt="Image" height="9" src="images/B9780124159501000173/fx058.jpg" width="133"/> can be improved slightly by recording in the <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> whether the lock has been passed locally. Instead of a <img alt="Image" height="9" src="images/B9780124159501000173/fx039.jpg" width="38"/> field, the <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> maintains a field that indicates whether its thread must wait, or whether it has acquired the lock, and if so, whether the lock was passed locally or globally. There is no need for a separate cluster-local field to record whether the lock was passed locally, and the cache miss that would be incurred by accessing that field after the lock is acquired. We leave the details as an exercise.<span aria-label="Page 171" epub:type="pagebreak" id="page_171" role="doc-pagebreak"/><span aria-label="Page 172" epub:type="pagebreak" id="page_172" role="doc-pagebreak"/></p></section></section><section><h2 class="h1hd" id="s0075"><a id="st0085"/>7.8 A composite lock</h2><p class="textfl" id="p0410">Spin lock algorithms impose trade-offs. Queue locks provide first-come-first-served fairness, fast lock release, and low contention, but require nontrivial protocols for recycling abandoned nodes. By contrast, back-off locks support trivial timeout protocols, but are inherently not scalable, and may have slow lock release if timeout parameters are not well tuned. In this section, we consider an advanced lock algorithm that combines the best of both approaches.</p><p class="text" id="p0415">Consider the following simple observation: In a queue lock, only the threads at the front of the queue need to perform lock hand-offs. One way to balance the merits of queue locks versus back-off locks is to keep a small number of waiting threads in a queue on the way to the critical section, and have the rest use exponential back-off while attempting to enter this short queue. It is trivial for the threads employing back-off to quit.</p><p class="text" id="p0420"><span aria-label="Page 173" epub:type="pagebreak" id="page_173" role="doc-pagebreak"/>The <img alt="Image" height="11" src="images/B9780124159501000173/fx059.jpg" width="86"/> class keeps a short, fixed-size array of lock nodes. Each thread that tries to acquire the lock selects a node in the array at random. If that node is in use, the thread backs off (adaptively) and tries again. Once the thread acquires a node, it enqueues that node in a <img alt="Image" height="9" src="images/B9780124159501000173/fx048.jpg" width="39"/>-style queue. The thread spins on the preceding node; when that node's owner signals it is done, the thread enters the critical section. When the thread leaves (after it completes or times out), it releases its node, and another thread may acquire it. The tricky part is recycling the freed nodes of the array while multiple threads attempt to acquire control over them.</p><p class="text" id="p0425">The <img alt="Image" height="11" src="images/B9780124159501000173/fx059.jpg" width="86"/>'s fields, constructor, and <img alt="Image" height="9" src="images/B9780124159501000173/fx005.jpg" width="39"/>() method appears in <a href="#f0130" id="cf0165">Fig. 7.24</a>. The <img alt="Image" height="9" src="images/B9780124159501000173/fx034.jpg" width="23"/> field is an <img alt="Image" height="11" src="images/B9780124159501000173/fx060.jpg" width="194"/> that combines a reference to a node with a version number (see <a href="B9780124159501000203.xhtml">Pragma 10.6.1</a> for a more detailed explanation of the <img alt="Image" height="11" src="images/B9780124159501000173/fx061.jpg" width="167"/> class); the version number is needed to avoid the <i>ABA</i> problem.<sup><a epub:type="noteref" href="#fn004" id="cf0170" role="doc-noteref">4</a></sup> The <img alt="Image" height="9" src="images/B9780124159501000173/fx034.jpg" width="23"/> field either is <i>null</i> or refers to the last node inserted <span aria-label="Page 174" epub:type="pagebreak" id="page_174" role="doc-pagebreak"/>in the queue. <a href="#f0135" id="cf0175">Fig. 7.25</a> shows the <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> class. Each <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> includes a <img alt="Image" height="9" src="images/B9780124159501000173/fx062.jpg" width="32"/> field and a reference to the predecessor node in the queue. The <img alt="Image" height="11" src="images/B9780124159501000173/fx063.jpg" width="46"/> field is a constant-size <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> array.</p><div class="pageavoid"><figure class="fig" id="f0130"><img alt="Image" height="372" src="images/B9780124159501000173/gr024.jpg" width="358"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.24</span> The <img alt="Image" height="11" src="images/B9780124159501000173/fx059.jpg" width="86"/> class: fields, constructor, and <img alt="Image" height="9" src="images/B9780124159501000173/fx005.jpg" width="39"/>() method.</div></figcaption></figure></div><div class="pageavoid"><figure class="fig" id="f0135"><img alt="Image" height="125" src="images/B9780124159501000173/gr025.jpg" width="338"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.25</span> The <img alt="Image" height="11" src="images/B9780124159501000173/fx059.jpg" width="86"/> class: the <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> class.</div></figcaption></figure></div><p class="text" id="p0430">A <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/> has four possible states: <img alt="Image" height="9" src="images/B9780124159501000173/fx064.jpg" width="46"/>, <img alt="Image" height="9" src="images/B9780124159501000173/fx065.jpg" width="52"/>, <img alt="Image" height="9" src="images/B9780124159501000173/fx066.jpg" width="46"/>, and <img alt="Image" height="9" src="images/B9780124159501000173/fx067.jpg" width="25"/>. A <img alt="Image" height="9" src="images/B9780124159501000173/fx064.jpg" width="46"/> node is linked into the queue, and the owning thread is either in the critical section or waiting to enter. A node becomes <img alt="Image" height="9" src="images/B9780124159501000173/fx065.jpg" width="52"/> when its owner leaves the critical section and releases the lock. The other two states occur when a thread abandons its attempt to acquire the lock. If the quitting thread has acquired a node but not enqueued it, then it marks the thread as <img alt="Image" height="9" src="images/B9780124159501000173/fx067.jpg" width="25"/>. If the node is enqueued, then it is marked as <img alt="Image" height="9" src="images/B9780124159501000173/fx066.jpg" width="46"/>.</p><p class="text" id="p0435"><a href="#f0140" id="cf0180">Fig. 7.26</a> shows the <img alt="Image" height="11" src="images/B9780124159501000173/fx046.jpg" width="46"/>() method. A thread acquires the lock in three steps. It first <i>acquires</i> a node in the <img alt="Image" height="11" src="images/B9780124159501000173/fx063.jpg" width="46"/> array (line 37), then enqueues that node in the queue (line 38), and finally waits until that node is at the head of the queue (line 39).</p><div class="pageavoid"><figure class="fig" id="f0140"><img alt="Image" height="208" src="images/B9780124159501000173/gr026.jpg" width="503"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.26</span> The <img alt="Image" height="11" src="images/B9780124159501000173/fx059.jpg" width="86"/> class: the <img alt="Image" height="11" src="images/B9780124159501000173/fx046.jpg" width="46"/>() method.</div></figcaption></figure></div><p class="text" id="p0440">The algorithm for acquiring a node in the <img alt="Image" height="11" src="images/B9780124159501000173/fx063.jpg" width="46"/> array appears in <a href="#f0145" id="cf0185">Fig. 7.27</a>. The thread selects a node at random and tries to acquire the node by changing that node's state from <img alt="Image" height="9" src="images/B9780124159501000173/fx067.jpg" width="25"/> to <img alt="Image" height="9" src="images/B9780124159501000173/fx064.jpg" width="46"/> (line 51). If it fails, it examines the node's status. If the node is <img alt="Image" height="9" src="images/B9780124159501000173/fx066.jpg" width="46"/> or <img alt="Image" height="9" src="images/B9780124159501000173/fx065.jpg" width="52"/> (line 56), the thread may “clean up” the node. To avoid synchronization conflicts with other threads, a node can be cleaned <span aria-label="Page 175" epub:type="pagebreak" id="page_175" role="doc-pagebreak"/>up only if it is the last queue node (that is, the value of <img alt="Image" height="9" src="images/B9780124159501000173/fx034.jpg" width="23"/>). If the tail node is <img alt="Image" height="9" src="images/B9780124159501000173/fx066.jpg" width="46"/>, <img alt="Image" height="9" src="images/B9780124159501000173/fx034.jpg" width="23"/> is redirected to that node's predecessor; otherwise <img alt="Image" height="9" src="images/B9780124159501000173/fx034.jpg" width="23"/> is set to <i>null</i>. If, instead, the allocated node is <img alt="Image" height="9" src="images/B9780124159501000173/fx064.jpg" width="46"/>, then the thread backs off and retries. If the thread times out before acquiring its node, it throws <img alt="Image" height="11" src="images/B9780124159501000173/fx069.jpg" width="106"/> (line 70).</p><div class="pageavoid"><figure class="fig" id="f0145"><img alt="Image" height="471" src="images/B9780124159501000173/gr027.jpg" width="517"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.27</span> The <img alt="Image" height="11" src="images/B9780124159501000173/fx059.jpg" width="86"/> class: the <img alt="Image" height="11" src="images/B9780124159501000173/fx068.jpg" width="79"/>() method.</div></figcaption></figure></div><p class="text" id="p0445">Once the thread acquires a node, the <img alt="Image" height="11" src="images/B9780124159501000173/fx070.jpg" width="72"/>() method (<a href="#f0150" id="cf0190">Fig. 7.28</a>) splices that node into the queue by repeatedly trying to set <img alt="Image" height="9" src="images/B9780124159501000173/fx034.jpg" width="23"/> to the allocated node. If it times out, it marks the allocated node as <img alt="Image" height="9" src="images/B9780124159501000173/fx067.jpg" width="25"/> and throws <img alt="Image" height="11" src="images/B9780124159501000173/fx069.jpg" width="106"/>. If it succeeds, it returns the prior value of <img alt="Image" height="9" src="images/B9780124159501000173/fx034.jpg" width="23"/>, acquired by the node's predecessor in the queue.</p><div class="pageavoid"><figure class="fig" id="f0150"><img alt="Image" height="208" src="images/B9780124159501000173/gr028.jpg" width="502"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.28</span> The <img alt="Image" height="11" src="images/B9780124159501000173/fx059.jpg" width="86"/> class: the <img alt="Image" height="11" src="images/B9780124159501000173/fx070.jpg" width="72"/>() method.</div></figcaption></figure></div><p class="text" id="p0450">Finally, once the node has been enqueued, the thread must wait its turn by calling <img alt="Image" height="9" src="images/B9780124159501000173/fx071.jpg" width="120"/>() (<a href="#f0155" id="cf0195">Fig. 7.29</a>). If the predecessor is <i>null</i>, then the thread's node is first in the queue, so the thread saves the node in the thread-local <img alt="Image" height="11" src="images/B9780124159501000173/fx073.jpg" width="39"/> field (for later use by <img alt="Image" height="9" src="images/B9780124159501000173/fx005.jpg" width="39"/>()), and enters the critical section. If the <span aria-label="Page 176" epub:type="pagebreak" id="page_176" role="doc-pagebreak"/><span aria-label="Page 177" epub:type="pagebreak" id="page_177" role="doc-pagebreak"/><span aria-label="Page 178" epub:type="pagebreak" id="page_178" role="doc-pagebreak"/>predecessor node is not <img alt="Image" height="9" src="images/B9780124159501000173/fx065.jpg" width="52"/>, the thread checks whether it is <img alt="Image" height="9" src="images/B9780124159501000173/fx066.jpg" width="46"/> (line 97). If so, the thread marks the node <img alt="Image" height="9" src="images/B9780124159501000173/fx067.jpg" width="25"/> and waits on the aborted node's predecessor. If the thread times out, then it marks its own node as <img alt="Image" height="9" src="images/B9780124159501000173/fx066.jpg" width="46"/> and throws <img alt="Image" height="11" src="images/B9780124159501000173/fx069.jpg" width="106"/>. Otherwise, when the predecessor node becomes <img alt="Image" height="9" src="images/B9780124159501000173/fx065.jpg" width="52"/> the thread marks it <img alt="Image" height="9" src="images/B9780124159501000173/fx067.jpg" width="25"/>, records its own node in the thread-local <img alt="Image" height="11" src="images/B9780124159501000173/fx072.jpg" width="39"/> field, and enters the critical section.</p><div class="pageavoid"><figure class="fig" id="f0155"><img alt="Image" height="421" src="images/B9780124159501000173/gr029.jpg" width="412"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.29</span> The <img alt="Image" height="11" src="images/B9780124159501000173/fx059.jpg" width="86"/> class: the <img alt="Image" height="9" src="images/B9780124159501000173/fx071.jpg" width="120"/>() method.</div></figcaption></figure></div><p class="text" id="p0455">The <img alt="Image" height="9" src="images/B9780124159501000173/fx005.jpg" width="39"/>() method (<a href="#f0130" id="cf0200">Fig. 7.24</a>) simply retrieves its node from <img alt="Image" height="11" src="images/B9780124159501000173/fx073.jpg" width="39"/> and marks it <img alt="Image" height="9" src="images/B9780124159501000173/fx065.jpg" width="52"/>.</p><p class="text" id="p0460"><a href="#f0160" id="cf0205">Fig. 7.30</a> illustrates an example execution of <img alt="Image" height="11" src="images/B9780124159501000173/fx059.jpg" width="86"/>.</p><div class="pageavoid"><figure class="fig" id="f0160"><img alt="Image" height="531" src="images/B9780124159501000173/gr030.jpg" width="496"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.30</span> The <img alt="Image" height="11" src="images/B9780124159501000173/fx059.jpg" width="86"/> class: an execution. In part (a), thread <i>A</i> (which acquired Node 3) is in the critical section. Thread <i>B</i> (Node 4) is waiting for <i>A</i> to release the critical section, and thread <i>C</i> (Node 1) is in turn waiting for <i>B</i>. Threads <i>D</i> and <i>E</i> are backing off, waiting to acquire a node. Node 2 is free. The <img alt="Image" height="9" src="images/B9780124159501000173/fx034.jpg" width="23"/> field refers to Node 1, the last node to be inserted into the queue. At this point, <i>B</i> times out, inserting an explicit reference to its predecessor, and changing Node 4's state from <img alt="Image" height="9" src="images/B9780124159501000173/fx064.jpg" width="46"/> (denoted by <i>W</i>) to <img alt="Image" height="9" src="images/B9780124159501000173/fx066.jpg" width="46"/> (denoted by <i>A</i>). In part (b), thread <i>C</i> cleans up the <img alt="Image" height="9" src="images/B9780124159501000173/fx066.jpg" width="46"/> Node 4, setting its state to <img alt="Image" height="9" src="images/B9780124159501000173/fx067.jpg" width="25"/> and following the explicit reference from 4 to 3 (by redirecting its local <img alt="Image" height="11" src="images/B9780124159501000173/fx072.jpg" width="39"/> field). It then starts waiting for <i>A</i> (Node 3) to leave the critical section. In part (c), <i>E</i> acquires the <img alt="Image" height="9" src="images/B9780124159501000173/fx067.jpg" width="25"/> Node 4, using <img alt="Image" height="12" src="images/B9780124159501000173/fx014.jpg" width="97"/> to set its state to <img alt="Image" height="9" src="images/B9780124159501000173/fx064.jpg" width="46"/>. Thread <i>E</i> then inserts Node 4 into the queue, using <img alt="Image" height="12" src="images/B9780124159501000173/fx014.jpg" width="97"/> to swap Node 4 into the tail, then waiting on Node 1, which was previously referred to by <img alt="Image" height="9" src="images/B9780124159501000173/fx034.jpg" width="23"/>.</div></figcaption></figure></div><p class="text" id="p0465"><img alt="Image" height="11" src="images/B9780124159501000173/fx059.jpg" width="86"/> has a number of attractive properties. Lock hand-off is fast, just as in the <img alt="Image" height="9" src="images/B9780124159501000173/fx037.jpg" width="46"/> and <img alt="Image" height="9" src="images/B9780124159501000173/fx048.jpg" width="39"/> algorithms. When threads back off, they access different locations, reducing contention. Abandoning a lock request is trivial for threads in the back-off stage, and relatively straightforward for threads that have acquired queue nodes. For <i>L</i> locks and <i>n</i> threads, the <img alt="Image" height="11" src="images/B9780124159501000173/fx059.jpg" width="86"/> class requires only <span class="hiddenClass"><mml:math><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000173/si12.png" style="vertical-align:middle" width="37"/></span> space in the worst case, as compared to the <img alt="Image" height="9" src="images/B9780124159501000173/fx048.jpg" width="39"/> class's <span class="hiddenClass"><mml:math><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>L</mml:mi><mml:mo>⋅</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000173/si13.png" style="vertical-align:middle" width="56"/></span>.</p><p class="text" id="p0470">There are some drawbacks: <img alt="Image" height="11" src="images/B9780124159501000173/fx059.jpg" width="86"/> does not guarantee first-come-first-served access. Also, a thread running alone must redirect the <img alt="Image" height="9" src="images/B9780124159501000173/fx034.jpg" width="23"/> field away from a released node, claim the node, and then splice it into the queue.</p></section><section><h2 class="h1hd" id="s0080"><a id="st0090"/>7.9 A fast path for threads running alone</h2><p class="textfl" id="p0475">Although performance under contention is important, so is performance in the absence of concurrency. Ideally, for a thread running alone, acquiring a lock should be as simple as acquiring an uncontended <img alt="Image" height="9" src="images/B9780124159501000173/fx020.jpg" width="46"/>. Unfortunately, as mentioned above, this is not true for the <img alt="Image" height="11" src="images/B9780124159501000173/fx059.jpg" width="86"/>. We can address this shortcoming by adding a “fast path” to <img alt="Image" height="11" src="images/B9780124159501000173/fx059.jpg" width="86"/>.</p><p class="text" id="p0480">A <i>fast path</i> for a complex, expensive algorithm is a simpler, cheaper alternative that works (or is efficient) only under certain (typically, common) conditions. In this case, we want a fast path for <img alt="Image" height="11" src="images/B9780124159501000173/fx059.jpg" width="86"/> for a thread that is running alone. We can accomplish this by extending the <img alt="Image" height="11" src="images/B9780124159501000173/fx059.jpg" width="86"/> algorithm so that a solitary thread acquires an idle lock without acquiring a node and splicing it into the queue.</p><p class="text" id="p0485">Here is a bird's-eye view. We add an extra state, distinguishing between a lock held by an ordinary thread and a lock held by a fast-path thread. If a thread discovers the lock is free, it tries a fast-path acquire. If it succeeds, then it has acquired the lock in a single atomic step. If it fails, then it enqueues itself just as before.</p><p class="text" id="p0490">We now examine the algorithm in detail. To reduce code duplication, we define the <img alt="Image" height="11" src="images/B9780124159501000173/fx074.jpg" width="140"/> class to be a subclass of <img alt="Image" height="11" src="images/B9780124159501000173/fx059.jpg" width="86"/>. The code appears in <a href="#f0165" id="cf0210">Figs. 7.31</a> and <a href="#f0170" id="cf0215">7.32</a>.</p><div class="pageavoid"><figure class="fig" id="f0165"><img alt="Image" height="438" src="images/B9780124159501000173/gr031.jpg" width="503"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.31</span> <img alt="Image" height="11" src="images/B9780124159501000173/fx074.jpg" width="140"/> class: The private <img alt="Image" height="9" src="images/B9780124159501000173/fx075.jpg" width="79"/>() method returns true if it succeeds in acquiring the lock through the fast path.</div></figcaption></figure></div><div class="pageavoid"><figure class="fig" id="f0170"><img alt="Image" height="323" src="images/B9780124159501000173/gr032.jpg" width="430"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.32</span> <img alt="Image" height="11" src="images/B9780124159501000173/fx074.jpg" width="140"/> class: <img alt="Image" height="9" src="images/B9780124159501000173/fx076.jpg" width="92"/>() and <img alt="Image" height="9" src="images/B9780124159501000173/fx005.jpg" width="39"/>() methods.</div></figcaption></figure></div><p class="text" id="p0495">We use a <i>fast-path flag</i> to indicate that a thread has acquired the lock through the fast path. Because we need to manipulate this flag together with the <img alt="Image" height="9" src="images/B9780124159501000173/fx034.jpg" width="23"/> field's reference, we “steal” a high-order bit from the <img alt="Image" height="9" src="images/B9780124159501000173/fx034.jpg" width="23"/> field's integer stamp using a <img alt="Image" height="9" src="images/B9780124159501000173/fx077.jpg" width="51"/> bitmask (line 2). The private <img alt="Image" height="9" src="images/B9780124159501000173/fx075.jpg" width="79"/>() method checks whether the <img alt="Image" height="9" src="images/B9780124159501000173/fx034.jpg" width="23"/> field's stamp has a clear fast-path flag and a <i>null</i> reference. If so, it tries to acquire the lock simply by applying <img alt="Image" height="12" src="images/B9780124159501000173/fx014.jpg" width="97"/> to set the fast-path flag to <i>true</i>, <span aria-label="Page 179" epub:type="pagebreak" id="page_179" role="doc-pagebreak"/>ensuring that the reference remains <i>null</i>. An uncontended lock acquisition thus requires a single atomic operation. The <img alt="Image" height="9" src="images/B9780124159501000173/fx075.jpg" width="79"/>() method returns <i>true</i> if it succeeds, and <i>false</i> otherwise.</p><p class="text" id="p0500">The <img alt="Image" height="11" src="images/B9780124159501000173/fx046.jpg" width="46"/>() method (lines 18–27) first tries the fast path by calling <img alt="Image" height="9" src="images/B9780124159501000173/fx075.jpg" width="79"/>(). If it fails, then it pursues the slow path by calling the <img alt="Image" height="11" src="images/B9780124159501000173/fx059.jpg" width="86"/> class's <img alt="Image" height="11" src="images/B9780124159501000173/fx046.jpg" width="46"/>() method. Before it can return from the slow path, however, it must ensure that no other thread holds the fast-path lock by waiting until the fast-path flag is clear (line 23).</p><p class="text" id="p0505">The <img alt="Image" height="9" src="images/B9780124159501000173/fx005.jpg" width="39"/>() method first calls <img alt="Image" height="9" src="images/B9780124159501000173/fx076.jpg" width="92"/>() (line 44). If that call fails to release the lock, it then calls the <img alt="Image" height="11" src="images/B9780124159501000173/fx059.jpg" width="86"/>'s <img alt="Image" height="9" src="images/B9780124159501000173/fx005.jpg" width="39"/>() method (line 45). The <img alt="Image" height="9" src="images/B9780124159501000173/fx076.jpg" width="92"/>() method returns <i>false</i> if the fast-path flag is not set (line 31). Otherwise, it repeatedly tries to clear the flag, leaving the reference component unchanged (lines 36–40), returning <i>true</i> when it succeeds.<span aria-label="Page 180" epub:type="pagebreak" id="page_180" role="doc-pagebreak"/></p></section><section><h2 class="h1hd" id="s0085"><a id="st0095"/>7.10 One lock to rule them all</h2><p class="textfl" id="p0510">In this chapter, we have seen a variety of spin locks that vary in characteristics and performance. Such a variety is useful, because no single algorithm is ideal for all applications. For some applications, complex algorithms work best; for others, simple algorithms are preferable. The best choice usually depends on specific aspects of the application and the target architecture.<span aria-label="Page 181" epub:type="pagebreak" id="page_181" role="doc-pagebreak"/></p></section><section><h2 class="h1hd" id="s0090"><a id="st0100"/>7.11 Chapter notes</h2><p class="textfl" id="p0515">The <img alt="Image" height="9" src="images/B9780124159501000173/fx023.jpg" width="52"/> is due to Larry Rudolph and Zary Segall <a epub:type="noteref" href="#br0750" id="cf0220" role="doc-noteref">[150]</a>. Exponential back-off is a well-known technique used in ethernet routing, presented in the context of multiprocessor mutual exclusion by Anant Agarwal and Mathews Cherian <a epub:type="noteref" href="#br0030" id="cf0225" role="doc-noteref">[6]</a>. Tom Anderson <a epub:type="noteref" href="#br0060" id="cf0230" role="doc-noteref">[12]</a> invented the <img alt="Image" height="9" src="images/B9780124159501000173/fx033.jpg" width="33"/> algorithm and was one of the first to empirically study the performance of spin locks in shared-memory multiprocessors. The <img alt="Image" height="9" src="images/B9780124159501000173/fx042.jpg" width="46"/>, due to John Mellor-Crummey and Michael Scott <a epub:type="noteref" href="#br0620" id="cf0235" role="doc-noteref">[124]</a>, is perhaps the best-known queue lock algorithm. Today's Java virtual machines use object synchronization based on simplified monitor algorithms such as the <i>Thinlock</i> of David Bacon, Ravi Konuru, Chet Murthy, and Mauricio Serrano <a epub:type="noteref" href="#br0075" id="cf0240" role="doc-noteref">[15]</a>, the <i>Metalock</i> of Ole Agesen, Dave Detlefs, Alex Garthwaite, Ross Knippel, Y. S. Ramakrishna, and Derek White <a epub:type="noteref" href="#br0035" id="cf0245" role="doc-noteref">[7]</a>, or the <i>RelaxedLock</i> of Dave Dice <a epub:type="noteref" href="#br0180" id="cf0250" role="doc-noteref">[36]</a>. All these algorithms are variations of the <img alt="Image" height="9" src="images/B9780124159501000173/fx042.jpg" width="46"/> lock.</p><p class="text" id="p0520">The <img alt="Image" height="9" src="images/B9780124159501000173/fx037.jpg" width="46"/> lock is due to Travis Craig, Erik Hagersten, and Anders Landin <a epub:type="noteref" href="#br0160" id="cs0010" role="doc-noteref">[32</a>,<a epub:type="noteref" href="#br0590" role="doc-noteref">118]</a>. The <img alt="Image" height="9" src="images/B9780124159501000173/fx048.jpg" width="39"/> with nonblocking timeout is due to Bill Scherer and Michael Scott <a epub:type="noteref" href="#br0765" id="cs0015" role="doc-noteref">[153</a>,<a epub:type="noteref" href="#br0770" role="doc-noteref">154]</a>. The <img alt="Image" height="11" src="images/B9780124159501000173/fx059.jpg" width="86"/> and its variations are due to Virendra Marathe, Mark Moir, and Nir Shavit <a epub:type="noteref" href="#br0605" id="cf0255" role="doc-noteref">[121]</a>. The notion of using a fast path in a mutual exclusion algorithm is due to Leslie Lamport <a epub:type="noteref" href="#br0530" id="cf0260" role="doc-noteref">[106]</a>. Hierarchical locks were invented by Zoran Radović and Erik Hagersten. The <img alt="Image" height="9" src="images/B9780124159501000173/fx053.jpg" width="46"/> is a variant of their original algorithm <a epub:type="noteref" href="#br0720" id="cf0265" role="doc-noteref">[144]</a>. Cohort locks are due to Dave Dice, Virendra Marathe, and Nir Shavit <a epub:type="noteref" href="#br0185" id="cf0270" role="doc-noteref">[37]</a>.</p><p class="text" id="p0525">Faith Fich, Danny Hendler, and Nir Shavit <a epub:type="noteref" href="#br0225" id="cf0275" role="doc-noteref">[45]</a> have extended the work of Jim Burns and Nancy Lynch to show that any starvation-free mutual exclusion algorithm requires <span class="hiddenClass"><mml:math><mml:mi mathvariant="normal">Ω</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000173/si14.png" style="vertical-align:middle" width="35"/></span> space, even if strong operations such as <img alt="Image" height="11" src="images/B9780124159501000173/fx013.jpg" width="59"/>() or <img alt="Image" height="12" src="images/B9780124159501000173/fx014.jpg" width="97"/> are used, implying that the queue-lock algorithms considered here are space-optimal.</p><p class="text" id="p0530">The schematic performance graph in this chapter is loosely based on empirical studies by Tom Anderson <a epub:type="noteref" href="#br0060" id="cf0280" role="doc-noteref">[12]</a>, as well as on data collected by the authors on various modern machines. We present schematic rather than actual data because of the great variation in machine architectures and their significant effect on lock performance.</p><p class="text" id="p0535">Programming languages such as C or C++ were not defined with concurrency in mind, so they did not define a memory model. The actual behavior of a concurrent C or C++ program is the result of a complex combination of the underlying hardware, the compiler, and the concurrency library. See Hans Boehm <a epub:type="noteref" href="#br0095" id="cf0285" role="doc-noteref">[19]</a> for a more detailed discussion of these issues. The Java memory model proposed here is the <i>second</i> memory model proposed for Java. Jeremy Manson, Bill Pugh, and Sarita Adve <a epub:type="noteref" href="#br0595" id="cf0290" role="doc-noteref">[119]</a> give a more complete description of this model.</p><p class="text" id="p0540">The Sherlock Holmes quote is from <i>The Sign of Four</i> <a epub:type="noteref" href="#br0205" id="cf0295" role="doc-noteref">[41]</a>.</p></section><section><h2 class="h1hd" id="s0095"><a id="st0105"/>7.12 Exercises</h2><p class="textfl" id="p0545"/><div class="boxg1" id="enun0010"><p class="b1num">Exercise 7.1 </p><div><p class="b1textfl" id="p0550"><a href="#f0175" id="cf0300">Fig. 7.33</a> shows an alternative implementation of <img alt="Image" height="9" src="images/B9780124159501000173/fx037.jpg" width="46"/> in which a thread reuses its own node instead of its predecessor node. Explain how this implementation can go wrong, and how the MCS lock avoids the problem even though it reuses thread-local nodes.</p><div class="pageavoid"><figure class="fig" id="f0175"><img alt="Image" height="356" src="images/B9780124159501000173/gr033.jpg" width="455"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 7.33</span> An incorrect attempt to implement a <img alt="Image" height="9" src="images/B9780124159501000173/fx037.jpg" width="46"/>.</div></figcaption></figure></div></div></div><p class="textfl"/><p class="text" id="p0555"/><div class="boxg1" id="enun0015"><p class="b1num">Exercise 7.2 </p><div><p class="b1textfl" id="p0560">Imagine <i>n</i> threads, each of which executes method <img alt="Image" height="12" src="images/B9780124159501000173/fx078.jpg" width="30"/> followed by method <img alt="Image" height="12" src="images/B9780124159501000173/fx079.jpg" width="30"/>. Suppose we want to make sure that no thread starts <img alt="Image" height="12" src="images/B9780124159501000173/fx079.jpg" width="30"/> until all threads have finished <img alt="Image" height="12" src="images/B9780124159501000173/fx078.jpg" width="30"/>. For this kind of synchronization, we place a <i>barrier</i> between <img alt="Image" height="12" src="images/B9780124159501000173/fx078.jpg" width="30"/> and <img alt="Image" height="12" src="images/B9780124159501000173/fx079.jpg" width="30"/>.</p><p class="b1text" id="p0565">First barrier implementation: We have a counter protected by a test-and-test-and-set lock. Each thread locks the counter, increments it, releases the lock, and spins, rereading the counter until it reaches <i>n</i>.</p><p class="b1text" id="p0570">Second barrier implementation: We have an <i>n</i>-element Boolean array <img alt="Image" height="9" src="images/B9780124159501000173/fx080.jpg" width="5"/><span class="hiddenClass"><mml:math><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>n</mml:mi><mml:mo linebreak="badbreak" linebreakstyle="after">−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000173/si15.png" style="vertical-align:middle" width="64"/></span>, all initially <i>false</i>. Thread 0 sets <img alt="Image" height="9" src="images/B9780124159501000173/fx080.jpg" width="5"/>[0] <span aria-label="Page 182" epub:type="pagebreak" id="page_182" role="doc-pagebreak"/>to <i>true</i>. Every thread <i>i</i>, for <span class="hiddenClass"><mml:math><mml:mn>0</mml:mn><mml:mo linebreak="goodbreak" linebreakstyle="after">&lt;</mml:mo><mml:mi>i</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">&lt;</mml:mo><mml:mi>n</mml:mi></mml:math></span><span><img alt="Image" height="11" src="images/B9780124159501000173/si16.png" style="vertical-align:middle" width="63"/></span>, spins until <img alt="Image" height="9" src="images/B9780124159501000173/fx080.jpg" width="5"/><span class="hiddenClass"><mml:math><mml:mo stretchy="false">[</mml:mo><mml:mi>i</mml:mi><mml:mo linebreak="badbreak" linebreakstyle="after">−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000173/si17.png" style="vertical-align:middle" width="44"/></span> is <i>true</i>, sets <img alt="Image" height="9" src="images/B9780124159501000173/fx080.jpg" width="5"/><span class="hiddenClass"><mml:math><mml:mo stretchy="false">[</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000173/si18.png" style="vertical-align:middle" width="17"/></span> to <i>true</i>, and then waits until <img alt="Image" height="9" src="images/B9780124159501000173/fx080.jpg" width="5"/><span class="hiddenClass"><mml:math><mml:mo stretchy="false">[</mml:mo><mml:mi>n</mml:mi><mml:mo linebreak="badbreak" linebreakstyle="after">−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000173/si19.png" style="vertical-align:middle" width="47"/></span> is <i>true</i>, after which it proceeds to leave the barrier.</p><p class="b1text" id="p0575">Compare (in 10 lines) the behavior of these two implementations on a bus-based cache-coherent architecture. Explain which approach you expect will perform better under low load and high load.</p></div></div><p class="textfl"/><p class="text" id="p0580"/><div class="boxg1" id="enun0020"><p class="b1num">Exercise 7.3 </p><div><p class="b1textfl" id="p0585">Show how to eliminate the separate cluster-local field that records whether the lock is passed locally by recording this information directly in each <img alt="Image" height="11" src="images/B9780124159501000173/fx038.jpg" width="32"/>, as described in Section <a href="#s0070" id="cf0305">7.7.3</a>.</p></div></div><p class="textfl"/><p class="text" id="p0590"/><div class="boxg1" id="enun0025"><p class="b1num">Exercise 7.4 </p><div><p class="b1textfl" id="p0595">Prove that the <img alt="Image" height="11" src="images/B9780124159501000173/fx074.jpg" width="140"/> implementation guarantees mutual exclusion, but is not starvation-free.</p></div></div><p class="textfl"/><p class="text" id="p0600"/><div class="boxg1" id="enun0030"><p class="b1num">Exercise 7.5 </p><div><p class="b1textfl" id="p0605">Design an <img alt="Image" height="9" src="images/B9780124159501000173/fx081.jpg" width="51"/>() method that tests whether any thread is holding a lock (but does not acquire the lock). Give implementations for</p><div><ul><li class="b1bulllist" id="u0010">•  a test-and-set spin lock,</li><li class="b1bulllist" id="u0015">•  the CLH queue lock, and</li><li class="b1bulllist" id="u0020">•  the MCS queue lock.</li></ul></div><p class="b1textfl"/></div></div><p class="textfl"/><p class="text" id="p0625"/><div class="boxg1" id="enun0035"><p class="b1num">Exercise 7.6 </p><div><p class="b1textfl" id="p0630">(Hard) Where does the <span class="hiddenClass"><mml:math><mml:mi mathvariant="normal">Ω</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000173/si14.png" style="vertical-align:middle" width="35"/></span> space complexity lower bound proof for deadlock-free mutual exclusion of Chapter <a href="B9780124159501000112.xhtml">2</a> break when locks are allowed to use read–modify–write operations?</p></div></div><p class="textfl"/></section><footer><section epub:type="bibliography" role="doc-bibliography"><div id="bl0340"><h2 class="reftitle" id="st0110">Bibliography</h2><p class="reflist" epub:type="biblioentry footnote" id="br0030" role="doc-biblioentry">[6] A. Agarwal, M. Cherian,  Adaptive backoff synchronization techniques,   <i>Proceedings of the 16th International Symposium on Computer Architecture</i>.  May 1989:396–406.</p><p class="reflist" epub:type="biblioentry footnote" id="br0035" role="doc-biblioentry">[7] Ole Agesen, David Detlefs, Alex Garthwaite, Ross Knippel, Y.S. Ramakrishna, Derek White,  An efficient meta-lock for implementing ubiquitous synchronization,   <cite><i>ACM SIGPLAN Notices</i></cite> 1999;34(10):207–222.</p><p class="reflist1" epub:type="biblioentry footnote" id="br0060" role="doc-biblioentry">[12] Thomas E. Anderson,  The performance of spin lock alternatives for shared-memory multiprocessors,   <cite><i>IEEE Transactions on Parallel and Distributed Systems</i></cite> 1990;1(1):6–16.</p><p class="reflist1" epub:type="biblioentry footnote" id="br0075" role="doc-biblioentry">[15] David F. Bacon, Ravi B. Konuru, Chet Murthy, Mauricio J. Serrano,  Thin locks: featherweight synchronization for Java,   <i>SIGPLAN Conference on Programming Language Design and Implementation</i>.  1998:258–268.</p><p class="reflist1" epub:type="biblioentry footnote" id="br0095" role="doc-biblioentry">[19] Hans-J. Boehm,  Threads cannot be implemented as a library,   <i>Proceedings of the 2005 ACM SIGPLAN Conference on Programming Language Design and Implementation</i>.  <i>PLDI '05</i>.  New York, NY, USA: ACM; 2005:261–268.</p><p class="reflist1" epub:type="biblioentry footnote" id="br0160" role="doc-biblioentry">[32] T. Craig,  <i>Building FIFO and priority-queueing spin locks from atomic swap</i>. [Technical Report TR 93-02-02] University of Washington, Department of Computer Science; February 1993.</p><p class="reflist1" epub:type="biblioentry footnote" id="br0180" role="doc-biblioentry">[36] David Dice,  Implementing fast Java monitors with relaxed-locks,   <i>Java Virtual Machine Research and Technology Symposium</i>.  2001:79–90.</p><p class="reflist1" epub:type="biblioentry footnote" id="br0185" role="doc-biblioentry">[37] David Dice, Virendra J. Marathe, Nir Shavit,  Lock cohorting: a general technique for designing NUMA locks,   <cite><i>ACM Transactions on Parallel Computing</i></cite> 2015;1(2), 13.</p><p class="reflist1" epub:type="biblioentry footnote" id="br0205" role="doc-biblioentry">[41] Arthur Conan Doyle,  <i>A Study in Scarlet and the Sign of Four</i>.  Berkley Publishing Group; 1994 0425102408.</p><p class="reflist1" epub:type="biblioentry footnote" id="br0225" role="doc-biblioentry">[45] F.E. Fich, D. Hendler, N. Shavit,  Linear lower bounds on real-world implementations of concurrent objects,   <i>Proc. of the 46th Annual Symposium on Foundations of Computer Science</i>.  <i>FOCS 2005</i>.  2005:165–173.</p><p class="reflist2" epub:type="biblioentry footnote" id="br0530" role="doc-biblioentry">[106] Leslie Lamport,  A fast mutual exclusion algorithm,   <cite><i>ACM Transactions on Computer Systems</i></cite> January 1987;5(1):1–11.</p><p class="reflist2" epub:type="biblioentry footnote" id="br0590" role="doc-biblioentry">[118] P. Magnussen, A. Landin, E. Hagersten,  Queue locks on cache coherent multiprocessors,   <i>Proceedings of the 8th International Symposium on Parallel Processing</i>.  <i>IPPS</i>.  IEEE Computer Society; April 1994:165–171.</p><p class="reflist2" epub:type="biblioentry footnote" id="br0595" role="doc-biblioentry">[119] Jeremy Manson, William Pugh, Sarita V. Adve,  The Java memory model,   <i>Proceedings of the 32nd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages</i>.  <i>POPL '05</i>.  New York, NY, USA: ACM; 2005:378–391.</p><p class="reflist2" epub:type="biblioentry footnote" id="br0605" role="doc-biblioentry">[121] Virendra J. Marathe, Mark Moir, Nir Shavit,  Composite abortable locks,   <i>Proceedings of the 20th International Conference on Parallel and Distributed Processing</i>.  <i>IPDPS'06</i>.  Washington, DC, USA: IEEE Computer Society; 2006:132.</p><p class="reflist2" epub:type="biblioentry footnote" id="br0620" role="doc-biblioentry">[124] John Mellor-Crummey, Michael Scott,  Algorithms for scalable synchronization on shared-memory multiprocessors,   <cite><i>ACM Transactions on Computer Systems</i></cite> 1991;9(1):21–65.</p><p class="reflist2" epub:type="biblioentry footnote" id="br0720" role="doc-biblioentry">[144] Zoran Radović, Erik Hagersten,  Hierarchical backoff locks for nonuniform communication architectures,   <i>Ninth International Symposium on High Performance Computer Architecture</i>.  <i>Anaheim, California, USA</i>.  February 2003:241–252.</p><p class="reflist2" epub:type="biblioentry footnote" id="br0750" role="doc-biblioentry">[150] L. Rudolph, Z. Segall,  Dynamic decentralized cache schemes for MIMD parallel processors,   <i>Proceedings of the 11th Annual International Symposium on Computer Architecture</i>.  ACM Press; 1984:340–347.</p><p class="reflist2" epub:type="biblioentry footnote" id="br0765" role="doc-biblioentry">[153] Michael L. Scott,  Non-blocking timeout in scalable queue-based spin locks,   <i>PODC '02: Proceedings of the Twenty-First Annual Symposium on Principles of Distributed Computing</i>.  New York, NY, USA: ACM Press; 2002:31–40.</p><p class="reflist2" epub:type="biblioentry footnote" id="br0770" role="doc-biblioentry">[154] Michael L. Scott, William N. Scherer,  Scalable queue-based spin locks with timeout,   <cite><i>ACM SIGPLAN Notices</i></cite> 2001;36(7):44–52.</p></div></section><section epub:type="rearnotes"><div class="ftnote"><hr/><p class="ftnote1" epub:type="footnote" id="fn001" role="doc-footnote"><sup><a epub:type="noteref" href="#cf0055" role="doc-noteref">1 </a></sup> <a id="np0010"/>“Most of our lock classes use the initials of their inventors, as explained in Section <a href="#s0090" id="cf0060">7.11</a>.”</p><p class="ftnote1" epub:type="footnote" id="fn002" role="doc-footnote"><sup><a epub:type="noteref" href="#cf0065" role="doc-noteref">2 </a></sup> <a id="np0015"/>“The role of the <img alt="Image" height="9" src="images/B9780124159501000173/fx018.jpg" width="53"/> declaration here is not to introduce a memory barrier but rather to prevent the compiler from applying any optimizations to the loop in line 19.”</p><p class="ftnote1" epub:type="footnote" id="fn003" role="doc-footnote"><sup><a epub:type="noteref" href="#cf0085" role="doc-noteref">3 </a></sup> <a id="np0020"/>“There is no need to reuse nodes in garbage-collected languages such as Java or C#, but reuse would be needed in languages such as C++ or C.”</p><p class="ftnote1" epub:type="footnote" id="fn004" role="doc-footnote"><sup><a epub:type="noteref" href="#cf0170" role="doc-noteref">4 </a></sup> <a id="np0025"/>“The ABA problem typically arises when using dynamically allocated memory in non-garbage-collected languages. See Section <a href="B9780124159501000203.xhtml">10.6</a> for a more complete discussion of this problem in that context. We encounter it here because we are manually managing memory by using an array to implement a dynamic linked list.”</p></div></section></footer></section></body></html>