<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Cache Size (Blocks)</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part233.htm">&lt; 上一个</a><span> | </span><a href="../ostep.html">内容</a><span> | </span><a href="part235.htm">下一个 &gt;</a></p><p class="s76" style="padding-left: 54pt;text-indent: 0pt;text-align: center;">Cache Size (Blocks)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 2pt;padding-left: 147pt;text-indent: 0pt;text-align: left;">Figure 22.3: <b>The 80-20 Workload</b></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 68pt;text-indent: 12pt;line-height: 89%;text-align: justify;">You might now be wondering: is LRU’s improvement over Random and FIFO really that big of a deal? The answer, as usual, is “it depends.” If each miss is very costly (not uncommon), then even a small increase in hit rate (reduction in miss rate) can make a huge difference on performance. If misses are not so costly, then of course the benefits possible with LRU are not nearly as important.</p><p style="padding-left: 68pt;text-indent: 12pt;line-height: 89%;text-align: justify;">Let’s look at one final workload. We call this one the “looping sequen- tial” workload, as in it, we refer to 50 pages in sequence, starting at 0, then 1, ..., up to page 49, and then we loop, repeating those accesses, for a total of 10,000 accesses to 50 unique pages. The last graph in Figure <span style=" color: #00AEEF;">22.4 </span>shows the behavior of the policies under this workload.</p><p style="padding-left: 68pt;text-indent: 12pt;line-height: 89%;text-align: justify;">This workload, common in many applications (including important commercial applications such as databases [CD85]), represents a worst- case for both LRU and FIFO. These algorithms, under a looping-sequential workload, kick out older pages; unfortunately, due to the looping nature of the workload, these older pages are going to be accessed sooner than the pages that the policies prefer to keep in cache. Indeed, even with a cache of size 49, a looping-sequential workload of 50 pages results in a 0% hit rate. Interestingly, Random fares notably better, not quite ap- proaching optimal, but at least achieving a non-zero hit rate. Turns out that random has some nice properties; one such property is not having weird corner-case behaviors.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s48" style="padding-left: 38pt;text-indent: 0pt;text-align: right;">100%</p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part233.htm">&lt; 上一个</a><span> | </span><a href="../ostep.html">内容</a><span> | </span><a href="part235.htm">下一个 &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
