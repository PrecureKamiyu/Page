<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>16.3  Estimating Statistics of Expression Results</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part297.htm">&lt; 上一个</a><span> | </span><a href="../database.html">内容</a><span> | </span><a href="part299.htm">下一个 &gt;</a></p><p class="s65" style="padding-left: 72pt;text-indent: 0pt;text-align: left;">16.3  <span style=" color: #00AEEF;">Estimating Statistics of Expression Results</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-left: 119pt;text-indent: 0pt;line-height: 83%;text-align: justify;"><span class="p">The cost of an operation depends on the size and other statistics of its inputs. Given an expression such as </span>r <span class="s86">⋈ </span><span class="p">(</span>s <span class="s86">⋈ </span>t<span class="p">) to estimate the cost of joining </span>r <span class="p">with (</span>s <span class="s86">⋈ </span>t<span class="p">), we need to have estimates of statistics such as the size of </span>s <span class="s86">⋈ </span>t<span class="p">.</span></p><p style="padding-left: 137pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">In this section, we ﬁrst list some statistics about database relations that are stored</p><p style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">in database-system catalogs, and then show how to use the stored statistics to estimate statistics on the results of various relational operations.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Given a query expression, we consider it as a tree; we can start from the bottom- level operations, and estimate their statistics, and continue the process on higher-level operations, till we reach the root of the tree. The size estimates that we compute as part of these statistics can be used to compute the cost of algorithms for individual operations in the tree, and these costs can be added up to ﬁnd the cost of an entire query plan, as we saw in Chapter 15.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">One thing that will become clear later in this section is that the estimates are not very accurate, since they are based on assumptions that may not hold exactly. A query- evaluation plan that has the lowest estimated execution cost may therefore not actually have the lowest actual execution cost. However, real-world experience has shown that even if estimates are not precise, the plans with the lowest estimated costs usually have actual execution costs that are either the lowest actual execution costs or are close to the lowest actual execution costs.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-top: 4pt;padding-left: 88pt;text-indent: 0pt;text-align: left;">16.3.1 Catalog Information</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">The database-system catalog stores the following statistical information about database relations:</p><p class="s13" style="padding-top: 10pt;padding-left: 91pt;text-indent: 0pt;text-align: left;"><span class="s39">• </span>n<span class="s145">r </span><span class="p">, the number of tuples in the relation </span>r<span class="p">.</span></p><p class="s13" style="padding-top: 2pt;padding-left: 91pt;text-indent: 0pt;text-align: left;"><span class="s39">• </span>b<span class="s97">r </span><span class="p">, the number of blocks containing tuples of relation </span>r<span class="p">.</span></p><p class="s13" style="padding-top: 1pt;padding-left: 91pt;text-indent: 0pt;text-align: left;"><span class="s39">• </span>l<span class="s145">r </span><span class="p">, the size of a tuple of relation </span>r <span class="p">in bytes.</span></p><p class="s13" style="padding-top: 3pt;padding-left: 107pt;text-indent: -16pt;line-height: 87%;text-align: left;"><span class="s39">• </span>f<span class="s97">r </span><span class="p">, the blocking factor of relation </span>r <span class="p">— that is, the number of tuples of relation </span>r <span class="p">that ﬁt into one block.</span></p><p style="padding-top: 4pt;padding-left: 107pt;text-indent: -16pt;text-align: left;"><span class="s39">• </span><i>V </i>(<i>A</i>, <i>r</i>), the number of distinct values that appear in the relation <i>r </i>for attribute <i>A</i>. This value is the same as the size of <span class="s15">Π</span><i>A</i>(<i>r</i>). If <i>A </i>is a key for relation <i>r</i>, <i>V </i>(<i>A</i>, <i>r</i>) is <i>n</i><span class="s97">r</span>.</p><p style="padding-top: 12pt;padding-left: 88pt;text-indent: 0pt;line-height: 83%;text-align: justify;">The last statistic, <i>V </i>(<i>A</i>, <i>r</i>), can also be maintained for sets of attributes, if desired, instead of just for individual attributes. Thus, given a set of attributes, <span class="s86"></span>, <i>V </i>(<span class="s86"></span>, <i>r</i>) is the size of <span class="s15">Π</span><span class="s369"></span>(<i>r</i>).</p><p style="padding-left: 106pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">If we assume that the tuples of relation <i>r </i>are stored together physically in a ﬁle, the</p><p class="s15" style="text-indent: 0pt;text-align: left;">⌈ ⌉</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 88pt;text-indent: 0pt;text-align: justify;">following equation holds:</p><p style="text-indent: 0pt;text-align: left;"><span><img width="12" height="1" alt="image" src="Image_2919.png"/></span></p><p class="s13" style="padding-left: 51pt;text-indent: 0pt;line-height: 17pt;text-align: center;">b <span class="s15">= </span><span class="s405">n</span><span class="s406">r</span></p><p class="s109" style="padding-left: 55pt;text-indent: 0pt;line-height: 35%;text-align: center;">r   <span class="s407">f</span><span class="s408">r</span></p><p style="padding-top: 9pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">Statistics about indices, such as the heights of B<span class="s181">+</span>-tree indices and number of leaf pages in the indices, are also maintained in the catalog.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">If we wish to maintain accurate statistics, then every time a relation is modiﬁed, we must also update the statistics. This update incurs a substantial amount of overhead. Therefore, most systems do not update the statistics on every modiﬁcation. Instead, they update the statistics during periods of light system load. As a result, the statistics used for choosing a query-processing strategy may not be completely accurate. How- ever, if not too many updates occur in the intervals between the updates of the statistics, the statistics will be suﬃciently accurate to provide a good estimation of the relative costs of the diﬀerent plans.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The statistical information noted here is simpliﬁed. Real-world optimizers often maintain further statistical information to improve the accuracy of their cost estimates of evaluation plans. For instance, most databases store the distribution of values for each attribute as a <span class="s63">histogram</span>: in a histogram, the values for the attribute are divided into a number of ranges, and with each range the histogram associates the number of tuples whose attribute value lies in that range. Figure 16.6 shows an example of a histogram for an integer-valued attribute that takes values in the range 1 to 25.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">As an example of a histogram, the range of values for an attribute <i>age </i>of a relation <i>person </i>could be divided into 0—9, 10—19, . . . , 90—99 (assuming a maximum age of 99). With each range we store a count of the number of <i>person </i>tuples whose <i>age </i>values lie in that range.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="251" height="167" alt="image" src="Image_2920.png"/></span></p><p class="s42" style="padding-top: 4pt;padding-left: 34pt;text-indent: 0pt;text-align: center;">50</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s42" style="padding-left: 1pt;text-indent: 0pt;text-align: left;">frequency</p><p style="text-indent: 0pt;text-align: left;"/><p class="s42" style="padding-left: 34pt;text-indent: 0pt;text-align: center;">40</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s42" style="padding-left: 34pt;text-indent: 0pt;text-align: center;">30</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s42" style="padding-left: 34pt;text-indent: 0pt;text-align: center;">20</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s42" style="padding-left: 34pt;text-indent: 0pt;text-align: center;">10</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s42" style="padding-top: 7pt;padding-left: 146pt;text-indent: 0pt;text-align: center;">1–5  6–10  11–15 16–20 21–25</p><p class="s42" style="padding-top: 3pt;padding-left: 152pt;text-indent: 0pt;text-align: center;">value</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s73" style="padding-top: 4pt;padding-left: 228pt;text-indent: 0pt;text-align: left;">Figure 16.6 <span class="s74">Example of histogram.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">The histogram shown in Figure 16.6, is an <span class="s63">equi-width histogram </span>since it divides the range of values into equal-sized ranges. In contrast, an <span class="s63">equi-depth </span>histogram adjusts the boundaries of the ranges such that each range has the same number of values. Thus, an equi-depth histogram merely stores the boundaries of partitions of the range, and need not store the number of values. For example, the following could be the equidepth histogram for the data whose equi-width histogram is shown in Figure 16.6:</p><p style="padding-top: 6pt;padding-left: 168pt;text-indent: 0pt;text-align: justify;">(4, 8, 14, 19)</p><p style="padding-top: 8pt;padding-left: 119pt;text-indent: 0pt;line-height: 76%;text-align: justify;">The histogram indicates that 1<span class="s15">∕</span>5th of the tuples have age less than 4, another 1<span class="s15">∕</span>5th have age <span class="s86">≥ </span>4 but <span class="s83">&lt; </span>8, and so on, with the last 1<span class="s15">∕</span>5th having age <span class="s86">≥ </span>19. Information about the total number of tuples is also stored with the equi-width histogram. Equi-depth</p><p style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">histograms are preferred to equi-width histograms since they provide better estimates, and occupy less space.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Histograms used in database systems can also record the number of distinct values in each range, in addition to the number of tuples with attribute values in that range. In our example, the histogram could store the number of distinct age values that lie in each range. Without such histogram information, an optimizer would have to assume that the distribution of values is uniform; that is, each range has the same number of distinct values.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">In many database applications, some values are very frequent, compared to other values. To get better estimates for queries that specify these values, many databases store a list of <i>n </i>most frequent values for some <i>n </i>(say 5 or 10), along with the number of times each value appears. In our example, if ages 4, 7, 18, 19, and 23 are the ﬁve most frequently occurring values, the database could store the number of persons having each of these ages. The histogram then only stores statistics for age values other than these ﬁve values, since we have now have exact counts for these values.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 17pt;text-align: left;">A histogram takes up only a little space, so histograms on several diﬀerent at- tributes can be stored in the system catalog.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 88pt;text-indent: 0pt;text-align: left;">16.3.2 Selection Size Estimation</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">The size estimate of the result of a selection operation depends on the selection predi- cate. We ﬁrst consider a single equality predicate, then a single comparison predicate, and ﬁnally combinations of predicates.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-left: 107pt;text-indent: -16pt;text-align: justify;"><span class="s39">• </span><span class="s15">σ</span><span class="s123">A</span> <span class="s137">=</span><span class="s15"> </span><span class="s123">a</span><span class="p">(</span>r<span class="p">): If </span>a <span class="p">is a frequently occurring value for which the occurrence count is available, we can use that value directly as the size estimate for the selection.</span></p><p class="s13" style="padding-left: 107pt;text-indent: 15pt;text-align: justify;"><span class="p">Otherwise if there is no histogram available, we assume uniform distribution of values (i.e., each value appears with equal probability), the selection result is estimated to have </span>n<span class="s97">r </span><span class="s15">∕</span>V <span class="p">(</span>A<span class="p">, </span>r<span class="p">) tuples, assuming that the value </span>a <span class="p">appears in attribute</span></p><p class="s13" style="padding-left: 107pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">A <span class="p">of some record of </span>r<span class="p">. The assumption that the value </span>a <span class="p">in the selection appears in</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_2921.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_2922.png"/></span></p><p style="padding-left: 107pt;text-indent: 0pt;text-align: justify;">some record is generally true, and cost estimates often make it implicitly. However, it is often not realistic to assume that each value appears with equal probability. The <i>course id </i>attribute in the <i>takes </i>relation is an example where the assumption is not valid. It is reasonable to expect that a popular undergraduate course will have many more students than a smaller specialized graduate course. Therefore, certain <i>course id </i>values appear with greater probability than do others. Despite the fact that the uniform-distribution assumption is often not correct, it is a reasonable approximation of reality in many cases, and it helps us to keep our presentation relatively simple.</p><p class="s13" style="padding-top: 1pt;padding-left: 107pt;text-indent: 14pt;line-height: 93%;text-align: justify;"><span class="p">If a histogram is available on attribute </span>A<span class="p">, we can locate the range that contains the value </span>a<span class="p">, and modify the above-mentioned estimate </span>n<span class="s145">r </span><span class="s15">∕</span>V <span class="p">(</span>A<span class="p">, </span>r<span class="p">) by using the frequency count for that range instead of </span>n<span class="s145">r </span><span class="p">, and the number of distinct values that occurs in that range instead of </span>V <span class="p">(</span>A<span class="p">, </span>r<span class="p">).</span></p><p style="padding-top: 5pt;padding-left: 107pt;text-indent: -16pt;line-height: 92%;text-align: justify;"><span class="s39">• </span><span class="s15">σ</span><i>A</i><span class="s369">≤</span><i>v</i>(<i>r</i>): Consider a selection of the form <span class="s15">σ</span><i>A</i><span class="s369">≤</span><i>v</i>(<i>r</i>). Suppose that the lowest and highest values (min(<i>A</i>, <i>r</i>) and max(<i>A</i>, <i>r</i>)) for the attribute are stored in the catalog. Assuming that values are uniformly distributed, we can estimate the number of records that will satisfy the condition <i>A </i><span class="s86">≤ </span><i>v </i>as:</p><p class="s13" style="padding-top: 3pt;padding-left: 113pt;text-indent: 0pt;line-height: 21pt;text-align: justify;"><span class="s50">° </span><span class="s51">0 if </span>v <span class="s83">&lt; </span><span class="p">min(</span>A<span class="p">, </span>r<span class="p">)</span></p><p class="s13" style="padding-left: 113pt;text-indent: 0pt;line-height: 18pt;text-align: justify;"><span class="s50">° </span>n<span class="s145">r </span><span class="p">if </span>v <span class="s86">≥ </span><span class="p">max(</span>A<span class="p">, </span>r<span class="p">), and,</span></p><p class="s50" style="text-indent: 0pt;line-height: 71%;text-align: left;">° <span class="s13">n</span><span class="s97">r </span><span class="s86">⋅      </span><span class="p">, otherwise.</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s119" style="padding-top: 1pt;padding-left: 140pt;text-indent: 0pt;line-height: 120%;text-align: justify;"><u><i>  v</i></u><span class="s409">−</span><u>min(</u><u><i>A</i></u><u>,</u><u><i>r</i></u><u>)  </u> max(<i>A</i>,<i>r</i>)<span class="s118">−</span>min(<i>A</i>,<i>r</i>)</p><p style="padding-top: 3pt;padding-left: 107pt;text-indent: 14pt;text-align: justify;">If a histogram is available on attribute <i>A</i>, we can get a more accurate estimate; we leave the details as an exercise for you.</p><p style="padding-left: 107pt;text-indent: 14pt;text-align: justify;">In some cases, such as when the query is part of a stored procedure, the value <i>v </i>may not be available when the query is optimized. In such cases, we assume that approximately one-half the records will satisfy the comparison condition. That is,</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="493" height="687" alt="image" src="Image_2923.png"/></span></p><p class="s73" style="padding-left: 183pt;text-indent: 0pt;text-align: left;">Note 16.2 <span class="s146">COMPUTING AND MAINTAINING STATISTICS</span></p><p style="padding-top: 2pt;padding-left: 129pt;text-indent: 1pt;text-align: justify;">Conceptually, statistics on relations can be thought of as materialized views, which should be automatically maintained when relations are modiﬁed. Unfortunately, keeping statistics up-to-date on every insert, delete or update to the database can be very expensive. On the other hand, optimizers generally do not need exact statis- tics: an error of a few percent may result in a plan that is not quite optimal being chosen, but the alternative plan chosen is likely to have a cost which is within a few percent of the optimal cost. Thus, it is acceptable to have statistics that are approximate.</p><p style="padding-left: 129pt;text-indent: 17pt;text-align: justify;">Database systems reduce the cost of generating and maintaining statistics, as outlined below, by exploiting the fact that statistics can be approximate.</p><p class="s39" style="padding-top: 9pt;padding-left: 148pt;text-indent: -16pt;text-align: justify;">• <span class="s40">Statistics are often computed from a sample of the underlying data, instead of examining the entire collection of data. For example, a fairly accurate his- togram can be computed from a sample of a few thousand tuples, even on a relation that has millions, or hundreds of millions of records. However, the sample used must be a </span><span class="s63">random sample</span><span class="p">; a sample that is not random may have an excessive representation of one part of the relation and can give misleading results. For example, if we used a sample of instructors to compute a histogram on salaries, if the sample has an overrepresentation of lower-paid instructors the histogram would result in wrong estimates. Database systems today rou- tinely use random sampling to create statistics. See the bibliographical notes online for references on sampling.</span></p><p style="padding-top: 3pt;padding-left: 148pt;text-indent: -16pt;text-align: justify;"><span class="s39">• </span><span class="s40">Statistics are not maintained on every update to the database. In fact, some database systems never update statistics automatically. They rely on database administrators periodically running a command to update statistics. Oracle and </span><span class="s41">P</span><span class="s40">ostgre</span><span class="s41">SQL </span><span class="s40">provide an </span><span class="s41">SQL </span><span class="s40">command called </span><b>analyze </b>that generates statis- tics on speciﬁed relations, or on all relations. <span class="s44">IBM DB2 </span>supports an equivalent command called <b>runstats</b>. See the system manuals for details. You should be aware that optimizers sometimes choose very bad plans due to incorrect statis- tics. Many database systems, such as <span class="s44">IBM DB2</span>, Oracle, and <span class="s44">SQL S</span>erver, update statistics automatically at certain points of time. For example, the system can keep approximate track of how many tuples there are in a relation and re- compute statistics if this number changes signiﬁcantly. Another approach is to compare estimated cardinalities of a relation scan with actual cardinalities when a query is executed, and if they diﬀer signiﬁcantly, initiate an update of statistics for that relation.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 6pt;padding-left: 107pt;text-indent: 0pt;line-height: 90%;text-align: left;">we assume the result has <i>n</i><span class="s145">r </span><span class="s15">∕</span>2 tuples; the estimate may be very inaccurate, but it is the best we can do without any further information.</p><p class="s39" style="padding-top: 4pt;padding-left: 91pt;text-indent: 0pt;text-align: left;">• <span class="s40">Complex selections:</span></p><p style="padding-top: 5pt;padding-left: 113pt;text-indent: 0pt;text-align: left;"><span class="s50">° </span><b>Conjunction: </b>A <i>conjunctive selection </i>is a selection of the form:</p><p class="s150" style="text-indent: 0pt;line-height: 6pt;text-align: left;">1  2  <i>n</i></p><p style="text-indent: 0pt;text-align: left;"/><p class="s122" style="padding-top: 8pt;padding-left: 84pt;text-indent: 0pt;text-align: center;"><span class="s117">σ</span><span class="s370">θ ∧θ ∧</span><span class="s371">⋯</span><span class="s118">∧θ </span>(<i>r</i>)</p><p class="s106" style="text-indent: 0pt;line-height: 6pt;text-align: left;">i</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 3pt;padding-left: 122pt;text-indent: 0pt;line-height: 93%;text-align: justify;">We can estimate the result size of such a selection: For each <span class="s15">θ</span><i>i</i>, we estimate the size of the selection <span class="s15">σ</span><span class="s137">θ</span><span class="s15"> </span>(<i>r</i>), denoted by <i>s</i><span class="s97">i</span>, as described previously. Thus, the probability that a tuple in the relation satisﬁes selection condition <span class="s15">θ</span><i>i</i><i> </i>is <i>s</i><span class="s97">i</span><span class="s15">∕</span><i>n</i><span class="s97">r</span>.</p><p class="s106" style="text-indent: 0pt;line-height: 6pt;text-align: left;">i</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 138pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">The preceding probability is called the <span class="s63">selectivity </span>of the selection <span class="s15">σ</span><span class="s137">θ</span><span class="s15"> </span>(<i>r</i>).</p><p style="padding-left: 122pt;text-indent: 0pt;text-align: justify;">Assuming that the conditions are <i>independent </i>of each other, the probability that a tuple satisﬁes all the conditions is simply the product of all these probabilities. Thus, we estimate the number of tuples in the full selection as:</p><p class="s13" style="text-indent: 0pt;line-height: 12pt;text-align: left;">n</p><p style="text-indent: 0pt;text-align: left;"/><p class="s15" style="text-indent: 0pt;text-align: left;">∗</p><p style="text-indent: 0pt;text-align: left;"/><p class="s13" style="text-indent: 0pt;line-height: 12pt;text-align: left;">n</p><p style="text-indent: 0pt;text-align: left;"/><p class="s15" style="padding-top: 4pt;padding-left: 84pt;text-indent: 0pt;line-height: 16pt;text-align: center;"><span class="s13">s</span><span class="s130">1 </span>∗ <span class="s13">s</span><span class="s130">2 </span>∗ <span class="s86">⋯ </span>∗ <span class="s13">s</span><span class="s97">n</span></p><p style="padding-left: 265pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="94" height="1" alt="image" src="Image_2924.png"/></span></p><p class="s109" style="padding-left: 67pt;text-indent: 0pt;line-height: 8pt;text-align: center;">r      <span class="s169">n</span></p><p class="s109" style="padding-left: 74pt;text-indent: 0pt;line-height: 8pt;text-align: center;">r</p><p style="padding-top: 2pt;padding-left: 113pt;text-indent: 0pt;text-align: left;"><span class="s50">° </span><b>Disjunction: </b>A <i>disjunctive selection </i>is a selection of the form:</p><p class="s150" style="text-indent: 0pt;line-height: 6pt;text-align: left;">1  2  <i>n</i></p><p style="text-indent: 0pt;text-align: left;"/><p class="s122" style="padding-top: 1pt;padding-left: 84pt;text-indent: 0pt;text-align: center;"><span class="s117">σ</span><span class="s370">θ ∨θ ∨</span><span class="s371">⋯</span><span class="s118">∨θ </span>(<i>r</i>)</p><p style="padding-top: 2pt;padding-left: 122pt;text-indent: 0pt;text-align: justify;">A disjunctive condition is satisﬁed by the union of all records satisfying the individual, simple conditions <span class="s15">θ</span><i>i</i>.</p><p style="padding-left: 122pt;text-indent: 14pt;line-height: 94%;text-align: justify;">As before, let <i>s</i><span class="s97">i</span><span class="s15">∕</span><i>n</i><span class="s97">r </span>denote the probability that a tuple satisﬁes condition <span class="s15">θ</span><i>i</i>. The probability that the tuple will satisfy the disjunction is then 1 minus the probability that it will satisfy <i>none </i>of the conditions:</p><p style="text-indent: 0pt;text-align: left;"><span><img width="12" height="1" alt="image" src="Image_2925.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="12" height="1" alt="image" src="Image_2926.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="12" height="1" alt="image" src="Image_2927.png"/></span></p><p class="s15" style="padding-top: 5pt;padding-left: 84pt;text-indent: 0pt;line-height: 16pt;text-align: center;"><span class="p">1 </span>− <span class="p">(1 </span>− <span class="s405">s</span><span class="s410">1 </span><span class="s94">) </span>∗ <span class="p">(1 </span>− <span class="s405">s</span><span class="s410">2 </span><span class="s94">) </span>∗ <span class="s86">⋯ </span>∗ <span class="p">(1 </span>− <span class="s405">s</span><span class="s406">n </span><span class="p">)</span></p><p class="s13" style="padding-left: 244pt;text-indent: 0pt;line-height: 14pt;text-align: left;">n<span class="s145">r      </span>n<span class="s145">r         </span>n<span class="s145">r</span></p><p style="padding-top: 3pt;padding-left: 122pt;text-indent: 0pt;line-height: 90%;text-align: justify;">Multiplying this value by <i>n</i><span class="s145">r </span>gives us the estimated number of tuples that satisfy the selection.</p><p style="padding-top: 8pt;padding-left: 122pt;text-indent: -8pt;line-height: 76%;text-align: left;"><span class="s50">° </span><b>Negation: </b>In the absence of nulls, the result of a selection <span class="s15">σ</span><span class="s137">¬θ</span>(<i>r</i>) is simply the tuples of <i>r </i>that are not in <span class="s15">σ</span><span class="s137">θ</span>(<i>r</i>). We already know how to estimate the number</p><p style="padding-left: 122pt;text-indent: 0pt;text-align: left;">of tuples in <span class="s15">σ</span><span class="s137">θ</span>(<i>r</i>). The number of tuples in <span class="s15">σ</span><span class="s137">¬θ</span>(<i>r</i>) is therefore estimated to be</p><p style="padding-left: 122pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><i>n</i><span class="s145">r </span>minus the estimated number of tuples in <span class="s15">σ</span><span class="s137">θ</span>(<i>r</i>).</p><p style="padding-left: 138pt;text-indent: 0pt;line-height: 12pt;text-align: justify;">We can account for nulls by estimating the number of tuples for which</p><p style="padding-left: 122pt;text-indent: 0pt;text-align: justify;">the condition <span class="s15">θ </span>would evaluate to <i>unknown</i>, and subtracting that number from the above estimate, ignoring nulls. Estimating that number would require extra statistics to be maintained in the catalog.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 88pt;text-indent: 0pt;text-align: left;">16.3.3 Join Size Estimation</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: left;">In this section, we see how to estimate the size of the result of a join.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-top: 5pt;padding-left: 97pt;text-indent: 0pt;line-height: 14pt;text-align: center;"><span class="p">The Cartesian product </span>r <span class="s15">× </span>s <span class="p">contains </span>n<span class="s145">r </span><span class="s15">∗ </span>n<span class="s145">s </span><span class="p">tuples. Each tuple of </span>r <span class="s15">× </span>s <span class="p">occupies</span></p><p class="s13" style="padding-left: 119pt;text-indent: 0pt;line-height: 13pt;text-align: left;">l<span class="s97">r </span><span class="s15">+ </span>l<span class="s97">s </span><span class="p">bytes, from which we can calculate the size of the Cartesian product.</span></p><p style="padding-left: 97pt;text-indent: 0pt;line-height: 12pt;text-align: center;">Estimating the size of a natural join is somewhat more complicated than estimating</p><p style="padding-left: 119pt;text-indent: 0pt;text-align: left;">the size of a selection or of a Cartesian product. Let <i>r</i>(<i>R</i>) and <i>s</i>(<i>S</i>) be relations.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-left: 139pt;text-indent: -16pt;line-height: 85%;text-align: justify;"><span class="s39">• </span><span class="s40">If </span>R <span class="s15">∩ </span>S <span class="s15">= ∅</span><span class="p">— that is, the relations have no attribute in common— then </span>r <span class="s86">⋈ </span>s <span class="p">is the same as </span>r <span class="s15">× </span>s<span class="p">, and we can use our estimation technique for Cartesian products.</span></p><p class="s13" style="padding-top: 5pt;padding-left: 139pt;text-indent: -16pt;line-height: 90%;text-align: justify;"><span class="s39">• </span><span class="s40">If </span>R <span class="s15">∩ </span>S <span class="p">is a key for </span>R<span class="p">, then we know that a tuple of </span>s <span class="p">will join with at most one tuple from </span>r<span class="p">. Therefore, the number of tuples in </span>r <span class="s86">⋈ </span>s <span class="p">is no greater than the number of tuples in </span>s<span class="p">. The case where </span>R <span class="s15">∩ </span>S <span class="p">is a key for </span>S <span class="p">is symmetric to the case just described. If </span>R <span class="s15">∩ </span>S <span class="p">forms a foreign key of </span>S<span class="p">, referencing </span>R<span class="p">, the number of tuples in </span>r <span class="s86">⋈ </span>s <span class="p">is exactly the same as the number of tuples in </span>s<span class="p">.</span></p><p class="s13" style="padding-top: 2pt;padding-left: 139pt;text-indent: -16pt;text-align: justify;"><span class="s39">• </span><span class="s40">The most diﬃcult case is when </span>R <span class="s15">∩ </span>S <span class="p">is a key for neither </span>R <span class="p">nor </span>S<span class="p">. In this case, we assume, as we did for selections, that each value appears with equal probability.</span></p><p style="padding-left: 98pt;text-indent: 0pt;line-height: 13pt;text-align: center;">Consider a tuple <i>t </i>of <i>r</i>, and assume <i>R </i><span class="s15">∩ </span><i>S </i><span class="s15">= </span><span class="s95">{</span>A<span class="s95">}</span>. We estimate that tuple <i>t </i>produces</p><p class="s13" style="padding-top: 5pt;padding-left: 141pt;text-indent: 0pt;text-align: center;">n<span class="s145">s</span></p><p style="padding-left: 299pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="41" height="1" alt="image" src="Image_2928.png"/></span></p><p class="s13" style="padding-left: 141pt;text-indent: 0pt;text-align: center;">V <span class="p">(</span>A<span class="p">, </span>s<span class="p">)</span></p><p class="s13" style="padding-top: 2pt;padding-left: 139pt;text-indent: 0pt;line-height: 93%;text-align: justify;"><span class="p">tuples in </span>r <span class="s86">⋈ </span>s<span class="p">, since this number is the average number of tuples in </span>s <span class="p">with a given value for the attributes </span>A<span class="p">. Considering all the tuples in </span>r<span class="p">, we estimate that there are</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="41" height="1" alt="image" src="Image_2929.png"/></span></p><p class="s13" style="padding-top: 7pt;padding-left: 299pt;text-indent: 0pt;line-height: 107%;text-align: center;">n<span class="s97">r </span><span class="s15">∗ </span>n<span class="s97">s </span>V <span class="p">(</span>A<span class="p">, </span>s<span class="p">)</span></p><p class="s13" style="padding-top: 3pt;padding-left: 139pt;text-indent: 0pt;line-height: 86%;text-align: left;"><span class="p">tuples in </span>r <span class="s86">⋈ </span>s<span class="p">. Observe that, if we reverse the roles of </span>r <span class="p">and </span>s <span class="p">in the preceding estimate, we obtain an estimate of</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="41" height="1" alt="image" src="Image_2930.png"/></span></p><p class="s13" style="padding-top: 7pt;padding-left: 299pt;text-indent: 0pt;line-height: 111%;text-align: center;">n<span class="s145">r </span><span class="s15">∗ </span>n<span class="s145">s </span>V <span class="p">(</span>A<span class="p">, </span>r<span class="p">)</span></p><p class="s13" style="padding-top: 1pt;padding-left: 139pt;text-indent: 0pt;line-height: 93%;text-align: justify;"><span class="p">tuples in </span>r <span class="s86">⋈ </span>s<span class="p">. These two estimates diﬀer if </span>V <span class="p">(</span>A<span class="p">, </span>r<span class="p">) </span><span class="s86">≠ </span>V <span class="p">(</span>A<span class="p">, </span>s<span class="p">). If this situation occurs, there are likely to be dangling tuples that do not participate in the join. Thus, the lower of the two estimates is probably the more accurate one.</span></p><p style="padding-left: 139pt;text-indent: 15pt;text-align: justify;">The preceding estimate of join size may be too high if the <i>V </i>(<i>A</i>, <i>r</i>) values for attribute <i>A </i>in <i>r </i>have few values in common with the <i>V </i>(<i>A</i>, <i>s</i>) values for attribute <i>A </i>in <i>s</i>. However, this situation is unlikely to happen in the real world, since dangling tuples either do not exist or constitute only a small fraction of the tuples, in most real-world relations.</p><p style="padding-left: 139pt;text-indent: 14pt;text-align: justify;">More important, the preceding estimate depends on the assumption that each value appears with equal probability. More sophisticated techniques for size esti- mation have to be used if this assumption does not hold. For example, if we have histograms on the join attributes of both relations, and both histograms have the same ranges, then we can use the above estimation technique within each range,</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 107pt;text-indent: 0pt;text-align: justify;">using the number of rows with values in the range instead of <i>n</i><span class="s145">r </span>or <i>n</i><span class="s145">s</span>, and the number of distinct values in that range, instead of <i>V </i>(<i>A</i>, <i>r</i>) or <i>V </i>(<i>A</i>, <i>s</i>). We then add up the size estimates obtained for each range to get the overall size estimate. We leave the case where both relations have histograms on the join attribute, but the</p><p style="padding-left: 107pt;text-indent: 0pt;text-align: justify;">histograms have diﬀerent ranges, as an exercise for you.</p><p class="s13" style="padding-top: 7pt;padding-left: 88pt;text-indent: 17pt;line-height: 93%;text-align: justify;"><span class="p">We can estimate the size of a theta join </span>r <span class="s86">⋈</span><span class="s136">θ </span>s <span class="p">by rewriting the join as </span><span class="s15">σ</span><span class="s137">θ</span><span class="p">(</span>r <span class="s15">× </span>s<span class="p">) and using the size estimates for Cartesian products along with the size estimates for selections, which we saw in Section 16.3.2.</span></p><p style="padding-left: 106pt;text-indent: 0pt;text-align: justify;">To illustrate all these ways of estimating join sizes, consider the expression:</p><p class="s13" style="padding-top: 4pt;padding-left: 239pt;text-indent: 0pt;text-align: justify;">student <span class="s86">⋈ </span>takes</p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">Assume the following catalog information about the two relations:</p><p class="s39" style="padding-top: 6pt;padding-left: 91pt;text-indent: 0pt;text-align: left;">• <span class="s13">n</span><span class="s97">student </span><span class="s15">= </span><span class="p">5000.</span></p><p class="s39" style="padding-top: 1pt;padding-left: 91pt;text-indent: 0pt;text-align: justify;">• <span class="s13">n</span><span class="s145">takes </span><span class="s15">= </span><span class="p">10000.</span></p><p style="padding-top: 2pt;padding-left: 107pt;text-indent: -16pt;text-align: justify;"><span class="s39">• </span><i>V </i>(<i>ID</i>, <i>takes</i>) <span class="s15">= </span>2500, which implies that only half the students have taken any course (this is unrealistic, but we use it to show that our size estimates are correct even in this case), and on average, each student who has taken a course has taken four courses.</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;line-height: 14pt;text-align: justify;">Note that since <span class="s69">ID </span>is a primary key of <i>student</i>, <i>V </i>(<i>ID</i>, <i>student</i>) <span class="s15">= </span><i>n</i><span class="s97">student </span><span class="s15">= </span>5000.</p><p style="padding-left: 88pt;text-indent: 17pt;line-height: 88%;text-align: justify;">The attribute <span class="s69">ID </span>in <i>takes </i>is a foreign key on <i>student</i>, and null values do not occur in <i>takes</i>.<span class="s69">ID</span>, since <span class="s69">ID </span>is part of the primary key of <i>takes</i>; thus, the size of <i>student </i><span class="s86">⋈ </span><i>takes </i>is exactly <i>n</i><span class="s97">takes</span>, which is 10000.</p><p class="s13" style="padding-left: 87pt;text-indent: 0pt;line-height: 12pt;text-align: right;"><span class="p">We now compute the size estimates for </span>student <span class="s86">⋈ </span>takes <span class="p">without using information</span></p><p style="padding-left: 87pt;text-indent: 0pt;line-height: 12pt;text-align: right;">about foreign keys. Since <i>V </i>(<i>ID</i>, <i>takes</i>) <span class="s15">= </span>2500 and <i>V </i>(<i>ID</i>, <i>student</i>) <span class="s15">= </span>5000, the two</p><p style="padding-left: 88pt;text-indent: 0pt;text-align: justify;">estimates we get are 5000 <span class="s15">∗ </span>10000<span class="s15">∕</span>2500 <span class="s15">= </span>20000 and 5000 <span class="s15">∗ </span>10000<span class="s15">∕</span>5000 <span class="s15">= </span>10000, and we choose the lower one. In this case, the lower of these estimates is the same as that which we computed earlier from information about foreign keys.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 88pt;text-indent: 0pt;text-align: left;">16.3.4 Size Estimation for Other Operations</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">Next we outline how to estimate the sizes of the results of other relational-algebra op- erations.</p><p style="padding-top: 10pt;padding-left: 107pt;text-indent: -16pt;text-align: justify;"><span class="s39">• </span><b>Projection: </b>The estimated size (number of records or number of tuples) of a pro- jection of the form <span class="s15">Π</span><i>A</i>(<i>r</i>) is <i>V </i>(<i>A</i>, <i>r</i>), since projection eliminates duplicates.</p><p style="padding-top: 5pt;padding-left: 107pt;text-indent: -16pt;line-height: 87%;text-align: justify;"><span class="s39">• </span><b>Aggregation: </b>The size of <span class="s149">G </span><span class="s15">γ</span><i>A</i>(<i>r</i>) is simply <i>V </i>(<i>G</i>, <i>r</i>), since there is one tuple in <span class="s149">G </span><span class="s15">γ</span><i>A</i>(<i>r</i>) for each distinct value of <i>G</i>.</p><p class="s15" style="padding-top: 4pt;padding-left: 107pt;text-indent: -16pt;text-align: justify;"><span class="s39">• </span><span class="s46">Set operations: </span><span class="p">If the two inputs to a set operation are selections on the same rela- tion, we can rewrite the set operation as disjunctions, conjunctions, or negations. For example, </span>σ<span class="s137">θ</span> <span class="p">(</span><span class="s13">r</span><span class="p">) </span>∪ σ<span class="s137">θ</span> <span class="p">(</span><span class="s13">r</span><span class="p">) can be rewritten as </span>σ<span class="s137">θ</span> <span class="s137">∨θ</span> <span class="p">(</span><span class="s13">r</span><span class="p">). Similarly, we can rewrite</span></p><p class="s150" style="padding-left: 175pt;text-indent: 0pt;line-height: 4pt;text-align: left;">1      2                 1  2</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 139pt;text-indent: 0pt;text-align: justify;">intersections as conjunctions, and we can rewrite set diﬀerence by using negation, so long as the two relations participating in the set operations are selections on the same relation. We can then use the estimates for selections involving conjunctions, disjunctions, and negation in Section 16.3.2.</p><p class="s13" style="padding-left: 139pt;text-indent: 14pt;text-align: justify;"><span class="p">If the inputs are not selections on the same relation, we estimate the sizes this way: The estimated size of </span>r <span class="s15">∪ </span>s <span class="p">is the sum of the sizes of </span>r <span class="p">and </span>s<span class="p">. The estimated size of </span>r <span class="s15">∩ </span>s <span class="p">is the minimum of the sizes of </span>r <span class="p">and </span>s<span class="p">. The estimated size of </span>r <span class="s15">− </span>s <span class="p">is the same size as </span>r<span class="p">. All three estimates may be inaccurate, but provide upper bounds on the sizes.</span></p><p class="s13" style="padding-top: 4pt;padding-left: 87pt;text-indent: 0pt;line-height: 15pt;text-align: right;"><span class="s39">• </span><b>Outer join: </b><span class="p">The estimated size of </span>r <span class="s15">⟕ </span>s <span class="p">is the size of </span>r <span class="s86">⋈ </span>s <span class="p">plus the size of </span>r<span class="p">; that of</span></p><p class="s13" style="padding-left: 119pt;text-indent: 0pt;line-height: 14pt;text-align: right;">r <span class="s15">⟖ </span>s <span class="p">is symmetric, while that of </span>r <span class="s15">⟗ </span>s <span class="p">is the size of </span>r <span class="s86">⋈ </span>s <span class="p">plus the sizes of </span>r <span class="p">and</span></p><p class="s13" style="padding-left: 139pt;text-indent: 0pt;line-height: 12pt;text-align: left;">s<span class="p">. All three estimates may be inaccurate, but provide upper bounds on the sizes.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 119pt;text-indent: 0pt;text-align: left;">16.3.5 Estimation of Number of Distinct Values</p><p style="padding-top: 6pt;padding-left: 122pt;text-indent: 0pt;line-height: 13pt;text-align: right;">The size estimates discussed earlier depend on statistics such as histograms, or at a minimum, the number of distinct values for an attribute. While these statistics can be precomputed and stored for relations in the database, we need to compute them for intermediate results. Note that estimation of the number of sizes and the number of distinct values of attributes in an intermediate result <i>E</i><span class="s97">i </span>helps us estimate the sizes and number of distinct values of attributes in the next level intermediate results that use <i>E</i><span class="s145">i</span>.</p><p style="padding-left: 119pt;text-indent: 0pt;line-height: 13pt;text-align: right;">For selections, the number of distinct values of an attribute (or set of attributes) <i>A</i></p><p style="padding-left: 58pt;text-indent: 0pt;text-align: center;">in the result of a selection, <i>V </i>(<i>A</i>, <span class="s15">σ</span><span class="s137">θ</span>(<i>r</i>)), can be estimated in these ways:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 123pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><span class="s39">• </span><span class="s40">If the selection condition </span><span class="s15">θ </span>forces <i>A </i>to take on a speciﬁed value (e.g., <i>A </i><span class="s15">= </span>3),</p><p style="padding-left: 139pt;text-indent: 0pt;line-height: 13pt;text-align: left;"><i>V </i>(<i>A</i>, <span class="s15">σ</span><span class="s137">θ</span>(<i>r</i>)) <span class="s15">= </span>1.</p><p style="padding-top: 4pt;padding-left: 139pt;text-indent: -16pt;text-align: left;"><span class="s39">• </span><span class="s40">If </span><span class="s15">θ </span>forces <i>A </i>to take on one of a speciﬁed set of values (e.g., (<i>A </i><span class="s15">= </span>1<span class="s15">∨</span><i>A </i><span class="s15">= </span>3<span class="s15">∨</span><i>A </i><span class="s15">= </span>4)), then <i>V </i>(<i>A</i>, <span class="s15">σ</span><span class="s137">θ</span>(<i>r</i>)) is set to the number of speciﬁed values.</p><p style="padding-top: 3pt;padding-left: 123pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><span class="s39">• </span><span class="s40">If the selection condition </span><span class="s15">θ </span>is of the form <i>A op v</i>, where <i>op </i>is a comparison operator,</p><p style="padding-left: 139pt;text-indent: 0pt;line-height: 13pt;text-align: left;"><i>V </i>(<i>A</i>, <span class="s15">σ</span><span class="s137">θ</span>(<i>r</i>)) is estimated to be <i>V </i>(<i>A</i>, <i>r</i>) <span class="s15">∗ </span><i>s</i>, where <i>s </i>is the selectivity of the selection.</p><p class="s13" style="padding-top: 6pt;padding-left: 139pt;text-indent: -16pt;line-height: 13pt;text-align: justify;"><span class="s39">• </span><span class="s40">In all other cases of selections, we assume that the distribution of </span>A <span class="p">values is inde- pendent of the distribution of the values on which selection conditions are speci- ﬁed, and we use an approximate estimate of min(</span>V <span class="p">(</span>A<span class="p">, </span>r<span class="p">), </span>n<span class="s136">σ</span><span class="s411">θ</span><span class="s130">(</span><span class="s149">r</span><span class="s130">)</span><span class="s94">). A more accurate estimate can be derived for this case using probability theory, but the preceding approximation works fairly well.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-left: 119pt;text-indent: 17pt;line-height: 90%;text-align: left;"><span class="p">For joins, the number of distinct values of an attribute (or set of attributes) </span>A <span class="p">in the result of a join, </span>V <span class="p">(</span>A<span class="p">, </span>r <span class="s86">⋈ </span>s<span class="p">), can be estimated in these ways:</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-top: 6pt;padding-left: 107pt;text-indent: -16pt;line-height: 78%;text-align: justify;"><a name="bookmark339"><span class="s39">• </span></a><span class="s40">If all attributes in </span>A <span class="p">are from </span>r<span class="p">, </span>V <span class="p">(</span>A<span class="p">, </span>r <span class="s86">⋈ </span>s<span class="p">) is estimated as min(</span>V <span class="p">(</span>A<span class="p">, </span>r<span class="p">), </span>n<span class="s145">r </span><span class="s412">⋈ </span><span class="s169">s</span><span class="p">), and similarly if all attributes in </span>A <span class="p">are from </span>s<span class="p">, </span>V <span class="p">(</span>A<span class="p">, </span>r <span class="s86">⋈ </span>s<span class="p">) is estimated to be min(</span>V <span class="p">(</span>A<span class="p">, </span>s<span class="p">), </span>n<span class="s97">r </span><span class="s413">⋈ </span><span class="s149">s</span><span class="p">).</span><a name="bookmark359">&zwnj;</a></p><p class="s13" style="padding-left: 150pt;text-indent: -59pt;line-height: 175%;text-align: left;"><span class="s39">• </span><span class="s40">If </span>A <span class="p">contains attributes </span>A<span class="p">1 from </span>r <span class="p">and </span>A<span class="p">2 from </span>s<span class="p">, then </span>V <span class="p">(</span>A<span class="p">, </span>r <span class="s86">⋈ </span>s<span class="p">) is estimated as: min(</span>V <span class="p">(</span>A<span class="p">1, </span>r<span class="p">) </span><span class="s15">∗ </span>V <span class="p">(</span>A<span class="p">2 </span><span class="s15">− </span>A<span class="p">1, </span>s<span class="p">), </span>V <span class="p">(</span>A<span class="p">1 </span><span class="s15">− </span>A<span class="p">2, </span>r<span class="p">) </span><span class="s15">∗ </span>V <span class="p">(</span>A<span class="p">2, </span>s<span class="p">), </span>n<span class="s145">r </span><span class="s412">⋈ </span><span class="s169">s</span><span class="p">)</span></p><p style="padding-top: 2pt;padding-left: 107pt;text-indent: 0pt;text-align: justify;">Note that some attributes may be in <i>A</i>1 as well as in <i>A</i>2, and <i>A</i>1 <span class="s15">− </span><i>A</i>2 and <i>A</i>2 <span class="s15">− </span><i>A</i>1 denote, respectively, attributes in <i>A </i>that are only from <i>r </i>and attributes in <i>A </i>that are only from <i>s</i>. Again, more accurate estimates can be derived by using probability theory, but the above approximations work fairly well.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The estimates of distinct values are straightforward for projections: They are the same in <span class="s15">Π</span><i>A</i>(<i>r</i>) as in <i>r</i>. The same holds for grouping attributes of aggregation. For results of <b>sum</b>, <b>count</b>, and <b>average</b>, we can assume, for simplicity, that all aggregate values are distinct. For <b>min</b>(<i>A</i>) and <b>max</b>(<i>A</i>), the number of distinct values can be estimated as min(<i>V </i>(<i>A</i>, <i>r</i>), <i>V </i>(<i>G</i>, <i>r</i>)), where <i>G </i>denotes the grouping attributes. We omit details of estimating distinct values for other operations.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part297.htm">&lt; 上一个</a><span> | </span><a href="../database.html">内容</a><span> | </span><a href="part299.htm">下一个 &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
