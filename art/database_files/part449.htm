<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>25.2  Performance Benchmarks</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part448.htm">&lt; 上一个</a><span> | </span><a href="../database.html">内容</a><span> | </span><a href="part450.htm">下一个 &gt;</a></p><p class="s65" style="padding-top: 8pt;padding-left: 40pt;text-indent: 0pt;text-align: left;">25.2  <span style=" color: #00AEEF;">Performance Benchmarks</span></p><p style="padding-top: 12pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">As database servers become more standardized, the diﬀerentiating factor among the products of diﬀerent vendors is those products’ performance. <span class="s63">Performance benchmarks </span>are suites of tasks that are used to quantify the performance of software systems.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-top: 4pt;padding-left: 119pt;text-indent: 0pt;text-align: left;">25.2.1 Suites of Tasks</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">Since most software systems, such as databases, are complex, there is a good deal of variation in their implementation by diﬀerent vendors. As a result, there is a signiﬁcant amount of variation in their performance on diﬀerent tasks. One system may be the most eﬃcient on a particular task; another may be the most eﬃcient on a diﬀerent task. Hence, a single task is usually insuﬃcient to quantify the performance of the system. Instead, the performance of a system is measured by suites of standardized tasks, called <i>performance benchmarks</i>.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Combining the performance numbers from multiple tasks must be done with care. Suppose that we have two tasks, <i>T</i><span class="s98">1</span> and <i>T</i><span class="s98">2</span>, and that we measure the throughput of a system as the number of transactions of each type that run in a given amount of time — say, 1 second. Suppose that system A runs <i>T</i><span class="s98">1</span> at 99 transactions per second and <i>T</i><span class="s98">2</span> at 1 transaction per second. Similarly, let system B run both <i>T</i><span class="s98">1</span> and <i>T</i><span class="s98">2</span> at 50 transactions per second. Suppose also that a workload has an equal mixture of the two types of transactions.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">If we took the average of the two pairs of numbers (i.e., 99 and 1, versus 50 and 50), it might appear that the two systems have equal performance. However, it is <i>wrong </i>to</p><p style="padding-top: 1pt;padding-left: 119pt;text-indent: 0pt;line-height: 83%;text-align: justify;">take the averages in this fashion — if we ran 50 transactions of each type, system <i>A </i>would take about 50<span class="s83">.</span>5 seconds to ﬁnish, whereas system <i>B </i>would ﬁnish in just 2 seconds!</p><p style="padding-left: 137pt;text-indent: 0pt;line-height: 9pt;text-align: justify;">The example shows that a simple measure of performance is misleading if there is</p><p style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">more than one type of transaction. The right way to average out the numbers is to take the <span class="s63">time to completion </span>for the workload, rather than the average <i>throughput </i>for each transaction type. We can then compute system performance accurately in transactions</p><p style="padding-top: 2pt;padding-left: 119pt;text-indent: 0pt;line-height: 63%;text-align: justify;">per second for a speciﬁed workload. Thus, system A takes 50<span class="s83">.</span>5<span class="s15">∕</span>100, which is 0<span class="s83">.</span>505 seconds per transaction, whereas system B takes 0<span class="s83">.</span>02 seconds per transaction, on av- erage. In terms of throughput, system A runs at an average of 1<span class="s83">.</span>98 transactions per second, whereas system B runs at 50 transactions per second. Assuming that transac-</p><p style="padding-top: 1pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">tions of all the types are equally likely, the correct way to average out the throughputs on diﬀerent transaction types is to take the <span class="s63">harmonic mean </span>of the throughputs. The harmonic mean of <i>n </i>throughputs <i>t</i><span class="s130">1</span><span class="s94">, </span><i>t</i><span class="s130">2</span><span class="s94">, </span><span class="s15">… </span>, <i>t</i><span class="s97">n </span>is deﬁned as:</p><p class="s96" style="padding-top: 4pt;padding-left: 269pt;text-indent: 0pt;text-align: justify;"> &nbsp;&nbsp;&nbsp; n &nbsp; </p><p class="s15" style="padding-top: 2pt;padding-left: 271pt;text-indent: 0pt;line-height: 11pt;text-align: justify;"><span class="s461">1</span><span class="p"> </span>+ <span class="s461">1</span><span class="p"> </span>+ <span class="s86">⋯ </span>+ <span class="s461">1</span></p><p class="s109" style="padding-left: 84pt;text-indent: 0pt;line-height: 10pt;text-align: center;">t<span class="s142">1   </span>t<span class="s142">2      </span>t<span class="s144">n</span></p><p style="padding-top: 2pt;padding-left: 119pt;text-indent: 17pt;line-height: 70%;text-align: left;">For our example, the harmonic mean for the throughputs in system A is 1<span class="s83">.</span>98. For system B, it is 50. Thus, system B is approximately 25 times faster than system A on a</p><p style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">workload consisting of an equal mixture of the two example types of transactions.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 119pt;text-indent: 0pt;text-align: left;">25.2.2 Database-Application Classes</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;"><span class="s63">Online transaction processing </span>(<span class="s64">OLTP</span>) and <span class="s63">decision support</span>, including <span class="s63">online analytical processing </span>(<span class="s64">OLAP</span>), are two broad classes of applications handled by database systems. These two classes of tasks have diﬀerent requirements. High concurrency and clever</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">techniques to speed up commit processing are required for supporting a high rate of update transactions. On the other hand, good query-evaluation algorithms and query optimization are required for decision support. The architecture of some database sys- tems has been tuned to transaction processing; that of others, such as the Teradata series of parallel database systems, has been tuned to decision support. Other vendors try to strike a balance between the two tasks.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Applications usually have a mixture of transaction-processing and decision-support requirements. Hence, which database system is best for an application depends on what mix of the two requirements the application has.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Suppose that we have throughput numbers for the two classes of applications sepa- rately, and the application at hand has a mix of transactions in the two classes. We must be careful even about taking the harmonic mean of the throughput numbers because of <span class="s63">interference </span>between the transactions. For example, a long-running decision-support transaction may acquire a number of locks, which may prevent all progress of update transactions. The harmonic mean of throughputs should be used only if the transac- tions do not interfere with one another.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 88pt;text-indent: 0pt;text-align: left;">25.2.3 The TPC Benchmarks</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">The <span class="s63">Transaction Processing Performance Council </span>(<span class="s64">TPC</span>) has deﬁned a series of bench- mark standards for database systems.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The <span class="s44">TPC </span>benchmarks are deﬁned in great detail. They deﬁne the set of relations and the sizes of the tuples. They deﬁne the number of tuples in the relations not as a ﬁxed number, but rather as a multiple of the number of claimed transactions per second, to reﬂect that a larger rate of transaction execution is likely to be correlated with a larger number of accounts. The performance metric is throughput, expressed as <span class="s63">transactions per second </span>(<span class="s64">TPS</span>). When its performance is measured, the system must provide a response time within certain bounds, so that a high throughput cannot be obtained at the cost of very long response times. Further, for business applications, cost is of great importance. Hence, the <span class="s44">TPC </span>benchmark also measures performance in terms of <span class="s63">price per </span><span class="s82">TPS</span>. A large system may have a high number of transactions per second, but it may be expensive (i.e., have a high price per <span class="s44">TPS</span>). Moreover, a company cannot claim <span class="s44">TPC </span>benchmark numbers for its systems <i>without </i>an external audit that ensures that the system faithfully follows the deﬁnition of the benchmark, including full support for the <span class="s44">ACID </span>properties of transactions.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The ﬁrst in the series was the <span class="s64">TPC-A </span><span class="s84">benchmark</span>, which was deﬁned in 1989. This benchmark simulates a typical bank application by a single type of transaction that models cash withdrawal and deposit at a bank teller. The transaction updates several relations— such as the bank balance, the teller’s balance, and the customer’s balance— and adds a record to an audit-trail relation. The benchmark also incorporates communi- cation with terminals, to model the end-to-end performance of the system realistically. The <span class="s64">TPC-B </span><span class="s84">benchmark </span>was designed to test the core performance of the database sys- tem, along with the operating system on which the system runs. It removes the parts</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">of the <span class="s44">TPC-A </span>benchmark that deal with users, communication, and terminals, to focus on the backend database server. Neither <span class="s44">TPC-A </span>nor <span class="s44">TPC-B </span>is in use today.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">The <span class="s64">TPC-C </span><span class="s84">benchmark </span>was designed to model a more complex system than the <span class="s44">TPC-A </span>benchmark. The <span class="s44">TPC-C </span>benchmark concentrates on the main activities in an order-entry environment, such as entering and delivering orders, recording payments, checking status of orders, and monitoring levels of stock. The <span class="s44">TPC-C </span>benchmark is still widely used for benchmarking online transaction processing (<span class="s44">OLTP</span>) systems.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: right;">The more recent <span class="s64">TPC-E </span><span class="s84">benchmark </span>is also aimed at <span class="s44">OLTP </span>systems but is based on a model of a brokerage ﬁrm, with customers who interact with the ﬁrm and generate transactions. The ﬁrm in turn interacts with ﬁnancial markets to execute transactions.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">The <span class="s64">TPC-D </span><span class="s84">benchmark </span>was designed to test the performance of database systems on decision-support queries. Decision-support systems are becoming increasingly im- portant today. The <span class="s44">TPC-A</span>, <span class="s44">TPC-B</span>, and <span class="s44">TPC-C </span>benchmarks measure performance on transaction-processing workloads and should not be used as a measure of performance on decision-support queries. The <span class="s44">D </span>in <span class="s44">TPC-D </span>stands for <b>decision support</b>. The <span class="s44">TPC-D </span>benchmark schema models a sales/distribution application, with parts, suppliers, cus- tomers, and orders, along with some auxiliary information. The sizes of the relations are deﬁned as a ratio, and database size is the total size of all the relations, expressed in giga- bytes. <span class="s44">TPC-D </span>at scale factor 1 represents the <span class="s44">TPC-D </span>benchmark on a 1-gigabyte database, while scale factor 10 represents a 10-gigabyte database. The benchmark workload con- sists of a set of 17 <span class="s44">SQL </span>queries modeling common tasks executed on decision-support systems. Some of the queries make use of complex <span class="s44">SQL </span>features, such as aggregation and nested queries.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">The benchmark’s users soon realized that the various <span class="s44">TPC-D </span>queries could be sig- niﬁcantly speeded up by using materialized views and other redundant information. There are applications, such as periodic reporting tasks, where the queries are known in advance, and materialized views can be selected carefully to speed up the queries. It is necessary, however, to account for the overhead of maintaining materialized views.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: right;">The <span class="s64">TPC-H </span><span class="s84">benchmark </span>(where ˝ represents ad hoc) is a reﬁnement of the <span class="s44">TPC-D </span>benchmark. The schema is the same, but there are 22 queries, of which 16 are from <span class="s44">TPC-D</span>. In addition, there are two updates, a set of inserts, and a set of deletes. <span class="s44">TPC- H </span>prohibits materialized views and other redundant information and permits indices only on primary and foreign keys. This benchmark models ad hoc querying where the queries are not known beforehand, so it is not possible to create appropriate material- ized views ahead of time. A variant, <span class="s44">TPC-R </span>(where <span class="s44">R </span>stands for “reporting”), which is no longer in use, allowed the use of materialized views and other redundant information. The <span class="s64">TPC</span><span class="s84">-</span><span class="s64">DS </span><span class="s84">benchmark </span>is a follow-up to the <span class="s44">TPC-H </span>benchmark and models the decision-support functions of a retail product supplier, including information about customers, orders, and products, and with multiple sales channels such as retail stores and online sales. It has two subparts of the schema, corresponding to ad hoc querying and reporting, similar to <span class="s44">TPC-H </span>and <span class="s44">TPC-R</span>. There is a query workload, as well as a data</p><p style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">maintenance workload.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s42" style="padding-top: 4pt;padding-left: 88pt;text-indent: 17pt;text-align: justify;"><a name="bookmark554">TPC-H </a><span class="s43">and </span>TPC-DS <span class="s43">measure performance in this way: The </span><span class="s63">power test </span><span class="p">runs the queries and updates one at a time sequentially, and 3600 seconds divided by the geomet- ric mean of the execution times of the queries (in seconds) gives a measure of queries per hour. The </span><span class="s63">throughput test </span><span class="p">runs multiple streams in parallel, with each stream exe- cuting all 22 queries. There is also a parallel update stream. Here the total time for the entire run is used to compute the number of queries per hour.</span><a name="bookmark584">&zwnj;</a></p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The <span class="s63">composite query per hour metric</span>, which is the overall metric, is then obtained as the square root of the product of the power and throughput metrics. A <span class="s63">composite price/performance metric </span>is deﬁned by dividing the system price by the composite met- ric.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">There are several other <span class="s44">TPC </span>benchmarks, such as a data integration benchmark (<span class="s44">TPC</span>-<span class="s44">DI</span>), benchmarks for big data systems based on Hadoop/Spark (<span class="s44">TPCx-HS</span>), and for back-end processing of internet-of-things data (<span class="s44">TPCx-IoT</span>).</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part448.htm">&lt; 上一个</a><span> | </span><a href="../database.html">内容</a><span> | </span><a href="part450.htm">下一个 &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
