<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>44.1 Disk Failure Modes</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part493.htm">&lt; 上一个</a><span> | </span><a href="../ostep.html">内容</a><span> | </span><a href="part495.htm">下一个 &gt;</a></p><p class="s40" style="padding-top: 2pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">44.1 Disk Failure Modes</p><p style="padding-top: 7pt;padding-left: 41pt;text-indent: 11pt;line-height: 89%;text-align: justify;">As you learned in the chapter about RAID, disks are not perfect, and can fail (on occasion). In early RAID systems, the model of failure was quite simple: either the entire disk is working, or it fails completely, and the detection of such a failure is straightforward. This <b>fail-stop </b>model of disk failure makes building RAID relatively simple [S90].</p><p style="padding-left: 41pt;text-indent: 11pt;line-height: 89%;text-align: left;">What you didn’t learn is about all of the other types of failure modes modern disks exhibit. Specifically, as Bairavasundaram et al. studied in great detail [B+07, B+08], modern disks will occasionally seem to be mostly working but have trouble successfully accessing one or more blocks. Specifically, two types of single-block failures are common and worthy of consideration: <b>latent-sector errors </b>(<b>LSEs</b>) and <b>block corruption</b>. We’ll now discuss each in more detail.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 21pt;text-indent: 0pt;text-align: center;">527</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:151.348pt" cellspacing="0"><tr style="height:9pt"><td style="width:52pt;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#221E1F"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:35pt;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#221E1F"><p class="s108" style="padding-right: 5pt;text-indent: 0pt;line-height: 8pt;text-align: right;">Cheap</p></td><td style="width:34pt;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#221E1F"><p class="s108" style="padding-left: 5pt;padding-right: 5pt;text-indent: 0pt;line-height: 8pt;text-align: center;">Costly</p></td></tr><tr style="height:10pt"><td style="width:52pt;border-top-style:solid;border-top-width:1pt;border-top-color:#221E1F"><p class="s108" style="padding-left: 5pt;text-indent: 0pt;line-height: 9pt;text-align: left;">LSEs</p></td><td style="width:35pt;border-top-style:solid;border-top-width:1pt;border-top-color:#221E1F"><p class="s108" style="padding-right: 5pt;text-indent: 0pt;line-height: 9pt;text-align: right;">9.40%</p></td><td style="width:34pt;border-top-style:solid;border-top-width:1pt;border-top-color:#221E1F"><p class="s108" style="padding-left: 5pt;padding-right: 3pt;text-indent: 0pt;line-height: 9pt;text-align: center;">1.40%</p></td></tr><tr style="height:9pt"><td style="width:52pt"><p class="s108" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Corruption</p></td><td style="width:35pt"><p class="s108" style="padding-right: 5pt;text-indent: 0pt;line-height: 8pt;text-align: right;">0.50%</p></td><td style="width:34pt"><p class="s108" style="padding-left: 5pt;padding-right: 3pt;text-indent: 0pt;line-height: 8pt;text-align: center;">0.05%</p></td></tr></table><p style="padding-top: 4pt;padding-left: 107pt;text-indent: 0pt;text-align: left;">Table 44.1: <b>Frequency of LSEs and Block Corruption</b></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 5pt;padding-left: 68pt;text-indent: 12pt;line-height: 89%;text-align: justify;">LSEs arise when a disk sector (or group of sectors) has been damaged in some way. For example, if the disk head touches the surface for some reason (a <b>head crash</b>, something which shouldn’t happen during nor- mal operation), it may damage the surface, making the bits unreadable. Cosmic rays can also flip bits, leading to incorrect contents. Fortunately, in-disk <b>error correcting codes </b>(<b>ECC</b>) are used by the drive to determine whether the on-disk bits in a block are good, and in some cases, to fix them; if they are not good, and the drive does not have enough informa- tion to fix the error, the disk will return an error when a request is issued to read them.</p><p style="padding-left: 68pt;text-indent: 12pt;line-height: 89%;text-align: justify;">There are also cases where a disk block becomes <b>corrupt </b>in a way not detectable by the disk itself. For example, buggy disk firmware may write a block to the wrong location; in such a case, the disk ECC indicates the block contents are fine, but from the client’s perspective the wrong block is returned when subsequently accessed. Similarly, a block may get cor- rupted when it is transferred from the host to the disk across a faulty bus; the resulting corrupt data is stored by the disk, but it is not what the client desires. These types of faults are particularly insidious because the are <b>silent faults</b>; the disk gives no indication of the problem when returning the faulty data.</p><p style="padding-left: 68pt;text-indent: 12pt;line-height: 89%;text-align: justify;">Prabhakaran et al. describes this more modern view of disk failure as the <b>fail-partial </b>disk failure model [P+05]. In this view, disks can still fail in their entirety (as was the case in the traditional fail-stop model); how- ever, disks can also seemingly be working and have one or more blocks become inaccessible (i.e., LSEs) or hold the wrong contents (i.e., corrup- tion). Thus, when accessing a seemingly-working disk, once in a while it may either return an error when trying to read or write a given block (a non-silent partial fault), and once in a while it may simply return the wrong data (a silent partial fault).</p><p style="padding-left: 68pt;text-indent: 12pt;line-height: 89%;text-align: justify;">Both of these types of faults are somewhat rare, but just how rare? Ta- ble <span style=" color: #00AEEF;">44.1 </span>summarizes some of the findings from the two Bairavasundaram studies [B+07,B+08].</p><p style="padding-left: 68pt;text-indent: 12pt;line-height: 89%;text-align: justify;">The table shows the percent of drives that exhibited at least one LSE or block corruption over the course of the study (about 3 years, over</p><p style="padding-left: 68pt;text-indent: 0pt;line-height: 89%;text-align: justify;">1.5 million disk drives). The table further sub-divides the results into “cheap” drives (usually SATA drives) and “costly” drives (usually SCSI or FibreChannel). As you can see from the table, while buying better drives reduces the frequency of both types of problem (by about an or- der of magnitude), they still happen often enough that you need to think carefully about them.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 2pt;padding-left: 41pt;text-indent: 0pt;text-align: left;">Some additional findings about LSEs are:</p><p class="s4" style="padding-top: 7pt;padding-left: 64pt;text-indent: -9pt;line-height: 89%;text-align: left;">• <span class="p">Costly drives with more than one LSE are as likely to develop ad- ditional errors as cheaper drives</span></p><p class="s4" style="padding-left: 54pt;text-indent: 0pt;line-height: 10pt;text-align: left;">• <span class="p">For most drives, annual error rate increases in year two</span></p><p class="s4" style="padding-left: 54pt;text-indent: 0pt;line-height: 10pt;text-align: left;">• <span class="p">LSEs increase with disk size</span></p><p class="s4" style="padding-left: 54pt;text-indent: 0pt;line-height: 10pt;text-align: left;">• <span class="p">Most disks with LSEs have less than 50</span></p><p class="s4" style="padding-left: 54pt;text-indent: 0pt;line-height: 10pt;text-align: left;">• <span class="p">Disks with LSEs are more likely to develop additional LSEs</span></p><p class="s4" style="padding-left: 54pt;text-indent: 0pt;line-height: 10pt;text-align: left;">• <span class="p">There exists a significant amount of spatial and temporal locality</span></p><p class="s4" style="padding-left: 54pt;text-indent: 0pt;line-height: 11pt;text-align: left;">• <span class="p">Disk scrubbing is useful (most LSEs were found this way)</span></p><p style="padding-top: 6pt;padding-left: 41pt;text-indent: 0pt;text-align: left;">Some findings about corruption:</p><p class="s4" style="padding-top: 7pt;padding-left: 64pt;text-indent: -9pt;line-height: 89%;text-align: left;">• <span class="p">Chance of corruption varies greatly across different drive models within the same drive class</span></p><p class="s4" style="padding-left: 54pt;text-indent: 0pt;line-height: 10pt;text-align: left;">• <span class="p">Age affects are different across models</span></p><p class="s4" style="padding-left: 54pt;text-indent: 0pt;line-height: 10pt;text-align: left;">• <span class="p">Workload and disk size have little impact on corruption</span></p><p class="s4" style="padding-left: 54pt;text-indent: 0pt;line-height: 10pt;text-align: left;">• <span class="p">Most disks with corruption only have a few corruptions</span></p><p class="s4" style="padding-left: 54pt;text-indent: 0pt;line-height: 10pt;text-align: left;">• <span class="p">Corruption is not independent with a disk or across disks in RAID</span></p><p class="s4" style="padding-left: 54pt;text-indent: 0pt;line-height: 10pt;text-align: left;">• <span class="p">There exists spatial locality, and some temporal locality</span></p><p class="s4" style="padding-left: 54pt;text-indent: 0pt;line-height: 11pt;text-align: left;">• <span class="p">There is a weak correlation with LSEs</span></p><p style="padding-top: 7pt;padding-left: 41pt;text-indent: 11pt;line-height: 89%;text-align: justify;">To learn more about these failures, you should likely read the original papers [B+07,B+08]. But hopefully the main point should be clear: if you really wish to build a reliable storage system, you must include machin- ery to detect and recovery from both LSEs and block corruption.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part493.htm">&lt; 上一个</a><span> | </span><a href="../ostep.html">内容</a><span> | </span><a href="part495.htm">下一个 &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
