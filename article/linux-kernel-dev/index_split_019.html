<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>Linux Kernel Development, Third Edition</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
<div id="filepos613760" style="height:0pt"></div><h2 class="calibre_4" id="calibre_pb_53"><span class="bold">10. Kernel Synchronization Methods</span></h2><div class="calibre_5"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos613936"> </div>
<p class="calibre_2">The previous chapter discussed the sources of and solutions to race conditions. Thankfully, the Linux kernel provides a family of synchronization methods. The Linux kernel’s synchronization methods enable developers to write efficient and race-free code. This chapter discusses these methods and their interfaces, behavior, and use.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos614376"> </div>
<h3 class="calibre_21"><span class="bold">Atomic Operations</span></h3><div class="calibre_22"> </div>
<p class="calibre_2">We start our discussion of synchronization methods with atomic operations because they are the foundation on which other synchronization methods are built. <em class="calibre4">Atomic operations</em> provide instructions that execute <em class="calibre4">atomically</em>—without interruption. Just as the atom was originally thought to be an indivisible particle, atomic operators are indivisible instructions. For example, as discussed in the previous chapter, an atomic increment can read and increment a variable by one in a single indivisible and uninterruptible step. Recall the simple race in incrementing an integer that we discussed in the previous chapter:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00112.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2"><a id="filepos615272"></a>With atomic operators, this race does not—indeed, cannot—occur. Instead, the outcome is always one of the following:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00113.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">Or</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00114.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">The ultimate value, always nine, is correct. It is never possible for the two atomic operations to occur on the same variable concurrently. Therefore, it is not possible for the increments to race.</p><div class="calibre_3"> </div>
<p class="calibre_2">The kernel provides two sets of interfaces for atomic operations—one that operates on integers and another that operates on individual bits. These interfaces are implemented on every architecture that Linux supports. Most architectures contain instructions that provide atomic versions of simple arithmetic operations. Other architectures, lacking direct atomic operations, provide an operation to lock the memory bus for a single operation, thus guaranteeing that another memory-affecting operation cannot occur simultaneously.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos616513"> </div>
<h4 class="calibre_27"><span class="calibre3">Atomic Integer Operations</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">The atomic integer methods operate on a special data type, <code class="calibre6"><span class="calibre7">atomic_t</span></code>. This special type is used, as opposed to having the functions work directly on the C <code class="calibre6"><span class="calibre7">int</span></code> type, for several reasons. First, having the atomic functions accept only the <code class="calibre6"><span class="calibre7">atomic_t</span></code> type ensures that the atomic operations are used only with these special types. Likewise, it also ensures that the data types are not passed to any nonatomic functions. Indeed, what good would atomic operations be if they were not consistently used on the data? Next, the use of <code class="calibre6"><span class="calibre7">atomic_t</span></code> ensures the compiler does not (erroneously but cleverly) optimize access to the value—it is important the atomic operations receive the correct memory address and not an alias. Finally, use of <code class="calibre6"><span class="calibre7">atomic_t</span></code> can hide any architecture-specific differences in its implementation. The <code class="calibre6"><span class="calibre7">atomic_t</span></code> type is defined in <code class="calibre6"><span class="calibre7">&lt;linux/types.h&gt;</span></code>:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">typedef struct {<br class="calibre1"/>        volatile int counter;<br class="calibre1"/>} atomic_t;</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">Despite being an integer, and thus 32 bits on all the machines that Linux supports, developers and their code once had to assume that an <code class="calibre6"><span class="calibre7">atomic_t</span></code> was no larger than 24 bits in size. The SPARC port in Linux has an odd implementation of atomic operations: A lock was embedded in the lower 8 bits of the 32-bit <code class="calibre6"><span class="calibre7">int</span></code> (it looked like <a href="#filepos619055">Figure 10.1</a>). The lock was used to protect concurrent access to the atomic type because the SPARC architecture <a id="filepos618546"></a>lacks appropriate support at the instruction level. Consequently, only 24 usable bits were available on SPARC machines. Although code that assumed that the full 32-bit range existed would work on other machines; it would have failed in strange and subtle ways on SPARC machines—and that is just rude. Recently, clever hacks have allowed SPARC to provide a fully usable 32-bit <code class="calibre6"><span class="calibre7">atomic_t</span></code>, and this limitation is no more.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos619055"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Figure 10.1. Old layout of the 32-bit <code class="calibre6"><span class="calibre15">atomic_t</span></code> on SPARC.</span></span></p><div class="calibre_24"> </div>
<p class="calibre_23"><img alt="image" src="images/00115.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">The declarations needed to use the atomic integer operations are in <code class="calibre6"><span class="calibre7">&lt;asm/atomic.h&gt;</span></code>. Some architectures provide additional methods that are unique to that architecture, but all architectures provide at least a minimum set of operations that are used throughout the kernel. When you write kernel code, you can ensure that these operations are correctly implemented on all architectures.</p><div class="calibre_3"> </div>
<p class="calibre_2">Defining an <code class="calibre6"><span class="calibre7">atomic_t</span></code> is done in the usual manner. Optionally, you can set it to an initial value:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00116.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">Operations are all simple:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00117.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">If you ever need to convert an <code class="calibre6"><span class="calibre7">atomic_t</span></code> to an <code class="calibre6"><span class="calibre7">int</span></code>, use <code class="calibre6"><span class="calibre7">atomic_read()</span></code>:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">printk("%d\n", atomic_read(&amp;v));   /* will print "7" */</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">A common use of the atomic integer operations is to implement counters. Protecting a sole counter with a complex locking scheme is overkill, so instead developers use <code class="calibre6"><span class="calibre7">atomic_inc()</span></code> and <code class="calibre6"><span class="calibre7">atomic_dec()</span></code>, which are much lighter in weight.</p><div class="calibre_3"> </div>
<p class="calibre_2">Another use of the atomic integer operators is atomically performing an operation and testing the result. A common example is the atomic decrement and test:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">int atomic_dec_and_test(atomic_t *v)</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">This function decrements by one the given atomic value. If the result is zero, it returns true; otherwise, it returns false. A full listing of the standard atomic integer operations (those found on all architectures) is in <a href="#filepos621902">Table 10.1</a>. All the operations implemented on a specific architecture can be found in <code class="calibre6"><span class="calibre7">&lt;asm/atomic.h&gt;</span></code>.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos621902"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Table 10.1. Atomic Integer Methods</span></span></p><div class="calibre_24"> </div>
<p class="calibre_23"><img alt="image" src="images/00118.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2"><a id="filepos622186"></a>The atomic operations are typically implemented as inline functions with inline assembly. In the case where a specific function is inherently atomic, the given function is usually just a macro. For example, on most architectures, a word-sized read is always atomic. That is, a read of a single word cannot complete in the middle of a write to that word. The read always returns the word in a consistent state, either before or after the write completes, but never in the middle. Consequently, <code class="calibre6"><span class="calibre7">atomic_read()</span></code> is usually just a macro returning the integer value of the <code class="calibre6"><span class="calibre7">atomic_t</span></code>:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00119.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<div border="1" class="calibre_26"><blockquote class="calibre10"><div class="calibre11">
<p class="calibre_2"></p><div class="calibre_3"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Atomicity Versus Ordering</span></span></p><div class="calibre_24"> </div>
<p class="calibre_2">The preceding discussion on atomic reading begs a discussion on the differences between atomicity and ordering. As discussed, a word-sized read always occurs atomically. It never interleaves with a write to the same word; the read always returns the word in a consistent state—perhaps before the write completes, perhaps after, but never during. For example, if an integer is initially 42 and then set to 365, a read on the integer always returns 42 or 365 and never some commingling of the two values. We call this <em class="calibre4">atomicity</em>.</p><div class="calibre_3"> </div>
<p class="calibre_2">Your code, however, might have more stringent requirements than this: Perhaps you require that the read always occurs <em class="calibre4">before</em> the pending write. This type of requirement is <em class="calibre4">not</em> atomicity, but <em class="calibre4">ordering</em>. Atomicity ensures that instructions occur without interruption and that they complete either in their entirety or not at all. Ordering, on the other hand, ensures that the desired, relative ordering of two or more instructions—even if they are to occur in separate threads of execution or even separate processors—is preserved.</p><div class="calibre_3"> </div>
<p class="calibre_2">The atomic operations discussed in this section guarantee only atomicity. Ordering is enforced via <em class="calibre4">barrier operations</em>, which we discuss later in this chapter.</p><div class="calibre_3"> </div>
</div></blockquote></div><div class="calibre_7"> </div>
<p class="calibre_2">In your code, it is usually preferred to choose atomic operations over more complicated locking mechanisms. On most architectures, one or two atomic operations incur less overhead and less cache-line thrashing than a more complicated synchronization method. As with any performance-sensitive code, however, testing multiple approaches is always smart.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos625095"> </div>
<h4 class="calibre_27"><span class="calibre3">64-Bit Atomic Operations</span></h4><div class="calibre_24"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos625221"> </div>
<p class="calibre_2">With the rising prevalence of 64-bit architectures, it is no surprise that the Linux kernel developers augmented the 32-bit <code class="calibre6"><span class="calibre7">atomic_t</span></code> type with a 64-bit variant, <code class="calibre6"><span class="calibre7">atomic64_t</span></code>. For portability, the size of <code class="calibre6"><span class="calibre7">atomic_t</span></code> cannot change between architectures, so <code class="calibre6"><span class="calibre7">atomic_t</span></code> is 32-bit even on 64-bit architectures. Instead, the <code class="calibre6"><span class="calibre7">atomic64_t</span></code> type provides a 64-bit atomic integer that functions otherwise identical to its 32-bit brother. Usage is exactly the same, except that the usable range of the integer is 64, rather than 32, bits. Nearly all the classic 32-bit atomic operations are implemented in 64-bit variants; they are prefixed with <em class="calibre4">atomic64</em> in lieu of <em class="calibre4">atomic</em>. <a href="#filepos626733">Table 10.2</a> is a full listing of the standard operations; some architectures implement more, but they are not portable. As with <code class="calibre6"><span class="calibre7">atomic_t</span></code>, the <code class="calibre6"><span class="calibre7">atomic64_t</span></code> type is just a simple wrapper around an integer, this type a <code class="calibre6"><span class="calibre7">long</span></code>:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">typedef struct {<br class="calibre1"/>        volatile long counter;<br class="calibre1"/>} atomic64_t;</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos626733"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Table 10.2. Atomic Integer Methods</span></span></p><div class="calibre_24"> </div>
<p class="calibre_23"><img alt="image" src="images/00120.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2"><a id="filepos627017"></a>All 64-bit architectures provide <code class="calibre6"><span class="calibre7">atomic64_t</span></code> and a family of arithmetic functions to operate on it. Most 32-bit architectures do not, however, support <code class="calibre6"><span class="calibre7">atomic64_t</span></code>—x86-32 is a notable exception. For portability between all Linux’s supported architectures, developers should use the 32-bit <code class="calibre6"><span class="calibre7">atomic_t</span></code> type. The 64-bit <code class="calibre6"><span class="calibre7">atomic64_t</span></code> is reserved for code that is both architecture-specific and that requires 64-bits.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos627625"> </div>
<h4 class="calibre_27"><span class="calibre3">Atomic Bitwise Operations</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">In addition to atomic integer operations, the kernel also provides a family of functions that operate at the bit level. Not surprisingly, they are architecture-specific and defined in <code class="calibre6"><span class="calibre7">&lt;asm/bitops.h&gt;</span></code>.</p><div class="calibre_3"> </div>
<p class="calibre_2">What might be surprising is that the bitwise functions operate on generic memory addresses. The arguments are a pointer and a bit number. Bit zero is the least significant bit of the given address. On 32-bit machines, bit 31 is the most significant bit, and bit 32 is the least significant bit of the following word. There are no limitations on the bit number supplied; although, most uses of the functions provide a word and, consequently, a bit number between 0 and 31 on 32-bit machines and 0 and 63 on 64-bit machines.</p><div class="calibre_3"> </div>
<p class="calibre_2">Because the functions operate on a generic pointer, there is no equivalent of the atomic integer’s <code class="calibre6"><span class="calibre7">atomic_t</span></code> type. Instead, you can work with a pointer to whatever data you want. Consider an example:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00121.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">A listing of the standard atomic bit operations is in <a href="#filepos629137">Table 10.3</a>.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos629137"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Table 10.3. Atomic Bitwise Methods</span></span></p><div class="calibre_24"> </div>
<p class="calibre_23"><img alt="image" src="images/00122.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">Conveniently, nonatomic versions of all the bitwise functions are also provided. They behave identically to their atomic siblings, except they do not guarantee atomicity, and their names are prefixed with double underscores. For example, the nonatomic form of <code class="calibre6"><span class="calibre7">test_bit()</span></code> is <code class="calibre6"><span class="calibre7">__test_bit()</span></code>. If you do not require atomicity (say, for example, because a lock already protects your data), these variants of the bitwise functions might be faster.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos629981"> </div>
<div border="1" class="calibre_26"><blockquote class="calibre10"><div class="calibre11">
<p class="calibre_2"></p><div class="calibre_3"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">What the Heck Is a Nonatomic Bit Operation?</span></span></p><div class="calibre_24"> </div>
<p class="calibre_2">On first glance, the concept of a nonatomic bit operation might not make any sense. Only a single bit is involved; thus, there is no possibility of inconsistency. If one of the operations succeeds, what else could matter? Sure, <em class="calibre4">ordering</em> might be important, but we are talking about <em class="calibre4">atomicity</em> here. At the end of the day, if the bit has a value provided by any of the instructions, we should be good to go, right?</p><div class="calibre_3"> </div>
<p class="calibre_2">Let’s jump back to just what atomicity means. Atomicity requires that either instructions succeed in their entirety, uninterrupted, or instructions fail to execute at all. Therefore, if you issue two atomic bit operations, you expect two operations to succeed. After both operations complete, the bit needs to have the value as specified by the second operation. Moreover, however, at some point in time prior to the final operation, the bit needs to hold the value as specified by the first operation. Put more generally, real atomicity requires that all intermediate states be correctly realized.</p><div class="calibre_3"> </div>
<p class="calibre_2">For example, assume you issue two atomic bit operations: Initially set the bit and then clear the bit. Without atomic operations, the bit might end up cleared, but it might <em class="calibre4">never</em> have been set. The set operation could occur simultaneously with the clear operation and fail. The clear operation would succeed, and the bit would emerge cleared as intended. With atomic operations, however, the set would actually occur—there would be a moment in time when a read would show the bit as set—and then the clear would execute and the bit would be zero.</p><div class="calibre_3"> </div>
<p class="calibre_2">This behavior can be important, especially when ordering comes into play or when dealing with hardware registers.</p><div class="calibre_3"> </div>
</div></blockquote></div><div class="calibre_7"> </div>
<p class="calibre_2">The kernel also provides routines to find the first set (or unset) bit starting at a given address:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">int find_first_bit(unsigned long *addr, unsigned int size)<br class="calibre1"/>int find_first_zero_bit(unsigned long *addr, unsigned int size)</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">Both functions take a pointer as their first argument and the number of bits in total to search as their second. They return the bit number of the first set or first unset bit, respectively. If your code is searching only a word, the routines <code class="calibre6"><span class="calibre7">__ffs()</span></code> and <code class="calibre6"><span class="calibre7">ffz()</span></code>, which take a single parameter of the word in which to search, are optimal.</p><div class="calibre_3"> </div>
<p class="calibre_2">Unlike the atomic integer operations, code typically has no choice whether to use the bitwise operations—they are the only portable way to set a specific bit. The only question is whether to use the atomic or nonatomic variants. If your code is inherently safe from race conditions, you can use the nonatomic versions, which might be faster depending on the architecture.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos633527"> </div>
<h3 class="calibre_21"><span class="bold">Spin Locks</span></h3><div class="calibre_22"> </div>
<p class="calibre_2">Although it would be nice if every critical region consisted of code that did nothing more complicated than incrementing a variable, reality is much crueler. In real life, critical regions can span multiple functions. For example, it is often the case that data must be removed from one structure, formatted and parsed, and added to another structure. This <a id="filepos633997"></a>entire operation must occur atomically; it must not be possible for other code to read from or write to either structure before the update is completed. Because simple atomic operations are clearly incapable of providing the needed protection in such a complex scenario, a more general method of synchronization is needed: <em class="calibre4">locks</em>.</p><div class="calibre_3"> </div>
<p class="calibre_2">The most common lock in the Linux kernel is the <em class="calibre4">spin lock</em>. A spin lock is a lock that can be held by at most one thread of execution. If a thread of execution attempts to acquire a spin lock while it is already held, which is called <em class="calibre4">contended</em>, the thread busy loops—<em class="calibre4">spins</em>—waiting for the lock to become available. If the lock is not contended, the thread can immediately acquire the lock and continue. The spinning prevents more than one thread of execution from entering the critical region at any one time. The same lock can be used in multiple locations, so all access to a given data structure, for example, can be protected and synchronized.</p><div class="calibre_3"> </div>
<p class="calibre_2">Going back to the door and key analogy from the last chapter, spin locks are akin to sitting outside the door, waiting for the fellow inside to come out and hand you the key. If you reach the door and no one is inside, you can grab the key and enter the room. If you reach the door and someone is currently inside, you must wait outside for the key, effectively checking for its presence repeatedly. When the room is vacated, you can grab the key and go inside. Thanks to the key (read: spin lock), only one person (read: thread of execution) is allowed inside the room (read: critical region) at the same time.</p><div class="calibre_3"> </div>
<p class="calibre_2">The fact that a contended spin lock causes threads to spin (essentially wasting processor time) while waiting for the lock to become available is salient. This behavior is the point of the spin lock. It is not wise to hold a spin lock for a long time. This is the nature of the spin lock: a lightweight single-holder lock that should be held for short durations. An alternative behavior when the lock is contended is to put the current thread to sleep and wake it up when it becomes available. Then the processor can go off and execute other code. This incurs a bit of overhead—most notably the two context switches required to switch out of and back into the blocking thread, which is certainly a lot more code than the handful of lines used to implement a spin lock. Therefore, it is wise to hold spin locks for less than the duration of two context switches. Because most of us have better things to do than measure context switches, just try to hold the lock for as little time as possible<sup class="calibre8"><a id="filepos636788" href="#filepos637038">1</a></sup> Later in this chapter we discuss <em class="calibre4">semaphores</em>, which provide a lock that makes the waiting thread sleep, rather than spin, when contended.</p><div class="calibre_3"> </div>
<p class="calibre_2"><sup class="calibre8"><a id="filepos637038" href="#filepos636788">1</a></sup>
<em class="calibre4">This is especially important now that the kernel is preemptive. The duration that locks are held is equivalent to the scheduling latency of the system.</em></p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos637302"> </div>
<h4 class="calibre_27"><span class="calibre3">Spin Lock Methods</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">Spin locks are architecture-dependent and implemented in assembly. The architecture-dependent code is defined in <code class="calibre6"><span class="calibre7">&lt;asm/spinlock.h&gt;</span></code>. The actual usable interfaces are defined in <code class="calibre6"><span class="calibre7">&lt;linux/spinlock.h&gt;</span></code>. The basic use of a spin lock is</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">DEFINE_SPINLOCK(mr_lock);<br class="calibre1"/><br class="calibre1"/>spin_lock(&amp;mr_lock);<br class="calibre1"/>/* critical region ... */<br class="calibre1"/>spin_unlock(&amp;mr_lock);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2"><a id="filepos638003"></a>The lock can be held simultaneously by at most only one thread of execution. Consequently, only one thread is allowed in the critical region at a time. This provides the needed protection from concurrency on multiprocessing machines. On uniprocessor machines, the locks compile away and do not exist; they simply act as markers to disable and enable kernel preemption. If kernel preempt is turned off, the locks compile away entirely.</p><div class="calibre_3"> </div>
<div border="1" class="calibre_26"><blockquote class="calibre10"><div class="calibre11">
<p class="calibre_2"></p><div class="calibre_3"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Warning: Spin Locks Are Not Recursive!</span></span></p><div class="calibre_24"> </div>
<p class="calibre_2">Unlike spin lock implementations in other operating systems and threading libraries, the Linux kernel’s spin locks are not recursive. This means that if you attempt to acquire a lock you already hold, you will spin, waiting for yourself to release the lock. But because you are busy spinning, you will never release the lock and you will deadlock. Be careful!</p><div class="calibre_3"> </div>
</div></blockquote></div><div class="calibre_7"> </div>
<p class="calibre_2">Spin locks can be used in interrupt handlers, whereas semaphores cannot be used because they sleep. If a lock is used in an interrupt handler, you must also disable local interrupts (interrupt requests on the current processor) before obtaining the lock. Otherwise, it is possible for an interrupt handler to interrupt kernel code while the lock is held and attempt to reacquire the lock. The interrupt handler spins, waiting for the lock to become available. The lock holder, however, does not run until the interrupt handler completes. This is an example of the double-acquire deadlock discussed in the previous chapter. Note that you need to disable interrupts only on the <em class="calibre4">current</em> processor. If an interrupt occurs on a different processor, and it spins on the same lock, it does not prevent the lock holder (which is on a different processor) from eventually releasing the lock.</p><div class="calibre_3"> </div>
<p class="calibre_2">The kernel provides an interface that conveniently disables interrupts and acquires the lock. Usage is</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">DEFINE_SPINLOCK(mr_lock);<br class="calibre1"/>unsigned long flags;<br class="calibre1"/><br class="calibre1"/>spin_lock_irqsave(&amp;mr_lock, flags);<br class="calibre1"/>/* critical region ... */<br class="calibre1"/>spin_unlock_irqrestore(&amp;mr_lock, flags);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">The routine <code class="calibre6"><span class="calibre7">spin_lock_irqsave()</span></code>saves the current state of interrupts, disables them locally, and then obtains the given lock. Conversely, <code class="calibre6"><span class="calibre7">spin_unlock_irqrestore()</span></code>unlocks the given lock and returns interrupts to their previous state. This way, if interrupts were initially disabled, your code would not erroneously enable them, but instead keep them disabled. Note that the <code class="calibre6"><span class="calibre7">flags</span></code> variable is seemingly passed by value. This is because the lock routines are implemented partially as macros.</p><div class="calibre_3"> </div>
<p class="calibre_2">On uniprocessor systems, the previous example must still disable interrupts to prevent an interrupt handler from accessing the shared data, but the lock mechanism is compiled away. The lock and unlock also disable and enable kernel preemption, respectively.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos641540"> </div>
<div border="1" class="calibre_26"><blockquote class="calibre10"><div class="calibre11">
<p class="calibre_2"></p><div class="calibre_3"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">What Do I Lock?</span></span></p><div class="calibre_24"> </div>
<p class="calibre_2">It is important that each lock is clearly associated with what it is locking. More important, you should protect <em class="calibre4">data</em> and not <em class="calibre4">code</em>. Despite the examples in this chapter explaining the importance of protecting the critical sections, it is the actual data inside that needs protection and not the code.</p><div class="calibre_3"> </div>
<p class="calibre_2">Big Fat Rule: Locks that simply wrap code regions are hard to understand and prone to race conditions. Lock data, not code.</p><div class="calibre_3"> </div>
<p class="calibre_2">Rather than lock code, always associate your shared data with a specific lock. For example, “<em class="calibre4">the</em>
<code class="calibre6"><span class="calibre7">struct foo</span></code>
<em class="calibre4">is locked by</em>
<code class="calibre6"><span class="calibre7">foo_lock</span></code>.” Whenever you access shared data, make sure it is safe. Most likely, this means obtaining the appropriate lock before manipulating the data and releasing the lock when finished.</p><div class="calibre_3"> </div>
</div></blockquote></div><div class="calibre_7"> </div>
<p class="calibre_2">If you always know before the fact that interrupts are initially enabled, there is no need to restore their previous state. You can unconditionally enable them on unlock. In those cases, <code class="calibre6"><span class="calibre7">spin_lock_irq()</span></code> and <code class="calibre6"><span class="calibre7">spin_unlock_irq()</span></code> are optimal:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">DEFINE_SPINLOCK(mr_lock);<br class="calibre1"/><br class="calibre1"/>spin_lock_irq(&amp;mr_lock);<br class="calibre1"/>/* critical section ... */<br class="calibre1"/>spin_unlock_irq(&amp;mr_lock);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">As the kernel grows in size and complexity, it is increasingly hard to ensure that interrupts are always enabled in any given code path in the kernel. Use of <code class="calibre6"><span class="calibre7">spin_lock_irq()</span></code>therefore is not recommended. If you do use it, you had better be positive that interrupts were originally on or people will be upset when they expect interrupts to be off but find them on!</p><div class="calibre_3"> </div>
<div border="1" class="calibre_26"><blockquote class="calibre10"><div class="calibre11">
<p class="calibre_2"></p><div class="calibre_3"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Debugging Spin Locks</span></span></p><div class="calibre_24"> </div>
<p class="calibre_2">The configure option <code class="calibre6"><span class="calibre7">CONFIG_DEBUG_SPINLOCK</span></code> enables a handful of debugging checks in the spin lock code. For example, with this option the spin lock code checks for the use of uninitialized spin locks and unlocking a lock that is not yet locked. When testing your code, you should always run with spin lock debugging enabled. For additional debugging of lock lifecycles, enable <code class="calibre6"><span class="calibre7">CONFIG_DEBUG_LOCK_ALLOC</span></code>.</p><div class="calibre_3"> </div>
</div></blockquote></div><div class="calibre_7"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos644728"> </div>
<h4 class="calibre_27"><span class="calibre3">Other Spin Lock Methods</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">You can use the method <code class="calibre6"><span class="calibre7">spin_lock_init()</span></code> to initialize a dynamically created spin lock (a <code class="calibre6"><span class="calibre7">spinlock_t</span></code> that you do not have a direct reference to, just a pointer).</p><div class="calibre_3"> </div>
<p class="calibre_2">The method <code class="calibre6"><span class="calibre7">spin_trylock()</span></code> attempts to obtain the given spin lock. If the lock is contended, rather than spin and wait for the lock to be released, the function immediately returns zero. If it succeeds in obtaining the lock, it returns nonzero. Similarly, <code id="filepos645424" class="calibre6"><span class="calibre7">spin_is_locked()</span></code> returns nonzero if the given lock is currently acquired. Otherwise, it returns zero. In neither case does <code class="calibre6"><span class="calibre7">spin_is_locked()</span></code> actually obtain the lock.<sup class="calibre8"><a id="filepos645664" href="#filepos645768">2</a></sup></p><div class="calibre_3"> </div>
<p class="calibre_2"><sup class="calibre8"><a id="filepos645768" href="#filepos645664">2</a></sup>
<em class="calibre4">Use of these two functions can lead to convoluted code. You should not frequently have to check the values of spin locks—your code should either always acquire the lock itself or always be called while the lock is already held. Some legitimate uses do exist, however, so these interfaces are provided.</em></p><div class="calibre_3"> </div>
<p class="calibre_2"><a href="#filepos646333">Table 10.4</a> shows a complete list of the standard spin lock methods.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos646333"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Table 10.4. Spin Lock Methods</span></span></p><div class="calibre_24"> </div>
<p class="calibre_23"><img alt="image" src="images/00123.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos646612"> </div>
<h4 class="calibre_27"><span class="calibre3">Spin Locks and Bottom Halves</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">As discussed in <a href="index_split_017.html#filepos487358">Chapter 8</a>, “Bottom Halves and Deferring Work,” certain locking precautions must be taken when working with bottom halves. The function <code class="calibre6"><span class="calibre7">spin_lock_bh()</span></code> obtains the given lock and disables all bottom halves. The function <code class="calibre6"><span class="calibre7">spin_unlock_bh()</span></code> performs the inverse.</p><div class="calibre_3"> </div>
<p class="calibre_2">Because a bottom half might preempt process context code, if data is shared between a bottom-half process context, you must protect the data in process context with both a lock and the disabling of bottom halves. Likewise, because an interrupt handler might preempt a bottom half, if data is shared between an interrupt handler and a bottom half, you must both obtain the appropriate lock and disable interrupts.</p><div class="calibre_3"> </div>
<p class="calibre_2"><a id="filepos647637"></a>Recall that two tasklets of the same type do not ever run simultaneously. Thus, there is no need to protect data used only within a single type of tasklet. If the data is shared between two different tasklets, however, you must obtain a normal spin lock before accessing the data in the bottom half. You do not need to disable bottom halves because a tasklet never preempts another running tasklet on the same processor.</p><div class="calibre_3"> </div>
<p class="calibre_2">With softirqs, regardless of whether it is the same softirq type, if data is shared by softirqs, it must be protected with a lock. Recall that softirqs, even two of the same type, might run simultaneously on multiple processors in the system. A softirq never preempts another softirq running on the same processor, however, so disabling bottom halves is not needed.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos648524"> </div>
<h3 class="calibre_21"><span class="bold">Reader-Writer Spin Locks</span></h3><div class="calibre_22"> </div>
<p class="calibre_2">Sometimes, lock usage can be clearly divided into reader and writer paths. For example, consider a list that is both updated and searched. When the list is updated (written to), it is important that no other threads of execution concurrently write to <em class="calibre4">or</em> read from the list. Writing demands mutual exclusion. On the other hand, when the list is searched (read from), it is only important that nothing else writes to the list. Multiple concurrent readers are safe so long as there are no writers. The task list’s access patterns (discussed in <a href="index_split_012.html#filepos167044">Chapter 3</a>, “Process Management”) fit this description. Not surprisingly, a <em class="calibre4">reader-writer spin lock</em> protects the task list.</p><div class="calibre_3"> </div>
<p class="calibre_2">When a data structure is neatly split into reader/writer or consumer/producer usage patterns, it makes sense to use a locking mechanism that provides similar semantics. To satisfy this use, the Linux kernel provides reader-writer spin locks. Reader-writer spin locks provide separate reader and writer variants of the lock. One or more readers can concurrently hold the reader lock. The writer lock, conversely, can be held by at most one writer with no concurrent readers. Reader/writer locks are sometimes called <em class="calibre4">shared/exclusive</em> or <em class="calibre4">concurrent/exclusive locks</em> because the lock is available in a shared (for readers) and an exclusive (for writers) form.</p><div class="calibre_3"> </div>
<p class="calibre_2">Usage is similar to spin locks. The reader-writer spin lock is initialized via</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">DEFINE_RWLOCK(mr_rwlock);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">Then, in the reader code path:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">read_lock(&amp;mr_rwlock);<br class="calibre1"/>/* critical section (read only) ... */<br class="calibre1"/>read_unlock(&amp;mr_rwlock);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">Finally, in the writer code path:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">write_lock(&amp;mr_rwlock);<br class="calibre1"/>/* critical section (read and write) ... */<br class="calibre1"/>write_unlock(&amp;mr_lock);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">Normally, the readers and writers are in entirely separate code paths, such as in this example.</p><div class="calibre_3"> </div>
<p class="calibre_2"><a id="filepos651134"></a>Note that you cannot “upgrade” a read lock to a write lock. For example, consider this code snippet:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">read_lock(&amp;mr_rwlock);<br class="calibre1"/>write_lock(&amp;mr_rwlock);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">Executing these two functions as shown will deadlock, as the write lock spins, waiting for all readers to release the shared lock—including yourself. If you ever need to write, obtain the write lock from the start. If the line between your readers and writers is muddled, it might be an indication that you do not need to use reader-writer locks. In that case, a normal spin lock is optimal.</p><div class="calibre_3"> </div>
<p class="calibre_2">It is safe for multiple readers to obtain the same lock. In fact, it is safe for the same thread to recursively obtain the same read lock. This lends itself to a useful and common optimization. If you have only readers in interrupt handlers but no writers, you can mix the use of the “interrupt disabling” locks. You can use <code class="calibre6"><span class="calibre7">read_lock()</span></code> instead of <code class="calibre6"><span class="calibre7">read_lock_irqsave()</span></code> for reader protection. You still need to disable interrupts for write access, à la <code class="calibre6"><span class="calibre7">write_lock_irqsave()</span></code>, otherwise a reader in an interrupt could deadlock on the held write lock. See <a href="#filepos652777">Table 10.5</a> for a full listing of the reader-writer spin lock methods.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos652726"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos652777"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Table 10.5. Reader-Writer Spin Lock Methods</span></span></p><div class="calibre_24"> </div>
<p class="calibre_23"><img alt="image" src="images/00124.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">A final important consideration in using the Linux reader-writer spin locks is that they favor readers over writers. If the read lock is held and a writer is waiting for exclusive access, readers that attempt to acquire the lock continue to succeed. The spinning writer does not acquire the lock until all readers release the lock. Therefore, a sufficient number of readers can starve pending writers. This is important to keep in mind when designing your locking. Sometimes this behavior is beneficial; sometimes it is catastrophic.</p><div class="calibre_3"> </div>
<p class="calibre_2">Spin locks provide a quick and simple lock. The spinning behavior is optimal for short hold times and code that cannot sleep (interrupt handlers, for example). In cases where the sleep time might be long or you potentially need to sleep <em class="calibre4">while</em> holding the lock, the semaphore is a solution.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos654003"> </div>
<h3 class="calibre_21"><span class="bold">Semaphores</span></h3><div class="calibre_22"> </div>
<p class="calibre_2">Semaphores in Linux are sleeping locks. When a task attempts to acquire a semaphore that is unavailable, the semaphore places the task onto a wait queue and puts the task to sleep. The processor is then free to execute other code. When the semaphore becomes available, one of the tasks on the wait queue is awakened so that it can then acquire the semaphore.</p><div class="calibre_3"> </div>
<p class="calibre_2">Let’s jump back to the door and key analogy. When a person reaches the door, he can grab the key and enter the room. The big difference lies in what happens when another dude reaches the door and the key is not available. In this case, instead of spinning, the fellow puts his name on a list and takes a number. When the person inside the room leaves, he checks the list at the door. If anyone’s name is on the list, he goes over to the first name and gives him a playful jab in the chest, waking him up and allowing him to enter the room. In this manner, the key (read: semaphore) continues to ensure that there is only one person (read: thread of execution) inside the room (read: critical region) at one time. This provides better processor utilization than spin locks because there is no time spent busy looping, but semaphores have much greater overhead than spin locks. Life is always a trade-off.</p><div class="calibre_3"> </div>
<p class="calibre_2">You can draw some interesting conclusions from the sleeping behavior of semaphores:</p><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• Because the contending tasks sleep while waiting for the lock to become available, semaphores are well suited to locks that are held for a long time.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• <a id="filepos655882"></a>Conversely, semaphores are not optimal for locks that are held for short periods because the overhead of sleeping, maintaining the wait queue, and waking back up can easily outweigh the total lock hold time.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• Because a thread of execution sleeps on lock contention, semaphores must be obtained only in process context because interrupt context is not schedulable.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• You can (although you might not want to) sleep while holding a semaphore because you will not deadlock when another process acquires the same semaphore. (It will just go to sleep and eventually let you continue.)</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• You cannot hold a spin lock while you acquire a semaphore, because you might have to sleep while waiting for the semaphore, and you cannot sleep while holding a spin lock.</p></blockquote><div class="calibre_3"> </div>
<p class="calibre_2">These facts highlight the uses of semaphores versus spin locks. In most uses of semaphores, there is little choice as to what lock to use. If your code needs to sleep, which is often the case when synchronizing with user-space, semaphores are the sole solution. It is often easier, if not necessary, to use semaphores because they allow you the flexibility of sleeping. When you do have a choice, the decision between semaphore and spin lock should be based on lock hold time. Ideally, all your locks should be held as briefly as possible. With semaphores, however, longer lock hold times are more acceptable. Additionally, unlike spin locks, semaphores do not disable kernel preemption and, consequently, code holding a semaphore can be preempted. This means semaphores do not adversely affect scheduling latency.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos657813"> </div>
<h4 class="calibre_27"><span class="calibre3">Counting and Binary Semaphores</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">A final useful feature of semaphores is that they can allow for an arbitrary number of simultaneous lock holders. Whereas spin locks permit at most one task to hold the lock at a time, the number of permissible simultaneous holders of semaphores can be set at declaration time. This value is called the <em class="calibre4">usage count</em> or simply the <em class="calibre4">count</em>. The most common value is to allow, like spin locks, only one lock holder at a time. In this case, the count is equal to one, and the semaphore is called either a <em class="calibre4">binary semaphore</em> (because it is either held by one task or not held at all) or a <em class="calibre4">mutex</em> (because it enforces mutual exclusion). Alternatively, the count can be initialized to a nonzero value greater than one. In this case, the semaphore is called a <em class="calibre4">counting semaphore</em>, and it enables at most <em class="calibre4">count</em> holders of the lock at a time. Counting semaphores are not used to enforce mutual exclusion because they enable multiple threads of execution in the critical region at once. Instead, they are used to enforce limits in certain code. They are not used much in the kernel. If you use a semaphore, you almost assuredly want to use a mutex (a semaphore with a count of one).</p><div class="calibre_3"> </div>
<p class="calibre_2"><a id="filepos659214"></a>Semaphores were formalized by Edsger Wybe Dijkstra<sup class="calibre8"><a id="filepos659269" href="#filepos660562">3</a></sup> in 1968 as a generalized locking mechanism. A semaphore supports two atomic operations, <code class="calibre6"><span class="calibre7">P()</span></code> and <code class="calibre6"><span class="calibre7">V()</span></code>, named after the Dutch word <em class="calibre4">Proberen</em>, to test (literally, to probe), and the Dutch word <em class="calibre4">Verhogen</em>, to increment. Later systems called these methods <code class="calibre6"><span class="calibre7">down()</span></code> and <code class="calibre6"><span class="calibre7">up()</span></code>, respectively, and so does Linux. The <code class="calibre6"><span class="calibre7">down()</span></code> method is used to acquire a semaphore by decrementing the count by one. If the new count is zero or greater, the lock is acquired and the task can enter the critical region. If the count is negative, the task is placed on a wait queue, and the processor moves on to something else. These names are used as verbs: You <em class="calibre4">down</em> a semaphore to acquire it. The <code class="calibre6"><span class="calibre7">up()</span></code> method is used to release a semaphore upon completion of a critical region. This is called <em class="calibre4">upping</em> the semaphore. The method increments the count value; if the semaphore’s wait queue is not empty, one of the waiting tasks is awakened and allowed to acquire the semaphore.</p><div class="calibre_3"> </div>
<p class="calibre_2"><sup class="calibre8"><a id="filepos660562" href="#filepos659269">3</a></sup>
<em class="calibre4">Dr. Dijkstra (1930–2002) is one of the most accomplished computer scientists in the (admittedly brief) history of computer scientists. His numerous contributions include work in OS design, algorithm theory, and the concept of semaphores. He was born in Rotterdam, The Netherlands, and taught at the University of Texas for 15 years. He would probably not be happy with the large number of GOTO statements in the Linux kernel, however.</em></p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos661115"> </div>
<h4 class="calibre_27"><span class="calibre3">Creating and Initializing Semaphores</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">The semaphore implementation is architecture-dependent and defined in <code class="calibre6"><span class="calibre7">&lt;asm/semaphore.h&gt;</span></code>. The <code class="calibre6"><span class="calibre7">struct semaphore</span></code> type represents semaphores. Statically declared semaphores are created via the following, where <code class="calibre6"><span class="calibre7">name</span></code> is the variable’s name and <code class="calibre6"><span class="calibre7">count</span></code> is the usage count of the semaphore:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">struct semaphore name;<br class="calibre1"/>sema_init(&amp;name, count);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">As a shortcut to create the more common mutex, use the following, where, again, <code class="calibre6"><span class="calibre7">name</span></code> is the variable name of the binary semaphore:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">static DECLARE_MUTEX(name);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">More frequently, semaphores are created dynamically, often as part of a larger structure. In this case, to initialize a dynamically created semaphore to which you have only an indirect pointer reference, just call <code class="calibre6"><span class="calibre7">sema_init()</span></code>, where <code class="calibre6"><span class="calibre7">sem</span></code> is a pointer and <code class="calibre6"><span class="calibre7">count</span></code> is the usage count of the semaphore:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">sema_init(sem, count);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">Similarly, to initialize a dynamically created mutex, you can use</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">init_MUTEX(sem);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2"><a id="filepos663052"></a>I do not know why the “mutex” in <code class="calibre6"><span class="calibre7">init_MUTEX()</span></code> is capitalized or why the “init” comes first here but second in <code class="calibre6"><span class="calibre7">sema_init()</span></code>. I suspect that after you read <a href="index_split_017.html#filepos487358">Chapter 8</a>, the inconsistency is not surprising.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos663424"> </div>
<h4 class="calibre_27"><span class="calibre3">Using Semaphores</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">The function <code class="calibre6"><span class="calibre7">down_interruptible()</span></code> attempts to acquire the given semaphore. If the semaphore is unavailable, it places the calling process to sleep in the <code class="calibre6"><span class="calibre7">TASK_INTERRUPTIBLE</span></code> state. Recall from <a href="index_split_012.html#filepos167044">Chapter 3</a> that this process state implies that a task can be awakened with a signal, which is generally a good thing. If the task receives a signal while waiting for the semaphore, it is awakened and <code class="calibre6"><span class="calibre7">down_interruptible()</span></code> returns <code class="calibre6"><span class="calibre7">-EINTR</span></code>. Alternatively, the function <code class="calibre6"><span class="calibre7">down()</span></code> places the task in the <code class="calibre6"><span class="calibre7">TASK_UNINTERRUPTIBLE</span></code> state when it sleeps. You most likely do not want this because the process waiting for the semaphore does not respond to signals. Therefore, use of <code class="calibre6"><span class="calibre7">down_interruptible()</span></code> is much more common (and correct) than <code class="calibre6"><span class="calibre7">down()</span></code>. Yes, again, the naming is not ideal.</p><div class="calibre_3"> </div>
<p class="calibre_2">You can use <code class="calibre6"><span class="calibre7">down_trylock()</span></code> to try to acquire the given semaphore without blocking. If the semaphore is already held, the function immediately returns nonzero. Otherwise, it returns zero and you successfully hold the lock.</p><div class="calibre_3"> </div>
<p class="calibre_2">To release a given semaphore, call <code class="calibre6"><span class="calibre7">up()</span></code>. Consider an example:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00125.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">A complete listing of the semaphore methods is in <a href="#filepos665341">Table 10.6</a>.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos665341"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Table 10.6. Semaphore Methods</span></span></p><div class="calibre_24"> </div>
<p class="calibre_23"><img alt="image" src="images/00126.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos665620"> </div>
<h3 class="calibre_21"><span class="bold">Reader-Writer Semaphores</span></h3><div class="calibre_22"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos665747"> </div>
<p class="calibre_2">Semaphores, like spin locks, also come in a reader-writer flavor. The situations where reader-writer semaphores are preferred over standard semaphores are the same as with reader-writer spin locks versus standard spin locks.</p><div class="calibre_3"> </div>
<p class="calibre_2">Reader-writer semaphores are represented by the <code class="calibre6"><span class="calibre7">struct rw_semaphore</span></code> type, which is declared in <code class="calibre6"><span class="calibre7">&lt;linux/rwsem.h&gt;</span></code>. Statically declared reader-writer semaphores are created via the following, where <code class="calibre6"><span class="calibre7">name</span></code> is the declared name of the new semaphore:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">static DECLARE_RWSEM(name);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">Reader-writer semaphores created dynamically are initialized via</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">init_rwsem(struct rw_semaphore *sem)</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">All reader-writer semaphores are mutexes—that is, their usage count is one—although they enforce mutual exclusion only for writers, not readers. Any number of readers can concurrently hold the read lock, so long as there are no writers. Conversely, only a sole writer (with no readers) can acquire the write variant of the lock. All reader-writer locks use uninterruptible sleep, so there is only one version of each <code class="calibre6"><span class="calibre7">down()</span></code>. For example:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00127.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2"><a id="filepos667483"></a>As with semaphores, implementations of <code class="calibre6"><span class="calibre7">down_read_trylock()</span></code> and <code class="calibre6"><span class="calibre7">down_write_trylock()</span></code> are provided. Each has one parameter: a pointer to a reader-writer semaphore. They both return nonzero if the lock is successfully acquired and zero if it is currently contended. Be careful: For admittedly no good reason, this is the opposite of normal semaphore behavior!</p><div class="calibre_3"> </div>
<p class="calibre_2">Reader-writer semaphores have a unique method that their reader-writer spin lock cousins do not have: <code class="calibre6"><span class="calibre7">downgrade_write()</span></code>. This function atomically converts an acquired write lock to a read lock.</p><div class="calibre_3"> </div>
<p class="calibre_2">Reader-writer semaphores, as spin locks of the same nature, should not be used unless a clear separation exists between write paths and read paths in your code. Supporting the reader-writer mechanisms has a cost, and it is worthwhile only if your code naturally splits along a reader/writer boundary.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos668590"> </div>
<h3 class="calibre_21"><span class="bold">Mutexes</span></h3><div class="calibre_22"> </div>
<p class="calibre_2">Until recently, the only sleeping lock in the kernel was the semaphore. Most users of semaphores instantiated a semaphore with a <em class="calibre4">count</em> of one and treated them as a <em class="calibre4">mutual exclusion</em> lock—a sleeping version of the spin lock. Unfortunately, semaphores are rather generic and do not impose many usage constraints. This makes them useful for managing exclusive access in obscure situations, such as complicated dances between the kernel and user-space. But it also means that simpler locking is harder to do, and the lack of enforced rules makes any sort of automated debugging or constraint enforcement impossible. Seeking a simpler sleeping lock, the kernel developers introduced the <em class="calibre4">mutex</em>. Yes, as you are now accustomed to, that is a confusing name. Let’s clarify. The term “mutex” is a generic name to refer to any sleeping lock that enforces mutual exclusion, such as a semaphore with a usage count of one. In recent Linux kernels, the proper noun “mutex” is now also a specific type of sleeping lock that implements mutual exclusion. That is, a mutex is a mutex.</p><div class="calibre_3"> </div>
<p class="calibre_2">The mutex is represented by <code class="calibre6"><span class="calibre7">struct mutex</span></code>. It behaves similar to a semaphore with a count of one, but it has a simpler interface, more efficient performance, and additional constraints on its use. To statically define a mutex, you do:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">DEFINE_MUTEX(name);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">To dynamically initialize a mutex, you call</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">mutex_init(&amp;mutex);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">Locking and unlocking the mutex is easy:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">mutex_lock(&amp;mutex);<br class="calibre1"/>/* critical region ... */<br class="calibre1"/>mutex_unlock(&amp;mutex);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">That is it! Simpler than a semaphore and without the need to manage usage counts. <a href="#filepos671027">Table 10.7</a> is a listing of the basic mutex methods.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos671027"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Table 10.7. Mutex Methods</span></span></p><div class="calibre_24"> </div>
<p class="calibre_23"><img alt="image" src="images/00128.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">The simplicity and efficiency of the mutex comes from the additional constraints it imposes on its users over and above what the semaphore requires. Unlike a semaphore, which implements the most basic of behavior in accordance with Dijkstra’s original design, the mutex has a stricter, narrower use case:</p><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• Only one task can hold the mutex at a time. That is, the usage count on a mutex is always one.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• Whoever locked a mutex must unlock it. That is, you cannot lock a mutex in one context and then unlock it in another. This means that the mutex isn’t suitable for more complicated synchronizations between kernel and user-space. Most use cases, however, cleanly lock and unlock from the same context.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• Recursive locks and unlocks are not allowed. That is, you cannot recursively acquire the same mutex, and you cannot unlock an unlocked mutex.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• A process cannot exit while holding a mutex.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• A mutex cannot be acquired by an interrupt handler or bottom half, even with <code class="calibre6"><span class="calibre7">mutex_trylock()</span></code>.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• A mutex can be managed only via the official API: It must be initialized via the methods described in this section and cannot be copied, hand initialized, or reinitialized.</p></blockquote><div class="calibre_3"> </div>
<p class="calibre_2">Perhaps the most useful aspect of the new struct mutex is that, via a special debugging mode, the kernel can programmatically check for and warn about violations of these constraints. When the kernel configuration option <code class="calibre6"><span class="calibre7">CONFIG_DEBUG_MUTEXES</span></code> is enabled, a <a id="filepos673354"></a>multitude of debugging checks ensure that these (and other) constraints are always upheld. This enables you and other users of the mutex to guarantee a regimented, simple usage pattern.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos673590"> </div>
<h4 class="calibre_27"><span class="calibre3">Semaphores Versus Mutexes</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">Mutexes and semaphores are similar. Having both in the kernel is confusing. Thankfully, the formula dictating which to use is quite simple: Unless one of mutex’s additional constraints prevent you from using them, prefer the new mutex type to semaphores. When writing new code, only specific, often low-level, uses need a semaphore. Start with a mutex and move to a semaphore only if you run into one of their constraints and have no other alternative.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos674226"> </div>
<h4 class="calibre_27"><span class="calibre3">Spin Locks Versus Mutexes</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">Knowing when to use a spin lock versus a mutex (or semaphore) is important to writing optimal code. In many cases, however, there is little choice. Only a spin lock can be used in interrupt context, whereas only a mutex can be held while a task sleeps. <a href="#filepos674751">Table 10.8</a> reviews the requirements that dictate which lock to use.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos674751"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Table 10.8. What to Use: Spin Locks Versus Semaphores</span></span></p><div class="calibre_24"> </div>
<p class="calibre_23"><img alt="image" src="images/00129.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos675054"> </div>
<h3 class="calibre_21"><span class="bold">Completion Variables</span></h3><div class="calibre_22"> </div>
<p class="calibre_2">Using <em class="calibre4">completion variables</em> is an easy way to synchronize between two tasks in the kernel when one task needs to signal to the other that an event has occurred. One task waits on the completion variable while another task performs some work. When the other task has completed the work, it uses the completion variable to wake up any waiting tasks. If you think this sounds like a semaphore, you are right—the idea is much the same. In fact, completion variables merely provide a simple solution to a problem whose answer is otherwise semaphores. For example, the <code class="calibre6"><span class="calibre7">vfork()</span></code> system call uses completion variables to wake up the parent process when the child process execs or exits.</p><div class="calibre_3"> </div>
<p class="calibre_2">Completion variables are represented by the <code class="calibre6"><span class="calibre7">struct completion</span></code> type, which is defined in <code class="calibre6"><span class="calibre7">&lt;linux/completion.h&gt;</span></code>. A statically created completion variable is created and initialized via</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">DECLARE_COMPLETION(mr_comp);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2"><a id="filepos676393"></a>A dynamically created completion variable is initialized via <code class="calibre6"><span class="calibre7">init_completion()</span></code>.</p><div class="calibre_3"> </div>
<p class="calibre_2">On a given completion variable, the tasks that want to wait call <code class="calibre6"><span class="calibre7">wait_for_completion()</span></code>. After the event has occurred, calling <code class="calibre6"><span class="calibre7">complete()</span></code> signals all waiting tasks to wake up. <a href="#filepos676941">Table 10.9</a> has a listing of the completion variable methods.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos676941"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Table 10.9. Completion Variable Methods</span></span></p><div class="calibre_24"> </div>
<p class="calibre_23"><img alt="image" src="images/00130.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">For sample usages of completion variables, see <code class="calibre6"><span class="calibre7">kernel/sched.c</span></code> and <code class="calibre6"><span class="calibre7">kernel/fork.c</span></code>. A common usage is to have a completion variable dynamically created as a member of a data structure. Kernel code waiting for the initialization of the data structure calls <code class="calibre6"><span class="calibre7">wait_for_completion()</span></code>. When the initialization is complete, the waiting tasks are awakened via a call to <code class="calibre6"><span class="calibre7">completion()</span></code>.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos677792"> </div>
<h3 class="calibre_21"><span class="bold">BKL: The Big Kernel Lock</span></h3><div class="calibre_22"> </div>
<p class="calibre_2">Welcome to the redheaded stepchild of the kernel. The Big Kernel Lock (BKL) is a global spin lock that was created to ease the transition from Linux’s original SMP implementation to fine-grained locking. The BKL has some interesting properties:</p><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• You can sleep while holding the BKL. The lock is automatically dropped when the task is unscheduled and reacquired when the task is rescheduled. Of course, this does not mean it is <em class="calibre4">always safe</em> to sleep while holding the BKL, merely that you <em class="calibre4">can</em> and you will not deadlock.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• The BKL is a recursive lock. A single process can acquire the lock multiple times and not deadlock, as it would with a spin lock.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• You can use the BKL only in process context. Unlike spin locks, you cannot acquire the BKL in interrupt context.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• New users of the BKL are forbidden. With every kernel release, fewer and fewer drivers and subsystems rely on the BKL.</p></blockquote><div class="calibre_3"> </div>
<p class="calibre_2">These features helped ease the transition from kernel version 2.0 to 2.2. When SMP support was introduced in kernel version 2.0, only one task could be in the kernel at a time. Of course, now the kernel is quite finely threaded, we have come a long way. A goal of 2.2 was to allow multiple processors to execute in the kernel concurrently. The BKL <a id="filepos679560"></a>was introduced to help ease the transition to finer-grained locking. It was a great aid then; now it is a scalability burden.</p><div class="calibre_3"> </div>
<p class="calibre_2">Use of the BKL is discouraged. In fact, new code should never introduce locking that uses the BKL. The lock is still fairly well used in parts of the kernel, however. Therefore, understanding the BKL and its interfaces is important. The BKL behaves like a spin lock, with the additions previously discussed. The function <code class="calibre6"><span class="calibre7">lock_kernel()</span></code> acquires the lock and the function <code class="calibre6"><span class="calibre7">unlock_kernel()</span></code> releases the lock. A single thread of execution might acquire the lock recursively but must then call <code class="calibre6"><span class="calibre7">unlock_kernel()</span></code> an equal number of times to release the lock. On the last unlock call, the lock will be released. The function <code class="calibre6"><span class="calibre7">kernel_locked()</span></code> returns nonzero if the lock is currently held; otherwise, it returns zero. These interfaces are declared in <code class="calibre6"><span class="calibre7">&lt;linux/smp_lock.h&gt;</span></code>. Here is sample usage:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00131.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">The BKL also disables kernel preemption while it is held. On UP kernels, the BKL code does not actually perform any physical locking. <a href="#filepos681101">Table 10.10</a> has a complete list of the BKL functions.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos681101"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Table 10.10. BKL Methods</span></span></p><div class="calibre_24"> </div>
<p class="calibre_23"><img alt="image" src="images/00132.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">One of the major issues concerning the BKL is determining what the lock is protecting. Too often, the BKL is seemingly associated with code (for example, “it synchronizes callers to <code class="calibre6"><span class="calibre7">foo()</span></code>”) instead of data (“it protects the <code class="calibre6"><span class="calibre7">foo</span></code> structure”). This makes replacing BKL uses with a spin lock difficult because it is not easy to determine just what is being locked. The replacement is made even harder in that the relationship between all BKL users needs to be determined.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos681987"> </div>
<h3 class="calibre_21"><span class="bold">Sequential Locks</span></h3><div class="calibre_22"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos682106"> </div>
<p class="calibre_2">The <em class="calibre4">sequential lock</em>, generally shortened to <em class="calibre4">seq lock</em>, is a newer type of lock introduced in the 2.6 kernel. It provides a simple mechanism for reading and writing shared data. It works by maintaining a sequence counter. Whenever the data in question is written to, a lock is obtained and a sequence number is incremented. Prior to and after reading the data, the sequence number is read. If the values are the same, a write did not begin in the middle of the read. Further, if the values are even, a write is not underway. (Grabbing the write lock makes the value odd, whereas releasing it makes it even because the lock starts at zero.)</p><div class="calibre_3"> </div>
<p class="calibre_2">To define a seq lock:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">seqlock_t mr_seq_lock = DEFINE_SEQLOCK(mr_seq_lock);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">The write path is then</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">write_seqlock(&amp;mr_seq_lock);<br class="calibre1"/>/* write lock is obtained... */<br class="calibre1"/>write_sequnlock(&amp;mr_seq_lock);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">This looks like normal spin lock code. The oddness comes in with the read path, which is quite a bit different:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00133.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">Seq locks are useful to provide a lightweight and scalable lock for use with many readers and a few writers. Seq locks, however, favor writers over readers. An acquisition of the write lock always succeeds as long as there are no other writers. Readers do not affect the write lock, as is the case with reader-writer spin locks and semaphores. Furthermore, pending writers continually cause the read loop (the previous example) to repeat, until there are no longer any writers holding the lock.</p><div class="calibre_3"> </div>
<p class="calibre_2">Seq locks are ideal when your locking needs meet most or all these requirements:</p><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• Your data has a lot of readers.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• Your data has few writers.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• Although few in number, you want to favor writers over readers and never allow readers to starve writers.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• Your data is simple, such as a simple structure or even a single integer that, for whatever reason, cannot be made atomic.</p></blockquote><div class="calibre_3"> </div>
<p class="calibre_2">A prominent user of the seq lock is <em class="calibre4">jiffies</em>, the variable that stores a Linux machine’s uptime (see <a href="index_split_020.html#filepos701833">Chapter 11</a>, “Timers and Time Management”). Jiffies holds a 64-bit count of <a id="filepos685156"></a>the number of clock ticks since the machine booted. On machines that cannot atomically read the full 64-bit <code class="calibre6"><span class="calibre7">jiffies_64</span></code> variable, <code class="calibre6"><span class="calibre7">get_jiffies_64()</span></code> is implemented using seq locks:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00134.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">Updating jiffies during the timer interrupt, in turns, grabs the write variant of the seq lock:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">write_seqlock(&amp;xtime_lock);<br class="calibre1"/>jiffies_64 += 1;<br class="calibre1"/>write_sequnlock(&amp;xtime_lock);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">For a deeper discussion on jiffies and kernel time keeping, see <a href="index_split_020.html#filepos701833">Chapter 11</a> and the files <code class="calibre6"><span class="calibre7">kernel/timer.c</span></code> and <code class="calibre6"><span class="calibre7">kernel/time/tick-common.c</span></code> in the kernel source tree.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos686189"> </div>
<h3 class="calibre_21"><span class="bold">Preemption Disabling</span></h3><div class="calibre_22"> </div>
<p class="calibre_2">Because the kernel is preemptive, a process in the kernel can stop running at any instant to enable a process of higher priority to run. This means a task can begin running in the same critical region as a task that was preempted. To prevent this, the kernel preemption code uses spin locks as markers of nonpreemptive regions. If a spin lock is held, the kernel is not preemptive. Because the concurrency issues with kernel preemption and SMP are the same, and the kernel is already SMP-safe; this simple change makes the kernel preempt-safe, too.</p><div class="calibre_3"> </div>
<p class="calibre_2">Or so we hope. In reality, some situations do not require a spin lock, but do need kernel preemption disabled. The most frequent of these situations is per-processor data. If the data is unique to each processor, there might be no need to protect it with a lock because only that one processor can access the data. If no spin locks are held, the kernel is preemptive, and it would be possible for a newly scheduled task to access this same variable, as shown here:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00135.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2"><a id="filepos687514"></a>Consequently, even if this were a uniprocessor computer, the variable could be accessed pseudo-concurrently by multiple processes. Normally, this variable would require a spin lock (to prevent true concurrency on multiprocessing machines). If this were a per-processor variable, however, it might not require a lock.</p><div class="calibre_3"> </div>
<p class="calibre_2">To solve this, kernel preemption can be disabled via <code class="calibre6"><span class="calibre7">preempt_disable()</span></code>. The call is nestable; you can call it any number of times. For each call, a corresponding call to <code class="calibre6"><span class="calibre7">preempt_enable()</span></code> is required. The final corresponding call to <code class="calibre6"><span class="calibre7">preempt_enable()</span></code> reenables preemption. For example:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">preempt_disable();<br class="calibre1"/>/* preemption is disabled ... */<br class="calibre1"/>preempt_enable();</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">The preemption count stores the number of held locks and <code class="calibre6"><span class="calibre7">preempt_disable()</span></code> calls. If the number is zero, the kernel is preemptive. If the value is one or greater, the kernel is not preemptive. This count is incredibly useful—it is a great way to do atomicity and sleep debugging. The function <code class="calibre6"><span class="calibre7">preempt_count()</span></code> returns this value. See <a href="#filepos689052">Table 10.11</a> for a listing of kernel preemption-related functions.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos689052"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Table 10.11. Kernel Preemption-Related Methods</span></span></p><div class="calibre_24"> </div>
<p class="calibre_23"><img alt="image" src="images/00136.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">As a cleaner solution to per-processor data issues, you can obtain the processor number (which presumably is used to index into the per-processor data) via <code class="calibre6"><span class="calibre7">get_cpu()</span></code>. This function disables kernel preemption prior to returning the current processor number:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00137.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos689778"> </div>
<h3 class="calibre_21"><span class="bold">Ordering and Barriers</span></h3><div class="calibre_22"> </div>
<p class="calibre_2">When dealing with synchronization between multiple processors or with hardware devices, it is sometimes a requirement that memory-reads (loads) and memory-writes (stores) issue in the order specified in your program code. When talking with hardware, you often need to ensure that a given read occurs before another read or write. Additionally, on symmetrical multiprocessing systems, it might be important for writes to appear in the order that your code issues them (usually to ensure subsequent reads see the data in the same order). Complicating these issues is the fact that both the compiler and the processor can reorder reads and writes<sup class="calibre8"><a id="filepos690550" href="#filepos690945">4</a></sup> for performance reasons. Thankfully, all processors that do reorder reads or writes provide machine instructions to enforce ordering requirements. It is also possible to instruct the compiler not to reorder instructions around a given point. These instructions are called <em class="calibre4">barriers</em>.</p><div class="calibre_3"> </div>
<p class="calibre_2"><sup class="calibre8"><a id="filepos690945" href="#filepos690550">4</a></sup>
<em class="calibre4">Intel x86 processors do not ever reorder writes. That is, they do not do out-of-order stores. But other processors do.</em></p><div class="calibre_3"> </div>
<p class="calibre_2">Essentially, on some processors the following code may allow the processor to store the new value in <code class="calibre6"><span class="calibre7">b</span></code>
<em class="calibre4">before</em> it stores the new value in <code class="calibre6"><span class="calibre7">a</span></code>:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">a = 1;<br class="calibre1"/>b = 2;</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">Both the compiler and processor see no relation between <code class="calibre6"><span class="calibre7">a</span></code> and <code class="calibre6"><span class="calibre7">b</span></code>. The compiler would perform this reordering at compile time; the reordering would be static, and the resulting object code would simply set <code class="calibre6"><span class="calibre7">b</span></code> before <code class="calibre6"><span class="calibre7">a</span></code>. The processor, however, could perform the reordering dynamically during execution by fetching and dispatching seemingly unrelated instructions in whatever order it feels is best. The vast majority of the time, such reordering is optimal because there is no apparent relation between <code class="calibre6"><span class="calibre7">a</span></code> and <code class="calibre6"><span class="calibre7">b</span></code>. Sometimes the programmer knows best, though.</p><div class="calibre_3"> </div>
<p class="calibre_2">Although the previous example might be reordered, the processor would never reorder writes such as the following because there is clearly a data dependency between <code class="calibre6"><span class="calibre7">a</span></code> and <code class="calibre6"><span class="calibre7">b</span></code>:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">a = 1;<br class="calibre1"/>b = a;</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">Neither the compiler nor the processor, however, knows about code in other contexts. Occasionally, it is important that writes are seen by other code and the outside world in the specific order you intend. This is often the case with hardware devices but is also common on multiprocessing machines.</p><div class="calibre_3"> </div>
<p class="calibre_2"><a id="filepos693140"></a>The <code class="calibre6"><span class="calibre7">rmb()</span></code> method provides a read memory barrier. It ensures that no loads are reordered across the <code class="calibre6"><span class="calibre7">rmb()</span></code> call. That is, no loads prior to the call will be reordered to after the call, and no loads after the call will be reordered to before the call.</p><div class="calibre_3"> </div>
<p class="calibre_2">The <code class="calibre6"><span class="calibre7">wmb()</span></code> method provides a write barrier. It functions in the same manner as <code class="calibre6"><span class="calibre7">rmb()</span></code>, but with respect to stores instead of loads—it ensures no stores are reordered across the barrier.</p><div class="calibre_3"> </div>
<p class="calibre_2">The <code class="calibre6"><span class="calibre7">mb()</span></code> call provides both a read barrier and a write barrier. No loads <em class="calibre4">or</em> stores will be reordered across a call to <code class="calibre6"><span class="calibre7">mb()</span></code>. It is provided because a single instruction (often the same instruction used by <code class="calibre6"><span class="calibre7">rmb()</span></code>) can provide both the load and store barrier.</p><div class="calibre_3"> </div>
<p class="calibre_2">A variant of <code class="calibre6"><span class="calibre7">rmb()</span></code>, <code class="calibre6"><span class="calibre7">read_barrier_depends()</span></code>, provides a read barrier but <em class="calibre4">only for loads on which subsequent loads depend</em>. All reads prior to the barrier are guaranteed to complete before any reads after the barrier that depend on the reads prior to the barrier. Got it? Basically, it enforces a read barrier, similar to <code class="calibre6"><span class="calibre7">rmb()</span></code>, but only for certain reads—those that depend on each other. On some architectures, <code class="calibre6"><span class="calibre7">read_barrier_depends()</span></code> is much quicker than <code class="calibre6"><span class="calibre7">rmb()</span></code> because it is not needed and is, thus, a <em class="calibre4">noop</em>.</p><div class="calibre_3"> </div>
<p class="calibre_2">Let’s consider an example using <code class="calibre6"><span class="calibre7">mb()</span></code> and <code class="calibre6"><span class="calibre7">rmb()</span></code>. The initial value of <code class="calibre6"><span class="calibre7">a</span></code> is one, and the initial value of <code class="calibre6"><span class="calibre7">b</span></code> is two.</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00138.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">Without using the memory barriers, on some processors it is possible for <code class="calibre6"><span class="calibre7">c</span></code> to receive the <em class="calibre4">new</em> value of <code class="calibre6"><span class="calibre7">b</span></code>, whereas <code class="calibre6"><span class="calibre7">d</span></code> receives the <em class="calibre4">old</em> value of <code class="calibre6"><span class="calibre7">a</span></code>. For example, <code class="calibre6"><span class="calibre7">c</span></code> could equal four (what you’d expect), yet <code class="calibre6"><span class="calibre7">d</span></code> could equal one (not what you’d expect). Using the <code class="calibre6"><span class="calibre7">mb()</span></code> ensured that <code class="calibre6"><span class="calibre7">a</span></code> and <code class="calibre6"><span class="calibre7">b</span></code> were written in the intended order, whereas the <code class="calibre6"><span class="calibre7">rmb()</span></code> insured <code class="calibre6"><span class="calibre7">c</span></code> and <code class="calibre6"><span class="calibre7">d</span></code> were read in the intended order.</p><div class="calibre_3"> </div>
<p class="calibre_2">This sort of reordering occurs because modern processors dispatch and commit instructions out of order, to optimize use of their pipelines. What can end up happening in the previous example is that the instructions associated with the loads of <code class="calibre6"><span class="calibre7">b</span></code> and <code class="calibre6"><span class="calibre7">a</span></code> occur out of order. The <code class="calibre6"><span class="calibre7">rmb()</span></code> and <code class="calibre6"><span class="calibre7">wmb()</span></code> functions correspond to instructions that tell the processor to commit any pending load or store instructions, respectively, before continuing.</p><div class="calibre_3"> </div>
<p class="calibre_2">Let’s look at a similar example, but one that uses <code class="calibre6"><span class="calibre7">read_barrier_depends()</span></code> instead of <code class="calibre6"><span class="calibre7">rmb()</span></code>. In this example, initially <code class="calibre6"><span class="calibre7">a</span></code> is one, <code class="calibre6"><span class="calibre7">b</span></code> is two, and <code class="calibre6"><span class="calibre7">p</span></code> is <code class="calibre6"><span class="calibre7">&amp;b</span></code>.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos697325"> </div>
<p class="calibre_31"><img alt="image" src="images/00139.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">Again, without memory barriers, it would be possible for <code class="calibre6"><span class="calibre7">b</span></code> to be set to <code class="calibre6"><span class="calibre7">pp</span></code> before <code class="calibre6"><span class="calibre7">pp</span></code> was set to <code class="calibre6"><span class="calibre7">p</span></code>. The <code class="calibre6"><span class="calibre7">read_barrier_depends()</span></code>, however, provides a sufficient barrier because the load of <code class="calibre6"><span class="calibre7">*pp</span></code> depends on the load of <code class="calibre6"><span class="calibre7">p</span></code>. It would also be sufficient to use <code class="calibre6"><span class="calibre7">rmb()</span></code> here, but because the reads are data dependent, we can use the potentially faster <code class="calibre6"><span class="calibre7">read_barrier_depends()</span></code>. Note that in either case, the <code class="calibre6"><span class="calibre7">mb()</span></code> is required to enforce the intended load/store ordering in the left thread.</p><div class="calibre_3"> </div>
<p class="calibre_2">The macros <code class="calibre6"><span class="calibre7">smp_rmb()</span></code>, <code class="calibre6"><span class="calibre7">smp_wmb()</span></code>, <code class="calibre6"><span class="calibre7">smp_mb()</span></code>, and <code class="calibre6"><span class="calibre7">smp_read_barrier_depends()</span></code> provide a useful optimization. On SMP kernels they are defined as the usual memory barriers, whereas on UP kernels they are defined only as a compiler barrier. You can use these SMP variants when the ordering constraints are specific to SMP systems.</p><div class="calibre_3"> </div>
<p class="calibre_2">The <code class="calibre6"><span class="calibre7">barrier()</span></code> method prevents the compiler from optimizing loads or stores across the call. The compiler knows not to rearrange stores and loads in ways that would change the effect of the C code and existing data dependencies. It does not have knowledge, however, of events that can occur outside the current context. For example, the compiler cannot know about interrupts that might read the same data you are writing. For this reason, you might want to ensure a store is issued before a load, for example. The previous memory barriers also function as compiler barriers, but a compiler barrier is much lighter in weight than a memory barrier. Indeed, a compiler barrier is practically free, because it simply prevents the compiler from <em class="calibre4">possibly</em> rearranging things.</p><div class="calibre_3"> </div>
<p class="calibre_2"><a href="#filepos699916">Table 10.12</a> has a full listing of the memory and compiler barrier methods provided by all architectures in the Linux kernel.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos699916"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Table 10.12. Memory and Compiler Barrier Methods</span></span></p><div class="calibre_24"> </div>
<p class="calibre_23"><img alt="image" src="images/00140.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2"><a id="filepos700214"></a>Note that the actual effects of the barriers vary for each architecture. For example, if a machine does not perform out-of-order stores (for example, Intel x86 processors do not), <code class="calibre6"><span class="calibre7">wmb()</span></code> does nothing. You can use the appropriate memory barrier for the worst case (that is, the weakest ordering processor) and your code will compile optimally for your architecture.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos700663"> </div>
<h3 class="calibre_21"><span class="bold">Conclusion</span></h3><div class="calibre_22"> </div>
<p class="calibre_2">This chapter applied the concepts and theories of the last chapter to help you understand the actual methods provided by the Linux kernel for enforcing synchronization and concurrency. We started with the simplest method of ensuring synchronization, atomic operations. We then looked at spin locks, the most common lock in the kernel, which provide a lightweight single-holder lock that busy waits while contended. Next, we discussed semaphores, a sleeping lock, and its more general (and used) cousin, the mutex. Following mutexes, we studied less common, more specialized locking primitives such as completion variables and seq locks. We poked fun at the BKL, looked at preemption disabling, and tackled barriers. It has been a wild ride.</p><div class="calibre_3"> </div>
<p class="calibre_2">Armed with this chapter’s arsenal of synchronization methods, you can now write kernel code that prevents race conditions, ensures the correct synchronization, and correctly runs on machines with multiple processors.</p><div class="calibre_3"> </div>  <div class="mbp_pagebreak" id="calibre_pb_54"></div>
</body></html>
