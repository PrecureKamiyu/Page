<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>18.10  Advanced Topics in Concurrency Control</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part337.htm">&lt; 上一个</a><span> | </span><a href="../database.html">内容</a><span> | </span><a href="part339.htm">下一个 &gt;</a></p><p class="s65" style="padding-left: 72pt;text-indent: 0pt;text-align: left;">18.10  <span style=" color: #00AEEF;">Advanced Topics in Concurrency Control</span></p><p style="padding-top: 12pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">Instead of using two-phase locking, special-purpose concurrency control techniques can be used for index structures, resulting in improved concurrency. When using main- memory databases, conversely, index concurrency control can be simpliﬁed. Further, concurrency control actions often become bottlenecks in main-memory databases, and techniques such as latch-free data structures have been designed to reduce concurrency control overheads. Instead of detecting conﬂicts at the level of reads and writes, it is pos- sible to consider operations, such as increment of a counter, as basic operations, and perform concurrency control on the basis of conﬂicts between operations. Certain ap- plications require guarantees on transaction completion time. Specialized concurrency control techniques have been developed for such applications.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-top: 4pt;padding-left: 88pt;text-indent: 0pt;text-align: left;">18.10.1 Online Index Creation</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">When we are dealing with large volumes of data (ranging in the terabytes), operations such as creating an index can take a long time — perhaps hours or even days. When the operation ﬁnishes, the index contents must be consistent with the contents of the relation, and all further updates to the relation must maintain the index.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">One way of ensuring that the data and the index are consistent is to block all up- dates to the relation while the index is created, for example by getting a shared lock on the relation. After the index is created, and the relation metadata are updated to reﬂect the existence of the index locks can be released. Subsequent update transactions will ﬁnd the index, and carry out index maintenance as part of the transaction.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">However, the above approach would make the system unavailable for updates to the relation for a very long time, which is unacceptable. Instead, most database systems support <span class="s63">online index creation</span>, which allows relation updates to occur even as the index is being created. Online index creation can be carried out as follows:</p><p class="s63" style="padding-top: 7pt;padding-left: 113pt;text-indent: -16pt;text-align: justify;">1. <span class="p">Index creation gets a snapshot of the relation and uses it to create the index; mean- while, the system logs all updates to the relation that happen after the snapshot is created.</span></p><p class="s63" style="padding-top: 6pt;padding-left: 113pt;text-indent: -17pt;text-align: justify;">2. <span class="p">When the index on the snapshot data is complete, it is not yet ready for use, since subsequent updates are missing. At this point, the log of updates to the relation is used to update the index. But while the index update is being carried out, further updates may be happening on the relation.</span></p><p class="s63" style="padding-top: 6pt;padding-left: 113pt;text-indent: -17pt;text-align: justify;">3. <span class="p">The index update then obtains a shared lock on the relation to prevent further updates and applies all remaining updates to the index. At this point, the index is consistent with the contents of the relation. The relation metadata are then updated to indicate the existence of the new index. Subsequently all locks are released.</span></p><p style="padding-left: 113pt;text-indent: 0pt;text-align: justify;">Any transaction that executes after this will see the existence of the index; if the transaction updates the relation, it will also update the index.</p><p style="padding-top: 7pt;padding-left: 88pt;text-indent: 17pt;text-align: justify;">Creation of materialized views that are maintained immediately, as part of the transaction that updates any of the relations used in the view, can also beneﬁt from on- line construction techniques that are similar to online index construction. The query deﬁning the view is executed on a snapshot of the participating relations, and subse- quent updates are logged. The updates are applied to the materialized view, with a ﬁnal phase of locking and catching up similar to the case of online index creation.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Schema changes such as adding or deleting attributes or constraints can also have a signiﬁcant impact if relations are locked while the schema change is implemented on all tuples.</p><p class="s39" style="padding-top: 4pt;padding-left: 107pt;text-indent: -16pt;text-align: justify;">• <span class="s40">For adding or deleting attributes, a version number can be kept with each tuple, and tuples can be updated in the background, or whenever they are accessed; the version number is used to determine if the schema change has already been applied</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 139pt;text-indent: 0pt;text-align: justify;">to the tuple, and the schema change is applied to the tuple if it has not already been applied.</p><p class="s40" style="padding-top: 3pt;padding-left: 139pt;text-indent: -16pt;text-align: justify;"><span class="s39">• </span>Adding of constraints requires that existing data must be checked to ensure that the constraint is satisﬁed. For example, adding a primary or unique key constraint on an attribute <span class="s41">ID </span>requires checking of existing tuples to ensure that no two tuples have the same <span class="s41">ID </span>value. Online addition of such constraints is done in a manner similar to online index construction, by checking the constraints on a relation snapshot, while keeping a log of updates that occur after the snapshot. The updates in the log must then be checked to ensure that they do not violate the constraint. In a ﬁnal catch-up phase, the constraint is checked on any remaining updates in the log and added to the relation metadata while holding a shared lock on the relation.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 119pt;text-indent: 0pt;text-align: left;">18.10.2 Concurrency in Index Structures</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">It is possible to treat access to index structures like any other database structure and to apply the concurrency-control techniques discussed earlier. However, since indices are accessed frequently, they would become a point of great lock contention, leading to a low degree of concurrency. Luckily, indices do not have to be treated like other database structures; it is desirable to release index locks early, in a non-two-phase manner, to maximize concurrency. In fact, it is perfectly acceptable for a transaction to perform a lookup on an index twice and to ﬁnd that the structure of the index has changed in between, as long as the index lookup returns the correct set of tuples. Informally, it is acceptable to have nonserializable concurrent access to an index, as long as the accuracy of the index is maintained; we formalize this notion next.</p><p class="s63" style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Operation serializability <span class="p">for index operations is deﬁned as follows: A concurrent execution of index operations on an index is said to be serializable if there is a se- rialization order of the operations that is consistent with the results that each index operation in the concurrent execution sees, as well as with the ﬁnal state of the index after all the operations have been executed. Index concurrency control techniques must ensure that any concurrent execution of index operations is serializable.</span></p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">We outline two techniques for managing concurrent access to B<span class="s181">+</span>-trees as well as an index-concurrency control technique to prevent the phantom phenomenon. The on- line bibliographical notes reference other techniques for B<span class="s181">+</span>-trees as well as techniques for other index structures. The techniques that we present for concurrency control on B<span class="s181">+</span>-trees are based on locking, but neither two-phase locking nor the tree protocol is employed. The algorithms for lookup, insertion, and deletion are those used in Chapter 14, with only minor modiﬁcations.</p><p style="padding-left: 137pt;text-indent: 0pt;line-height: 12pt;text-align: justify;">The ﬁrst technique is called the <span class="s63">crabbing protocol</span>:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s39" style="padding-left: 139pt;text-indent: -16pt;text-align: justify;">• <span class="s40">When searching for a key value, the crabbing protocol ﬁrst locks the root node in shared mode. When traversing down the tree, it acquires a shared lock on the child node to be traversed further. After acquiring the lock on the child node, it releases the lock on the parent node. It repeats this process until it reaches a leaf node.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s39" style="padding-top: 4pt;padding-left: 91pt;text-indent: 0pt;text-align: left;">• <span class="s40">When inserting or deleting a key value, the crabbing protocol takes these actions:</span></p><p class="s50" style="padding-top: 10pt;padding-left: 122pt;text-indent: -8pt;line-height: 77%;text-align: justify;">° <span class="s51">It follows the same protocol as for searching until it reaches the desired leaf node. Up to this point, it obtains (and releases) only shared locks.</span></p><p class="s50" style="padding-top: 6pt;padding-left: 113pt;text-indent: 0pt;text-align: justify;">° <span class="s51">It locks the leaf node in exclusive mode and inserts or deletes the key value.</span></p><p class="s50" style="padding-top: 4pt;padding-left: 122pt;text-indent: -8pt;line-height: 77%;text-align: justify;">° <span class="s51">If it needs to split a node or coalesce it with its siblings, or redistribute key values between siblings, the crabbing protocol locks the parent of the node in</span></p><p style="padding-left: 122pt;text-indent: 0pt;text-align: justify;">exclusive mode. After performing these actions, it releases the locks on the node and siblings.</p><p style="padding-left: 122pt;text-indent: 15pt;text-align: justify;">If the parent requires splitting, coalescing, or redistribution of key values, the protocol retains the lock on the parent, and splitting, coalescing, or redistri- bution propagates further in the same manner. Otherwise, it releases the lock on the parent.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 88pt;text-indent: 17pt;text-align: right;">The protocol gets its name from the way in which crabs advance by moving side- ways, moving the legs on one side, then the legs on the other, and so on alternately. The progress of locking while the protocol both goes down the tree and goes back up (in case of splits, coalescing, or redistribution) proceeds in a similar crab-like manner. Once a particular operation releases a lock on a node, other operations can access that node. There is a possibility of deadlocks between search operations coming down the tree, and splits, coalescing, or redistribution propagating up the tree. The system can easily handle such deadlocks by restarting the search operation from the root, after</p><p style="padding-left: 88pt;text-indent: 0pt;text-align: justify;">releasing the locks held by the operation.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Locks that are held for a short duration, instead of being held in a two-phase man- ner, are often referred to as <span class="s63">latches</span>. Latches are used internally in databases to achieve mutual exclusion on shared data structures. In the above case, locks are held in a way that does not ensure mutual exclusion during an insert or delete operation, yet the resultant execution of index operations is serializable.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The second technique achieves even more concurrency, avoiding even holding the lock on one node while acquiring the lock on another node; thereby, deadlocks are avoided, and concurrency is increased. This technique uses a modiﬁed version of B<span class="s181">+</span>- trees called <span class="s63">B-link trees</span>; B-link trees require that every node (including internal nodes, not just the leaves) maintain a pointer to its right sibling. This pointer is required be- cause a lookup that occurs while a node is being split may have to search not only that node but also that node’s right.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Unlike the crabbing protocol, the <span class="s63">B-link-tree locking protocol </span>holds locks on only one internal node at a time. The protocol releases the lock on the current internal node before requesting a lock on a child node (when traversing downwards), or on a parent node (while traversing upwards during a split or merge). Doing so can result in anomalies: for example, between the time the lock on a node is released and the lock on a parent is requested, a concurrent insert or delete on a sibling may cause a split or merge on the parent, and the original parent node may no longer be a parent of the</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">child node when it is locked. The protocol detects and handles such situations, ensuring operation serializability while avoiding deadlocks between operations and increasing concurrency compared to the crabbing protocol.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">The phantom phenomenon, where conﬂicts between a predicate read and an insert or update are not detected, can allow nonserializable executions to occur. The index- locking technique, which we saw in Section 18.4.3, prevents the phantom phenomenon by locking index leaf nodes in a two-phase manner. Instead of locking an entire index leaf node, some index concurrency-control schemes use <span class="s63">key-value locking </span>on individual key values, allowing other key values to be inserted or deleted from the same leaf. Key- value locking thus provides increased concurrency.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Using key-value locking na¨ıvely, however, would allow the phantom phenomenon to occur; to prevent the phantom phenomenon, the <span class="s63">next-key locking </span>technique is used. In this technique, every index lookup must lock not only the keys found within the range (or the single key, in case ofa point lookup) but also the next-key value — that is, the key value just greater than the last key value that was within the range. Also, every insert must lock not only the value that is inserted, but also the next-key value. Thus, if a transaction attempts to insert a value that was within the range of the index lookup of another transaction, the two transactions would conﬂict on the key value next to the inserted key value. Similarly, deletes must also lock the next-key value to the value being deleted to ensure that conﬂicts with subsequent range lookups of other queries are detected.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-top: 7pt;padding-left: 119pt;text-indent: 0pt;text-align: left;">18.10.3 Concurrency Control in Main-Memory Databases</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">With data stored on hard disk, the cost of <span class="s44">I/O </span>operations often dominates the cost of transaction processing. When disk <span class="s44">I/O </span>is the bottleneck cost in a system, there is little beneﬁt from optimizing other smaller costs, such as the cost of concurrency control. However, in a main-memory database, with disk <span class="s44">I/O </span>no longer the bottleneck, systems beneﬁt from reducing other costs, such as query processing costs, as we saw in Section 15.8; we now consider how to reduce the cost of concurrency control in main-memory databases.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">As we saw in Section 18.10.2, concurrency-control techniques for operations on disk-based index structures acquire locks on individual nodes, to increase the potential for concurrent access to the index. However, such locking comes at the increased cost of acquiring the locks. In a main-memory database, where data are in memory, index operations take very little time for execution. Thus, it may be acceptable to perform locking at a coarse granularity: for example, the entire index could be locked using a single latch (i.e., short duration lock), the operation performed, and the latch released. The reduced overhead of locking has been found to make up for the slightly reduced concurrency, and to improve overall performance.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">There is another way to improve performance with in-memory indices, using atomic instructions to carry out index updates without acquiring any latches at all.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 88pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="494" height="1" alt="image" src="Image_3025.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-top: 4pt;padding-left: 218pt;text-indent: 0pt;text-align: left;">insert<span class="p">(</span>value<span class="p">, </span>head<span class="p">) </span><span class="s95">{</span></p><p class="s13" style="padding-left: 239pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">node <span class="p">= </span><b>new </b>node</p><p class="s13" style="padding-top: 3pt;padding-left: 239pt;text-indent: 0pt;line-height: 65%;text-align: justify;">node<span class="s15">−</span><span class="s83">&gt;</span>value <span class="p">= </span>value node<span class="s15">−</span><span class="s83">&gt;</span>next <span class="p">= </span>head head <span class="p">= </span>node</p><p class="s95" style="text-indent: 0pt;text-align: center;">}</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 88pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="494" height="1" alt="image" src="Image_3026.png"/></span></p><p class="s73" style="padding-top: 8pt;padding-left: 59pt;text-indent: 0pt;text-align: center;">Figure 18.22 <span class="s74">Insertion code that is unsafe with concurrent inserts.</span></p><p style="padding-top: 8pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">Data structures implementations that support concurrent operations without requir- ing latches are called <span class="s63">latch-free data structure </span>implementations.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Consider a linked list, where each node has a value <i>value </i>and a <i>next </i>pointer, and the head of the linked list is stored in the variable <i>head</i>. The function <i>insert</i>() shown in Figure 18.22 would work correctly to insert a node at the head of the list, if there are no concurrent invocations of the code for the same list.<span class="s76">7</span></p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">However, if two processes execute the <i>insert</i>() function concurrently on the same list, it is possible that both of them would read the same value of variable <i>head</i>, and then both would update the variable after that. The ﬁnal result would contain one of the two nodes being inserted, while the other node being inserted would be lost.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">One way of preventing such a problem is to get an exclusive latch (short term lock) on the linked list, perform the <i>insert</i>() function, and then release the latch. The <i>insert</i>() function can be modiﬁed to acquire and release a latch on the list.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">An alternative implementation, which is faster in practice, is to use an atomic <i>compare-and-swap</i>() instruction, abbreviated to CAS, which works as follows: The in- struction CAS(<i>var</i>, <i>oldval</i>, <i>newval</i>) takes three arguments: a variable <i>var </i>and two values, <i>oldval </i>and <i>newval</i>. The instruction does the following atomically: check if the value of <i>var </i>is equal to <i>oldval</i>, and if so, set <i>var </i>to <i>newval</i>, and return success. If the value is not equal, it returns failure. The instruction is supported by most modern processor architectures, and it executes very quickly.</p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3027.png"/></span></p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The function <i>insert latchfree</i>(), shown in Figure 18.23 is a modiﬁcation of <i>insert</i>() that works correctly even with concurrent inserts on the same list, without obtaining any latches. With this code, if two processes concurrently read the old value of <i>head</i>, and then both execute the CAS instruction, one of them will ﬁnd the CAS instruction returning success, while the other one will ﬁnd it returning failure since the value of <i>head </i>changes between the time it is read and when the CAS instruction is executed. The repeat loop then retries the insert using the new value of <i>head</i>, until it succeeds.</p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3028.png"/></span></p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Function <i>delete latchfree</i>(), shown in Figure 18.23, similarly implements deletion from the head of the list using the compare and swap instruction, without requiring latches. (In this case, the list is used as a stack, since deletion occurs at the head of</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 88pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="96" height="1" alt="image" src="Image_3029.png"/></span></p><p class="s77" style="padding-top: 3pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">7<span class="s78">We assume all parameters are passed by reference.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 119pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="494" height="1" alt="image" src="Image_3030.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3031.png"/></span></p><p class="s13" style="padding-top: 5pt;padding-left: 187pt;text-indent: -21pt;line-height: 92%;text-align: left;">insert latchfree<span class="p">(</span>head<span class="p">, </span>value<span class="p">) </span><span class="s95">{ </span>node <span class="p">= </span><b>new </b>node node<span class="s15">−</span><span class="s83">&gt;</span>value <span class="p">= </span>value</p><p class="s46" style="padding-left: 187pt;text-indent: 0pt;line-height: 8pt;text-align: left;">repeat</p><p class="s13" style="padding-top: 1pt;padding-left: 208pt;text-indent: 0pt;line-height: 84%;text-align: left;">oldhead <span class="p">= </span>head node<span class="s15">−</span><span class="s83">&gt;</span>next <span class="p">= </span>oldhead</p><p class="s13" style="padding-left: 208pt;text-indent: 0pt;line-height: 8pt;text-align: left;">result <span class="p">= CAS(</span>head<span class="p">, </span>oldhead<span class="p">, </span>node<span class="p">)</span></p><p style="padding-left: 187pt;text-indent: 0pt;text-align: left;"><b>until </b>(<i>result </i><span class="s15">== </span>success)</p><p class="s95" style="padding-left: 166pt;text-indent: 0pt;line-height: 13pt;text-align: left;">}</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3032.png"/></span></p><p class="s13" style="padding-left: 166pt;text-indent: 0pt;text-align: left;">delete latchfree<span class="p">(</span>head<span class="p">) </span><span class="s95">{</span></p><p style="padding-left: 187pt;text-indent: 0pt;text-align: left;">/* This function is not quite safe; see explanation in text. */</p><p class="s46" style="padding-left: 187pt;text-indent: 0pt;text-align: left;">repeat</p><p class="s13" style="padding-left: 208pt;text-indent: 0pt;line-height: 11pt;text-align: left;">oldhead <span class="p">= </span>head</p><p class="s13" style="padding-left: 208pt;text-indent: 0pt;line-height: 17pt;text-align: left;">newhead <span class="p">= </span>oldhead<span class="s15">−</span><span class="s83">&gt;</span>next</p><p class="s13" style="padding-left: 208pt;text-indent: 0pt;line-height: 10pt;text-align: left;">result <span class="p">= CAS(</span>head<span class="p">, </span>oldhead<span class="p">, </span>newhead<span class="p">)</span></p><p style="padding-left: 187pt;text-indent: 0pt;text-align: left;"><b>until </b>(<i>result </i><span class="s15">== </span>success)</p><p class="s95" style="padding-left: 166pt;text-indent: 0pt;line-height: 13pt;text-align: left;">}</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 119pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="494" height="1" alt="image" src="Image_3033.png"/></span></p><p class="s73" style="padding-top: 8pt;padding-left: 182pt;text-indent: 0pt;text-align: left;">Figure 18.23 <span class="s74">Latch-free insertion and deletion on a list.</span></p><p style="padding-top: 10pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">the list.) However, it has a problem: it does not work correctly in some rare cases. The problem can occur when a process <i>P</i>1 is performing a delete, with node <i>n</i>1 at the head of the list, and concurrently a second process <i>P</i>2 deletes the ﬁrst two elements, <i>n</i>1 and <i>n</i>2, and then reinserts <i>n</i>1 at the head of the list, with some other element, say <i>n</i>3 as the next element. If <i>P</i>1 read <i>n</i>1 before <i>P</i>2 deleted it, but performs the CAS after <i>P</i>2 has reinserted <i>n</i>1, the CAS operation of <i>P</i>1 will succeed, but set the head of the list to point to <i>n</i>2, which has been deleted, leaving the list in an inconsistent state. This problem is known as the <i>ABA problem</i>.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">One solution is to keep a counter along with each pointer, which is incremented every time the pointer is updated. The CAS instruction is applied on the (pointer, counter) pair; most CAS implementations on 64 bit processors support such a double compare-and-swap on 128 bits. The ABA problem can then be avoided since although the reinsert of <i>n</i>1 would result in the head pointing to <i>n</i>1, the counter would be diﬀer- ent, resulting in the CAS operation of <i>P</i>1 failing. See the online solutions to Practice Exercise 18.16 for more details of the ABA problem and the above solution. With such a modiﬁcation, both inserts and deletes can be executed concurrently without acquir- ing latches. There are other solutions that do not require a double compare-and-swap, but are more complicated.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Deletion from the tail of the list (to implement a queue) as well as more complex data structures such as hash indices and search trees can also be implemented in a latch-</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">free manner. It is best to use latch-free data structure implementations (more often referred to as <span class="s63">lock-free data structure </span>implementations) that are provided by standard libraries, such as the Boost library for C++, or the <span class="s49">ConcurrentLinkedQueue </span>class in Java; do not build your own, since you may introduce bugs due to “<i>race conditions</i>” between concurrent accesses, that can be very hard to detect or debug.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Since today’s multiprocessor <span class="s44">CPU</span>s have a large number of cores, latch-free imple- mentations have been found to signiﬁcantly outperform implementations that obtain latches, in the context of in-memory indices and other in-memory data structures</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-top: 10pt;padding-left: 88pt;text-indent: 0pt;text-align: left;">18.10.4 Long-Duration Transactions</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">The transaction concept developed initially in the context of data-processing applica- tions, in which most transactions are noninteractive and of short duration. Serious problems arise when this concept is applied to database systems that involve human interaction. Such transactions have these key properties:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 8pt;padding-left: 107pt;text-indent: -16pt;text-align: justify;"><span class="s39">• </span><b>Long duration</b>. Once a human interacts with an active transaction, that transaction becomes a <span class="s63">long-duration transaction </span>from the perspective of the computer, since human response time is slow relative to computer speed. Furthermore, in design applications, the human activity may involve hours, days, or an even longer period. Thus, transactions may be of long duration in human terms, as well as in machine terms.</p><p class="s39" style="padding-top: 3pt;padding-left: 107pt;text-indent: -16pt;text-align: justify;">• <span class="s46">Exposure of uncommitted data</span><span class="p">. Data generated and displayed to a user by a long- duration transaction are uncommitted, since the transaction may abort. Thus, users— and, as a result, other transactions— may be forced to read uncommitted data. If several users are cooperating on a project, user transactions may need to exchange data prior to transaction commit.</span></p><p class="s39" style="padding-top: 3pt;padding-left: 107pt;text-indent: -16pt;text-align: justify;">• <span class="s46">Subtasks</span><span class="p">. An interactive transaction may consist of a set of subtasks initiated by the user. The user may wish to abort a subtask without necessarily causing the entire transaction to abort.</span></p><p class="s39" style="padding-top: 4pt;padding-left: 107pt;text-indent: -16pt;text-align: justify;">• <span class="s46">Recoverability</span><span class="p">. It is unacceptable to abort a long-duration interactive transaction because of a system crash. The active transaction must be recovered to a state that existed shortly before the crash so that relatively little human work is lost.</span></p><p class="s39" style="padding-top: 4pt;padding-left: 107pt;text-indent: -16pt;text-align: justify;">• <span class="s46">Performance</span><span class="p">. Good performance in an interactive transaction system is deﬁned as fast response time. This deﬁnition is in contrast to that in a noninteractive system, in which high throughput (number of transactions per second) is the goal. Systems with high throughput make eﬃcient use of system resources. However, in the case of interactive transactions, the most costly resource is the user. If the eﬃciency and satisfaction of the user are to be optimized, response time should be fast (from a human perspective). In those cases where a task takes a long time, response time</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:241.014pt" cellspacing="0"><tr style="height:18pt"><td style="width:64pt;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#221E1F;border-right-style:solid;border-right-width:1pt;border-right-color:#221E1F" bgcolor="#C6E9FA"><p class="s71" style="padding-top: 2pt;padding-left: 24pt;padding-right: 24pt;text-indent: 0pt;line-height: 14pt;text-align: center;">T<span class="s232">1</span></p></td><td style="width:64pt;border-left-style:solid;border-left-width:1pt;border-left-color:#221E1F;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#221E1F" bgcolor="#C6E9FA"><p class="s71" style="padding-top: 2pt;padding-left: 26pt;padding-right: 26pt;text-indent: 0pt;line-height: 14pt;text-align: center;">T<span class="s232">2</span></p></td></tr><tr style="height:17pt"><td style="width:64pt;border-top-style:solid;border-top-width:1pt;border-top-color:#221E1F;border-right-style:solid;border-right-width:1pt;border-right-color:#221E1F"><p class="s72" style="padding-top: 3pt;padding-left: 6pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><span class="s424">read</span>(<i>A</i>)</p></td><td style="width:64pt;border-top-style:solid;border-top-width:1pt;border-top-color:#221E1F;border-left-style:solid;border-left-width:1pt;border-left-color:#221E1F"><p style="text-indent: 0pt;text-align: left;"><br/></p></td></tr><tr style="height:15pt"><td style="width:64pt;border-right-style:solid;border-right-width:1pt;border-right-color:#221E1F"><p class="s71" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">A <span class="s72">:= </span>A <span class="s365">− </span><span class="s72">50</span></p></td><td style="width:64pt;border-left-style:solid;border-left-width:1pt;border-left-color:#221E1F"><p style="text-indent: 0pt;text-align: left;"><br/></p></td></tr><tr style="height:13pt"><td style="width:64pt;border-right-style:solid;border-right-width:1pt;border-right-color:#221E1F"><p class="s72" style="padding-left: 6pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><span class="s424">write</span>(<i>A</i>)</p></td><td style="width:64pt;border-left-style:solid;border-left-width:1pt;border-left-color:#221E1F"><p style="text-indent: 0pt;text-align: left;"><br/></p></td></tr><tr style="height:13pt"><td style="width:64pt;border-right-style:solid;border-right-width:1pt;border-right-color:#221E1F"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:64pt;border-left-style:solid;border-left-width:1pt;border-left-color:#221E1F"><p class="s72" style="padding-left: 7pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><span class="s424">read</span>(<i>B</i>)</p></td></tr><tr style="height:15pt"><td style="width:64pt;border-right-style:solid;border-right-width:1pt;border-right-color:#221E1F"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:64pt;border-left-style:solid;border-left-width:1pt;border-left-color:#221E1F"><p class="s71" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">B <span class="s72">:= </span>B <span class="s365">− </span><span class="s72">10</span></p></td></tr><tr style="height:13pt"><td style="width:64pt;border-right-style:solid;border-right-width:1pt;border-right-color:#221E1F"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:64pt;border-left-style:solid;border-left-width:1pt;border-left-color:#221E1F"><p class="s72" style="padding-left: 7pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><span class="s424">write</span>(<i>B</i>)</p></td></tr><tr style="height:13pt"><td style="width:64pt;border-right-style:solid;border-right-width:1pt;border-right-color:#221E1F"><p class="s72" style="padding-left: 6pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><span class="s424">read</span>(<i>B</i>)</p></td><td style="width:64pt;border-left-style:solid;border-left-width:1pt;border-left-color:#221E1F"><p style="text-indent: 0pt;text-align: left;"><br/></p></td></tr><tr style="height:15pt"><td style="width:64pt;border-right-style:solid;border-right-width:1pt;border-right-color:#221E1F"><p class="s71" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">B <span class="s72">:= </span>B <span class="s365">+ </span><span class="s72">50</span></p></td><td style="width:64pt;border-left-style:solid;border-left-width:1pt;border-left-color:#221E1F"><p style="text-indent: 0pt;text-align: left;"><br/></p></td></tr><tr style="height:13pt"><td style="width:64pt;border-right-style:solid;border-right-width:1pt;border-right-color:#221E1F"><p class="s72" style="padding-left: 6pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><span class="s424">write</span>(<i>B</i>)</p></td><td style="width:64pt;border-left-style:solid;border-left-width:1pt;border-left-color:#221E1F"><p style="text-indent: 0pt;text-align: left;"><br/></p></td></tr><tr style="height:13pt"><td style="width:64pt;border-right-style:solid;border-right-width:1pt;border-right-color:#221E1F"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:64pt;border-left-style:solid;border-left-width:1pt;border-left-color:#221E1F"><p class="s72" style="padding-left: 7pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><span class="s424">read</span>(<i>A</i>)</p></td></tr><tr style="height:15pt"><td style="width:64pt;border-right-style:solid;border-right-width:1pt;border-right-color:#221E1F"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:64pt;border-left-style:solid;border-left-width:1pt;border-left-color:#221E1F"><p class="s71" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">A <span class="s72">:= </span>A <span class="s365">+ </span><span class="s72">10</span></p></td></tr><tr style="height:14pt"><td style="width:64pt;border-right-style:solid;border-right-width:1pt;border-right-color:#221E1F"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:64pt;border-left-style:solid;border-left-width:1pt;border-left-color:#221E1F"><p class="s72" style="padding-left: 7pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><span class="s424">write</span>(<i>A</i>)</p></td></tr></table><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s73" style="padding-top: 4pt;padding-left: 195pt;text-indent: 0pt;text-align: left;">Figure 18.24 <span class="s74">A non-conflict-serializable schedule.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 139pt;text-indent: 0pt;text-align: left;">should be predictable (i.e., the variance in response times should be low) so that users can manage their time well.</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 17pt;text-align: justify;">Snapshot isolation, described in Section 18.8, can provide a partial solution to these issues, as can the <i>optimistic concurrency control without read validation </i>protocol described in Section 18.9.3. The latter protocol was in fact designed speciﬁcally to deal with long-duration transactions that involve user interaction. Although it does not guarantee serializability, optimistic concurrency control without read validation is quite widely used.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">However, when transactions are of long duration, conﬂicting updates are more likely, resulting in additional waits or aborts. These considerations are the basis for the alternative concepts of correctness of concurrent executions and transaction recovery that we consider in the remainder of this section.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 119pt;text-indent: 0pt;text-align: left;">18.10.5 Concurrency Control with Operations</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">Consider a bank database consisting of two accounts <i>A </i>and <i>B</i>, with the consistency requirement that the sum <i>A </i>+ <i>B </i>be preserved. Consider the schedule of Figure 18.24. Although the schedule is not conﬂict serializable, it nevertheless preserves the sum of <i>A+ B</i>. It also illustrates two important points about the concept of correctness without serializability.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s63" style="padding-left: 128pt;text-indent: 0pt;text-align: left;">1. <span class="p">Correctness depends on the speciﬁc consistency constraints for the database.</span></p><p class="s63" style="padding-top: 6pt;padding-left: 145pt;text-indent: -17pt;text-align: left;">2. <span class="p">Correctness depends on the properties of operations performed by each transac- tion.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 17pt;text-align: justify;">While two-phase locking ensures serializability, it can result in poor concurrency in case a large number of transactions conﬂict on a particular data item. Timestamp and validation protocols also have similar problems in this case.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Concurrency can be increased by treating some operations besides <b>read </b>and <b>write </b>as fundamental low-level operations and to extend concurrency control to deal with them.</p><p style="padding-left: 106pt;text-indent: 0pt;text-align: justify;">Consider the case of materialized view maintenance, which we saw in Section</p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3034.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3035.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3036.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3037.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3038.png"/></span></p><p style="padding-left: 88pt;text-indent: 0pt;text-align: justify;">16.5.1. Suppose there is a relation <i>sales</i>(<i>date, custID, itemID, amount</i>), and a materi- alized view <i>daily sales total</i>(<i>date, total amount</i>), that records total sales on each day. Every sales transaction must update the materialized view as part of the transaction if immediate view maintenance is used. With a high volume of sales, and every trans- action updating the same record in the <i>daily sales total </i>relation, the degree of concur- rency will be quite low if two-phase locking is used on the materialized view.</p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3039.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3040.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3041.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3042.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3043.png"/></span></p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">A better way to perform concurrency control for the materialized view is as follows: Observe that each transaction increments a record in the <i>daily sales total </i>relation by some value but does not need to see the value. It would make sense to have an operation <span class="s49">increment</span>(<i>v</i>, <i>n</i>), that adds a value <i>n </i>to a variable <i>v </i>without making the value of <i>v </i>visible to the transaction; we shall see shortly how this is implemented. In our sales example, a transaction that inserts a <i>sales </i>tuple with amount <i>n </i>invokes the increment operation with the ﬁrst argument being the <i>total amount </i>value of the appropriate tuple in the materialized view <i>daily sales total</i>, and the second argument being the value <i>n</i>.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The <span class="s49">increment </span>operation does not lock the variable in a two-phase manner; how- ever, individual operations should be executed serially on the variable. Thus, if two increment operations are initiated concurrently on the same variable, one must ﬁn- ish before the other is allowed to start. This can be ensured by acquiring an exclusive latch (lock) on the variable <i>v </i>before starting the operation and releasing the latch after the operation has ﬁnished its updates. Increment operations can also be implemented using compare-and-swap operations, without getting latches.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Two transactions that invoke the <span class="s49">increment </span>operation should be allowed to execute concurrently to avoid concurrency control bottlenecks. In fact, increment operations executed by two transactions do not conﬂict with each other, since the ﬁnal result is the same regardless of the order in which the operations were executed. If one of the transactions rolls back, the <span class="s49">increment</span>(<i>v</i>, <i>n</i>) operation must be rolled back by execut- ing an operation <span class="s49">increment</span>(<i>v</i>, <span class="s15">−</span><i>n</i>), which adds a negative of the original value; this operation is referred to as a <span class="s63">compensating operation</span>.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: right;">However, if a transaction <i>T </i>wishes to read the materialized view, it clearly conﬂicts with any concurrent transaction that has performed an increment operation; the value that <i>T </i>reads depends on whether the other transaction is serialized before or after <i>T </i>. We can deﬁne a locking protocol to handle the preceding situation by deﬁning an <span class="s63">increment lock</span>. The increment lock is compatible with itself but is not compatible with shared and exclusive locks. Figure 18.25 shows a lock-compatibility matrix for three</p><p style="padding-left: 88pt;text-indent: 0pt;text-align: left;">lock modes: share mode, exclusive mode, and increment mode.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:234.982pt" cellspacing="0"><tr style="height:19pt"><td style="width:31pt;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#231F20;border-right-style:solid;border-right-width:1pt;border-right-color:#231F20" bgcolor="#C7EAFB"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:36pt;border-left-style:solid;border-left-width:1pt;border-left-color:#231F20;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#231F20;border-right-style:solid;border-right-width:1pt;border-right-color:#231F20" bgcolor="#C7EAFB"><p class="s444" style="padding-top: 2pt;padding-left: 2pt;text-indent: 0pt;text-align: center;">S</p></td><td style="width:38pt;border-left-style:solid;border-left-width:1pt;border-left-color:#231F20;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#231F20;border-right-style:solid;border-right-width:1pt;border-right-color:#231F20" bgcolor="#C7EAFB"><p class="s444" style="padding-top: 2pt;padding-left: 2pt;text-indent: 0pt;text-align: center;">X</p></td><td style="width:34pt;border-left-style:solid;border-left-width:1pt;border-left-color:#231F20;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#231F20;border-right-style:solid;border-right-width:1pt;border-right-color:#231F20" bgcolor="#C7EAFB"><p class="s444" style="padding-top: 2pt;padding-left: 1pt;text-indent: 0pt;text-align: center;">I</p></td></tr><tr style="height:19pt"><td style="width:31pt;border-top-style:solid;border-top-width:1pt;border-top-color:#231F20;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#231F20;border-right-style:solid;border-right-width:1pt;border-right-color:#231F20" bgcolor="#C7EAFB"><p class="s444" style="padding-top: 2pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">S</p></td><td style="width:36pt;border-top-style:solid;border-top-width:1pt;border-top-color:#231F20;border-left-style:solid;border-left-width:1pt;border-left-color:#231F20;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#231F20;border-right-style:solid;border-right-width:1pt;border-right-color:#231F20"><p class="s444" style="padding-top: 2pt;padding-left: 3pt;padding-right: 5pt;text-indent: 0pt;text-align: center;">true</p></td><td style="width:38pt;border-top-style:solid;border-top-width:1pt;border-top-color:#231F20;border-left-style:solid;border-left-width:1pt;border-left-color:#231F20;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#231F20;border-right-style:solid;border-right-width:1pt;border-right-color:#231F20"><p class="s444" style="padding-top: 3pt;padding-left: 7pt;padding-right: 6pt;text-indent: 0pt;text-align: center;">false</p></td><td style="width:34pt;border-top-style:solid;border-top-width:1pt;border-top-color:#231F20;border-left-style:solid;border-left-width:1pt;border-left-color:#231F20;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#231F20;border-right-style:solid;border-right-width:1pt;border-right-color:#231F20"><p class="s444" style="padding-top: 3pt;padding-left: 4pt;padding-right: 4pt;text-indent: 0pt;text-align: center;">false</p></td></tr><tr style="height:19pt"><td style="width:31pt;border-top-style:solid;border-top-width:1pt;border-top-color:#231F20;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#231F20;border-right-style:solid;border-right-width:1pt;border-right-color:#231F20" bgcolor="#C7EAFB"><p class="s444" style="padding-top: 2pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">X</p></td><td style="width:36pt;border-top-style:solid;border-top-width:1pt;border-top-color:#231F20;border-left-style:solid;border-left-width:1pt;border-left-color:#231F20;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#231F20;border-right-style:solid;border-right-width:1pt;border-right-color:#231F20"><p class="s444" style="padding-top: 2pt;padding-left: 5pt;padding-right: 5pt;text-indent: 0pt;text-align: center;">false</p></td><td style="width:38pt;border-top-style:solid;border-top-width:1pt;border-top-color:#231F20;border-left-style:solid;border-left-width:1pt;border-left-color:#231F20;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#231F20;border-right-style:solid;border-right-width:1pt;border-right-color:#231F20"><p class="s444" style="padding-top: 2pt;padding-left: 7pt;padding-right: 6pt;text-indent: 0pt;text-align: center;">false</p></td><td style="width:34pt;border-top-style:solid;border-top-width:1pt;border-top-color:#231F20;border-left-style:solid;border-left-width:1pt;border-left-color:#231F20;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#231F20;border-right-style:solid;border-right-width:1pt;border-right-color:#231F20"><p class="s444" style="padding-top: 2pt;padding-left: 4pt;padding-right: 4pt;text-indent: 0pt;text-align: center;">false</p></td></tr><tr style="height:19pt"><td style="width:31pt;border-top-style:solid;border-top-width:1pt;border-top-color:#231F20;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#231F20;border-right-style:solid;border-right-width:1pt;border-right-color:#231F20" bgcolor="#C7EAFB"><p class="s444" style="padding-top: 1pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">I</p></td><td style="width:36pt;border-top-style:solid;border-top-width:1pt;border-top-color:#231F20;border-left-style:solid;border-left-width:1pt;border-left-color:#231F20;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#231F20;border-right-style:solid;border-right-width:1pt;border-right-color:#231F20"><p class="s444" style="padding-top: 1pt;padding-left: 5pt;padding-right: 5pt;text-indent: 0pt;text-align: center;">false</p></td><td style="width:38pt;border-top-style:solid;border-top-width:1pt;border-top-color:#231F20;border-left-style:solid;border-left-width:1pt;border-left-color:#231F20;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#231F20;border-right-style:solid;border-right-width:1pt;border-right-color:#231F20"><p class="s444" style="padding-top: 1pt;padding-left: 7pt;padding-right: 6pt;text-indent: 0pt;text-align: center;">false</p></td><td style="width:34pt;border-top-style:solid;border-top-width:1pt;border-top-color:#231F20;border-left-style:solid;border-left-width:1pt;border-left-color:#231F20;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#231F20;border-right-style:solid;border-right-width:1pt;border-right-color:#231F20"><p class="s444" style="padding-top: 1pt;padding-left: 2pt;padding-right: 4pt;text-indent: 0pt;text-align: center;">true</p></td></tr></table><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s73" style="padding-top: 4pt;padding-left: 158pt;text-indent: 0pt;text-align: left;">Figure 18.25 <span class="s74">Lock-compatibility matrix with increment lock mode.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">As another example of special-purpose concurrency control for operations, con- sider an insert operation on a B<span class="s181">+</span>-tree index which releases locks early, as we saw in Section 18.10.2. In this case, there is no special lock mode, but holding locks on leaf nodes in a two-phase manner (or using next-key locking) as we saw in Section 18.10.2 ensures serializability. The insert operation may have modiﬁed several nodes of the B<span class="s181">+</span>- tree index. Other transactions may have read and updated these nodes further while processing other operations. To roll back the insertion, we would have to delete the</p><p style="padding-left: 119pt;text-indent: 0pt;line-height: 93%;text-align: justify;">record inserted by <i>T</i><span class="s97">i</span>; deletion is the compensating action for insertion. The result is a correct, consistent B<span class="s181">+</span>-tree, but not necessarily one with exactly the same structure as the one we had before <i>T</i><span class="s97">i </span>started.</p><p style="padding-left: 137pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">While operation locking can be done in a way that ensures serializability, in some</p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3044.png"/></span></p><p style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">cases it may even be used in a way that does not guarantee serializability, but where violations may be acceptable. Consider the case of concert tickets, where every transac- tion needs to access and update the total ticket sales. We can have an operation <span class="s49">incre- ment conditional</span>(<i>v</i>, <i>n</i>) which increments <i>v </i>by <i>n</i>, provided the resultant value would be</p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3045.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3046.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3047.png"/></span></p><p style="padding-left: 119pt;text-indent: 0pt;line-height: 91%;text-align: justify;"><span class="s86">≥ </span>0; the operation returns a status of success in case the resultant value is <span class="s86">≥ </span>0 and re- turns failure otherwise. Consider a transaction <i>T</i><span class="s97">i </span>executed to purchase tickets. To book three tickets, where variable <i>avail tickets </i>indicates the number of available tickets, the transaction can execute <span class="s49">increment conditional</span>(<i>avail tickets</i>, <span class="s15">−</span>3). A return value of</p><p style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">success indicates that there were enough tickets available, and decrements the avail- able tickets, while failure indicates insuﬃcient availability of tickets.</p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3048.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3049.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3050.png"/></span></p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">If the variable <i>avail tickets </i>is locked in a two-phase manner, concurrency would be very poor, with customers being forced to wait for bookings while an earlier transaction commits, even when there are many tickets available. Concurrency can be greatly in- creased by executing the <span class="s49">increment conditional </span>operation, without holding any locks on <i>avail tickets </i>in a two-phase manner; instead, an exclusive lock is obtained on the variable, the operation is performed, and the lock is then released.</p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3051.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3052.png"/></span></p><p style="padding-left: 119pt;text-indent: 17pt;line-height: 13pt;text-align: justify;">The transaction <i>T</i><span class="s97">i </span>also needs to carry out other steps, such as collecting the pay- ment; if one of the subsequent steps, such as payment, fails, the increment operation must be rolled back by executing a compensating operation; if the original operation added <span class="s15">−</span><i>n </i>to <i>avail tickets</i>, the compensating operation adds <span class="s15">+</span><i>n </i>to <i>avail tickets</i>.</p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3053.png"/></span></p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">It may appear that two <span class="s49">increment conditional </span>operations are compatible with each other, similar to the <span class="s49">increment </span>operation that we saw earlier. But that is not</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;"><a name="bookmark391">the case. Consider two concurrent transactions to purchase a single ticket, and assume that there is only one ticket left. The order in which the operations are executed has an obvious impact on which one succeeds and which one fails. Nevertheless, many real- world applications allow operations that hold short-term locks while they execute and release them at the end of the operation to increase concurrency, even at the cost of loss of serializability in some situations.</a><a name="bookmark432">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 88pt;text-indent: 0pt;text-align: left;">18.10.6 Real-Time Transaction Systems</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">In certain applications, the constraints include <span class="s63">deadlines </span>by which a task must be com- pleted. Examples of such applications include plant management, traﬃc control, and scheduling. When deadlines are included, correctness of an execution is no longer solely an issue of database consistency. Rather, we are concerned with how many dead- lines are missed, and by how much time they are missed. Deadlines are characterized as follows:</p><p class="s39" style="padding-top: 7pt;padding-left: 107pt;text-indent: -16pt;text-align: left;">• <span class="s63">Hard deadline</span><span class="p">. Serious problems, such as system crash, may occur if a task is not completed by its deadline.</span></p><p class="s39" style="padding-top: 4pt;padding-left: 91pt;text-indent: 0pt;text-align: left;">• <span class="s63">Firm deadline</span><span class="p">. The task has zero value if it is completed after the deadline.</span></p><p class="s39" style="padding-top: 3pt;padding-left: 107pt;text-indent: -16pt;text-align: left;">• <span class="s63">Soft deadlines</span><span class="p">. The task has diminishing value if it is completed after the deadline, with the value approaching zero as the degree of lateness increases.</span></p><p style="padding-top: 8pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">Systems with deadlines are called <span class="s63">real-time systems</span>.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Transaction management in real-time systems must take deadlines into account. If the concurrency-control protocol determines that a transaction <i>T</i><span class="s97">i </span>must wait, it may cause <i>T</i><span class="s145">i </span>to miss the deadline. In such cases, it may be preferable to pre-empt the trans- action holding the lock, and to allow <i>T</i><span class="s145">i </span>to proceed. Pre-emption must be used with care, however, because the time lost by the pre-empted transaction (due to rollback and restart) may cause the pre-empted transaction to miss its deadline. Unfortunately, it is diﬃcult to determine whether rollback or waiting is preferable in a given situation.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Due to the unpredictable nature of delays when reading data from disk, main- memory databases are often used if real-time constraints have to be met. However, even if data are resident in main memory, variances in execution time arise from lock waits, transaction aborts, and so on. Researchers have devoted considerable eﬀort to concur- rency control for real-time databases. They have extended locking protocols to provide higher priority for transactions with early deadlines. They have found that optimistic concurrency protocols perform well in real-time databases; that is, these protocols re- sult in fewer missed deadlines than even the extended locking protocols. The online bibliographical notes provide references to research in the area of real-time databases.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part337.htm">&lt; 上一个</a><span> | </span><a href="../database.html">内容</a><span> | </span><a href="part339.htm">下一个 &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
