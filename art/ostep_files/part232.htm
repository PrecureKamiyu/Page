<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Cache Size (Blocks)</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part231.htm">&lt; 上一个</a><span> | </span><a href="../ostep.html">内容</a><span> | </span><a href="part233.htm">下一个 &gt;</a></p><p class="s76" style="padding-left: 41pt;text-indent: 0pt;text-align: center;">Cache Size (Blocks)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 2pt;padding-left: 106pt;text-indent: 0pt;text-align: justify;">Figure 22.2: <b>The No-Locality Workload</b></p><p style="padding-top: 4pt;padding-left: 41pt;text-indent: 11pt;line-height: 89%;text-align: justify;">Figure <span style=" color: #00AEEF;">22.2 </span>plots the results of the experiment for optimal, LRU, Ran- dom, and FIFO. The y-axis of the figure shows the hit rate that each policy achieves; the x-axis varies the cache size as described above.</p><p style="padding-left: 41pt;text-indent: 11pt;line-height: 89%;text-align: justify;">We can draw a number of conclusions from the graph. First, when there is no locality in the workload, it doesn’t matter much which realistic policy you are using; LRU, FIFO, and Random all perform the same, with the hit rate exactly determined by the size of the cache. Second, when the cache is large enough to fit the entire workload, it also doesn’t matter which policy you use; all policies (even optimal) converge to a 100% hit rate when all the referenced blocks fit in cache. Finally, you can see that optimal performs noticeably better than the realistic policies; peeking into the future, if it were possible, does a much better job of replacement.</p><p style="padding-left: 41pt;text-indent: 11pt;line-height: 89%;text-align: justify;">The next workload we examine is called the “80-20” workload, which exhibits locality: 80% of the references are made to 20% of the pages (the “hot” pages); the remaining 20% of the references are made to the re- maining 80% of the pages (the “cold” pages). In our workload, there are a total 100 unique pages again; thus, “hot” pages are referred to most of the time, and “cold” pages the remainder. Figure <span style=" color: #00AEEF;">22.3 </span>shows how the policies perform with this workload.</p><p style="padding-left: 41pt;text-indent: 11pt;line-height: 89%;text-align: justify;">As you can see from the figure, while both random and FIFO do rea- sonably well, LRU does better, as it is more likely to hold onto the hot pages; as those pages have been referred to frequently in the past, they are likely to be referred to again in the near future. Optimal once again does better, showing that LRU’s historical information is not perfect.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s48" style="padding-left: 38pt;text-indent: 0pt;text-align: right;">100%</p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part231.htm">&lt; 上一个</a><span> | </span><a href="../ostep.html">内容</a><span> | </span><a href="part233.htm">下一个 &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
