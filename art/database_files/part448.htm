<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>25.1  Performance Tuning</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part447.htm">&lt; 上一个</a><span> | </span><a href="../database.html">内容</a><span> | </span><a href="part449.htm">下一个 &gt;</a></p><p class="s65" style="padding-top: 7pt;padding-left: 40pt;text-indent: 0pt;text-align: left;">25.1  <span style=" color: #00AEEF;">Performance Tuning</span></p><p style="padding-top: 12pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">Tuning the performance of a system involves adjusting various parameters and design choices to improve its performance for a speciﬁc application. Various aspects of a database-system design— ranging from high-level aspects such as the schema and trans- action design to database parameters such as buﬀer sizes, down to hardware issues such as number of disks— aﬀect the performance of an application. Each of these aspects can be adjusted so that performance is improved.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 88pt;text-indent: 0pt;text-align: left;">25.1.1 Motivation for Tuning</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">Applications sometimes exhibit poor performance, with queries taking a long time to complete, leading to users being unable to carry out tasks that they need to do. We describe a few real-world examples that we have seen, including their causes and how tuning ﬁxed the problems.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">In one of the applications, we found that users were experiencing long delays and time-outs in the web applications. On monitoring the database, we found that the <span class="s44">CPU </span>usage was very high, with negligible disk and network usage. Further analysis of queries running on the database showed that a simple lookup query on a large relation was us- ing a full relation scan, which was quite expensive. Adding an index to the attribute used in the lookup drastically reduced the execution time of the query and a key per- formance problem vanished immediately.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">In a second application, we found that a query had very poor performance. Examin- ing the query, we found that the programmer had written an unnecessarily complicated query, with several nested subqueries, and the optimizer produced a bad plan for the query, as we realized after observing the query plan. To ﬁx the problem, we rewrote the query using joins instead of nested subqueries, that is, we decorrelated the query; this change greatly reduced the execution time.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">In a third application, we found that the application fetched a large number of rows from a query, and issued another database query for each row that it fetched. This resulted in a large number of separate queries being sent to the database, resulting in poor performance. It is possible to replace such a large number of queries with a single query that fetches all required data, as we see later in this section. Such a change improved the performance of the application by an order of magnitude.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">In a fourth application, we found that while the application performed ﬁne un- der light load during testing, it completely stopped working when subjected to heavy load when it was used by actual users. In this case, we found that in some of the in- terfaces, programmers had forgotten to close <span class="s44">JDBC </span>connections. Databases typically support only a limited number of <span class="s44">JDBC </span>connections, and once that limit was reached, the application was unable to connect to the database, and thus it stopped working.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">Ensuring that connections were closed ﬁxed this problem. While this was technically a bug ﬁx, not a tuning action, we thought it is a good idea to highlight this problem since we have found many applications have this problem. Connection pooling, which keeps database connections open for use by subsequent transactions, is a related appli- cation tuning optimization, since it avoids the cost of repeated opening and closing of database connections.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">It is also worth pointing out that in several cases above the performance problems did not show up during testing, either because the test database was much smaller than the actual database size or because the testing was done with a much lighter load (number of concurrent users) than the load on the live system. It is important that performance testing be done on realistic database sizes, with realistic load, so problems show up during testing, rather than on a live system.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-top: 7pt;padding-left: 119pt;text-indent: 0pt;text-align: left;">25.1.2 Location of Bottlenecks</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">The performance of most systems (at least before they are tuned) is usually limited primarily by the performance of one or a few components, called <span class="s63">bottlenecks</span>. For in- stance, a program may spend 80 percent of its time in a small loop deep in the code, and the remaining 20 percent of the time on the rest of the code; the small loop then is a bottleneck. Improving the performance of a component that is not a bottleneck does little to improve the overall speed of the system; in the example, improving the speed of the rest of the code cannot lead to more than a 20 percent improvement overall, whereas improving the speed of the bottleneck loop could result in an improvement of nearly 80 percent overall, in the best case.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Hence, when tuning a system, we must ﬁrst try to discover what the bottlenecks are and then eliminate them by improving the performance of system components causing the bottlenecks. When one bottleneck is removed, it may turn out that another component becomes the bottleneck. In a well-balanced system, no single component is the bottleneck. If the system contains bottlenecks, components that are not part of the bottleneck are underutilized, and could perhaps have been replaced by cheaper components with lower performance.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">For simple programs, the time spent in each region of the code determines the overall execution time. However, database systems are much more complex, and query execution involves not only <span class="s44">CPU </span>time, but also disk <span class="s44">I/O </span>and network communication. A ﬁrst step in diagnosing problems to use monitoring tools provided by operating systems to ﬁnd the usage level of the <span class="s44">CPU</span>, disks, and network links.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">It is also important to monitor the database itself, to ﬁnd out what is happening in the database system. For example, most databases provide ways to ﬁnd out which queries (or query templates, where the same query is executed repeatedly with diﬀerent constants) are taking up the maximum resources, such as <span class="s44">CPU</span>, disk <span class="s44">I/O</span>, or network capacity. In addition to hardware resource bottlenecks, poor performance in a database system may potentially be due to contention on locks, where transactions wait in lock</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="493" height="201" alt="image" src="Image_3392.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s73" style="padding-left: 43pt;text-indent: 0pt;text-align: center;">Note 25.1 <span class="s146">DATABASE PERFORMANCE MONITORING TOOLS</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 9pt;text-indent: 0pt;text-align: justify;">Most database systems provide view relations that can be queried to monitor database system performance. For example, <span class="s44">P</span>ostgre<span class="s44">SQL </span>provides view relations <span class="s49">pg stat statements </span>and <span class="s49">pgpgrowlocks </span>to monitor resource usage of <span class="s44">SQL </span>state- ments and lock contention respectively. <span class="s44">M</span>y<span class="s44">SQL </span>supports a command <span class="s49">show pro- cessinfo </span>that can be used to monitor what transactions are currently executing and their resource usage. Microsoft <span class="s44">SQL S</span>erver provides stored procedures <span class="s49">sp monitor</span>, <span class="s49">sp who</span>, and <span class="s49">sp lock </span>to monitor system resource usage. The Oracle Database SQL Tuning Guide, available online, provides details of similar views in Oracle.</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 88pt;text-indent: 0pt;text-align: justify;">queues for a long time. Again, most databases provide mechanisms to monitor lock contention.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Monitoring tools can help detect where the bottleneck lies (such as <span class="s44">CPU</span>, <span class="s44">I/O</span>, or locks), and to locate the queries that are causing the maximum performance prob- lems. In this chapter, we discuss a number of techniques that can be used to ﬁx per- formance problems, such as adding required indices or materialized views, rewriting queries, rewriting applications, or adding hardware to improve performance.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">To understand the performance of database systems better, it is very useful to model database systems as <span class="s63">queueing systems</span>. A transaction requests various services from the database system, starting from entry into a server process, disk reads during execution, <span class="s44">CPU </span>cycles, and locks for concurrency control. Each of these services has a queue associated with it, and small transactions may spend most of their time wait- ing in queues— especially in disk <span class="s44">I/O </span>queues — instead of executing code. Figure 25.1 illustrates some of the queues in a database system. Note that each lockable item has a separate queue in the concurrency control manager. The database system may have a single queue at the disk manager or may have separate queues for diﬀerent disks in case the disks are directly controlled by the database. The transaction queue is used by the database system to control the admission of new queries when the number of requests exceeds the number of concurrent query execution tasks that the database allows.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">As a result of the numerous queues in the database, bottlenecks in a database sys- tem typically show up in the form of long queues for a particular service, or, equiva- lently, in high utilizations for a particular service. If requests are spaced exactly uni- formly, and the time to service a request is less than or equal to the time before the next request arrives, then each request will ﬁnd the resource idle and can therefore start execution immediately without waiting. Unfortunately, the arrival of requests in a database system is never so uniform and is often random.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">If a resource, such as a disk, has a low utilization, then when a request is made, the resource is likely to be idle, in which case the waiting time for the request will be 0. Assuming uniformly randomly distributed arrivals, the length of the queue (and</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="24" height="57" alt="image" src="Image_3393.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="121" height="38" alt="image" src="Image_3394.png"/></span></p><p class="s42" style="padding-top: 3pt;padding-left: 21pt;text-indent: -9pt;text-align: left;">transaction source</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><span><img width="57" height="5" alt="image" src="Image_3395.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="57" height="5" alt="image" src="Image_3396.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="5" height="55" alt="image" src="Image_3397.png"/></span></p><p class="s42" style="padding-top: 6pt;padding-left: 285pt;text-indent: 10pt;text-align: right;">page request</p><p class="s42" style="padding-top: 4pt;padding-left: 21pt;text-indent: 0pt;text-align: left;">page reply</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="126" height="155" alt="image" src="Image_3398.png"/></span></p><p class="s42" style="padding-left: 24pt;text-indent: -24pt;text-align: left;">concurrency-control manager</p><p style="text-indent: 0pt;text-align: left;"/><p class="s42" style="text-indent: 0pt;line-height: 11pt;text-align: left;">…</p><p style="text-indent: 0pt;text-align: left;"/><p class="s42" style="text-indent: 11pt;text-align: left;">lock request</p><p style="text-indent: 0pt;text-align: left;"/><p class="s42" style="text-indent: 0pt;text-align: left;">lock grant</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><span><img width="24" height="57" alt="image" src="Image_3399.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="24" height="57" alt="image" src="Image_3400.png"/></span></p><p class="s42" style="padding-top: 3pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">CPU manager</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><span><img width="24" height="57" alt="image" src="Image_3401.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="28" height="13" alt="image" src="Image_3402.png"/></span></p><p class="s42" style="padding-top: 5pt;padding-left: 11pt;text-indent: -5pt;text-align: left;">transaction manager</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 20pt;text-indent: 0pt;text-align: left;"><span><img width="24" height="56" alt="image" src="Image_3403.png"/></span></p><p class="s42" style="padding-left: 17pt;text-indent: -10pt;text-align: left;">transaction queue</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><span><img width="5" height="55" alt="image" src="Image_3404.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="57" height="13" alt="image" src="Image_3405.png"/></span></p><p class="s42" style="padding-top: 8pt;padding-left: 4pt;text-indent: 5pt;text-align: left;">buﬀer manager</p><p style="text-indent: 0pt;text-align: left;"/><p class="s42" style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;text-align: center;">disk manager</p><p class="s537" style="padding-top: 3pt;padding-left: 12pt;text-indent: 0pt;text-align: center;"><span><img width="24" height="57" alt="image" src="Image_3406.png"/></span> <span style=" color: #231F20;">… </span><span><img width="24" height="57" alt="image" src="Image_3407.png"/></span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s42" style="padding-left: 32pt;text-indent: 5pt;text-align: left;">page request</p><p class="s42" style="padding-top: 9pt;padding-left: 37pt;text-indent: 0pt;text-align: left;">page reply</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s73" style="padding-top: 4pt;padding-left: 212pt;text-indent: 0pt;text-align: left;">Figure 25.1 <span class="s74">Queues in a database system.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">correspondingly the waiting time) goes up exponentially with utilization; as utilization approaches 100 percent, the queue length increases sharply, resulting in excessively long waiting times. The utilization of a resource should be kept low enough that queue length is short. As a rule of the thumb, utilizations of around 70 percent are consid- ered to be good, and utilizations above 90 percent are considered excessive, since they will result in signiﬁcant delays. To learn more about the theory of queueing systems, generally referred to as <span class="s63">queueing theory</span>, you can consult the references cited in the bibliographical notes.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 119pt;text-indent: 0pt;text-align: left;">25.1.3 Tuning Levels</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">Tuning is typically done in the context of applications, and can be done at the database system layer, or outside the database system.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Tuning at layers above the database is application dependent, and is not our focus, but we mention a few such techniques. Proﬁling application code to ﬁnd code blocks that have a heavy <span class="s44">CPU </span>consumption, and rewriting them to reduce <span class="s44">CPU </span>load is an option for <span class="s44">CPU </span>intensive applications. Application servers often have numerous pa- rameters that can be tuned to improve performance, or to ensure that the application does not run out of memory. Multiple application servers that work in parallel are often</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">used to handle higher workloads. A <i>load balancer </i>is used to route requests to one of the application servers; to ensure session continuity, requests from a particular source are always routed to the same application server. Connection pooling (described in Section 9.7.1) is another widely technique to reduce the overhead of database connection cre- ation. Web application interfaces may be tuned to improve responsiveness, for example by replacing legacy web interfaces by ones based on JavaScript and Ajax (described in Section 9.5.1.3).</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Returning to database tuning, database administrators and application developers can tune a database system at three levels.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The highest level of database tuning, which is under the control of application developers, includes the schema and queries. The developer can tune the design of the schema, the indices that are created, and the transactions that are executed to improve performance. Tuning at this level is comparatively system independent.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The second level consists of the database-system parameters, such as buﬀer size and checkpointing intervals. The exact set of database-system parameters that can be tuned depends on the speciﬁc database system. Most database-system manuals provide information on what database-system parameters can be adjusted, and how you should choose values for the parameters. Well-designed database systems perform as much tuning as possible automatically, freeing the user or database administrator from the burden. For instance, in many database systems the buﬀer size is ﬁxed but tunable. If the system automatically adjusts the buﬀer size by observing indicators such as page- fault rates, then the database administrator will not have to worry about tuning the buﬀer size.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The lowest level is at the hardware level. Options for tuning systems at this level include replacing hard disks with solid-state drives (which use ﬂash storage), adding more disks or using a <span class="s44">RAID </span>system if disk <span class="s44">I/O </span>is a bottleneck, adding more memory if the disk buﬀer size is a bottleneck, or moving to a system with more processors if <span class="s44">CPU </span>usage is a bottleneck.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The three levels of tuning interact with one another; we must consider them to- gether when tuning a system. For example, tuning at a higher level may result in the hardware bottleneck changing from the disk system to the <span class="s44">CPU</span>, or vice versa. Tuning of queries and the physical schema is usually the ﬁrst step to improving performance. Tuning of database system parameters, in case the database system does automate this task, can also be done in parallel. If performance is still poor, tuning of logical schema and tuning of hardware are the next logical steps.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 88pt;text-indent: 0pt;text-align: left;">25.1.4 Tuning of Physical Schema</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">Tuning of the physical schema, such as indices and materialized views, is the least disruptive mode of tuning, since it does not aﬀect application code in any way. We now study diﬀerent aspects of tuning of the physical schema.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s183" style="padding-top: 4pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">25.1.4.1 Tuning of Indices</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">We can tune the indices in a database system to improve performance. If queries are the bottleneck, we can often speed them up by creating appropriate indices on relations. If updates are the bottleneck, there may be too many indices, which have to be updated when the relations are updated. Removing indices may speed up certain updates.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">The choice of the type of index also is important. Some database systems support diﬀerent kinds of indices, such as hash indices, B<span class="s181">+</span>-tree indices, and write-optimized indices such as <span class="s44">LSM </span>trees (Section 24.2). If range queries are common, B<span class="s181">+</span>-tree indices are preferable to hash indices. If the system has a very high write load, but a relatively low read load, write-optimized <span class="s44">LSM </span>tree indices may be preferable to B<span class="s181">+</span>-tree indices.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Whether to make an index a clustered index is another tunable parameter. Only one index on a relation can be made clustered, by storing the relation sorted on the index attributes. Generally, the index that beneﬁts the greatest number of queries and updates should be made clustered.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">To help identify what indices to create, and which index (if any) on each relation should be clustered, most commercial database systems provide <i>tuning wizards</i>; these are described in more detail in Section 25.1.4.4. These tools use the past history of queries and updates (called the <i>workload</i>) to estimate the eﬀects of various indices on the execution time of the queries and updates in the workload. Recommendations on what indices to create are based on these estimates.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s183" style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">25.1.4.2 Using Materialized Views</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">Maintaining materialized views can greatly speed up certain types of queries, in par- ticular aggregate queries. Recall the example from Section 16.5 where the total salary for each department (obtained by summing the salary of each instructor in the depart- ment) is required frequently. As we saw in that section, creating a materialized view storing the total salary for each department can greatly speed up such queries.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Materialized views should be used with care, however, since there is not only space overhead for storing them but, more important, there is also time overhead for main- taining materialized views. In the case of <span class="s63">immediate view maintenance</span>, if the updates of a transaction aﬀect the materialized view, the materialized view must be updated as part of the same transaction. The transaction may therefore run slower. In the case of <span class="s63">deferred view maintenance</span>, the materialized view is updated later; until it is updated, the materialized view may be inconsistent with the database relations. For instance, the materialized view may be brought up to date when a query uses the view, or periodically. Using deferred maintenance reduces the burden on update transactions.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">The database administrator is responsible for the selection of materialized views and for view-maintenance policies. The database administrator can make the selection manually by examining the types of queries in the workload and ﬁnding out which queries need to run faster and which updates/queries may be executed more slowly. From the examination, the database administrator may choose an appropriate set of</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">materialized views. For instance, the administrator may ﬁnd that a certain aggregate is used frequently, and choose to materialize it, or may ﬁnd that a particular join is computed frequently, and choose to materialize it.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">However, manual choice is tedious for even moderately large sets of query types, and making a good choice may be diﬃcult, since it requires understanding the costs of diﬀerent alternatives; only the query optimizer can estimate the costs with reason- able accuracy without actually executing the query. Thus, a good set of views may be found only by trial and error — that is, by materializing one or more views, running the workload, and measuring the time taken to run the queries in the workload. The administrator repeats the process until a set of views is found that gives acceptable performance.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">A better alternative is to provide support for selecting materialized views within the database system itself, integrated with the query optimizer. This approach is described in more detail in Section 25.1.4.4.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s183" style="padding-top: 7pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">25.1.4.3 Horizontal Partitioning of Relation Schema</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">Horizontal partitioning of relations is widely used for parallel and distributed storage and query processing. However, it can also be used in a centralized system to improve queries and updates by breaking up the tuples of a relation into partitions.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">For example, suppose that a database stores a large relation that has a <i>date </i>attribute, and most operations work on data inserted within the past few months. Suppose now that the relation is partitioned on the <i>date </i>attribute, with one partition for each (<i>year, month</i>) combination. Then, queries that contain a selection on <i>date</i>, such as <i>date</i>=&#39;2018- 06-01&#39;, need access only partitions that could possibly contain such tuples, skipping all other partitions.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">More importantly, indices could be created independently on each partition. Sup- pose an index is created on an attribute <span class="s44">ID</span>, with a separate index on each partition. A query that speciﬁes selection on <span class="s44">ID</span>, along with a date or a date range, need look up the index on only those partitions that match the speciﬁed date or date range. Since each partition is smaller than the whole relation, the indices too are smaller, speeding up index lookup. Index insertion is also much faster, since the index size is much smaller than an index on the entire relation. And most importantly, even as the total data size grows, the partition size never grows beyond some limit, ensuring that the performance of such queries does not degrade with time.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">There is a cost to such partitioning: queries that do not contain a selection on the partitioning attribute need to individually access each of the partitions, potentially slowing down such queries signiﬁcantly. If such queries are rare, the beneﬁts of parti- tioning outweigh the costs, making them an attractive technique for optimization.</p><p style="padding-left: 88pt;text-indent: 17pt;line-height: 93%;text-align: justify;">Even if the database does not support partitioning internally, it is possible to re- place a relation <i>r </i>by multiple physical relations <i>r</i><span class="s98">1</span>, <i>r</i><span class="s98">2</span>, <span class="s15">… </span>, <i>r</i><span class="s97">n</span>, and the original relation <i>r </i>is deﬁned by the view <i>r </i><span class="s15">= </span><i>r</i><span class="s98">1</span> <span class="s15">∪ </span><i>r</i><span class="s98">2</span> <span class="s15">∪…∪ </span><i>r</i><span class="s97">n</span>. Suppose that the database optimizer knows</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 5pt;padding-left: 119pt;text-indent: 0pt;line-height: 88%;text-align: justify;">the predicate deﬁning each <i>r</i><span class="s145">i </span>(in our example, the date range corresponding to each <i>r</i><span class="s97">i</span>). Then the optimizer can replace a query on <i>r </i>that includes a selection on the parti- tioning attribute (<i>date</i>, in our example), with a query on the only relevant <i>r</i><span class="s97">i</span>s. Indices would have to be created separately on each of the <i>r</i><span class="s97">i</span>s.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s183" style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">25.1.4.4 Automated Tuning of Physical Design</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">Most commercial database systems today provide tools to help the database adminis- trator with index and materialized view selection and other tasks related to physical database design such as how to partition data in a parallel database system.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">These tools examine the <span class="s63">workload </span>(the history of queries and updates) and sug- gest indices and views to be materialized. The database administrator may specify the importance of speeding up diﬀerent queries, which the tool takes into account when selecting views to materialize. Often tuning must be done before the application is fully developed, and the actual database contents may be small on the development database but are expected to be much larger on a production database. Thus, some tuning tools also allow the database administrator to specify information about the expected size of the database and related statistics.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Microsoft’s Database Tuning Assistant, for example, allows the user to ask “what if” questions, whereby the user can pick a view, and the optimizer then estimates the eﬀect of materializing the view on the total cost of the workload and on the individual costs of diﬀerent types of queries and updates in the workload.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">The automatic selection of indices and materialized views is usually implemented by enumerating diﬀerent alternatives and using the query optimizer to estimate the costs and beneﬁts of selecting each alternative by using the workload. Since the number of design alternatives and the potential workload may be extremely large, the selection techniques must be designed carefully.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">The ﬁrst step is to generate a workload. This is usually done by recording all the queries and updates that are executed during some time period. Next, the selection tools perform <span class="s63">workload compression</span>, that is, create a representation of the workload using a small number of updates and queries. For example, updates of the same form can be represented by a single update with a weight corresponding to how many times the update occurred. Queries of the same form can be similarly replaced by a repre- sentative with appropriate weight. After this, queries that are very infrequent and do not have a high cost may be discarded from consideration. The most expensive queries may be chosen to be addressed ﬁrst. Such workload compression is essential for large workloads.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">With the help of the optimizer, the tool would come up with a set of indices and materialized views that could help the queries and updates in the compressed workload. Diﬀerent combinations of these indices and materialized views can be tried out to ﬁnd the best combination. However, an exhaustive approach would be totally impractical, since the number of potential indices and materialized views is already large, and each</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s73" style="padding-left: 43pt;text-indent: 0pt;text-align: center;">Note 25.2 <span class="s146">TUNING TOOLS</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 9pt;text-indent: 0pt;text-align: justify;">Tuning tools, such as the Database Engine Tuning Advisor provided by <span class="s44">SQL S</span>erver and the <span class="s44">SQL </span>Tuning Advisor of Oracle, provide recommendations such as what indices or materialized views to add, or how to partition a relation, to improve performance. These recommendations can then be accepted and implemented by a database administrator.</p><p style="padding-left: 9pt;text-indent: 17pt;text-align: justify;">Auto Tuning in Microsoft Azure <span class="s44">SQL </span>can automatically create and drop in- dices to improve query performance. A risk with automatically changing the phys- ical schema is that some queries may perform poorly. For example, an optimizer may choose a plan using a newly created index, assuming, based on wrong esti- mates of cost, that the new plan is cheaper than the plan used before the index was created. In reality, the query may run slower using the new plan, which may aﬀect users. The “force last good plan” feature can monitor query performance after any change such as addition of an index, and if performance is worse, it can force the database to use the old plan before the change (as long as it is still valid).</p><p style="padding-left: 9pt;text-indent: 17pt;text-align: justify;">Oracle also provides auto tuning support, for example recommending if an index should be added, or monitoring the use of a query to decide if it should be optimized for fetching only a few rows or for fetching all rows (the best plan may be very diﬀerent if only the ﬁrst few rows are fetched or if all rows are fetched).</p><p style="padding-left: 88pt;text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 88pt;text-indent: 0pt;text-align: justify;">subset of these is a potential design alternative, leading to an exponential number of alternatives. Heuristics are used to reduce the space of alternatives, that is, to reduce the number of combinations considered.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Greedy heuristics for index and materialized view selection operate as follows: They estimate the beneﬁts of materializing diﬀerent indices or views (using the op- timizer’s cost estimation functionality as a subroutine). They then choose the index or view that gives either the maximum beneﬁt or the maximum beneﬁt per unit space (i.e., beneﬁt divided by the space required to store the index or view). The cost of maintain- ing the index or view must be taken into account when computing the beneﬁt. Once the heuristic has selected an index or view, the beneﬁts of other indices or views may have changed, so the heuristic recomputes these and chooses the next best index or view for materialization. The process continues until either the available disk space for storing indices or materialized views is exhausted or the cost of maintaining the remaining candidates is more than the beneﬁt to queries that could use the indices or views.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Real-world index and materialized-view selection tools usually incorporate some elements of greedy selection but use other techniques to get better results. They also support other aspects of physical database design, such as deciding how to partition a relation in a parallel database, or what physical storage mechanism to use for a relation.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-top: 4pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">25.1.5 Tuning of Queries</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">The performance of an application can often be signiﬁcantly improved by rewriting queries or by changing how the application issues queries to the database.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s183" style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">25.1.5.1 Tuning of Query Plans</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">In the past, optimizers on many database systems were not particularly good, so how a query was written would have a big inﬂuence on how it was executed, and therefore on the performance. Today’s advanced optimizers can transform even badly written queries and execute them eﬃciently, so the need for tuning individual queries is less important than it used to be. However, sometimes query optimizers choose bad plans for one of several reasons, which we describe next.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Before checking if something needs to be tuned in the plan for a query, it is useful to ﬁnd out what plan is being used for the query. Most databases support an <span class="s49">explain </span>command, which allows you to see what plan is being used for a query. The <span class="s49">explain </span>command also shows the statistics that the optimizer used or computed for diﬀerent parts of the query plan, and estimates of the costs of each part of a query plan. Vari- ants of the <span class="s49">explain </span>command also execute the query and get actual tuple counts and execution time for diﬀerent parts of the query plan.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Incorrect statistics are often the reason for the choice of a bad plan. For example, if the optimizer thinks that the relations involved in a join have very few tuples, it may choose nested loops join, which would be very ineﬃcient if the relations actually have a large number of tuples.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Ideally, database statistics should be updated whenever relations are updated. How- ever, doing so adds unacceptable overhead to update queries. Instead, databases either periodically update statistics or leave it to the system administrator to issue a com- mand to update statistics. Some databases, such as <span class="s44">P</span>ostgre<span class="s44">SQL </span>and <span class="s44">M</span>y<span class="s44">SQL </span>support a command called <span class="s49">analyze</span>,<span class="s76">1</span> which can be used to recompute statistics. For example, <span class="s49">analyze instructor </span>would recompute statistics for the instructor relation, while <span class="s49">ana- lyze </span>with no arguments would recompute statistics for all relations in <span class="s44">P</span>ostgre<span class="s44">SQL</span>. It is highly recommended to run this command after loading data into the database, or after making a signiﬁcant number of inserts or deletes on a relation.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Some databases such as Oracle and Microsoft SQL Server keep track of inserts and deletes to relations, and they update statistics whenever the relation size changes by a signiﬁcant fraction, making execution of the analyze command unnecessary.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Another reason for poor performance of queries is the lack of required indices. As we saw earlier, the choice of indices can be done as part of the tuning of the physical schema, but examining a query helps us understand what indices may be useful to speed up that query.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Indices are particularly important for queries that fetch only a few rows from a large relation, based on a predicate. For example, a query that ﬁnds students in a department</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 119pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="95" height="1" alt="image" src="Image_3408.png"/></span></p><p class="s80" style="padding-top: 3pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;"><span class="s77">1</span><span class="s78">The command is called </span><span class="s184">analyze table </span>in the case of <span class="s161">M</span>y<span class="s161">SQL</span>.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3409.png"/></span></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">may beneﬁt from an index on the <i>student </i>relation on the attribute <i>dept name</i>. Indices on join attributes are often very useful. For example, if the above query also included a join of <i>student </i>with <i>takes </i>on the attribute <i>takes</i>.<span class="s44">ID</span>, an index on <i>takes</i>.<span class="s44">ID </span>could be useful.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Note that databases typically create indices on primary-key attributes, which can be used for selections as well as joins. For example, in our university schema, the primary- key index on <i>takes </i>has <span class="s44">ID </span>as its ﬁrst attribute and may thus be useful for the above join.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Complex queries containing <i>nested subqueries </i>are not optimized very well by many optimizers. We saw techniques for nested subquery decorrelation in Section 16.4.4. If a subquery is not decorrelated, it gets executed repeatedly, potentially resulting in a great deal of random <span class="s44">I/O</span>. In contrast, decorrelation allows eﬃcient set-oriented operations such as joins to be used, minimizing random <span class="s44">I/O</span>. Most database query optimizers incorporate some forms of decorrelation, but some can handle only very simple nested subqueries. The execution plan chosen by the optimizer can be found as described in Chapter 16. If the optimizer has not succeeded in decorrelating a nested subquery, the query can be decorrelated by rewriting it manually.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s183" style="padding-left: 88pt;text-indent: 0pt;text-align: justify;">25.1.5.2 Improving Set Orientation</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">When <span class="s44">SQL </span>queries are executed from an application program, it is often the case that a query is executed frequently, but with diﬀerent values for a parameter. Each call has an overhead of communication with the server, in addition to processing overheads at the server.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">For example, consider a program that steps through each department, invoking an embedded <span class="s44">SQL </span>query to ﬁnd the total salary of all instructors in the department:</p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3410.png"/></span></p><p class="s46" style="padding-top: 10pt;padding-left: 233pt;text-indent: 0pt;text-align: left;">select sum<span class="p">(</span><i>salary</i><span class="p">) </span>from <i>instructor </i>where <i>dept name</i><span class="p">=? </span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3411.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3412.png"/></span></p><p style="padding-top: 9pt;padding-left: 88pt;text-indent: 17pt;text-align: justify;">If the <i>instructor </i>relation does not have a clustered index on <i>dept name</i>, each such query will result in a scan of the relation. Even if there is such an index, a random <span class="s44">I/O </span>operation will be required for each <i>dept name </i>value.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Instead, we can use a single <span class="s44">SQL </span>query to ﬁnd total salary expenses of each depart- ment:</p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3413.png"/></span></p><p style="padding-top: 3pt;padding-left: 212pt;text-indent: 0pt;text-align: left;"><b>select </b><i>dept name</i>, <b>sum</b>(<i>salary</i>) <b>from </b><i>instructor</i></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3414.png"/></span></p><p class="s46" style="padding-left: 212pt;text-indent: 0pt;text-align: left;">group by <i>dept name</i><span class="p">;</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 88pt;text-indent: 0pt;text-align: justify;">This query can be evaluated with a single scan of the <i>instructor </i>relation, avoiding ran- dom <span class="s44">I/O </span>for each department. The results can be fetched to the client side using a single round of communication, and the client program can then step through the results to ﬁnd the aggregate for each department. Combining multiple <span class="s44">SQL </span>queries into a single</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 119pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="494" height="1" alt="image" src="Image_3415.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s49" style="padding-top: 4pt;padding-left: 247pt;text-indent: -63pt;text-align: left;">PreparedStatement pStmt = conn.prepareStatement( &quot;insert into instructor values(?,?,?,?)&quot;);</p><p class="s49" style="padding-left: 183pt;text-indent: 0pt;text-align: left;">pStmt.setString(1, &quot;88877&quot;); pStmt.setString(2, &quot;Perry&quot;); pStmt.setInt(3, &quot;Finance&quot;); pStmt.setInt(4, 125000); pStmt.addBatch( ); pStmt.setString(1, &quot;88878&quot;); pStmt.setString(2, &quot;Thierry&quot;); pStmt.setInt(3, &quot;Physics&quot;); pStmt.setInt(4, 100000); pStmt.addBatch( ); pStmt.executeBatch( );</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 119pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="494" height="1" alt="image" src="Image_3416.png"/></span></p><p class="s74" style="padding-top: 8pt;padding-left: 228pt;text-indent: 0pt;text-align: left;"><span class="s73">Figure 25.2 </span>Batch update in <span class="s157">JDBC</span>.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s42" style="padding-top: 10pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">SQL <span class="s43">query as above can reduce execution costs greatly in many cases — for example, if the </span><span class="s13">instructor </span><span class="p">relation is very large and has a large number of departments.</span></p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">The <span class="s44">JDBC API </span>also provides a feature called <span class="s63">batch update </span>that allows a number of inserts to be performed using a single communication with the database. Figure 25.2 illustrates the use of this feature. The code shown in the ﬁgure requires only one round of communication with the database, when the <span class="s49">executeBatch() </span>method is executed, in contrast to similar code without the batch update feature that we saw in Figure 5.2. In the absence of batch update, as many rounds of communication with the database are required as there are instructors to be inserted. The batch update feature also enables the database to process a batch of inserts at once, which can potentially be done much more eﬃciently than a series of single record inserts.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Another technique used widely in client-server systems to reduce the cost of com- munication and <span class="s44">SQL </span>compilation is to use stored procedures, where queries are stored at the server in the form of procedures, which may be precompiled. Clients can invoke these stored procedures rather than communicate a series of queries.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s183" style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">25.1.5.3 Tuning of Bulk Loads and Updates</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">When loading a large volume of data into a database (called a <span class="s63">bulk load </span>operation), performance is usually very poor if the inserts are carried out as separate <span class="s44">SQL </span>insert statements. One reason is the overhead of parsing each <span class="s44">SQL </span>query; a more important reason is that performing integrity constraint checks and index updates separately for each inserted tuple results in a large number of random <span class="s44">I/O </span>operations. If the inserts were done as a large batch, integrity-constraint checking and index update can be done</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">in a much more set-oriented fashion, reducing overheads greatly; performance improve- ments of an order of magnitude or more are not uncommon.</p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3417.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3418.png"/></span></p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">To support bulk load operations, most database systems provide a <span class="s63">bulk import </span>util- ity and a corresponding <span class="s63">bulk export </span>utility. The bulk-import utility reads data from a ﬁle and performs integrity constraint checking as well as index maintenance in a very eﬃcient manner. Common input and output ﬁle formats supported by such bulk im- port/export utilities include text ﬁles with characters such as commas or tabs separating attribute values, with each record in a line of its own (such ﬁle formats are referred to as <i>comma-separated values </i>or <i>tab-separated values </i>formats). Database-speciﬁc binary formats as well as <span class="s44">XML </span>formats are also supported by bulk import/export utilities. The names of the bulk import/export utilities diﬀer by database. In <span class="s44">P</span>ostgre<span class="s44">SQL</span>, the utilities are called <span class="s49">pg dump </span>and <span class="s49">pg restore </span>(<span class="s44">P</span>ostgre<span class="s44">SQL </span>also provides an <span class="s44">SQL </span>command <b>copy</b>, which provides similar functionality). The bulk import/export utility in Oracle is called <span class="s66">SQL*L</span><b>oader</b>, the utility in <span class="s44">DB2 </span>is called <span class="s49">load</span>, and the utility in <span class="s44">SQL S</span>erver is called <span class="s49">bcp </span>(<span class="s44">SQL S</span>erver also provides an <span class="s44">SQL </span>command called <b>bulk insert</b>).</p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3419.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3420.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3421.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3422.png"/></span></p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">We now consider the case of tuning of bulk updates. Suppose we have a relation <i>funds received</i>(<i>dept name</i>, <i>amount</i>) that stores funds received (say, by electronic funds transfer) for each of a set of departments. Suppose now that we want to add the amounts to the balances of the corresponding department budgets. In order to use the <span class="s44">SQL </span>update statement to carry out this task, we have to perform a look up on the <i>funds received </i>relation for each tuple in the <i>department </i>relation. We can use subqueries in the update clause to carry out this task, as follows: We assume for simplicity that the relation <i>funds received </i>contains at most one tuple for each department.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-left: 115pt;text-indent: 0pt;text-align: left;"><b>update </b>department <b>set </b>budget <span class="p">= </span>budget <span class="p">+</span></p><p style="padding-left: 179pt;text-indent: 0pt;text-align: left;">(<b>select </b><i>amount</i></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3423.png"/></span></p><p class="s46" style="padding-left: 184pt;text-indent: 0pt;text-align: left;">from <i>funds received</i></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3424.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3425.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3426.png"/></span></p><p class="s13" style="padding-left: 184pt;text-indent: 0pt;text-align: left;"><b>where </b>funds received.dept name <span class="p">= </span>department<span class="p">.</span>dept name<span class="p">)</span></p><p class="s46" style="padding-left: 136pt;text-indent: 0pt;text-align: left;">where exists<span class="p">(</span></p><p class="s46" style="padding-left: 179pt;text-indent: 0pt;text-align: left;">select <span class="p">*</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3427.png"/></span></p><p class="s46" style="padding-left: 184pt;text-indent: 0pt;text-align: left;">from <i>funds received</i></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3428.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3429.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3430.png"/></span></p><p class="s13" style="padding-left: 184pt;text-indent: 0pt;text-align: left;"><b>where </b>funds received.dept name <span class="p">= </span>department<span class="p">.</span>dept name<span class="p">);</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3431.png"/></span></p><p style="padding-left: 88pt;text-indent: 0pt;text-align: justify;">Note that the condition in the <b>where </b>clause of the update ensures that only accounts with corresponding tuples in <i>funds received </i>are updated, while the subquery within the <b>set </b>clause computes the amount to be added to each such department.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">There are many applications that require updates such as that illustrated above. Typically, there is a table, which we shall call the <span class="s63">master table</span>, and updates to the master table are received as a batch. Now the master table has to be correspondingly updated. <span class="s44">SQL:2003 </span>introduced a special construct, called the <b>merge </b>construct, to simplify the task of performing such merging of information. For example, the preceding update can be expressed using <b>merge </b>as follows:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s46" style="padding-top: 4pt;padding-left: 210pt;text-indent: 0pt;text-align: left;">merge into <i>department </i>as <i>A</i></p><p class="s46" style="padding-left: 210pt;text-indent: 0pt;text-align: left;">using  <span class="p">(</span>select <span class="p">*</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3432.png"/></span></p><p class="s46" style="padding-left: 253pt;text-indent: 0pt;text-align: left;">from <i>funds received</i><span class="p">) </span>as <i>F</i></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3433.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3434.png"/></span></p><p style="padding-left: 231pt;text-indent: 0pt;text-align: left;"><b>on </b>(<i>A</i>.<i>dept name </i>= <i>F </i>.<i>dept name</i>)</p><p class="s46" style="padding-left: 210pt;text-indent: 0pt;text-align: left;">when matched then</p><p class="s13" style="padding-left: 231pt;text-indent: 0pt;text-align: left;"><b>update set </b>budget <span class="p">= </span>budget <span class="p">+ </span>F.amount<span class="p">;</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">When a record from the subquery in the <b>using </b>clause matches a record in the <i>depart- ment </i>relation, the <b>when matched </b>clause is executed, which can execute an update on the relation; in this case, the matching record in the <i>department </i>relation is updated as shown.</p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3435.png"/></span></p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">The <b>merge </b>statement can also have a <b>when not matched then </b>clause, which permits insertion of new records into the relation. In the preceding example, when there is no matching department for a <i>funds received </i>tuple, the insertion action could create a new department record (with a null <i>building</i>) using the following clause:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s46" style="padding-left: 204pt;text-indent: 0pt;text-align: left;">when not matched then</p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3436.png"/></span></p><p style="padding-left: 225pt;text-indent: 0pt;text-align: left;"><b>insert values </b>(<i>F.dept name</i>, <i>null</i>, <i>F.budget</i>)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">Although not very meaningful in this example,<span class="s76">2</span> the <b>when not matched then </b>clause can be quite useful in other cases. For example, suppose the local relation is a copy of a master relation, and we receive updated as well as newly inserted records from the master relation. The <b>merge </b>statement can update matched records (these would be updated old records) and insert records that are not matched (these would be new records).</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Not all <span class="s44">SQL </span>implementations support the <b>merge </b>statement currently; see the re- spective system manuals for further details.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 119pt;text-indent: 0pt;text-align: left;">25.1.6 Tuning of the Logical Schema</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">Performance of queries can sometimes be improved by tuning of the logical schema. For example, within the constraints of the chosen normal form, it is possible to parti- tion relations vertically. Consider the <i>course </i>relation, with the schema:</p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3437.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3438.png"/></span></p><p style="padding-top: 9pt;padding-left: 218pt;text-indent: 0pt;text-align: left;"><i>course </i>(<u><i>course id</i></u>, <i>title</i>, <i>dept name</i>, <i>credits</i>)</p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3439.png"/></span></p><p style="padding-top: 9pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">for which <i>course id </i>is a key. Within the constraints of the normal forms (<span class="s44">BCNF </span>and</p><p class="s42" style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">3NF<span class="s43">), we can partition the </span><span class="s13">course </span><span class="p">relation into two relations:</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3440.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3441.png"/></span></p><p style="padding-top: 9pt;padding-left: 214pt;text-indent: 0pt;text-align: left;"><i>course credit </i>(<u><i>course id</i></u>, <i>credits</i>)</p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3442.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3443.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3444.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3445.png"/></span></p><p style="padding-left: 214pt;text-indent: 0pt;text-align: left;"><i>course title dept </i>(<u><i>course id</i></u>, <i>title</i>, <i>dept name</i>)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 119pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="96" height="1" alt="image" src="Image_3446.png"/></span></p><p class="s77" style="padding-top: 3pt;padding-left: 119pt;text-indent: 0pt;text-align: left;">2<span class="s78">A better action here would have been to insert these records into an error relation, but that cannot be done with the</span></p><p class="s79" style="padding-left: 119pt;text-indent: 0pt;text-align: left;">merge <span class="s80">statement.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3447.png"/></span></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">The two representations are logically equivalent, since <i>course id </i>is a key, but they have diﬀerent performance characteristics.</p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3448.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3449.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3450.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3451.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3452.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3453.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3454.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3455.png"/></span></p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">If most accesses to course information look at only the <i>course id </i>and <i>credits</i>, then they can be run against the <i>course credit </i>relation, and access is likely to be somewhat faster, since the <i>title </i>and <i>dept name </i>attributes are not fetched. For the same reason, more tuples of <i>course credit </i>will ﬁt in the buﬀer than corresponding tuples of <i>course</i>, again leading to faster performance. This eﬀect would be particularly marked if the <i>title </i>and <i>dept name </i>attributes were large. Hence, a schema consisting of <i>course credit </i>and <i>course title dept </i>would be preferable to a schema consisting of the <i>course </i>relation in this case.</p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3456.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3457.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3458.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3459.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3460.png"/></span></p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">On the other hand, if most accesses to course information require both <i>dept name </i>and <i>credits</i>, using the <i>course </i>relation would be preferable, since the cost of the join of <i>course credit </i>and <i>course title dept </i>would be avoided. Also, the storage overhead would be lower, since there would be only one relation, and the attribute <i>course id </i>would not be replicated.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The <span class="s63">column store </span>approach to storing data are based on vertical partitioning but takes it to the limit by storing each attribute (column) of the relation in a separate ﬁle, as we saw in Section 13.6. Note that in a column store it is not necessary to re- peat the primary-key attribute since the <i>i</i><span class="s76">th</span> row can be reconstructed by taking the <i>i</i><span class="s76">th</span> entry for each desired column. Column stores have been shown to perform well for several data-warehouse applications by reducing <span class="s44">I/O</span>, improving cache performance, enabling greater gains from data compression, and allowing eﬀective use of <span class="s44">CPU </span>vector- processing capabilities.</p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3461.png"/></span></p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Another trick to improve performance is to store a <i>denormalized relation</i>, such as a join of <i>instructor </i>and <i>department</i>, where the information about <i>dept name</i>, <i>building</i>, and <i>budget </i>is repeated for every instructor. More eﬀort has to be expended to make sure the relation is consistent whenever an update is carried out. However, a query that fetches the names of the instructors and the associated buildings will be speeded up, since the join of <i>instructor </i>and <i>department </i>will have been precomputed. If such a query is executed frequently, and has to be performed as eﬃciently as possible, the denormalized relation could be beneﬁcial.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Materialized views can provide the beneﬁts that denormalized relations provide, at the cost of some extra storage. A major advantage to materialized views over denor- malized relations is that maintaining consistency of redundant data becomes the job of the database system, not the programmer. Thus, materialized views are preferable, whenever they are supported by the database system.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Another approach to speed up the computation of the join without materializing it is to cluster records that would match in the join on the same disk page. We saw such clustered ﬁle organizations in Section 13.3.3.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 88pt;text-indent: 0pt;text-align: left;">25.1.7 Tuning of Concurrent Transactions</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">Concurrent execution of diﬀerent types of transactions can sometimes lead to poor performance because of contention on locks. We ﬁrst consider the case of read-write</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">contention, which is more common, and then consider the case of write-write con- tention.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">As an example of <span class="s63">read-write contention</span>, consider the following situation on a bank- ing database. During the day, numerous small update transactions are executed almost continuously. Suppose that a large query that computes statistics on branches is run at the same time. If the query performs a scan ona relation, it may block out all updates on the relation while it runs, and that can have a disastrous eﬀect on the performance of the system.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Several database systems— Oracle, <span class="s44">P</span>ostgre<span class="s44">SQL</span>, and Microsoft <span class="s44">SQL S</span>erver, for ex- ample — support snapshot isolation, whereby queries are executed on a snapshot of the data, and updates can go on concurrently. (Snapshot isolation is described in detail in Section 18.8.) Snapshot isolation should be used, if available, for large queries, to avoid lock contention in the above situation. In <span class="s44">SQL S</span>erver, executing the statement</p><p class="s46" style="padding-top: 10pt;padding-left: 225pt;text-indent: 0pt;text-align: left;">set transaction isolation level snapshot</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">at the beginning of a transaction results in snapshot isolation being used for that trans- action. In Oracle and <span class="s44">P</span>ostgre<span class="s44">SQL</span>, using the keyword <b>serializable </b>in place of the key- word <b>snapshot </b>in the above command has the same eﬀect, since these systems actually use snapshot isolation (serializable snapshot isolation, in the case of <span class="s44">P</span>ostgre<span class="s44">SQL </span>ver- sion 9.1 onwards) when the isolation level is set to serializable.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">If snapshot isolation is not available, an alternative option is to execute large queries at times when updates are few or nonexistent. However, for databases supporting web sites, there may be no such quiet period for updates.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Another alternative is to use weaker levels of consistency, such as the <b>read commit- ted </b>isolation level, whereby evaluation of the query has a minimal impact on concurrent updates, but the query results are not guaranteed to be consistent. The application se- mantics determine whether approximate (inconsistent) answers are acceptable.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">We now consider the case of <span class="s63">write-write contention</span>. Data items that are updated very frequently can result in poor performance with locking, with many transactions waiting for locks on those data items. Such data items are called <span class="s63">update hot spots</span>. Update hot spots can cause problems even with snapshot isolation, causing frequent transaction aborts due to write-validation failures. A commonly occurring situation that results in an update hot spot is as follows: transactions need to assign unique identiﬁers to data items being inserted into the database, and to do so they read and increment a sequence counter stored in a tuple in the database. If inserts are frequent, and the sequence counter is locked in a two-phase manner, the tuple containing the sequence counter becomes a hot spot.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">One way to improve concurrency is to release the lock on the sequence counter immediately after it is read and incremented; however, after doing so, even if the trans- action aborts, the update to the sequence counter should not be rolled back. To under- stand why, suppose <i>T</i><span class="s98">1</span> increments the sequence counter, and then <i>T</i><span class="s98">2</span> increments the sequence counter before <i>T</i><span class="s98">1</span> commits; if <i>T</i><span class="s98">1</span> then aborts, rolling back its update, either</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">by restoring the counter to the original value or by decrementing the counter, will result in the sequence value used by <i>T</i><span class="s98">2</span> getting reused by a subsequent transaction.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Most databases provide a special construct for creating <span class="s63">sequence counters </span>that im- plement early, non-two-phase lock release, coupled with special-case treatment of undo logging so that updates to the counter are not rolled back if the transaction aborts. The <span class="s44">SQL </span>standard allows a sequence counter to be created using the command:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s46" style="padding-left: 63pt;text-indent: 0pt;text-align: center;">create sequence <i>counter1</i><span class="p">;</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 88pt;text-indent: 0pt;text-align: justify;">In the above command, <i>counter1 </i>is the name of the sequence; multiple sequences can be created with diﬀerent names. The syntax to get a value from the sequence is not standardized; in Oracle, <i>counter1.nextval </i>would return the next value of the sequence, after incrementing it, while the function call <i>nextval </i>(’<i>counter1</i>’) would have the same eﬀect in <span class="s44">P</span>ostgre<span class="s44">SQL</span>, and <span class="s44">DB2 </span>uses the syntax <b>nextval for </b><i>counter1</i>.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The <span class="s44">SQL </span>standard provides an alternative to using an explicit sequence counter, which is useful when the goal is to give unique identiﬁers to tuples inserted into a re- lation. To do so, the keyword <b>identity </b>can be added to the declaration of an integer attribute of a relation (usually this attribute would also be declared as the primary key). If the value for that attribute is left unspeciﬁed in an insert statement for that relation, a unique new value is created automatically for each newly inserted tuple. A non-two-phase locked sequence counter is used internally to implement the <b>identity </b>dec- laration, with the counter incremented each time a tuple is inserted. Several databases, including <span class="s44">DB2 </span>and <span class="s44">SQL S</span>erver support the <b>identity </b>declaration, although the syntax varies. <span class="s44">P</span>ostgre<span class="s44">SQL </span>supports a data type called <b>serial</b>, which provides the same eﬀect; the <span class="s44">P</span>ostgre<span class="s44">SQL </span>type <b>serial </b>is implemented by transparently creating a non-two-phase locked sequence.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">It is worth noting that since the acquisition of a sequence number by a transaction cannot be rolled back if the transaction aborts (for reasons discussed earlier), transac- tion aborts may result in <i>gaps in the sequence numbers </i>in tuples inserted in the database. For example, there may be tuples with identiﬁer value 1001 and 1003, but no tuple with value 1002, if the transaction that acquired the sequence number 1002 did not com- mit. Such gaps are not acceptable in some applications; for example, some ﬁnancial applications require that there be no gaps in bill or receipt numbers. Database pro- vided sequences and automatically incremented attributes should not be used for such applications, since they can result in gaps. A sequence counter stored in normal tuples, which is locked in a two-phase manner, would not be susceptible to such gaps since a transaction abort would restore the sequence counter value, and the next transaction would get the same sequence number, avoiding a gap.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Long update transactions can cause performance problems with system logs and can increase the time taken to recover from system crashes. If a transaction performs many updates, the system log may become full even before the transaction completes, in which case the transaction will have to be rolled back. If an update transaction runs for a long time (even with few updates), it may block deletion of old parts of the log,</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">if the logging system is not well designed. Again, this blocking could lead to the log getting ﬁlled up.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">To avoid such problems, many database systems impose strict limits on the num- ber of updates that a single transaction can carry out. Even if the system does not impose such limits, it is often helpful to break up a large update transaction into a set of smaller update transactions where possible. For example, a transaction that gives a raise to every employee in a large corporation could be split up into a series of small transactions, each of which updates a small range of employee-ids. Such transactions are called <span class="s63">minibatch transactions</span>. However, minibatch transactions must be used with care. First, if there are concurrent updates on the set of employees, the result of the set of smaller transactions may not be equivalent to that of the single large transaction. Second, if there is a failure, the salaries of some of the employees would have been increased by committed transactions, but salaries of other employees would not. To avoid this problem, as soon as the system recovers from failure, we must execute the transactions remaining in the batch.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Long transactions, whether read-only or update, can also result in the lock table becoming full. If a single query scans a large relation, the query optimizer would ensure that a relation lock is obtained instead of acquiring a large number of tuple locks. However, if a transaction executes a large number of small queries or updates, it may acquire a large number of locks, resulting in the lock table becoming full.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">To avoid this problem, some databases provide for automatic <span class="s63">lock escalation</span>; with this technique, if a transaction has acquired a large number of tuple locks, tuple locks are upgraded to page locks, or even full relation locks. Recall that with multiple- granularity locking (Section 18.3), once a coarser-level lock is obtained, there is no need to record ﬁner-level locks, so tuple lock entries can be removed from the lock table, freeing up space. On databases that do not support lock escalation, it is possible for the transaction to explicitly acquire a relation lock, thereby avoiding the acquisition of tuple locks.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 119pt;text-indent: 0pt;text-align: left;">25.1.8 Tuning of Hardware</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">Hardware bottlenecks could include memory, <span class="s44">I/O</span>, <span class="s44">CPU </span>and network capacity. We focus on memory and <span class="s44">I/O </span>tuning in this section. The availability of processors with a large number of <span class="s44">CPU </span>cores, and support for multiple <span class="s44">CPU</span>s on a single machine allows system designers to choose the <span class="s44">CPU </span>model and number of <span class="s44">CPU</span>s to meet the <span class="s44">CPU </span>requirements of the application at an acceptable cost. How to tune or choose between <span class="s44">CPU </span>and network interconnect options is a topic outside the domain of database tuning.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Even in a well-designed transaction processing system, each transaction usually has to do at least a few <span class="s44">I/O </span>operations, if the data required by the transaction are on disk. An important factor in tuning a transaction processing system is to make sure that the disk subsystem can handle the rate at which <span class="s44">I/O </span>operations are required. For instance, consider a hard disk that supports an access time of about 10 milliseconds, and average transfer rate of 25 to 100 megabytes per second (a fairly typical disk today). Such a disk</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">would support a little under 100 random-access <span class="s44">I/O </span>operations of 4 kilobytes each per second. If each transaction requires just two <span class="s44">I/O </span>operations, a single disk would support at most 50 transactions per second.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">An obvious way to improve performance is to replace a hard disk with a solid-state drive (<span class="s44">SSD</span>), since a single <span class="s44">SSD </span>can support tens of thousands of random <span class="s44">I/O </span>operations per second. A drawback of using <span class="s44">SSDs </span>is that they cost a lot more than hard disks for a given storage capacity. Another way to support more transactions per second is to increase the number of disks. If the system needs to support <i>n </i>transactions per second, each performing two <span class="s44">I/O </span>operations, data must be striped (or otherwise partitioned) across at least <i>n</i><span class="s15">∕</span>50 hard disks (ignoring skew), or <i>n</i><span class="s15">∕</span>5000 <span class="s44">SSDs</span>, if the <span class="s44">SSD </span>supports 10,000 random <span class="s44">I/O </span>operations per second.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Notice here that the limiting factor is not the capacity of the disk, but the speed at which random data can be accessed (limited in a hard disk by the speed at which the disk arm can move). The number of <span class="s44">I/O </span>operations per transaction can be reduced by storing more data in memory. If all data are in memory, there will be no disk <span class="s44">I/O </span>except for writes. Keeping frequently used data in memory reduces the number of disk <span class="s44">I/O</span>s and is worth the extra cost of memory. Keeping very infrequently used data in memory would be a waste, since memory is much more expensive than disk.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The question is, for a given amount of money available for spending on disks or memory, what is the best way to spend the money to achieve the maximum number of transactions per second? A reduction of one <span class="s44">I/O </span>per second saves:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 169pt;text-indent: 0pt;text-align: left;">(<i>price per disk drive</i>)<span class="s15">∕</span>(<i>access per second per disk</i>)</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 17pt;line-height: 13pt;text-align: justify;">Thus, if a particular page is accessed once in <i>m </i>seconds, the saving due to keeping it in memory is <u>&nbsp;1</u> times the above value. Storing a page in memory costs:</p><p class="s109" style="padding-left: 158pt;text-indent: 0pt;line-height: 5pt;text-align: left;">m</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 88pt;text-indent: 47pt;line-height: 196%;text-align: left;">(<i>price per megabyte of memory</i>)<span class="s15">∕</span>(<i>pages per megabyte of memory</i>) Thus, the break-even point is:</p><p class="s539" style="padding-left: 14pt;text-indent: 0pt;line-height: 49%;text-align: center;"><span class="s379"> 1</span><span class="p"> </span>∗ <span class="s96">&nbsp; price per disk drive </span><span class="s13"> </span>= <span class="s540">&nbsp;price per megabyte of memory</span></p><p class="s13" style="padding-left: 59pt;text-indent: 0pt;line-height: 12pt;text-align: center;">m  access per second per disk  pages per megabyte of memory</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">We can rearrange the equation and substitute current values for each of the above parameters to get a value for <i>m</i>; if a page is accessed more frequently than once in <i>m </i>seconds, it is worth buying enough memory to store it.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">As of 2018, hard-disk technology and memory and disk prices (which we assume to be about $50 for a 1-terabyte disk and $80 for 16-gigabytes of memory) give a value of <i>m </i>around 4 hours for 4-kilobytes pages that are randomly accessed; that is, if a page on hard disk is accessed at least once in 4 hours, it makes sense to purchase enough memory to cache it in memory. Note that if we use larger pages, the time decreases; for example, a page size of 16-kilobytes will lead to a value of <i>m </i>of 1 hour instead of 4 hours.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 119pt;text-indent: 17pt;text-align: justify;">With disk and memory cost and speeds as of the 1980/1990s, the corresponding value was 5 minutes with 4-kilobytes pages. Thus, a widely used rule of thumb, called the <span class="s63">ﬁve minute rule</span>, which said that data should be cached in memory if it is accessed more frequently than once in 5 minutes.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">With <span class="s44">SSD </span>technology and prices as of 2018 (which we assume to be around $500 for a 800 gigabytes <span class="s44">SSD</span>, which supports 67,000 random reads and 20,000 random writes per second), if we make the same comparison between keeping a page in memory versus fetching it from <span class="s44">SSD</span>, the time comes to around 7 minutes with 4-kilobyte pages. That is, if a page on <span class="s44">SSD </span>is accessed more frequently than once in 7 minutes, it is worth purchasing enough memory to cache it in memory.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: right;">For data that are sequentially accessed, signiﬁcantly more pages can be read per second. Assuming 1 megabyte of data are read at a time, the breakeven point for hard disk currently is about 2.5 minutes. Thus, sequentially accessed data on hard disk should be cached in memory if they are used at least once in 2.5 minutes. For <span class="s44">SSDs</span>, the breakeven point is much smaller, at 1.6 seconds. In other words, there is little beneﬁt in caching sequentially accessed data in memory unless it is very frequently accessed. The above rules of thumb take only the number of <span class="s44">I/O </span>operations per second into account and do not consider factors such as response time. Some applications need to keep even infrequently used data in memory to support response times that are less</p><p style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">than or comparable to disk-access time.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Since <span class="s44">SSD </span>storage is more expensive than disk, one way to get faster random <span class="s44">I/O </span>for frequently used data, while paying less for storing less frequently used data, is to use the <span class="s63">ﬂash-as-buﬀer </span>approach. In this approach, ﬂash storage is used as a persistent buﬀer, with each block having a permanent location on disk, but stored in ﬂash instead of being written to disk as long as it is frequently used. When ﬂash storage is full, a block that is not frequently used is evicted and ﬂushed back to disk if it was updated after being read from disk. Disk subsystems that provide hard disks along with <span class="s44">SSDs </span>that act as buﬀers are commercially available. A rule of thumb for deciding how much <span class="s44">SSD </span>storage to purchase is that a 4-kilobyte page should be kept on <span class="s44">SSD</span>, instead of hard disk, if it is accessed more frequently than once in a day (the computation is similar to the case of caching in main memory versus fetching from disk/<span class="s44">SSD</span>). Note that in such a setup, the database system cannot control what data reside in which part of the storage.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">If the storage system allows direct access to <span class="s44">SSDs </span>as well as hard disks, the database administrator can control the mapping of relations or indices to disks and allocate frequently used relations/indices to ﬂash storage. The tablespace feature, supported by most database systems, can be used to control the mapping by creating a tablespace on ﬂash storage and assigning desired relations and indices to that tablespace. Controlling the mapping at a ﬁner level of granularity than a relation, however, requires changes to the database-system code.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Another aspect of tuning is whether to use <span class="s44">RAID </span>1 or <span class="s44">RAID </span>5. The answer depends on how frequently the data are updated, since <span class="s44">RAID </span>5 is much slower than <span class="s44">RAID </span>1 on</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;"><a name="bookmark553">random writes: </a><span class="s44">RAID </span>5 requires 2 reads and 2 writes to execute a single random write request. If an application performs <i>r </i>random reads and <i>w </i>random writes per second to support a particular throughput rate, a <span class="s44">RAID </span>5 implementation would require <i>r </i><span class="s15">+ </span>4<i>w </i><span class="s42">I/O </span><span class="s43">operations per second, whereas a </span><span class="s42">RAID </span><span class="s43">1 implementation would require </span><i>r </i><span class="s15">+ </span>2<i>w </i><span class="s42">I/O </span><span class="s43">operations per second. We can then calculate the number of disks required to support the required </span><span class="s42">I/O </span><span class="s43">operations per second by dividing the result of the calculation by 100 </span><span class="s42">I/O </span><span class="s43">operations per second (for current-generation disks). For many applications, </span><i>r </i>and <i>w </i>are large enough that the (<i>r </i><span class="s15">+ </span><i>w</i>)<span class="s15">∕</span>100 disks can easily hold two copies of all the data. For such applications, if <span class="s44">RAID </span>1 is used, the required number of disks is actually less than the required number of disks if <span class="s44">RAID </span>5 is used! Thus, <span class="s44">RAID </span>5 is useful only when the data storage requirements are very large, but the update rates, and particularly random update rates, are small.<a name="bookmark583">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 88pt;text-indent: 0pt;text-align: left;">25.1.9 Performance Simulation</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">To test the performance of a database system even before it is installed, we can create a performance-simulation model of the database system. Each service shown in Figure 25.1, such as the <span class="s44">CPU</span>, each disk, the buﬀer, and the concurrency control, is modeled in the simulation. Instead of modeling details of a service, the simulation model may capture only some aspects of each service, such as the <span class="s63">service time </span>— that is, the time taken to ﬁnish processing a request once processing has begun. Thus, the simulation can model a disk access from just the average disk-access time.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Since requests for a service generally have to wait their turn, each service has an associated queue in the simulation model. A transaction consists of a series of requests. The requests are queued up as they arrive and are serviced according to the policy for that service, such as ﬁrst come, ﬁrst served. The models for services such as <span class="s44">CPU </span>and the disks conceptually operate in parallel, to account for the fact that these subsystems operate in parallel in a real system.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Once the simulation model for transaction processing is built, the system adminis- trator can run a number of experiments on it. The administrator can use experiments with simulated transactions arriving at diﬀerent rates to ﬁnd how the system would behave under various load conditions. The administrator could run other experiments that vary the service times for each service to ﬁnd out how sensitive the performance is to each of them. System parameters, too, can be varied, so that performance tuning can be done on the simulation model.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part447.htm">&lt; 上一个</a><span> | </span><a href="../database.html">内容</a><span> | </span><a href="part449.htm">下一个 &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
