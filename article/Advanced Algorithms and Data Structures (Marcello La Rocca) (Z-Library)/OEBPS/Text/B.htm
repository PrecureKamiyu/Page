<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>appendix B</title>
    
  <link href="../../stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="../../page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
  <div class="tocheadb">
    <h1 class="tochead" id="heading_id_2"><a id="pgfId-998530"></a><a id="pgfId-998542"></a>appendix B. Big-O notation</h1>
  </div>

  <p class="body"><a id="pgfId-998553"></a>In this <a id="marker-999999"></a>appendix, we provide a refresher about the RAM model and the renowned big-O mathematical notation, showing you it’s not as bad as you might have heard. Don’t worry; to go through the book you’ll only need a high-level understanding, just the bare minimum to apply it in the algorithm analysis.</p>

  <h2 class="fm-head" id="heading_id_3"><a id="pgfId-998564"></a>B.1 Algorithms and performance</h2>

  <p class="body"><a id="pgfId-998578"></a>Describing <a id="marker-1000003"></a>the performance of an algorithm is not a trivial exercise. You might be used to describing the performance of your code in term of benchmarks, and that might seem straightforward, but if you start thinking about how to describe it effectively, so that your findings can be shared and be meaningful to others, then it raises more issues than you initially thought of.</p>

  <p class="body"><a id="pgfId-998593"></a>For example, what does performance even mean? It usually implies some kind of measure, so what will it be?</p>

  <p class="body"><a id="pgfId-998602"></a>Your first answer might be that you measure the time interval needed to run the algorithm on a certain input. A step further might even be realizing that you might need to average over several inputs, and several runs on the same input, to account for external factors. This would still be a noisy measurement, especially with modern multicore architectures. It’s going to be hard to sandbox your experiments, and both the operating system and background processes will influence the result.</p>

  <p class="body"><a id="pgfId-998619"></a>But this is not even the worst part. This result will be largely influenced by the hardware you are running your experiments on, so it won’t have any meaning as an absolute number. You might try to run a benchmark test and compare your algorithm performance to some other known algorithm. Sometimes this technique produces meaningful results, but it doesn’t seem like the way to go, because there would still be too many variables to take into consideration, from the hardware and operating system it’s running on to the type and size of input used in your tests.</p>

  <p class="body"><a id="pgfId-998637"></a>Continuing in your reasoning, you can think about counting the instructions that are run. This is probably a good indicator of how much time will be needed to run the whole algorithm, and sufficiently generalizable, right?</p>

  <p class="body"><a id="pgfId-998646"></a>Well . . . not quite.</p>

  <ol class="calibre18">
    <li class="fm-list-numbered">
      <p class="list"><a class="calibre14" id="pgfId-998661"></a>Will you count machine instructions? If so, it will not be platform-agnostic.</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-998673"></a>If, instead, you count high-level instructions only, it will heavily depend on the programming language you choose. Scala or Nim can be much more succinct than Java, Pascal, or COBOL.</p>
    </li>

    <li class="fm-list-numbered-last">
      <p class="list"><a class="calibre14" id="pgfId-998697"></a>What can be considered an improvement? Is it relevant if your algorithm runs 99 instructions instead of 101?</p>
    </li>
  </ol>

  <p class="body"><a id="pgfId-998709"></a>We could keep going, but you should get the gist by now. The issue here is that we were focusing too much on details that have little importance. The key to get out of this impasse is to abstract out these details: this was obtained by defining a simplified computational model, the RAM model. The latter is a set of basic operations working on an internal <a id="marker-1000007"></a><i class="calibre17">random access memory</i>.</p>

  <h2 class="fm-head" id="heading_id_4"><a id="pgfId-998728"></a>B.2 The RAM model</h2>

  <p class="body"><a id="pgfId-998742"></a>Under <a id="marker-1000011"></a><a id="marker-1000015"></a>the RAM model, a few assumptions hold:</p>

  <ul class="calibre19">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre14" id="pgfId-998754"></a>Each basic operation (arithmetic operations, <code class="fm-code-in-text">if</code>, or function call) takes exactly a single one-time step (henceforth just referred to as <i class="calibre15">step</i><a class="calibre14" id="marker-1000019"></a>).</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-998773"></a>Loops and subroutines are not considered simple operations. Instead, they are the composition of many one-time-step operations and consume resources proportional to the number of times they run.</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-998785"></a>Each memory access takes exactly one step.</p>
    </li>

    <li class="fm-list-numbered-last">
      <p class="list"><a class="calibre14" id="pgfId-998797"></a>Memory is considered infinite.</p>
    </li>
  </ul>

  <p class="body"><a id="pgfId-998809"></a>The last point might seem a bit unrealistic, but notice that in this model we make no distinction between accesses to actual cache, RAM, hard drive, or data-center storage. In other words</p>

  <ul class="calibre19">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre14" id="pgfId-998821"></a>For most real-world applications, we can imagine providing the memory needed.</p>
    </li>

    <li class="fm-list-numbered-last">
      <p class="list"><a class="calibre14" id="pgfId-998838"></a>With this assumption, we can abstract away the details of the memory implementation and focus on the logic.</p>
    </li>
  </ul>

  <p class="body"><a id="pgfId-998850"></a>Under the RAM model, the performance of an algorithm is measured as the number of steps it takes on a given input.</p>

  <p class="body"><a id="pgfId-998859"></a>These simplifications allow us to abstract out the details of the platform. For some problems or some variants, we might be interested in bringing some details back. For instance, we can distinguish cache accesses from disk accesses. But in general, this generalization serves us well.</p>

  <p class="body"><a id="pgfId-998869"></a>Now that we’ve established the model we’ll use, let’s discuss what we’ll consider to be relevant improvement of an <a id="marker-1000023"></a><a id="marker-1000027"></a>algorithm.</p>

  <h2 class="fm-head" id="heading_id_5"><a id="pgfId-998881"></a>B.3 Order of magnitude</h2>

  <p class="body"><a id="pgfId-998895"></a>The <a id="marker-1000031"></a>other aspect we still need to simplify is the way we count instructions. We might decide to count only some kinds of operations like memory accesses. Or, when analyzing sorting algorithms, we can only take into account the number of element swaps.</p>

  <p class="body"><a id="pgfId-998915"></a>Also, as suggested, small variations in the number of steps executed are hardly relevant. Rather, we could reason on order of magnitude changes: 2x, 10x, 100x, and so on.</p>

  <p class="body"><a id="pgfId-998928"></a>But to really understand when an algorithm performs better than another one on a given problem instance, we need another epiphany: we need to express the number of steps performed as a function of the problem size.</p>

  <p class="body"><a id="pgfId-998937"></a>Suppose we are comparing two sorting algorithms, and we state that “on a given test set, the first algorithm takes 100 steps to get to the solution while the second one takes 10.” Does that really help us predict the performance of either algorithm on another problem instance?</p>

  <p class="body"><a id="pgfId-998950"></a>Conversely, if we can prove that on an array with n elements, algorithm A needs <code class="fm-code-in-text">n * n</code> element swaps, while algorithm B only takes <code class="fm-code-in-text">n</code>, then we have a very good way to predict how each of them will perform on input of any size.</p>

  <p class="body"><a id="pgfId-998965"></a>This is where big-O notation kicks in. But first, take a look at figure B.1 to get an idea of how the running times for these two algorithms would compare. This chart should make you realize why we would like to stick with <a id="marker-1000035"></a>algorithm B.</p>

  <p class="fm-figure"><img alt="" class="calibre23" src="../Images/appB_F1.png"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1011181"></a>Figure B.1 Visual comparison of the running time of a quadratic algorithm (A) and a linear algorithm (B). The former grows so much faster that, although the <code class="fm-code-in-text">y</code> axes shows up to 10 times the max value reached by algorithm B, it only manages to show the plot for algorithm A (the curvy line) up to<a href="#pgfId-1000080"><sup class="footnotenumber">1</sup></a> <code class="fm-code-in-text">n~=30</code>.</p>

  <h2 class="fm-head" id="heading_id_6"><a id="pgfId-999006"></a>B.4 Notation</h2>

  <p class="body"><a id="pgfId-999018"></a>Big-O <a id="marker-1000039"></a>notation is a mathematical symbolization used to describe how certain quantities grow with the size of an input. Usually it takes the form of a capital <code class="fm-code-in-text">o</code>, enclosing an expression within parentheses: something like <code class="fm-code-in-text">O(f(n))</code>, hence the name big-O. <code class="fm-code-in-text">f(n</code><a id="marker-1000043"></a><code class="fm-code-in-text">)</code> here can be any function with input <code class="fm-code-in-text">n</code>; we only consider functions on integers, because <code class="fm-code-in-text">n</code> usually describes the size of some input.</p>

  <p class="body"><a id="pgfId-999047"></a>We are not going to describe big-O notation in detail here; it’s way out of our scope. But there are many textbooks available with in-depth dissertations on the topic.</p>

  <p class="body"><a id="pgfId-999064"></a>The main concept you need to remember is that the notation <code class="fm-code-in-text">O(f(n))</code> expresses a bound.</p>

  <p class="body"><a id="pgfId-999075"></a>Mathematically, saying <code class="fm-code-in-text">g(n) = O(f(n))</code> means that for any large enough input, there is a real value constant <code class="fm-code-in-text">c</code> (whose value does not depend on n), such that <code class="fm-code-in-text">g(n)</code> <span class="cambria">≤</span> <code class="fm-code-in-text">c * f(n)</code> for every possible value of <code class="fm-code-in-text">n</code> (possibly larger than a certain value <code class="fm-code-in-text">n<sub class="subscript1">0</sub></code>).</p>

  <p class="body"><a id="pgfId-999098"></a>For instance, if <code class="fm-code-in-text">f(n) = n</code> and <code class="fm-code-in-text">g(n) = 40 + 3*n</code>, we can choose <code class="fm-code-in-text">c = 4</code> and <code class="fm-code-in-text">n<sub class="subscript1">0</sub> = 40</code>.</p>

  <p class="body"><a id="pgfId-999117"></a>Figure B.2 shows how these three functions grow with respect to each other. While <code class="fm-code-in-text">f(n)</code> is always smaller than <code class="fm-code-in-text">g(n), c*f(n)</code> becomes larger than <code class="fm-code-in-text">g(n</code><a id="marker-1000051"></a><code class="fm-code-in-text">)</code> at some point. To better understand the turning point, we can evaluate the two formulas by substituting actual values for their parameter <code class="fm-code-in-text">n</code>. We use the following notation <code class="fm-code-in-text">f(1) -&gt; 1</code> to assert that <code class="fm-code-in-text">f(1)</code> evaluates to <code class="fm-code-in-text">1</code> (in other words, the result of calling <code class="fm-code-in-text">f(1)</code> is equal to 1).</p>

  <p class="body"><a id="pgfId-999158"></a>For <code class="fm-code-in-text">n</code> lower than <code class="fm-code-in-text">40</code>, <code class="fm-code-in-text">g(n)</code> will be larger. For <code class="fm-code-in-text">n = 30, f(30) -&gt; 120</code> and <code class="fm-code-in-text">g(n) -&gt; 130</code>. Instead, we know that <code class="fm-code-in-text">f(40) -&gt; 160</code> and <code class="fm-code-in-text">g(40) -&gt; 160, f(41) -&gt; 164</code> while <code class="fm-code-in-text">g(41) -&gt; 163</code>. For any value greater than <code class="fm-code-in-text">41</code>, <code class="fm-code-in-text">40 + 3 *n &lt;= 4 * n</code>.</p>

  <p class="fm-figure"><img alt="" class="calibre23" src="../Images/appB_F2.png"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1011223"></a>Figure B.2 Visual comparison of functions: <code class="fm-code-in-text">f(n)=n</code>, <code class="fm-code-in-text">g(n) = 40 + 3*n</code>, <code class="fm-code-in-text">4*f(n)</code>. While <code class="fm-code-in-text">f(n)</code> is always smaller than <code class="fm-code-in-text">g(n)</code>, <code class="fm-code-in-text">4*f(n)</code> becomes larger than <code class="fm-code-in-text">g(n)</code> for sufficiently large values of <code class="fm-code-in-text">n</code>.</p>

  <p class="body"><a id="pgfId-999221"></a>But don’t forget that the condition <code class="fm-code-in-text">g(n)</code> <span class="cambria">≤</span> <code class="fm-code-in-text">c * f(n)</code> must hold true for every <code class="fm-code-in-text">n</code> <span class="cambria">≥</span> <code class="fm-code-in-text">n<sub class="subscript1">0</sub></code>. We can’t rigorously prove that by plotting a chart or plugging in (a finite number of) values for <code class="fm-code-in-text">n</code> in the formula (see figure B.3 for a counter-example), but we would need to resort to some algebra; nevertheless, plotting the functions can help you get an idea of how they grow and whether you are going in the right direction.</p>

  <p class="fm-figure"><img alt="" class="calibre23" src="../Images/appB_F3.png"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1011265"></a>Figure B.3 An example showing why we need to be careful when drawing conclusions. While <code class="fm-code-in-text">g(n)</code> is larger than <code class="fm-code-in-text">f(n)</code> at <code class="fm-code-in-text">n<sub class="calibre33">0</sub>~=112</code>, this doesn’t hold true for any value of <code class="fm-code-in-text">n &gt;n<sub class="calibre33">0</sub></code>. In fact, at <code class="fm-code-in-text">n<sub class="calibre33">1</sub>~=887</code>, we have another intersection between the two functions, and after that point <code class="fm-code-in-text">f(n)</code> again becomes larger than <code class="fm-code-in-text">g(n)</code>.</p>

  <p class="body"><a id="pgfId-999284"></a>Moving back to our example, if we say that algorithm A is <code class="fm-code-in-text">O(n<sup class="superscript1">2</sup>)</code>, it means that <code class="fm-code-in-text">T(n) = O(n<sup class="superscript1">2</sup>)</code>, where <code class="fm-code-in-text">T(n)</code> is the running time of the algorithm. Or, in other words, algorithm A will never require more than a quadratic number of steps.</p>

  <p class="body"><a id="pgfId-999300"></a>The definition for <code class="fm-code-in-text">O(n)</code> has some consequences:</p>

  <ul class="calibre19">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre14" id="pgfId-999312"></a>“For any large enough input.” This is a crucial piece. We are interested in how our functions behave when <code class="fm-code-in-text">n</code> gets (very) large and we don’t care if for small values of <code class="fm-code-in-text">n</code> the inequalities don’t hold. Think, for example, of the functions <code class="fm-code-in-text">f(x) = ex</code> and <code class="fm-code-in-text">g(x) = e * x. f(x) &lt; g(x)</code> when <code class="fm-code-in-text">x</code> is smaller than <code class="fm-code-in-text">1</code>, but for larger values, <code class="fm-code-in-text">f(x)</code> grows much faster.</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-999351"></a>Constant factors don’t matter: <code class="fm-code-in-text">O(n) = O(3 * n) = O(100 * n)</code>. You can prove this by choosing the right values for the constant in the previous inequality.</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-999368"></a>Some problems require constant time: think about summing the first <code class="fm-code-in-text">n</code> integers. With the naïve algorithm, you would need <code class="fm-code-in-text">n-1</code> sums, but with Gauss’ method, you only need one sum, one multiplication and one division, independent of the output.</p>

      <p class="fm-list-body"><a class="calibre14" id="pgfId-999384"></a>To sum this up using a formula, we can write <code class="fm-code-in-text">O(c) = O(1)</code> for any positive constant <code class="fm-code-in-text">c</code>.</p>

      <p class="fm-list-body"><a class="calibre14" id="pgfId-999401"></a><code class="fm-code-in-text">O(1)</code> denotes a constant running time: in other words, one that does not depend on the input size.</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-999413"></a>When summing big-O expressions, the biggest wins: <code class="fm-code-in-text">O(f(n) + g(n)) = O(f(n))</code> if <code class="fm-code-in-text">g(n) = O(f(n))</code>. So, if two algorithms are run in sequence, the total running time is dominated by the slowest.</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-999430"></a><code class="fm-code-in-text">O(f(n) * g(n))</code> can’t be simplified unless either function is constant.</p>
    </li>
  </ul>

  <p class="fm-callout"><a id="pgfId-999444"></a><span class="fm-callout-head">Note</span> Often when we give an algorithm running time using big-O notation, we imply that the bound is both lower and upper—unless we explicitly say otherwise. Nevertheless, <span class="cambria">Θ</span><code class="fm-code-in-text2">(f(n))</code> would be the correct notation for the class of functions whose upper and lower bound is <code class="fm-code-in-text2">f(n</code><a id="marker-1000059"></a><code class="fm-code-in-text2">)</code>.</p>

  <p class="body"><a id="pgfId-999466"></a>Now we have all the tools we need to unequivocally describe algorithms’ performance. You will see this notation in action a lot in the remaining sections of this <a id="marker-1003984"></a>appendix.</p>

  <h2 class="fm-head" id="heading_id_7"><a id="pgfId-999478"></a>B.5 Examples</h2>

  <p class="body"><a id="pgfId-999490"></a>If <a id="marker-1000067"></a>it’s the first time you have seen big-O notation, it’s perfectly normal to feel slightly confused. It takes some time and lots of practice to get used to it.</p>

  <p class="body"><a id="pgfId-999505"></a>Let’s see a few examples and try to apply what we described in the previous section in mathematical terms.</p>

  <p class="body"><a id="pgfId-999514"></a>Suppose you have 4 numbers you’d like to sum: <code class="fm-code-in-text">{1, 3, -1.4, 7}</code>. How many additions will you need? Let’s see:</p>
  <pre class="programlisting"><a id="pgfId-999534"></a>1 + 3 + (-1.4) + 7</pre>

  <p class="body"><a id="pgfId-999543"></a>It looks like you can do with three additions. What about if we have to sum 10 numbers? You can easily verify that we need nine. Can we generalize this number of operations for any size of the input? Yes, we can, as it’s easy to prove that we always need <code class="fm-code-in-text">n-1</code> additions to sum up <code class="fm-code-in-text">n</code> numbers.</p>

  <p class="body"><a id="pgfId-999556"></a>So, we can say that summing up the elements of a list of <code class="fm-code-in-text">n</code> numbers (asymptotically) requires <code class="fm-code-in-text">O(n)</code> operations. If we denote with <code class="fm-code-in-text">T(n)</code> the number of operations needed, we can say that <code class="fm-code-in-text">T(n) = O(n)</code>.</p>

  <p class="body"><a id="pgfId-999575"></a>Let’s consider two slight variations:</p>

  <ul class="calibre19">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre14" id="pgfId-999584"></a>We sum the first five elements of a list twice, and the other elements once.</p>
    </li>

    <li class="fm-list-numbered-last">
      <p class="list"><a class="calibre14" id="pgfId-999596"></a>We sum the squares of the elements.</p>
    </li>
  </ul>

  <p class="body"><a id="pgfId-999608"></a>In the first case, if our list is <code class="fm-code-in-text">{1, 3, -1.4, 7, 4, 1, 2}</code>, we have</p>
  <pre class="programlisting"><a id="pgfId-999619"></a>1 + 3 + (-1.4) + 7 + 4 + 1 + 2 + <span class="calibre31">1 + 3 + (-1.4) + 7 + 4</span></pre>

  <p class="body"><a id="pgfId-999629"></a>You can see the repeated elements underlined in this formula. So, for <code class="fm-code-in-text">n=7</code>, we need 11 operations.</p>

  <p class="body"><a id="pgfId-999640"></a>In general, we will need <code class="fm-code-in-text">n+4</code> operations, and <code class="fm-code-in-text">T<sub class="subscript1">1</sub>(n) = n+4</code>.</p>

  <p class="body"><a id="pgfId-999655"></a>Is it true that <code class="fm-code-in-text">T<sub class="subscript1">1</sub>(n) = O(n)</code>? Let’s go back to our definition. We need to find two constants, an integer <code class="fm-code-in-text">n<sub class="subscript1">0</sub></code> and a real number <code class="fm-code-in-text">c</code>, such that</p>
  <pre class="programlisting">T<code class="fm-code-in-text2"><sub class="subscript">1</sub></code>(n) <span class="cambria">≤</span> c * n for each n &gt; n<code class="fm-code-in-text2"><sub class="subscript">0</sub>
<span class="cambria">⇔</span>
n + 4 <span class="cambria">≤</span> c * n for each n &gt; n<code class="fm-code-in-text"><sub class="subscript1">0 </sub></code>
<span class="cambria">⇔</span>
c <span class="cambria">≥</span> 1 + 4/n for each n &gt; n<code class="fm-code-in-text"><sub class="subscript1">0 </sub></code></code></pre>

  <p class="body"><a id="pgfId-999733"></a>Since <code class="fm-code-in-text">4/n</code> decreases when <code class="fm-code-in-text">n</code> grows, we can choose <code class="fm-code-in-text">c=2</code> and <code class="fm-code-in-text">n<sub class="subscript1">0</sub>=4</code>, or, say, <code class="fm-code-in-text">c=100</code> and n<code class="fm-code-in-text"><sub class="subscript1">0</sub></code>=1, and the inequality will be satisfied.</p>

  <p class="body"><a id="pgfId-999760"></a>The same is true if we consider summing squares: for <code class="fm-code-in-text">n</code> numbers, we will need <code class="fm-code-in-text">n</code> multiplications (or squarings) and <code class="fm-code-in-text">n-1</code> sums, so <code class="fm-code-in-text">T<sub class="subscript1">2</sub>(n) = 2n-1</code>.</p>

  <p class="body"><a id="pgfId-999784"></a>We can prove that <code class="fm-code-in-text">T<sub class="subscript1">2</sub>(n) = O(n)</code> by choosing <code class="fm-code-in-text">c=2.5</code> and <code class="fm-code-in-text">n<sub class="subscript1">0</sub>=1</code>.</p>

  <p class="body"><a id="pgfId-1003061"></a>Now, we could also say that <code class="fm-code-in-text">T<sub class="subscript1">1</sub>(n) = O(n<sup class="superscript1">2</sup>)</code>. We leave it as an exercise for you to find appropriate values for <code class="fm-code-in-text">c</code> and <code class="fm-code-in-text">n<sub class="subscript1">0</sub></code>. However, this bound would not be strict: in other words, there exist other functions of n such that <code class="fm-code-in-text">T<sub class="subscript1">1</sub>(n)</code> <span class="cambria">≤</span> <code class="fm-code-in-text">f(n) &lt; O(n<sup class="superscript1">2</sup>)</code> for <code class="fm-code-in-text">n</code> large enough.</p>

  <p class="body"><a id="pgfId-1003049"></a>Likewise, we could also say that <code class="fm-code-in-text">T<sub class="subscript1">1</sub>(n) = O(n<sup class="superscript1">1000</sup>)</code>. That would certainly be true, but how helpful would it be knowing that our algorithm takes less than the age of the universe on a small input?<a href="#pgfId-1000094"><sup class="footnotenumber">2</sup></a></p>

  <p class="body"><a id="pgfId-999862"></a>As you might suspect, we are usually interested in strict bounds. While this is true and expected, and for our summation examples it seems trivial to prove that the <code class="fm-code-in-text">O(n)</code> bound is strict, you might be surprised to learn that there are some algorithms for which we don’t know what the stricter bound is, or at least we can’t prove it.</p>

  <p class="body"><a id="pgfId-999874"></a>As a final example, let’s consider the task of enumerating all the couples of numbers in a list, regardless of their order. For instance, given the list <code class="fm-code-in-text">{1, 2, 3}</code>, we have the pairs <code class="fm-code-in-text">(1,2), (1,3), (3,2)</code>.</p>

  <p class="body"><a id="pgfId-999887"></a>It turns out that the number of unordered pairs for <code class="fm-code-in-text">n</code> elements is <code class="fm-code-in-text">T<sub class="subscript1">3</sub>(n) = n * (n-1) / 2</code>:</p>
  <pre class="programlisting"><a id="pgfId-999903"></a>T<sub class="calibre25">3</sub>(n) = n * (n-1) / 2 <span class="cambria">≤</span> 1*n<sup class="superscript2">2</sup> for n &gt; 1</pre>

  <p class="body"><a id="pgfId-999918"></a>Thus we can say <code class="fm-code-in-text">T<sub class="subscript1">3</sub>(n) = O(n<sup class="superscript1">2</sup>)</code>. This time, the quadratic bound is also a strict bound, as shown <a id="marker-1000071"></a>in <a id="marker-1000075"></a>figure B.4.</p>

  <p class="fm-figure"><img alt="" class="calibre23" src="../Images/appB_F4.png"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1011307"></a>Figure B.4 Visual comparison of functions: <code class="fm-code-in-text">f(n)=n*(n-1)</code>, <code class="fm-code-in-text">g(n) = n<sup class="calibre27">2</sup></code>. The latter is always larger for any positive value of <code class="fm-code-in-text">n</code>.</p>
  <hr class="calibre22"/>

  <p class="fm-footnote"><sup class="footnotenumber">1.</sup> <a id="pgfId-1000080"></a>In this context, and for the rest of the book, ~= means “approximately equal to.”</p>

  <p class="fm-footnote"><sup class="footnotenumber">2.</sup> <a id="pgfId-1000094"></a>This might be useful if we need to prove that an algorithm will actually run in finite time. But with real-world applications, it’s usually of little practical use.</p>
</body>
</html>
