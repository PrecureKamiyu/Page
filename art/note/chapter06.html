<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2023-06-21 Wed 01:49 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Memory and its Performance</title>
<meta name="generator" content="Org mode" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<style>body {font-family: serif, 宋体;font-size: 200%;} a {color: black; text-decoration: none;}</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2019 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Memory and its Performance</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org1b21c30">1. Beginning</a></li>
<li><a href="#orgc06f762">2. 概述</a>
<ul>
<li><a href="#org7f6a210">2.1. 分类学</a></li>
<li><a href="#org34445e8">2.2. Memory heirarchy</a></li>
<li><a href="#orge71c0b4">2.3. Main 存</a></li>
</ul>
</li>
<li><a href="#org5b33860">3. SemiConductors Chips</a>
<ul>
<li><a href="#org9cfe964">3.1. 半导体存储芯片的基本结构</a></li>
<li><a href="#org85eefb4">3.2. RAM</a>
<ul>
<li><a href="#orga970746">3.2.1. SRAM 和 DRAM</a></li>
<li><a href="#org0af12b2">3.2.2. SRAM 和 DRAM 的结构示意图</a></li>
<li><a href="#org6331332">3.2.3. SRAM 时序分析</a></li>
<li><a href="#orge7864dc">3.2.4. <span class="todo TODO">TODO</span> The Examples of SRAM and DRAM</a></li>
<li><a href="#org14d2097">3.2.5. <span class="todo TODO">TODO</span> DRAM 时序分析</a></li>
<li><a href="#org266ac43">3.2.6. DRAM 的刷新方式</a></li>
<li><a href="#orgcfa74ef">3.2.7. The comparison between DRAM and SRAM</a></li>
</ul>
</li>
<li><a href="#org658f5d7">3.3. ROM</a>
<ul>
<li><a href="#orgccdcd23">3.3.1. ROM 的简单分类学</a></li>
<li><a href="#org27b3609">3.3.2. EPROM 的结构介绍</a></li>
</ul>
</li>
<li><a href="#org6473f9b">3.4. Chips 和 CPU 的链接 (important)</a>
<ul>
<li><a href="#orgb459d52">3.4.1. How to Deal lianxian</a></li>
<li><a href="#org64990cc">3.4.2. <span class="todo TODO">TODO</span> Example of the lianxian of chips and cpu</a></li>
</ul>
</li>
<li><a href="#orga642888">3.5. 存储器的校验 Parity</a>
<ul>
<li><a href="#org92e3019">3.5.1. 校验的电路结构</a></li>
<li><a href="#org9eeabc3">3.5.2. Hamming Code</a></li>
</ul>
</li>
<li><a href="#orgea85c61">3.6. <span class="done DONE">DONE</span> 提高访问速度的方式</a>
<ul>
<li><a href="#orgc0db36b">3.6.1. 总结</a></li>
<li><a href="#orgee223bf">3.6.2. 单体多字</a></li>
<li><a href="#org7115ba2">3.6.3. 多体并行</a></li>
<li><a href="#orgae74638">3.6.4. 存控</a></li>
<li><a href="#org15f98cc">3.6.5. <span class="done DONE">DONE</span> Synchronous DRAM</a></li>
<li><a href="#orga3ba464">3.6.6. <span class="todo TODO">TODO</span> Rambus DRAM</a></li>
<li><a href="#org83fe9a0">3.6.7. Cache DRAM</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgf4613af">4. Cache</a>
<ul>
<li><a href="#org8d92ef9">4.1. An introduction</a></li>
<li><a href="#org9b77b8d">4.2. <span class="done DONE">DONE</span> The Elements of Cache</a>
<ul>
<li><a href="#org5f44220">4.2.1. Hit and Miss</a></li>
</ul>
</li>
<li><a href="#org41537af">4.3. The Structure of the Cache</a>
<ul>
<li><a href="#org4c68c2b">4.3.1. The REAL Structure of Cache</a></li>
<li><a href="#org88ffe98">4.3.2. Block Size and its Effect to Hit Rate</a></li>
</ul>
</li>
<li><a href="#org3cd457b">4.4. <span class="done DONE">DONE</span> Mapping Strategy</a>
<ul>
<li><a href="#org69c7e5f">4.4.1. Direct Mapping</a></li>
<li><a href="#org2c4fc95">4.4.2. (full) Associative Mapping</a></li>
<li><a href="#org13dcac7">4.4.3. Set-Associative Mapping</a></li>
</ul>
</li>
<li><a href="#org46f7797">4.5. <span class="done DONE">DONE</span> Write Policy</a>
<ul>
<li><a href="#orgc342b8a">4.5.1. Why We have to maintain the consistency of the memory heirarchy</a></li>
<li><a href="#orga2c6169">4.5.2. Two strategies</a></li>
<li><a href="#orge50e0e7">4.5.3. Write Through</a></li>
<li><a href="#orge4c3f79">4.5.4. Write Back</a></li>
<li><a href="#org00b03af">4.5.5. <span class="todo TODO">TODO</span> The More into Write Policy</a></li>
</ul>
</li>
<li><a href="#org064306e">4.6. <span class="done DONE">DONE</span> Ways to Improve the Performance of Cache</a>
<ul>
<li><a href="#orgdde759d">4.6.1. Multi-level Cache</a></li>
<li><a href="#org56bd975">4.6.2. <span class="todo WAITING">WAITING</span> Split Cache</a></li>
</ul>
</li>
<li><a href="#orgc0374f9">4.7. <span class="done DONE">DONE</span> Replacement Algorithm</a>
<ul>
<li><a href="#org51699c2">4.7.1. <span class="todo WAITING">WAITING</span> More into Replacement Algorithm</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org79c5271">5. Virtual Memory (from <i>Patterson</i>)</a>
<ul>
<li><a href="#orgbdddff4">5.1. what is virtual memory</a></li>
<li><a href="#org27254fd">5.2. Page and Page table</a>
<ul>
<li><a href="#org2bec6db">5.2.1. the Translation</a></li>
<li><a href="#org08bc495">5.2.2. Page Table</a></li>
<li><a href="#orgfc31d5c">5.2.3. Writes in Virtual Memory</a></li>
<li><a href="#org0b24574">5.2.4. TLB</a></li>
<li><a href="#orga901e67">5.2.5. Ways to improve the performance of Page Table</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgd2b1f93">6. External Memory</a>
<ul>
<li><a href="#orgda93c03">6.1. <span class="done DONE">DONE</span> RAID from Stallings</a>
<ul>
<li><a href="#org3d0d7ce">6.1.1. RAID and some related Concepts</a></li>
<li><a href="#org791d17d">6.1.2. RAID Level 0</a></li>
<li><a href="#orgb47aa87">6.1.3. RAID Level 1</a></li>
<li><a href="#org150a3dd">6.1.4. RAID Level 2</a></li>
<li><a href="#org3c55dcf">6.1.5. <span class="todo TODO">TODO</span> RAID Level 3</a></li>
<li><a href="#orgf5f1d7c">6.1.6. RAID Level 4</a></li>
<li><a href="#org639142f">6.1.7. RAID Level 5</a></li>
<li><a href="#org803aead">6.1.8. RAID Level 6</a></li>
</ul>
</li>
<li><a href="#org4abcaac">6.2. Magnetic Disk &amp; Optical Memory &amp; Magnetic Tap</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-org1b21c30" class="outline-2">
<h2 id="org1b21c30"><span class="section-number-2">1</span> Beginning</h2>
<div class="outline-text-2" id="text-1">
<ul class="org-ul">
<li>Note taken on <span class="timestamp-wrapper"><span class="timestamp">[2023-06-07 Wed 22:37] </span></span> <br />
This chapter has huge amount of content, but arranged in a shitty way. Becareful.</li>
</ul>
<ol class="org-ol">
<li>概述</li>
<li>Main Memory. 内存也称为 Main 存</li>
<li>Cache. Main 存和 CPU (Processor) 之间的</li>
<li>虚拟 Memory. Main 存相关的.</li>
<li>辅助存储器. External 存储器. 比如说硬盘.</li>
</ol>
</div>
</div>

<div id="outline-container-orgc06f762" class="outline-2">
<h2 id="orgc06f762"><span class="section-number-2">2</span> 概述</h2>
<div class="outline-text-2" id="text-2">
<ul class="org-ul">
<li>Note taken on <span class="timestamp-wrapper"><span class="timestamp">[2023-06-07 Wed 22:24] </span></span> <br />
And you don't have to remember the classification here. You can just learn it, with no pressure.</li>
<li>Note taken on <span class="timestamp-wrapper"><span class="timestamp">[2023-06-07 Wed 22:22] </span></span> <br />
This section is absolutely shit.</li>
</ul>

<p>
为什么研究存储器非常重要?
</p>

<ul class="org-ul">
<li>CPU 的运行速度变得高的同时, 存储器的读取速度跟不上这个发展, 于是说, 计算机系统的运行速度收到了存储器很大程度上的制约.</li>
<li>另一方面, 当我们 IO 设备的数量不断增多, 若是 IO 设备和存储器之间的, 信息交换都是直接通过 CPU 来实现. 那么其将降低 CPU 的运转效率.</li>
</ul>

<p>
随后我们对存储器进行分类, 因为, 嘛, 反正我们有很多存储器. 随后, 这种分类让我们看到的那些区别, 正是这些区别让我们有 Memory Heirarchy. 目前我们有三种分类方法: 
</p>

<ol class="org-ol">
<li>按照存储介质进行分类;</li>
<li>按照存取方式进行分类;</li>
<li>按照功能进行分类.</li>
</ol>

<p>
这些分类方法是让我们看见这些存储方式的特点. 总之是有好处的.
</p>
</div>

<div id="outline-container-org7f6a210" class="outline-3">
<h3 id="org7f6a210"><span class="section-number-3">2.1</span> 分类学</h3>
<div class="outline-text-3" id="text-2-1">
<ul class="org-ul">
<li>Note taken on <span class="timestamp-wrapper"><span class="timestamp">[2023-06-16 Fri 12:53] </span></span> <br />
You should the word "random accessing" which means that you can access to the memory specified by the address you have given.</li>
</ul>

<p>
<b>按照存储介质进行分类</b>:
</p>
<ol class="org-ol">
<li>SemiConductor 存储器. 这是一种 volatile 的存储器, 也就是 "断电会丢
失" 的存储器.</li>
<li>磁表面存储器. Magnetic Disk. 使用了磁介质来存储.</li>
<li>磁芯存储器. ?什么价吧.</li>
<li>光盘存储器. 在读写过程之中应用了激光.</li>
</ol>


<p>
<b>按照存储方式分类</b>
</p>
<ol class="org-ol">
<li>RAM. 可读可写的存储器. 有 SRAM (Static RAM) 和 DRAM (Dynamic RAM).</li>
<li>ROM. 只可读的存储器. 有很多种, 比如说 EPROM, EEPROM, Flash
Memory. 值得注意的是, Flash Memory 的功能并不是很一样, 虽然其也是
ROM 的一种, 但是从结果上来看, 功能已经很不一样了.</li>
<li>串行访问存储器. 简单来说, 就是和 Random accessing 相反的一个存在.
RA 指的是, 能够通过地址来进行访问. 这种就是随机访问, 也就是说, 给定
了一个地址, 我们能够直接访问到那个地址里面的数据. 串行访问存储器就
是不能够做到这一点的存储器.</li>
</ol>


<p>
<b>按照功能进行分类.</b> 这里就不进行分类了, 因为分类是显然的. 这是由他们的物理特性决定的.
</p>
</div>
</div>

<div id="outline-container-org34445e8" class="outline-3">
<h3 id="org34445e8"><span class="section-number-3">2.2</span> Memory heirarchy</h3>
<div class="outline-text-3" id="text-2-2">
<p>
一个金字塔. 越接近 CPU, 存储器就越快, 越贵; 越远离 CPU, 存储器就越慢, 越便宜, 于是相应的就越多. 我们稍微看一下这个层级,简单来说, 我们有
</p>

<pre class="example">
CPU &lt;-&gt; 缓存 &lt;-&gt; Main 存 &lt;-&gt; 辅存
</pre>

<p>
huancun refers to the cache. Cache is usually not visible to the programmers. Programmers mostly manipulate with the memory, which is here, the main memory. fucun refers to the external memory, for example disk.
</p>

<p>
Main 存就是我们常说的内存啦. 缓存的存在是为了加速 CPU 和 Main 存之间的交互. 如果说我们知道了 hit rate 的概念, 当这个 hit rate 的数值接近于 1 的时候, 我们就可以说, CPU 能够以 "缓存的速度" 去访问 Main 存, 也就是说, 相当于缓存的大小被扩张为 Main 存的大小.
</p>

<p>
值得注意的是, Main 存以及 Cache 可以被称为 Internal Memory. 因为其是放
在板上的, 与之相对的是, 辅存被称为 External Memory. 这是说, 存储设备是
和 Chip 分开的. 于是我们能够知道访问 External Memory 的时候, 需要涉及
Bus. 应该.
</p>

<hr />

<p>
在 main 存和 CPU 之间还发展出来了虚拟存储. 简单来说, 这是一层抽象.  因
为我们的 Main 存的大小是实际上并没有那么大, 这层抽象让我们可以将一些并
不是 Main 存的地方 "看作" 是 Main 存. 剩下的细节交给系统和操作系统进行
处理.
</p>

<p>
这里面我们有两种概念: 1. 逻辑 (Logical) 地址; 2. 物理 (Physical) 地址.
前者就是一种逻辑上的地址, 已经被封装过了的地址, 而物理地址就是实际的,
Chip 上面的地址, 程序执行过程之中真正访问的地址.
</p>
</div>
</div>

<div id="outline-container-orge71c0b4" class="outline-3">
<h3 id="orge71c0b4"><span class="section-number-3">2.3</span> Main 存</h3>
<div class="outline-text-3" id="text-2-3">
<p>
<b>Word</b>: 字长便是 word 的长度. 如果说内部有 4 个 bytes, 这四个字节是可以独立寻
址的. 也就是说, 有一个特定的地址和其对应. 如果说地址长度是 n, word 的
长度是 \(2^m\)  bytes 的话, "寻址范围" 为 \(2^{n-m}\) 以及 \(2^n\).
</p>

<p>
我们能够有按 word寻址, 也能够按照 bytes 寻址
</p>

<p>
<b>寻址范围</b>: 一般来说, 地址的长度就能够算出 "寻址范围", 虽然说是范围, 但实际上, 我
们可以直接认为是, "能够访问的单元个数的多少". 这里我们可以讨论两种寻址
方式的 "寻址范围". 是很简单的东西.
</p>


<p>
<b>技术指标</b>: 简单来说, 有两个指标: 1. Capacity; 2. Speed. 
</p>

<ul class="org-ul">
<li>Capacity: 对于前者我们可以计算一个 Main 存之中的 bits 数量, 也可以计算其中 bytes数量. 这很明显是废话. 一般来说, 我们以 bytes 为单位. 当我们说出 1M 的存储容量的时候, 我们能够知道其地址长度为 20. 因为 2<sup>20</sup> 约等于 1M, 也即, 我们能够访问 1M 的数量的 bytes.</li>
<li>Speed: 指的是存储器获取到数据所用的时间. 这个指标可能还可以使用 Latency 来描述</li>
<li>带宽: 表示单位时间内, 存储器存取的信息量. 能够知道, 带宽和 bandwidth 和 Speed 之间有强关联.</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org5b33860" class="outline-2">
<h2 id="org5b33860"><span class="section-number-2">3</span> SemiConductors Chips</h2>
<div class="outline-text-2" id="text-3">
</div>
<div id="outline-container-org9cfe964" class="outline-3">
<h3 id="org9cfe964"><span class="section-number-3">3.1</span> 半导体存储芯片的基本结构</h3>
<div class="outline-text-3" id="text-3-1">
<p>
我们看芯片的接线就行了. <b>地址线</b>, 输入地址; <b>片选器</b>: 选择芯片内部的 RAM
芯片, 这是说, 一个存储器可以由很多个 RAM 芯片组成, 我们通过这个片选器
来选择具体是哪一个芯片.  <b>数据线</b>, 从芯片之中接出来的线, 大小为一个
word. <b>读写控制器</b>, 控制读写的使能.
</p>
</div>
</div>

<div id="outline-container-org85eefb4" class="outline-3">
<h3 id="org85eefb4"><span class="section-number-3">3.2</span> RAM</h3>
<div class="outline-text-3" id="text-3-2">
</div>
<div id="outline-container-orga970746" class="outline-4">
<h4 id="orga970746"><span class="section-number-4">3.2.1</span> SRAM 和 DRAM</h4>
<div class="outline-text-4" id="text-3-2-1">
<ul class="org-ul">
<li>Note taken on <span class="timestamp-wrapper"><span class="timestamp">[2023-06-16 Fri 15:02] </span></span> <br />
The unit of DRAM can be consist of 4 transistors. But we can simplify it such that it consist of 1 transistor.</li>
</ul>

<p>
SRAM 使用了多个晶体管 (6个, 具体来说), 而 DRAM 使用了 1 个晶体管和一个
电容 (这是指一个存储单元内部用到的元件). 后者的造价便宜, 但是访问速度
比较慢, 并且需要刷新, 这个刷新是很有意思的概念, 这是说, DRAM 之中的数
据会 fade away, 于是说, 经常需要刷新. 其在读取之后, 内部的存储信息也会
失效, 于是需要将原本存储的信息再放回去.
</p>

<p>
我们先是介绍 DRAM 的结构: 我这里建议读者直接查看书本. 稍微了解到这个晶
体管是如何工作的. 这里说, 当我们读取数据的时候, 电容 (Capacitor) 放电,
于是我们得到了信息, 但是同时电容将电放出, 于是这里需要 recharge.
</p>

<p>
随后是介绍 SRAM 的结构: 我这里建议读者直接查看书本. 当我们知道了晶体管
是怎么工作的之后, 了解 SRAM 的结构就不是一件难事了. SRAM 里面是一个
Latch. 这是一个简单的 latch. 有两个端: A<sub>1</sub>, A<sub>2</sub>. 我们有一个 bit 的输入,
记为 B, 那么我们将 B 接入 A<sub>1</sub>, bar B接入 A<sub>2</sub>. 这就是一个 bit 的写操作.
</p>

<p>
OK, 去读, 去看图. 参见 Tang 第二版 76 页. 值得注意的是, Tang 写得一坨
答辩. 可以先去 81 页了解一下 DRAM 的工作原理, 因为 Tang 并没有介绍晶体
管是怎么工作的. 也可以参考 Stallings 的书.
</p>
</div>
</div>

<div id="outline-container-org0af12b2" class="outline-4">
<h4 id="org0af12b2"><span class="section-number-4">3.2.2</span> SRAM 和 DRAM 的结构示意图</h4>
<div class="outline-text-4" id="text-3-2-2">
<p>
草泥马这写的是什么几把. 建议查看 <a href="https:en.wikipedia.org/wiki/Dynamic_random-access_memory">wikipedia</a> for more information. 主要
是接线很多, 但是又不知道接线是用来干什么的. 首先我们要认知到, SRAM 和
DRAM 的基本存储单元是什么? 有多少个接线. 随后我们才能读懂书上的这些图.
</p>

<p>
DRAM 和 SRAM 的单元是类似的, 都有着: 
</p>
<ul class="org-ul">
<li>读选择线, 写选择线</li>
<li>读数据线, 写数据线</li>
</ul>
<p>
就是说, 一个单元格具有两个输入和两个输出. 这里有一点不同, 就是 DRAM 有
一个预充电信号. 
总之略, 最好还是看看书. 我这里就不进行抄写了.
</p>

<p>
One should learn the structure of DRAM and then the structure of SRAM. Because you need to know how the transistor works, which is very important.
</p>

<p>
OK, 去读, 去看图. 参见 Tang 第二版 76 页. 值得注意的是, Tang 写得一坨
答辩. 可以先去 81 页了解一下 DRAM 的工作原理, 因为 Tang 并没有介绍晶体
管是怎么工作的. 也可以参考 Stallings 的书.
</p>
</div>

<ol class="org-ol">
<li><a id="org901db74"></a>The structure of DRAM<br />
<div class="outline-text-5" id="text-3-2-2-1">
<p>
我们先是介绍 DRAM 的结构: 我这里建议读者直接查看书本. 稍微了解到这个晶
体管是如何工作的. 这里说, 当我们读取数据的时候, 电容 (Capacitor) 放电,
于是我们得到了信息, 但是同时电容将电放出, 于是这里需要 recharge.
</p>

<p>
DRAM consists of a capatitor (idk how it spell) and three transistor (and we also have a version with only one transistor). 
</p>

<p>
The transistor works like a gate. The middle input can be viewed as a handle. If it is on the signal can go through the transistor, (the gate is open).
</p>

<p>
The capacitor store some 电压; if the gate is open, the current just let go; if the gate is closed, the current remains. The read process is the exact process of let go the electron stored in capacitor. 
</p>

<p>
Conversely, the process of write is to store some electron into the capacitor.
</p>
</div>
</li>

<li><a id="org427c8be"></a>The structure of SRAM<br />
<div class="outline-text-5" id="text-3-2-2-2">
<p>
随后是介绍 SRAM 的结构: 我这里建议读者直接查看书本. 当我们知道了晶体管
是怎么工作的之后, 了解 SRAM 的结构就不是一件难事了. SRAM 里面是一个
Latch. 这是一个简单的 latch. 有两个端: A<sub>1</sub>, A<sub>2</sub>. 我们有一个 bit 的输入,
记为 B, 那么我们将 B 接入 A<sub>1</sub>, bar B接入 A<sub>2</sub>. 这就是一个 bit 的写操作.
</p>

<p>
Simple practise: go and check the book. Because I can't draw a picture here. If you think the book is shit, then you can check <i>Stallings</i>' book. 
</p>
</div>
</li>
</ol>
</div>

<div id="outline-container-org6331332" class="outline-4">
<h4 id="org6331332"><span class="section-number-4">3.2.3</span> SRAM 时序分析</h4>
<div class="outline-text-4" id="text-3-2-3">
<ul class="org-ul">
<li>Note taken on <span class="timestamp-wrapper"><span class="timestamp">[2023-06-16 Fri 17:53] </span></span> <br />
we analyse a cycle of read or write operation. The start of the cycle and the end of the cycle are marked by the change of the address line. That is to say, if the address line change, then we are heading to next cycle. What we want to know is what elements are here to compose the minimun of the cycle time.</li>
</ul>
<p>
Although the analysis seems so useless, you should read it as well. 
</p>


<p>
<b>Read</b>: Anyway, we need to figure out the signals first. As you can see, the addresss line is the input, and the there is a signal called pianxuan signal (OK, the input method is down for now, I can just type in English). And the output is the data line. Namely, we have: 
</p>

<ul class="org-ul">
<li><b>A</b>: address line: usually it is 32-bit long or 64-bit long. It depends on the system, you know. Our device is mainly x64, that is to say the address line is 64-bit long.</li>
<li>\(\bf\overline{CS}\): the 片选 signal. CS is 低有效. It is triggerred when the signal become 0</li>
<li><b>D<sub>out</sub></b>: the data we get from the chip.</li>
</ul>

<p>
All this is what we need to analyse the read operation. The process is like 1. The address is ready; 2. CS is ready; 3. Consequently, the Data is ready. The rest of  the text is all blah.
</p>

<p>
<b>Write</b>:  Write is relatively complex. We have the write enable signal, namly, \(\bf \overline{WE}\). And we should note that when the data is not valid, it is at 高态. 
</p>

<ul class="org-ul">
<li><b>A</b>: the address line</li>
<li>\(\bf \overline{WE}\): Write enable</li>
<li><b>D<sub>in</sub></b>: the input Data, that is the data that we want to write.</li>
</ul>

<p>
When the address line is ready, the write enable and cs signal should wait for a moment for the data line ready. After the dataline is (almost) ready, we enable the write function. And then we write the data to the memory. And some how idk why we need to hold on for a sec, and then we shall continue. 
</p>

<p>
It takes many procedure: 1. A ready; 2. wait; 3. WE and CS is valid; 4. wait for writing done; 5.(we and cs is not valid now) and another wait (this wait is called write restoration time); 6. OK for next cycle. 
</p>

<p>
what we have here is a lot of phase: 2. wait Data line be ready; 4. wait for writing operation (latency); 5. another wait (write restoration). 
</p>

<p>
Here is some other thing that you should notice; you can check out the book.
</p>
</div>
</div>

<div id="outline-container-orge7864dc" class="outline-4">
<h4 id="orge7864dc"><span class="section-number-4">3.2.4</span> <span class="todo TODO">TODO</span> The Examples of SRAM and DRAM</h4>
<div class="outline-text-4" id="text-3-2-4">
<p>
This section is like shit. 
</p>

<p>
What we are going to do is to analyse the pictures in the book which show some examples of SRAM and DRAM chips. 
</p>

<p>
None of the example is useful. But it is a chance for use to practise some skills of shit-eating.
</p>
</div>
</div>
<div id="outline-container-org14d2097" class="outline-4">
<h4 id="org14d2097"><span class="section-number-4">3.2.5</span> <span class="todo TODO">TODO</span> DRAM 时序分析</h4>
</div>
<div id="outline-container-org266ac43" class="outline-4">
<h4 id="org266ac43"><span class="section-number-4">3.2.6</span> DRAM 的刷新方式</h4>
<div class="outline-text-4" id="text-3-2-6">
<p>
有三种刷新方式, 我们依次介绍其特点. 以一个 128 × 128 的 DRAM 为例子.
刷新 128 行需要 64 μs, 我们每 2ms 就需要刷新.
</p>

<p>
<b>集中刷新</b>: 2ms 之中抽出 64 μs 专门用来刷新. 这段期间并不能进行读写操做.
</p>

<p>
<b>分散刷新</b>: 进行一个读取操作的时候就进行一个行的刷新.
</p>

<p>
<b>异步刷新</b>: 每隔 \(\displaystyle \frac{64\, \mathrm{\mu s}}{128}\) 就刷新一次. 因为刷新操作和读写操作并不是同步的, 于是称为异步的. 也就是说刷新和读写操作并不是一样的. 
</p>
</div>
</div>

<div id="outline-container-orgcfa74ef" class="outline-4">
<h4 id="orgcfa74ef"><span class="section-number-4">3.2.7</span> The comparison between DRAM and SRAM</h4>
<div class="outline-text-4" id="text-3-2-7">
<p>
This one is relatively simple. You should be already very clear about it after you have learned all these shit.
</p>
</div>
</div>
</div>

<div id="outline-container-org658f5d7" class="outline-3">
<h3 id="org658f5d7"><span class="section-number-3">3.3</span> ROM</h3>
<div class="outline-text-3" id="text-3-3">
</div>
<div id="outline-container-orgccdcd23" class="outline-4">
<h4 id="orgccdcd23"><span class="section-number-4">3.3.1</span> ROM 的简单分类学</h4>
<div class="outline-text-4" id="text-3-3-1">
<ul class="org-ul">
<li><b>基本ROM</b> (read-only memory 掩模 rom) 介绍过的 (long ago). 在一个节点上面放着一个电容, 导通的时候接入低电压 (因为电容接地了); 如果没有电容, 读出的时候就是高电压. The read operation is a little bit tricky here. Anyway if thre is transistor (MOS), then the corresponding bit is <b>1</b>.</li>

<li><b>PROM</b> (Programmable ROM) 其内部有一个熔丝, 通过是否熔断这个熔丝来达成
program. 这种 program 是一次性的. 但是比基本ROM要方便.</li>

<li><b>EPROM</b> (Erasable) 可擦除的, optically erasable. 结构不介绍了. 几把.</li>

<li><b>EEPROM</b> (electrically erasable) 可电擦除的, 不知道用来干嘛.</li>

<li><b>Flash Memory</b> 用于手机等, 功能已经和 RAM 差不多了.</li>
</ul>
</div>
</div>

<div id="outline-container-org27b3609" class="outline-4">
<h4 id="org27b3609"><span class="section-number-4">3.3.2</span> EPROM 的结构介绍</h4>
<div class="outline-text-4" id="text-3-3-2">
<p>
简单来说, 就是使用了一个特殊的晶体管, 这个晶体管叫什么, 雪崩注入式的晶
体管. 总之是一个很奇怪的名字. 这个晶体管之中有一个名为浮动栅的结构. 当
晶体管上面的一个 D 口接入了电源之后, 这个东西就能开始运作了, 其能够阻
断晶体管内部的电流的流通. 那么当这个电压接入的时候, 其存的就是 0. 没有
接入的话, 存的就是 1.
</p>

<p>
其实是很简单的东西. 我们稍微看一下就知道是什么了.
</p>
</div>
</div>
</div>

<div id="outline-container-org6473f9b" class="outline-3">
<h3 id="org6473f9b"><span class="section-number-3">3.4</span> Chips 和 CPU 的链接 (important)</h3>
<div class="outline-text-3" id="text-3-4">
</div>
<div id="outline-container-orgb459d52" class="outline-4">
<h4 id="orgb459d52"><span class="section-number-4">3.4.1</span> How to Deal lianxian</h4>
<div class="outline-text-4" id="text-3-4-1">
<ul class="org-ul">
<li>Note taken on <span class="timestamp-wrapper"><span class="timestamp">[2023-06-16 Fri 18:42] </span></span> <br />
The problem here is a completely garbage. As you can see the previous chapter just finished saying things like "the direct link between the CPU  (processor) and the memory will slow down the performance". Shit. Now, what are we doing? Garbage actually.</li>
</ul>

<p>
CPU 和 RAM 或者 ROM 之间的 chip 链接:
</p>

<p>
给定了 chips (you can't use other chips) 和一个译码器 (in general case), 要你将 CPU 和 chip 之间连接起来.  片选信号一般连入高位, 地址一般连入低位. 高位的这些信号决定片选信号的产生. 片选信号产生了之后, 链接到 ROM RAM 芯片的 CS 上.
</p>

<p>
<b>解题步骤</b> :
</p>
<ol class="org-ol">
<li>根据地址范围写出相应的二进制地址. 以方便决定如何使用 74138 译码器.</li>
<li>根据地址范围的大小, 决定使用的 chip</li>
<li>分配 CPU 地址线. 一般来说这是简单的.</li>
<li>决定片选信号. 查看第一步的二进制地址. 且, CPU 的 MREQ 信号一般要接
入译码器的使能端. (MREQ signal is the signal that saying the cpu is going to read / write memory or not. If MREQ is no valid, then the whole memory should not be working).</li>
</ol>

<p>
还需要查看 Tang 99页的例题. 令人无语的题. 大概就考这种程度的东西. 真是
丢人. 令人叹息, 说到底就是喜欢这种垃圾.
</p>
</div>
</div>

<div id="outline-container-org64990cc" class="outline-4">
<h4 id="org64990cc"><span class="section-number-4">3.4.2</span> <span class="todo TODO">TODO</span> Example of the lianxian of chips and cpu</h4>
<div class="outline-text-4" id="text-3-4-2">
<ul class="org-ul">
<li>Note taken on <span class="timestamp-wrapper"><span class="timestamp">[2023-06-16 Fri 18:48] </span></span> <br />
The problems here are boring. But it may vary, in a shitty way though.</li>
</ul>

<p>
SHIT
</p>
</div>
</div>
</div>

<div id="outline-container-orga642888" class="outline-3">
<h3 id="orga642888"><span class="section-number-3">3.5</span> 存储器的校验 Parity</h3>
<div class="outline-text-3" id="text-3-5">
<p>
建议阅读 Stallings 一节.
</p>
</div>

<div id="outline-container-org92e3019" class="outline-4">
<h4 id="org92e3019"><span class="section-number-4">3.5.1</span> 校验的电路结构</h4>
<div class="outline-text-4" id="text-3-5-1">
<p>
参考 Stallings 一节. 我们说我们有一串数据需要传输. 在传输之前, 我们通过函数 f, 生成一个 K bits 的校验码. 传输了之后我们再次进行校验码的生成.
</p>

<p>
对比两次得到的校验码, 我们知道, 数据是否有损坏. 两次校验码取 XOR 得到数据, 这个 XOR 得到的结果称为 Syndrome Word.
</p>

<p>
我们假设 N 是 数据的长度. 因为 K bits 的校验码, 其能够做到 2<sup>K</sup> 的定位.
那么我们实际上有不等式:
</p>

<p>
\[
2 ^ K  - 1 \ge  N  + K 
\]
</p>

<p>
实际上我们还能够确认 K bits 的校验码在传输的过程之中是否有发生错误.  所以说不等号后面加上了一个 K. 还有, 如果说 Syndrome Word 是 0 的话, 其就说明这里并没有错误. 于是说不等号前面有一个  \(-1\), 因为其中有一个值拿去放到别的地方了
</p>
</div>
</div>

<div id="outline-container-org9eeabc3" class="outline-4">
<h4 id="org9eeabc3"><span class="section-number-4">3.5.2</span> Hamming Code</h4>
<div class="outline-text-4" id="text-3-5-2">
<p>
Hamming Code 是常见的 single error correction code. 其能够检测出一位数据的错误. n其工作原理就是将某些位取 XOR 得到的结果. 直观理解请看 Stallings 的书.
</p>

<p>
在这里我们进一步采用一个模式, 这个模式能够让我们比较简单的生成 Hamming
Code. 我们将 Hamming Code 和 数据 bits 放到一排.  对于 2 的次幂的位置,
其上面放的是 Hamming Code 的位. 我们设 C1 C2 C4 为 Code 的位, 设 Dn 
是第 n 个数据位. 编排如下.
</p>

<pre class="example">
C1C2D1C4D2D3D4
</pre>

<p>
上面是一个 4 位数据的校验码 (D stands for data), 校验码 (C for idk) 是三位. 
我们按照下面方式得出 Cn. 考虑位置码, 也就是位置的二进制码, 比如说, 
第6位就是 110. 我们说 C1 的值为, 位置码个位数是 1 的数据位的 XOR. 类似的 
C2 的值为 "位置码的第二位数为 1 的数据位的 XOR".
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<tbody>
<tr>
<td class="org-left">位置</td>
<td class="org-right">001</td>
<td class="org-right">010</td>
<td class="org-right">011</td>
<td class="org-right">100</td>
<td class="org-right">101</td>
<td class="org-right">110</td>
<td class="org-right">111</td>
</tr>

<tr>
<td class="org-left">位置</td>
<td class="org-right">1</td>
<td class="org-right">2</td>
<td class="org-right">3</td>
<td class="org-right">4</td>
<td class="org-right">5</td>
<td class="org-right">6</td>
<td class="org-right">7</td>
</tr>

<tr>
<td class="org-left">数据</td>
<td class="org-right">C1</td>
<td class="org-right">C2</td>
<td class="org-right">D1</td>
<td class="org-right">C4</td>
<td class="org-right">D2</td>
<td class="org-right">D3</td>
<td class="org-right">D4</td>
</tr>
</tbody>
</table>

<pre class="example">
C1 = D1 ^ D2 ^ D4
</pre>
</div>
</div>
</div>

<div id="outline-container-orgea85c61" class="outline-3">
<h3 id="orgea85c61"><span class="section-number-3">3.6</span> <span class="done DONE">DONE</span> 提高访问速度的方式</h3>
<div class="outline-text-3" id="text-3-6">
<ul class="org-ul">
<li>State "DONE"       from "TODO"       <span class="timestamp-wrapper"><span class="timestamp">[2023-06-17 Sat 02:02]</span></span></li>
</ul>
</div>
<div id="outline-container-orgc0db36b" class="outline-4">
<h4 id="orgc0db36b"><span class="section-number-4">3.6.1</span> 总结</h4>
<div class="outline-text-4" id="text-3-6-1">
<p>
总共分为两个部分: 1. 单字多体和多体并行; 2. 高性能存储芯片. 第二个部分主要抄袭 Stallings 的对应部分. 有兴趣的读者可以选择查看后者.
</p>

<p>
<b>第一个部分</b>: 什么是"体"? 体就是一个模块. 模块就是体. 在这里, 体是半个 RAM 或者别的东西. 其能够独立的工作, 结构上也相对独立, 也就是说, 其有独立的控制单元什么的, 我们用其来实现加速, 比如说利用流水线的思想.
</p>

<p>
<b>第二个部分</b>: 可以参考 Stallings. 其告诉了三种结构: 1. Synchronous DRAM; 2. Rambus DRAM; 3. Cache DRAM. 能够看出为什么这里是抄袭. 因为第二个部分针对的是 DRAM, 这样考虑的话, 这个部分应当放到前面来讲述, 但是 Tang 并没有这么做, 使得编排的逻辑并不是很规整. 并且, Cache 还没有介绍.
</p>

<ul class="org-ul">
<li><b>Synchronous DRAM</b>, 其思想很简单. 为 RAM 增加一个时钟. 我们利用起这个时钟. 一般来说, 当我们传输数据的时候, 需要和 CPU 同步, 并且应当指定地址. 但是 SDRAM 使用了 Burst Mode. 我输入了一个地址, 指定了传输数据的大小 (有多少个 word), 随后 SDRAM 就能够一直传输, 直到传输的数据达到了所需的大小. 这便是 burst mode. 有兴趣的可以查看 wikipedia.</li>
<li><b>Rambus DRAM</b>.  Use bus and modules (and of course a control unit)</li>
<li><b>Cache DRAM</b>. 可以查看 Patterson 相关部分. 其说明得更多. (introduce more concepts) 简单来说, 就是运用了 Cache 的思想, 使用 SRAM 作为一个 buffer.</li>
</ul>
</div>
</div>

<div id="outline-container-orgee223bf" class="outline-4">
<h4 id="orgee223bf"><span class="section-number-4">3.6.2</span> 单体多字</h4>
<div class="outline-text-4" id="text-3-6-2">
<p>
使用一个 bandwidth 为多个字节的存储器, 设为 \(n\). 根据地址, 一次取出
\(n\) 个字节, 送入选择器之类的东西. 使得每隔 \(T\big/ n\) 就能送入一个字节的数据.
</p>
</div>
</div>

<div id="outline-container-org7115ba2" class="outline-4">
<h4 id="org7115ba2"><span class="section-number-4">3.6.3</span> 多体并行</h4>
<div class="outline-text-4" id="text-3-6-3">
<p>
<a id="orgbd591b8"></a>
</p>

<ul class="org-ul">
<li>Note taken on <span class="timestamp-wrapper"><span class="timestamp">[2023-06-16 Fri 19:13] </span></span> <br />
似乎 <i>高位编址</i> 又称为 <i>顺序存储</i>; <i>低位编址</i> 又称为 <i>交叉存储</i>. 建议 Tang 同学下次抄教材的时候将别人的东西抄完整来.</li>
</ul>

<p>
一个正常的地址可以看为两个部分: 1. <b>体编号</b>; 2. <b>体内地址</b>. 前者告诉我们应当在哪一个体内寻找数据, 后者告诉我们在体内的哪里寻找数据.
</p>

<p>
这样将地址分为两个部分处理称为 <b>交叉编址</b>. 常用的有两种编址: 我们可以将 <b>低</b> 位地址看为体编号, 或者是相反, 将 <b>高</b> 位地址看作是体编号. 前者称为低位交叉编址, 后者称为高位交叉编址. 
</p>

<p>
多体并行运用了类似于流水线的思想. 当我们要 <b>交叉地访问不同体</b> 的时候, 速度是最大的. 如果说 <b>连续的数据</b> (地址连续) 都在 <b>一个体内</b>, 我们访问连续的数据的时候速度就没有变化. 高位编址就是这种情况. 连续的地址, 其高位不容易改变, 那么, 它们倾向于放在同一个体内. 于是高位编址对于 <b>访问连续的数据</b> 来说, 并没有加速作用. 相反地, 低位编址就能够加速.
</p>

<p>
Please read the note under the current item.
</p>
</div>
</div>
<div id="outline-container-orgae74638" class="outline-4">
<h4 id="orgae74638"><span class="section-number-4">3.6.4</span> 存控</h4>
<div class="outline-text-4" id="text-3-6-4">
<p>
这实际上是排队器. 这点 Patterson 有提及; 也就是将访问的请求进行排队.
</p>
</div>
</div>

<div id="outline-container-org15f98cc" class="outline-4">
<h4 id="org15f98cc"><span class="section-number-4">3.6.5</span> <span class="done DONE">DONE</span> Synchronous DRAM</h4>
<div class="outline-text-4" id="text-3-6-5">
<ul class="org-ul">
<li>State "DONE"       from "TODO"       <span class="timestamp-wrapper"><span class="timestamp">[2023-06-16 Fri 20:56]</span></span></li>

<li>Note taken on <span class="timestamp-wrapper"><span class="timestamp">[2023-06-16 Fri 20:54] </span></span> <br />
Things are weird. There is bus. Does the cpu really have to wait for the output of the data without SDRAM?</li>
</ul>

<p>
The idea is the key. SDRAM use a clock. The clock enables an important feature, namly the <b>burst mode</b>. 
</p>

<p>
When we want to retrive data from memory, we inform memory with address; then the data is retrived from memory, we capture it; we inform memory with another address (usually this address is adjacent to the previous one); the same thing happens. The cpu have to <b>wait</b> for output data. And specify every address of every blocks.
</p>

<p>
Why? Maybe it is because that it doesn't have a clock. Anyway SDRAM fixes the problem here: the cpu call the memory to do some read / write operation, and then cpu just goes back to its own business; after the data is available, the cpu capture the data (<b>without waiting for the output</b>).
</p>

<p>
In <b>burst mode</b>, we want to get a series of blocks; we inform the memory with the address (the start address); then the memory just keeps outputing data without the need to informing the address again. that is why it is called <b>burst mode</b>.
</p>

<p>
<b>DDR</b> is short for <b>Double Data Rate SDRAM</b>. Anyway, it is fast. I mean, fast.
</p>

<p>
For more information, please check <a href="https:google.com/search?q=burstmode">wikipedia</a>.
</p>
</div>
</div>

<div id="outline-container-orga3ba464" class="outline-4">
<h4 id="orga3ba464"><span class="section-number-4">3.6.6</span> <span class="todo TODO">TODO</span> Rambus DRAM</h4>
<div class="outline-text-4" id="text-3-6-6">
<ul class="org-ul">
<li>Note taken on <span class="timestamp-wrapper"><span class="timestamp">[2023-06-16 Fri 21:35] </span></span> <br />
So Stallings wrote shit too.</li>
<li>Note taken on <span class="timestamp-wrapper"><span class="timestamp">[2023-06-16 Fri 21:02] </span></span> <br />
Gonna drown in all that Tang shit. How can a man just keeping shit around?</li>
</ul>

<p>
Source: Stallings
</p>

<p>
DRAM use <b>block-oriented</b> protocol to deliver address and control information (that is actually to say it use something like bus, but the transfer of the information is asychronous). 
</p>

<p>
Much of the details are omitted here. Just get it and that will be fine. 
</p>

<p>
Anyway, you can check out the Stallings for more information.
</p>
</div>
</div>

<div id="outline-container-org83fe9a0" class="outline-4">
<h4 id="org83fe9a0"><span class="section-number-4">3.6.7</span> Cache DRAM</h4>
<div class="outline-text-4" id="text-3-6-7">
<p>
One shall read Patterson for this section.
</p>

<p>
This one is rather simple.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgf4613af" class="outline-2">
<h2 id="orgf4613af"><span class="section-number-2">4</span> Cache</h2>
<div class="outline-text-2" id="text-4">
</div>
<div id="outline-container-org8d92ef9" class="outline-3">
<h3 id="org8d92ef9"><span class="section-number-3">4.1</span> An introduction</h3>
<div class="outline-text-3" id="text-4-1">
<ul class="org-ul">
<li><i>miss</i>, <i>miss penalty</i>, <i>hit</i>, <i>hit rate</i></li>
</ul>

<p>
This section tells the principle of cache and then tells some key concepts like <b>hit</b>, <b>miss</b> and so on.
</p>

<p>
Anyway. A cache is memory that lies between processor and main memory. It is used to speed up the accessing time. Some blocks of the data are loaded into cache. (Mind the word "block") And if processor want to access to the data, it will check cache first. And if the data is indeed in the cache, then the processor can just get the data via accessing to cache, none of the main memory's business. 
</p>

<p>
So it will speed up the accessing time, since the cache is faster (and is more expensive than main memory).
</p>

<p>
If the data is on the cache, then it is called a <b>hit</b>; if not, it is called a <b>miss</b>. If a miss occurs, we will have to access to the main memory, and send the data to cache and to processor. The extra time that it takes is called <b>miss penalty</b>.
</p>
</div>
</div>

<div id="outline-container-org9b77b8d" class="outline-3">
<h3 id="org9b77b8d"><span class="section-number-3">4.2</span> <span class="done DONE">DONE</span> The Elements of Cache</h3>
<div class="outline-text-3" id="text-4-2">
<ul class="org-ul">
<li>State "DONE"       from "TODO"       <span class="timestamp-wrapper"><span class="timestamp">[2023-06-16 Fri 21:59]</span></span></li>
</ul>
<p>
Anyway, we are going to talk about the structure of the cache here. And moreover we are going to talk something about the attributes of a cache.
</p>
</div>

<div id="outline-container-org5f44220" class="outline-4">
<h4 id="org5f44220"><span class="section-number-4">4.2.1</span> Hit and Miss</h4>
<div class="outline-text-4" id="text-4-2-1">
<ul class="org-ul">
<li>Note taken on <span class="timestamp-wrapper"><span class="timestamp">[2023-06-16 Fri 19:23] </span></span> <br />
This is called improve stability by <b>redundancy</b>.</li>
</ul>

<p>
Anyway. A cache is memory that lies between processor and main memory. It is used to speed up the accessing time. Some blocks of the data are loaded into cache. (Mind the word "block") And if processor want to access to the data, it will check cache first. And if the data is indeed in the cache, then the processor can just get the data via accessing to cache, none of the main memory's business. 
</p>

<p>
So it will speed up the accessing time, since the cache is faster (and is more expensive than main memory).
</p>

<p>
If the data is on the cache, then it is called a <b>hit</b>; if not, it is called a <b>miss</b>. If a miss occurs, we will have to access to the main memory, and send the data to cache and to processor. The extra time that it takes is called <b>miss penalty</b>.
</p>
</div>
</div>
</div>

<div id="outline-container-org41537af" class="outline-3">
<h3 id="org41537af"><span class="section-number-3">4.3</span> The Structure of the Cache</h3>
<div class="outline-text-3" id="text-4-3">
<ul class="org-ul">
<li>Note taken on <span class="timestamp-wrapper"><span class="timestamp">[2023-06-16 Fri 19:27] </span></span> <br />
For the name of <b>line</b>, Stallings has discussed about it: it is used to distinguish between that in cache and that in memory.</li>
<li>Note taken on <span class="timestamp-wrapper"><span class="timestamp">[2023-06-16 Fri 19:24] </span></span> <br />
For principle of locality, check either Stallings or Patterson.</li>
</ul>

<p>
This part is rather simple, for we have already been familiar with the structure of cache. 
</p>

<p>
The data transferred between cache and main memory is by <b>blocks</b>. A block consists of words.
</p>

<p>
It uses the principle of locality, to improve the performance. So we know that a block has usually more than one word (it won't use spatial locality if it does). The main memory is divided into blocks. Cache can load blocks of data from memory. The <b>mapping</b> between the blocks number in main memory and the block number in cache (that is called <b>line</b> number, which is the position that in cache) is a topic in next some section.
</p>

<p>
A line in a cache is the <b>basic unit</b> of a cache. It consists of a block and some <b>extra</b> information field including <b>tag field</b> and <b>valid-tag field</b>. The name of line is used, to note the difference of the blocks that in main memory and that in cache, and to note that there is some other information in the cache line.
</p>
</div>

<div id="outline-container-org4c68c2b" class="outline-4">
<h4 id="org4c68c2b"><span class="section-number-4">4.3.1</span> The REAL Structure of Cache</h4>
<div class="outline-text-4" id="text-4-3-1">
<p>
Cache lies between processor and memory.
</p>

<p>
There are two more important parts: 1. Mapping; 2. Replacing.
</p>

<p>
Mapp is the map from <b>read address</b> to the address in cache. Replacing is about how we deal with the situation where the cache is full. These two part require at least two modules.
</p>

<p>
So the structure of cache consists of 1. processor; 2. cache; 3. memory; 4. map module; 5. replace module; 6. bus. 
</p>
</div>
</div>

<div id="outline-container-org88ffe98" class="outline-4">
<h4 id="org88ffe98"><span class="section-number-4">4.3.2</span> Block Size and its Effect to Hit Rate</h4>
<div class="outline-text-4" id="text-4-3-2">
<p>
Source: Patterson
</p>

<p>
According to the principle of locality, the bigger block size can improve the hit rate, subsequently improving the performance. 
</p>

<p>
But if we consider the latency (that is the miss penalty), things get interesting, because if the improvement brought by the increase of hit rate is no greater than the <b>degeneration</b> brought by the increase of miss penalty, then the performance is being worse as the block size grows. For more information, you can check <i>Patterson</i> for more information.
</p>

<p>
Moreover, the miss rate will go up eventually if the block size keeps increasing. Because as the blocksize goes up, total number of the blocks is low.
</p>
</div>
</div>
</div>

<div id="outline-container-org3cd457b" class="outline-3">
<h3 id="org3cd457b"><span class="section-number-3">4.4</span> <span class="done DONE">DONE</span> Mapping Strategy</h3>
<div class="outline-text-3" id="text-4-4">
<ul class="org-ul">
<li>State "DONE"       from "TODO"       <span class="timestamp-wrapper"><span class="timestamp">[2023-06-17 Sat 00:21]</span></span></li>
</ul>
<p>
The mapping is from the blocks in the memory to the line in the cache, that is to say when given the position of a block, how do we find the corresponding position in the cache? There are some strategies of mapping.
</p>

<p>
The simplest one is called <b>Direct Mapping</b>. It is simple. There are also other ways called <b>associative mapping</b> and <b>set-associative mapping</b>. 
</p>
</div>

<div id="outline-container-org69c7e5f" class="outline-4">
<h4 id="org69c7e5f"><span class="section-number-4">4.4.1</span> Direct Mapping</h4>
<div class="outline-text-4" id="text-4-4-1">
<p>
Modula!
</p>

<p>
The details are omitted here. You can check Patterson and Stallings for more information.
</p>
</div>
</div>

<div id="outline-container-org2c4fc95" class="outline-4">
<h4 id="org2c4fc95"><span class="section-number-4">4.4.2</span> (full) Associative Mapping</h4>
<div class="outline-text-4" id="text-4-4-2">
<p>
First, cut the word address into two field: 1. tag, 2. word. Word field is used to locate the data inside of the block. Tag is used to identify.
</p>

<p>
Anyway, initially, we give an address. We load the block into cache (into the first line). Store the tag into the line. 
</p>

<p>
Next, afterwards, if we want to retrieve from the memory, we check the cache, to see if there is a line, whose tag is the same as the tag of the given address. If there is, then it is a hit; if not, it is a miss. If there is a miss, then load the block into the second line.
</p>

<p>
And we have done here.
</p>

<p>
The procedure is done here.
</p>

<p>
The feature is that the line number is not affected by the address of the memory. Randomly given an address, the line number could be anyone.
</p>
</div>
</div>

<div id="outline-container-org13dcac7" class="outline-4">
<h4 id="org13dcac7"><span class="section-number-4">4.4.3</span> Set-Associative Mapping</h4>
<div class="outline-text-4" id="text-4-4-3">
<p>
Set-Associative mapping is to combine the two kinds of methods. 
</p>

<p>
Let us look at direct mapping. The address is divided into two groups. Line number field is the line number. Yes, indeed.
</p>
<ol class="org-ol">
<li>line number field</li>
<li>word field</li>
</ol>

<p>
Let us look at associative mapping. The address is divided into two groups. 
</p>
<ol class="org-ol">
<li>tag field</li>
<li>word field</li>
</ol>

<p>
In the combination of the two method, the address is divided into three groups.
</p>
<ol class="org-ol">
<li>tag field</li>
<li>set field</li>
<li>word field</li>
</ol>

<p>
where the tag field works just like that in associative mapping, and set field works just like that in the direct mapping: set field is the set number.
</p>

<p>
Anyway, the cache is divided into many sets. The set field determined the set number. JUST LIKE THAT IN DIRECT MAPPING. Commonly, the arrangement is like: 
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">field</td>
<td class="org-left">tag</td>
<td class="org-left">set</td>
<td class="org-left">word</td>
</tr>

<tr>
<td class="org-left">address</td>
<td class="org-left">xxx</td>
<td class="org-left">xxxxxxx</td>
<td class="org-left">xx</td>
</tr>

<tr>
<td class="org-left">length</td>
<td class="org-left">3</td>
<td class="org-left">7</td>
<td class="org-left">2</td>
</tr>
</tbody>
</table>

<p>
here I specify the length of the field. OK, then we have a 12-bits address. and the block size is four bytes; and there are \(2 ^7\) sets; there are \(2 ^3\) lines in one set; there are \(2 ^{10}\) lines in the cache in total.
</p>
</div>
</div>
</div>

<div id="outline-container-org46f7797" class="outline-3">
<h3 id="org46f7797"><span class="section-number-3">4.5</span> <span class="done DONE">DONE</span> Write Policy</h3>
<div class="outline-text-3" id="text-4-5">
<ul class="org-ul">
<li>State "DONE"       from "TODO"       <span class="timestamp-wrapper"><span class="timestamp">[2023-06-17 Sat 00:30]</span></span></li>
</ul>

<p>
For write policy, one can check the page 137 of Stallings.
</p>
</div>

<div id="outline-container-orgc342b8a" class="outline-4">
<h4 id="orgc342b8a"><span class="section-number-4">4.5.1</span> Why We have to maintain the consistency of the memory heirarchy</h4>
<div class="outline-text-4" id="text-4-5-1">
<p>
In computer science, a consistency model specifies a contract between ther programmer and a system. The system guarantees that if the programmer follows the rules for operations on memory, memory will be consistent and the results of reading, writing, or updating memory will be predictable. This is important because it allows for reliable and predicable behavior of programs that rely on shared memory.
</p>

<p>
idk.
</p>

<p>
I just don't know why.
</p>
</div>
</div>

<div id="outline-container-orga2c6169" class="outline-4">
<h4 id="orga2c6169"><span class="section-number-4">4.5.2</span> Two strategies</h4>
<div class="outline-text-4" id="text-4-5-2">
<p>
There are ways to maintain the consistency. In short, there are two ways: <b>write-through</b> and <b>write-back.</b>
</p>

<p>
Let us look at write-through, to check how it maintain the consistency. Write-through is to say, when you want to change some data, if it is on cache, you need to change the content of cache and that of the main memory.
</p>
</div>
</div>

<div id="outline-container-orge50e0e7" class="outline-4">
<h4 id="orge50e0e7"><span class="section-number-4">4.5.3</span> Write Through</h4>
<div class="outline-text-4" id="text-4-5-3">
<p>
Write through is to say, when we <b>change</b> the data in <b>cache</b>, we also change the data that in <b>memory</b>. It is a good idea? It slows down the performance, right? The speed of writing data remains <b>unchanged</b>. The time it takes to write to cache is the same as that to memory. 
</p>
</div>
</div>

<div id="outline-container-orge4c3f79" class="outline-4">
<h4 id="orge4c3f79"><span class="section-number-4">4.5.4</span> Write Back</h4>
<div class="outline-text-4" id="text-4-5-4">
<p>
Write Back is to say, when we <b>change</b> the data in <b>cache</b>, we write the data <b>back</b> when that <b>block</b> is about to be subtituted. The speed is guaranteed, but its realization is more sophisticated.
</p>
</div>
</div>

<div id="outline-container-org00b03af" class="outline-4">
<h4 id="org00b03af"><span class="section-number-4">4.5.5</span> <span class="todo TODO">TODO</span> The More into Write Policy</h4>
</div>
</div>

<div id="outline-container-org064306e" class="outline-3">
<h3 id="org064306e"><span class="section-number-3">4.6</span> <span class="done DONE">DONE</span> Ways to Improve the Performance of Cache</h3>
<div class="outline-text-3" id="text-4-6">
<ul class="org-ul">
<li>State "DONE"       from "TODO"       <span class="timestamp-wrapper"><span class="timestamp">[2023-06-17 Sat 01:54]</span></span></li>
</ul>

<p>
One can use multiple level of cache.
</p>
</div>
<div id="outline-container-orgdde759d" class="outline-4">
<h4 id="orgdde759d"><span class="section-number-4">4.6.1</span> Multi-level Cache</h4>
<div class="outline-text-4" id="text-4-6-1">
<p>
Source: Stallings page 138
</p>
</div>
<ol class="org-ol">
<li><a id="org37db8ec"></a>Before Muti-level Cache<br />
<div class="outline-text-5" id="text-4-6-1-1">
<p>
We add a level of cache. Let us say L1 and L2.
</p>

<p>
It can improve the performance. 
</p>

<p>
But how? 
</p>

<p>
First we should know that what have constrained the speed of a memory chip. Ok, let me put it straight, the <b>latency</b> constrain the speed. 
</p>

<p>
Next we should know the principle of the cache. Of course, you know the principle of locality, but what we need here is something more essential: 
</p>

<p>
<b>The speed of cache memory should be faster than the speed of the main memory.</b>
</p>

<p>
That is right. So, the speed of L1 should be above of that of L2. How can we do that? 
</p>

<p>
At the first place, when we consider one-level cache, the cache use SRAM. SRAM is more expensive and takes more space than DRAM and it is faster than DRAM. So SRAM can be the cache if the main memory is consist of DRAM.
</p>

<p>
OK, that is very convincing, but does it have to do with multi-level cache? 
</p>

<p>
Of course, what we need here, is to find a way to improve the speed of SRAM, or specifically, to find a way to distinguish the speed of one kind of SRAM and the other, such that we can build multi-level cache.
</p>
</div>
</li>

<li><a id="org1f1c801"></a>The Bus<br />
<div class="outline-text-5" id="text-4-6-1-2">
<p>
WHAT HAD HAPPENED?
</p>

<p>
The main point is the position of the SRAM chips. We need the knowledge of the bus here. If we put the SRAM chips on the <b>processor</b>
's chip, then the speed should be faster. Let us call those SRAM chips L1.
</p>

<p>
And we put the L2 chips outside of the processor chip.
</p>

<p>
The  physical distance between the L1 and the processor is smaller. Consequently, the speed of the L1 should be faster. It is because the communication between L1 and processor does not depend on bus. But the communication between processor chip and L2 depend on bus.
</p>

<p>
The dependency leads to the performance difference. So, as a result, we can build a multi-level cache. And indeed just like SRAM takes more space, the space on the processor chip is limited. So the size of L1 is limited too.
</p>
</div>
</li>

<li><a id="orgb74f8ab"></a><span class="todo WAITING">WAITING</span> The performance analysis<br />
<div class="outline-text-5" id="text-4-6-1-3">
<ul class="org-ul">
<li>State "WAITING"    from "SOMEDAY"    <span class="timestamp-wrapper"><span class="timestamp">[2023-06-17 Sat 03:03]</span></span></li>
</ul>
</div>
</li>
</ol>
</div>
<div id="outline-container-org56bd975" class="outline-4">
<h4 id="org56bd975"><span class="section-number-4">4.6.2</span> <span class="todo WAITING">WAITING</span> Split Cache</h4>
<div class="outline-text-4" id="text-4-6-2">
<ul class="org-ul">
<li>State "WAITING"    from "SOMEDAY"    <span class="timestamp-wrapper"><span class="timestamp">[2023-06-17 Sat 02:45] </span></span> <br />
when I review about the pipeline one shall complete the task.</li>
</ul>
<p>
Source: Stallings page 140
</p>

<p>
It is a way to split the cache into two parts: 
</p>
<ol class="org-ol">
<li>One is for instructions</li>
<li>the other is for data</li>
</ol>

<p>
The performance is enhanced, for these reasons: 
</p>
<ol class="org-ol">
<li>No write is need in instruction L1. Consequently, the implementations are different.</li>
<li>The key advantage is that it eliminates contention for the cache between the instruction fetch / decode unit and the execution unit.</li>
</ol>

<p>
The second advantage concerns with the pipeline design, which I have completely forget about. Shit.
</p>
</div>
</div>
</div>

<div id="outline-container-orgc0374f9" class="outline-3">
<h3 id="orgc0374f9"><span class="section-number-3">4.7</span> <span class="done DONE">DONE</span> Replacement Algorithm</h3>
<div class="outline-text-3" id="text-4-7">
<ul class="org-ul">
<li>State "DONE"       from "TODO"       <span class="timestamp-wrapper"><span class="timestamp">[2023-06-17 Sat 02:52]</span></span></li>
</ul>

<p>
Source: Stallings page 136. It ain't hard.
</p>

<p>
When the cache is full, and we want to fill some blocks into the cache, we need the replacement algorithm to determine which blcok is about to be replaced. 
</p>

<p>
We have three kinds of algorithms available.
</p>
<ol class="org-ol">
<li><b>LRU</b>: least recently used</li>
<li><b>LFU</b>: least frequently used</li>
<li><b>FIFO</b>: first in first out</li>
</ol>
<p>
of course, each of them has some advantages.
</p>
</div>

<div id="outline-container-org51699c2" class="outline-4">
<h4 id="org51699c2"><span class="section-number-4">4.7.1</span> <span class="todo WAITING">WAITING</span> More into Replacement Algorithm</h4>
<div class="outline-text-4" id="text-4-7-1">
<ul class="org-ul">
<li>State "WAITING"    from "TODO"       <span class="timestamp-wrapper"><span class="timestamp">[2023-06-17 Sat 03:11] </span></span> <br />
till i wanna do it.</li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-org79c5271" class="outline-2">
<h2 id="org79c5271"><span class="section-number-2">5</span> Virtual Memory (from <i>Patterson</i>)</h2>
<div class="outline-text-2" id="text-5">
</div>
<div id="outline-container-orgbdddff4" class="outline-3">
<h3 id="orgbdddff4"><span class="section-number-3">5.1</span> what is virtual memory</h3>
<div class="outline-text-3" id="text-5-1">
<p>
If we make main memory to work as the "cache" between the memory and the "secondary heirarchy" (in the book, we use the term secondary heirarchy, for some reason, I may use external memory instead of this one.), the technique is called virtual memory. 
</p>

<p>
Virtual Memory has two main motivation: One is to enhance the performance of the external memory (you know the latency of the external memory is way too long.); 
</p>

<p>
The other is to remove the programming burdens of a samll limited amount of  the main memory. So the programmers can just use some very large address withou hesitation.
</p>

<p>
<b>Some Terminologies</b>: page and page faults.
</p>

<p>
Some terminologies are different for some historical reason. The "block" in virtual memory is called "page"; the miss is called "page fault".
</p>

<p>
i just don't know why.
</p>

<p>
<b>More terminologies</b>: Address Space, Swap Space, Virtual Machine, Process.
</p>


<p>
what is virtual machine and process? I don't know. But one should know it actually. When it comes to the discussion of virtual memory, we will also talk about the virtual machine and the process, because one of the main function of virtual memory is to enable the processes do not affect one another's memory space (and moreover the space that is in the external memory).
</p>

<p>
What is swap space? The pages that a process need will be put into the swap space (which locates in the external memory) for future use (for example, to load a page from the swap space into the main memory, and for example, to exchange a page that in the main memory and a page in swap space).
</p>
</div>
</div>

<div id="outline-container-org27254fd" class="outline-3">
<h3 id="org27254fd"><span class="section-number-3">5.2</span> Page and Page table</h3>
<div class="outline-text-3" id="text-5-2">
</div>
<div id="outline-container-org2bec6db" class="outline-4">
<h4 id="org2bec6db"><span class="section-number-4">5.2.1</span> the Translation</h4>
<div class="outline-text-4" id="text-5-2-1">
<p>
As in the cache, the page size is matter. Page size varies depending on the use and the system. I am not quite sure.
</p>

<p>
As for the translation in the Page mapping, we are given an address and we shall translate the address into some real address in the main memory or some location in the external memory. The former one (the real address in main memory) is called <b>physical address</b>. You can actually call the address (needed to be translated) the <b>logical address</b>. When the page is not in the memory, then there is a page fault. The <b>OS</b> now takes in charge to find the data location in the external memory, after which the system fetches the data.
</p>
</div>
</div>


<div id="outline-container-org08bc495" class="outline-4">
<h4 id="org08bc495"><span class="section-number-4">5.2.2</span> Page Table</h4>
<div class="outline-text-4" id="text-5-2-2">
<p>
But there is something that is a little bit different from the cache, that is the page table. Page Table works very similiar to the tag field that in the cache. But there is a problem, that is the table could be shockingly large. But we have some approaches to deal with the problems.
</p>

<p>
The first one is simple that is to allow the table to grow as the process consumes more space. It requires that the table to grow in one direction. 
</p>

<p>
The second one is something I don't know. The table is divided into two parts: one is for stack and one is for heap. The table can grow in two directions.
</p>

<p>
The third one is to apply hashing function. Although I am not very familiar with hashing function, I think the approach is of no problems.
</p>

<p>
The fourth one is to allow pages to be paged. What the fuck does it mean?
</p>

<p>
The fifth one is to use multi-level page table. For example, we can divide the logical address into three parts: the first part is for first table; the second part is for the secondary table; the last part is the page offset. Here, two-level table is employed.
</p>
</div>
</div>

<div id="outline-container-orgfc31d5c" class="outline-4">
<h4 id="orgfc31d5c"><span class="section-number-4">5.2.3</span> Writes in Virtual Memory</h4>
<div class="outline-text-4" id="text-5-2-3">
<p>
Just that the write policy here can only be write-back, because the latency of external memory is way too long.
</p>
</div>
</div>

<div id="outline-container-org0b24574" class="outline-4">
<h4 id="org0b24574"><span class="section-number-4">5.2.4</span> TLB</h4>
<div class="outline-text-4" id="text-5-2-4">
<p>
TLB is the buffer that hold the translation of the address.
</p>

<p>
That is the TLB stores some logical addresses and corresponding physical address. A TLB miss could be translated into two situation: one is that the translation is indeed not in the TLB but in the Page Table; the other is that it is also a page fault, that is to say the page is not in the memory but in the external memory.
</p>
</div>
</div>

<div id="outline-container-orga901e67" class="outline-4">
<h4 id="orga901e67"><span class="section-number-4">5.2.5</span> Ways to improve the performance of Page Table</h4>
<div class="outline-text-4" id="text-5-2-5">
<p>
there are five ways to decrease the maximum of the Page Table:
they are
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgd2b1f93" class="outline-2">
<h2 id="orgd2b1f93"><span class="section-number-2">6</span> External Memory</h2>
<div class="outline-text-2" id="text-6">
</div>
<div id="outline-container-orgda93c03" class="outline-3">
<h3 id="orgda93c03"><span class="section-number-3">6.1</span> <span class="done DONE">DONE</span> RAID from Stallings</h3>
<div class="outline-text-3" id="text-6-1">
<ul class="org-ul">
<li>State "DONE"       from "TODO"       <span class="timestamp-wrapper"><span class="timestamp">[2023-06-17 Sat 17:09]</span></span></li>
</ul>
<p>
Source: Stallings page 194
</p>

<p>
The key word is <b>redundancy</b>
</p>

<pre class="example">
redundancy
</pre>

<div class="org-center">
<p>
redundancy
</p>
</div>

<p>
REDUNDANCY
</p>

<p>
<i>redundancy</i>
</p>
</div>

<div id="outline-container-org3d0d7ce" class="outline-4">
<h4 id="org3d0d7ce"><span class="section-number-4">6.1.1</span> RAID and some related Concepts</h4>
<div class="outline-text-4" id="text-6-1-1">
<p>
RAID is an external memory system coined by some researchers in UCB.
</p>

<p>
<b>redundancy</b>: It takes advantages of the <b>redundancy</b> to improve the performance.
</p>

<p>
<b>Strip and Stripe</b>:  strip is the concept used to describe how the memory is divided. It tells you the basic the unit of the some strategies here. For example, in RAID 2, the strip is very small. and the very strip has a simple parity bit. For example, the strip is RAID 0, is like the block that we use (but the name is different, and the concepts are different after all). The memory of RAID 0 is striped across the available disks (leads to a high access speed). 
As for stripe, the word stripe is the verb form of strip.
</p>

<p>
<b>From RAID 0 to RAID 6</b>: The raid system integrate many types of the disk type. For different type of the memory operation (for example, an array of read operations or an array of write operations, and for example, access request from multiple I/O devices, and for example, large, continuous blocks access request). Different RAID can best-coped with certain situation.
</p>

<p>
<b>The key of RAID (Idk)</b>: In the construction of different RAID, two things are important: <b>1. How Data is Distributed</b>; <b>2. How Redundancy is implemented</b>. The exact two keys determine the performance of the RAID and its application.
</p>
</div>
</div>

<div id="outline-container-org791d17d" class="outline-4">
<h4 id="org791d17d"><span class="section-number-4">6.1.2</span> RAID Level 0</h4>
<div class="outline-text-4" id="text-6-1-2">
<p>
RAID 0 uses no redundancy. Technically, RAID 0 does not belong to RAID system. Anyway there it is.
</p>

<p>
RAID 0 is used for the <b>user and system</b> data. It is distributed over an array of disks.
</p>

<blockquote>
<p>
If there are two I/O requests, and the requested blocks are likely on different disks, then the two requests can be issued in parallel.
</p>
</blockquote>

<p>
The quote turns out to be quite inaccurate. The implementation of RAID 0 can serve two purpose: <b>1. High Data Transfer Capacity</b>; <b>2. High I/O Request Rate</b>. The quote is telling about the second purpose. And the implementation is already been discussed one can check <a href="#orgbd591b8">3.6.3</a>
for more information.
</p>
</div>
</div>

<div id="outline-container-orgb47aa87" class="outline-4">
<h4 id="orgb47aa87"><span class="section-number-4">6.1.3</span> RAID Level 1</h4>
<div class="outline-text-4" id="text-6-1-3">
<p>
RAID 1 is a mirrored RAID 0. It implements redundancy by using a copy of itself, that is, there are two disks, and they carry the same data.
</p>

<p>
There is something we should notice: 
</p>
<ol class="org-ol">
<li>Advantage: Higher Read Speed. The read operation can be runned uncondtionally parrallelly. So the read speed is twice as the RAID 0's.</li>
<li>Neither Advantage or Disadvantage: The write speed remains unchanged. Although we have to write data into two disks, the write operations is parrallel. So the speed is unchanged.</li>
<li>Advantage: Safety. Recovery from a failure is simple. "When a drive fails, the data may still be accessed from the second drive".</li>
<li>Disadvantage: Expensive.</li>
</ol>

<p>
<b>Suit for</b>: 
</p>
<ol class="org-ol">
<li>for the data transfer intensive application with a high percentage of reads.</li>
<li>for system software and data and other highly critical files.</li>
</ol>
</div>
</div>

<div id="outline-container-org150a3dd" class="outline-4">
<h4 id="org150a3dd"><span class="section-number-4">6.1.4</span> RAID Level 2</h4>
<div class="outline-text-4" id="text-6-1-4">
<p>
RAID 2 and RAID 3 use parity code. But the striping is very different. The parity code is store in other strips. The strips are very small in RAID 2. Usually one byte or word.
</p>

<p>
<b>Suit for</b>: where many disk errors occur.
</p>
</div>
</div>

<div id="outline-container-org3c55dcf" class="outline-4">
<h4 id="org3c55dcf"><span class="section-number-4">6.1.5</span> <span class="todo TODO">TODO</span> RAID Level 3</h4>
<div class="outline-text-4" id="text-6-1-5">
<p>
RAID 3 use a simple parity bit for a byte. That is it usually XOR all the bits in a byte and store it right next to the byte. And the parity bit and the byte compose a strip.
</p>
</div>
</div>

<div id="outline-container-orgf5f1d7c" class="outline-4">
<h4 id="orgf5f1d7c"><span class="section-number-4">6.1.6</span> RAID Level 4</h4>
<div class="outline-text-4" id="text-6-1-6">
<p>
RAID 4 is like RAID 3 but the strip is different. The strips are large.
</p>
</div>
</div>

<div id="outline-container-org639142f" class="outline-4">
<h4 id="org639142f"><span class="section-number-4">6.1.7</span> RAID Level 5</h4>
<div class="outline-text-4" id="text-6-1-7">
<p>
RAID 5 is like RAID 4 but the striping is different. The parity block is interleaved so that parity block and data block can be accessed simultaneously.
</p>
</div>
</div>

<div id="outline-container-org803aead" class="outline-4">
<h4 id="org803aead"><span class="section-number-4">6.1.8</span> RAID Level 6</h4>
<div class="outline-text-4" id="text-6-1-8">
<p>
RAID 6 is a revised version of RAID 5. It uses two kinds of parity code. And as the RAID 5, the parity blocks are interleaved.
</p>
</div>
</div>
</div>

<div id="outline-container-org4abcaac" class="outline-3">
<h3 id="org4abcaac"><span class="section-number-3">6.2</span> Magnetic Disk &amp; Optical Memory &amp; Magnetic Tap</h3>
<div class="outline-text-3" id="text-6-2">
<p>
Google it.
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="date">Created: 2023-06-21 Wed 01:49</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>