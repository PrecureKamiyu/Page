<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>Linux Kernel Development, Third Edition</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
<div id="filepos487358" style="height:0pt"></div><h2 class="calibre_4" id="calibre_pb_47"><span class="bold">8. Bottom Halves and Deferring Work</span></h2><div class="calibre_5"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos487535"> </div>
<p class="calibre_2">The previous chapter discussed interrupt handlers, the kernel mechanism for dealing with hardware interrupts. Interrupt handlers are an important—indeed, required—part of any operating system. Due to various limitations, however, interrupt handlers can form only the first half of any interrupt processing solution. These limitations include</p><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• Interrupt handlers run asynchronously and thus interrupt other, potentially important, code, including other interrupt handlers. Therefore, to avoid stalling the interrupted code for too long, interrupt handlers need to run as quickly as possible.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• Interrupt handlers run with the current interrupt level disabled at best (if <code class="calibre6"><span class="calibre7">IRQF_DISABLED</span></code> is unset), and at worst (if <code class="calibre6"><span class="calibre7">IRQF_DISABLED</span></code> is set) with all interrupts on the current processor disabled. As disabling interrupts prevents hardware from communicating with the operating systems, interrupt handlers need to run as quickly as possible.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• Interrupt handlers are often timing-critical because they deal with hardware.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• Interrupt handlers do not run in process context; therefore, they cannot block. This limits what they can do.</p></blockquote><div class="calibre_3"> </div>
<p class="calibre_2">It should now be evident that interrupt handlers are only a piece of the solution to managing hardware interrupts. Operating systems certainly need a quick, asynchronous, simple mechanism for immediately responding to hardware and performing any time-critical actions. Interrupt handlers serve this function well; but other, less critical work can and should be deferred to a later point when interrupts are enabled.</p><div class="calibre_3"> </div>
<p class="calibre_2">Consequently, managing interrupts is divided into two parts, or <em class="calibre4">halves</em>. The first part, interrupt handlers (<em class="calibre4">top halves</em>), are executed by the kernel asynchronously in immediate response to a hardware interrupt, as discussed in the previous chapter. This chapter looks at the second part of the interrupt solution, <em class="calibre4">bottom halves</em>.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos490048"> </div>
<h3 class="calibre_21"><span class="bold">Bottom Halves</span></h3><div class="calibre_22"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos490164"> </div>
<p class="calibre_2">The job of bottom halves is to perform any interrupt-related work not performed by the interrupt handler. In an ideal world, this is nearly all the work because you want the interrupt handler to perform as little work (and in turn be as fast) as possible. By offloading as much work as possible to the bottom half, the interrupt handler can return control of the system to whatever it interrupted as quickly as possible.</p><div class="calibre_3"> </div>
<p class="calibre_2">Nonetheless, the interrupt handler must perform <em class="calibre4">some</em> of the work. For example, the interrupt handler almost assuredly needs to acknowledge to the hardware the receipt of the interrupt. It may need to copy data to or from the hardware. This work is timing-sensitive, so it makes sense to perform it in the interrupt handler.</p><div class="calibre_3"> </div>
<p class="calibre_2">Almost anything else is fair game for performing in the bottom half. For example, if you copy data from the hardware into memory in the top half, it certainly makes sense to process it in the bottom half. Unfortunately, no hard and fast rules exist about what work to perform where—the decision is left entirely up to the device-driver author. Although no arrangement is <em class="calibre4">illegal</em>, an arrangement can certainly be <em class="calibre4">suboptimal</em>. Remember, interrupt handlers run asynchronously, with at least the current interrupt line disabled. Minimizing their duration is important. Although it is not always clear how to divide the work between the top and bottom half, a couple of useful tips help:</p><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• If the work is time sensitive, perform it in the interrupt handler.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• If the work is related to the hardware, perform it in the interrupt handler.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• If the work needs to ensure that another interrupt (particularly the same interrupt) does not interrupt it, perform it in the interrupt handler.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• For everything else, consider performing the work in the bottom half.</p></blockquote><div class="calibre_3"> </div>
<p class="calibre_2">When attempting to write your own device driver, looking at other interrupt handlers and their corresponding bottom halves can help. When deciding how to divide your interrupt processing work between the top and bottom half, ask yourself what <em class="calibre4">must</em> be in the top half and what <em class="calibre4">can</em> be in the bottom half. Generally, the quicker the interrupt handler executes, the better.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos492963"> </div>
<h4 class="calibre_27"><span class="calibre3">Why Bottom Halves?</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">It is crucial to understand why to defer work, and when exactly to defer it. You want to limit the amount of work you perform in an interrupt handler because interrupt handlers run with the current interrupt line disabled on all processors. Worse, handlers that register with <code class="calibre6"><span class="calibre7">IRQF_DISABLED</span></code> run with <em class="calibre4">all</em> interrupt lines disabled on the local processor, plus the current interrupt line disabled on all processors. Minimizing the time spent with interrupts disabled is important for system response and performance. Add to this the fact that interrupt handlers run asynchronously with respect to other code—even other interrupt handlers—and it is clear that you should work to minimize how long interrupt handlers run. Processing incoming network traffic should not prevent the kernel’s receipt of keystrokes. The solution is to defer some of the work until later.</p><div class="calibre_3"> </div>
<p class="calibre_2"><a id="filepos494057"></a>But when is “later?” The important thing to realize is that <em class="calibre4">later</em> is often simply <em class="calibre4">not now</em>. The point of a bottom half is <em class="calibre4">not</em> to do work at some specific point in the future, but simply to defer work until <em class="calibre4">any</em> point in the future when the system is less busy and interrupts are again enabled. Often, bottom halves run immediately after the interrupt returns. The key is that they run with all interrupts enabled.</p><div class="calibre_3"> </div>
<p class="calibre_2">Linux is not alone in separating the processing of hardware interrupts into two parts; most operating systems do so. The top half is quick and simple and runs with some or all interrupts disabled. The bottom half (however it is implemented) runs later with all interrupts enabled. This design keeps system latency low by running with interrupts disabled for as little time as necessary.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos495004"> </div>
<h4 class="calibre_27"><span class="calibre3">A World of Bottom Halves</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">Unlike the top half, which is implemented entirely via the interrupt handler, multiple mechanisms are available for implementing a bottom half. These mechanisms are different interfaces and subsystems that enable you to implement bottom halves. Whereas the previous chapter looked at just a single way of implementing interrupt handlers, this chapter looks at multiple methods of implementing bottom halves. Over the course of Linux’s history, there have been many bottom-half mechanisms. Confusingly, some of these mechanisms have similar or even dumb names. It requires a special type of programmer to name bottom halves.</p><div class="calibre_3"> </div>
<p class="calibre_2">This chapter discusses both the design and implementation of the bottom-half mechanisms that exist in 2.6. We also discuss how to use them in the kernel code you write. The old, but long since removed, bottom-half mechanisms are historically significant, and so they are mentioned when relevant.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos496156"> </div>
<h5 class="calibre_29"><span class="calibre3">The Original “Bottom Half”</span></h5><div class="calibre_24"> </div>
<p class="calibre_2">In the beginning, Linux provided only the “bottom half” for implementing bottom halves. This name was logical because at the time that was the only means available for deferring work. The infrastructure was also known as <em class="calibre4">BH</em>, which is what we will call it to avoid confusion with the generic term <em class="calibre4">bottom half</em>. The BH interface was simple, like most things in those good old days. It provided a statically created list of 32 bottom halves for the entire system. The top half could mark whether the bottom half would run by setting a bit in a 32-bit integer. Each BH was globally synchronized. No two could run at the same time, even on different processors. This was easy to use, yet inflexible; a simple approach, yet a bottleneck.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos497107"> </div>
<h5 class="calibre_29"><span class="calibre3">Task Queues</span></h5><div class="calibre_24"> </div>
<p class="calibre_2">Later on, the kernel developers introduced <em class="calibre4">task queues</em> both as a method of deferring work and as a replacement for the BH mechanism. The kernel defined a family of queues. Each queue contained a linked list of functions to call. The queued functions were run at certain times, depending on which queue they were in. Drivers could register their bottom halves in the appropriate queue. This worked fairly well, but it was still too inflexible <a id="filepos497671"></a>to replace the BH interface entirely. It also was not lightweight enough for performance-critical subsystems, such as networking.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos497851"> </div>
<h5 class="calibre_29"><span class="calibre3">Softirqs and Tasklets</span></h5><div class="calibre_24"> </div>
<p class="calibre_2">During the 2.3 development series, the kernel developers introduced <em class="calibre4">softirqs</em> and <em class="calibre4">tasklets</em>. With the exception of compatibility with existing drivers, softirqs and tasklets could completely replace the BH interface.<sup class="calibre8"><a id="filepos498211" href="#filepos499202">1</a></sup> Softirqs are a set of statically defined bottom halves that can run simultaneously on any processor; even two of the same type can run concurrently. Tasklets, which have an awful and confusing name,<sup class="calibre8"><a id="filepos498462" href="#filepos499542">2</a></sup> are flexible, dynamically created bottom halves built on top of softirqs. Two different tasklets can run concurrently on different processors, but two of the same type of tasklet cannot run simultaneously. Thus, tasklets are a good trade-off between performance and ease of use. For most bottom-half processing, the tasklet is sufficient. Softirqs are useful when performance is critical, such as with networking. Using softirqs requires more care, however, because two of the same softirq can run at the same time. In addition, softirqs must be registered statically at compile time. Conversely, code can dynamically register tasklets.</p><div class="calibre_3"> </div>
<p class="calibre_2"><sup class="calibre8"><a id="filepos499202" href="#filepos498211">1</a></sup>
<em class="calibre4">It is nontrivial to convert BHs to softirqs or tasklets because BHs are globally synchronized and, therefore, assume that no other BH is running during their execution. The conversion did eventually happen, however, in 2.5.</em></p><div class="calibre_3"> </div>
<p class="calibre_2"><sup class="calibre8"><a id="filepos499542" href="#filepos498462">2</a></sup>
<em class="calibre4">They have nothing to do with tasks. Think of a tasklet as a simple and easy-to-use softirq.</em></p><div class="calibre_3"> </div>
<p class="calibre_2">To further confound the issue, some people refer to all bottom halves as software interrupts or softirqs. In other words, they call both the softirq mechanism and bottom halves in general softirqs. Ignore those people. They run with the same crowd that named the BH and tasklet mechanisms.</p><div class="calibre_3"> </div>
<p class="calibre_2">While developing the 2.5 kernel, the BH interface was finally tossed to the curb because all BH users were converted to the other bottom-half interfaces. Additionally, the task queue interface was replaced by the work queue interface. Work queues are a simple yet useful method of queuing work to later be performed in process context. We get to them later.</p><div class="calibre_3"> </div>
<p class="calibre_2">Consequently, today 2.6 has three bottom-half mechanisms in the kernel: softirqs, tasklets, and work queues. The old BH and task queue interfaces are but mere memories.</p><div class="calibre_3"> </div>
<div border="1" class="calibre_26"><blockquote class="calibre10"><div class="calibre11">
<p class="calibre_2"></p><div class="calibre_3"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Kernel Timers</span></span></p><div class="calibre_24"> </div>
<p class="calibre_2">Another mechanism for deferring work is <em class="calibre4">kernel timers</em>. Unlike the mechanisms discussed in the chapter thus far, timers defer work for a specified amount of time. That is, although the tools discussed in this chapter are useful to defer work to <em class="calibre4">any time but now</em>, you use timers to defer work until at least a specific time has elapsed.</p><div class="calibre_3"> </div>
<p class="calibre_2">Therefore, timers have different uses than the general mechanisms discussed in this chapter. A full discussion of timers is given in <a href="index_split_020.html#filepos701833">Chapter 11</a>, “Timers and Time Management.”</p><div class="calibre_3"> </div>
</div></blockquote></div><div class="calibre_7"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos501662"> </div>
<h5 class="calibre_29"><span class="calibre3">Dispelling the Confusion</span></h5><div class="calibre_24"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos501788"> </div>
<p class="calibre_2">This is some seriously confusing stuff, but actually it involves just naming issues. Let’s go over it again.</p><div class="calibre_3"> </div>
<p class="calibre_2"><em class="calibre4">Bottom half</em> is a generic operating system term referring to the deferred portion of interrupt processing, so named because it represents the second, or bottom, half of the interrupt processing solution. In Linux, the term currently has this meaning, too. All the kernel’s mechanisms for deferring work are “bottom halves.” Some people also confusingly call all bottom halves “softirqs.”</p><div class="calibre_3"> </div>
<p class="calibre_2">Bottom half also refers to the original deferred work mechanism in Linux. This mechanism is also known as a BH, so we call it by that name now and leave the former as a generic description. The BH mechanism was deprecated a while back and fully removed in the 2.5 development kernel series.</p><div class="calibre_3"> </div>
<p class="calibre_2">Currently, three methods exist for deferring work: softirqs, tasklets, and work queues. Tasklets are built on softirqs and work queues are their own subsystem. <a href="#filepos503105">Table 8.1</a> presents a history of bottom halves.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos503105"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Table 8.1. Bottom Half Status</span></span></p><div class="calibre_24"> </div>
<p class="calibre_23"><img alt="image" src="images/00088.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">With this naming confusion settled, let’s look at the individual mechanisms.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos503517"> </div>
<h3 class="calibre_21"><span class="bold">Softirqs</span></h3><div class="calibre_22"> </div>
<p class="calibre_2">The place to start this discussion of the actual bottom half methods is with softirqs. Softirqs are rarely used directly; tasklets are a much more common form of bottom half. Nonetheless, because tasklets are built on softirqs, we cover them first. The softirq code lives in the file <code class="calibre6"><span class="calibre7">kernel/softirq.c</span></code> in the kernel source tree.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos504041"> </div>
<h4 class="calibre_27"><span class="calibre3">Implementing Softirqs</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">Softirqs are statically allocated at compile time. Unlike tasklets, you cannot dynamically register and destroy softirqs. Softirqs are represented by the <code class="calibre6"><span class="calibre7">softirq_action</span></code> structure, which is defined in <code class="calibre6"><span class="calibre7">&lt;linux/interrupt.h&gt;</span></code>:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12"><a id="filepos504550"></a>struct softirq_action {<br class="calibre1"/>        void (*action)(struct softirq_action *);<br class="calibre1"/>};</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">A 32-entry array of this structure is declared in <code class="calibre6"><span class="calibre7">kernel/softirq.c</span></code>:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">static struct softirq_action softirq_vec[NR_SOFTIRQS];</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">Each registered softirq consumes one entry in the array. Consequently, there are <code class="calibre6"><span class="calibre7">NR_SOFTIRQS</span></code> registered softirqs. The number of registered softirqs is statically determined at compile time and cannot be changed dynamically. The kernel enforces a limit of 32 registered softirqs; in the current kernel, however, only nine exist.<sup class="calibre8"><a id="filepos505414" href="#filepos505517">3</a></sup></p><div class="calibre_3"> </div>
<p class="calibre_2"><sup class="calibre8"><a id="filepos505517" href="#filepos505414">3</a></sup>
<em class="calibre4">Most drivers use tasklets or work queues for their bottom half. Tasklets are built off softirqs, as the next section explains.</em></p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos505755"> </div>
<h5 class="calibre_29"><span class="calibre3">The Softirq Handler</span></h5><div class="calibre_24"> </div>
<p class="calibre_2">The prototype of a softirq handler, <code class="calibre6"><span class="calibre7">action</span></code>, looks like</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">void softirq_handler(struct softirq_action *)</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">When the kernel runs a softirq handler, it executes this <code class="calibre6"><span class="calibre7">action</span></code> function with a pointer to the corresponding <code class="calibre6"><span class="calibre7">softirq_action</span></code> structure as its lone argument. For example, if <code class="calibre6"><span class="calibre7">my_softirq</span></code> pointed to an entry in the <code class="calibre6"><span class="calibre7">softirq_vec</span></code> array, the kernel would invoke the softirq handler function as</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">my_softirq-&gt;action(my_softirq);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">It seems a bit odd that the kernel passes the entire structure to the softirq handler. This trick enables future additions to the structure without requiring a change in every softirq handler.</p><div class="calibre_3"> </div>
<p class="calibre_2">A softirq never preempts another softirq. The only event that can preempt a softirq is an interrupt handler. Another softirq—even the same one—can run on another processor, however.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos507263"> </div>
<h5 class="calibre_29"><span class="calibre3">Executing Softirqs</span></h5><div class="calibre_24"> </div>
<p class="calibre_2">A registered softirq must be marked before it will execute. This is called <em class="calibre4">raising the softirq</em>. Usually, an interrupt handler marks its softirq for execution before returning. Then, at a suitable time, the softirq runs. Pending softirqs are checked for and executed in the following places:</p><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• In the return from hardware interrupt code path</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• In the <code class="calibre6"><span class="calibre7">ksoftirqd</span></code> kernel thread</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• In any code that explicitly checks for and executes pending softirqs, such as the networking subsystem</p></blockquote><div class="calibre_3"> </div>
<p class="calibre_2">Regardless of the method of invocation, softirq execution occurs in <code class="calibre6"><span class="calibre7">__do_softirq()</span></code>, which is invoked by <code class="calibre6"><span class="calibre7">do_softirq()</span></code>. The function is quite simple. If there are pending softirqs, <code class="calibre6"><span class="calibre7">__do_softirq()</span></code> loops over each one, invoking its handler. Let’s look at a simplified variant of the important part of <code class="calibre6"><span class="calibre7">__do_softirq()</span></code>:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00089.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">This snippet is the heart of softirq processing. It checks for, and executes, any pending softirqs. Specifically</p><div class="calibre_3"> </div>
<ol class="calibre13">
<li value="1" class="calibre14">It sets the <code class="calibre6"><span class="calibre7">pending</span></code> local variable to the value returned by the <code class="calibre6"><span class="calibre7">local_softirq_pending()</span></code> macro. This is a 32-bit mask of pending softirqs—if bit <code class="calibre6"><span class="calibre7">n</span></code> is set, the <code class="calibre6"><span class="calibre7">n</span></code>th softirq is pending.</li>
<li value="2" class="calibre14">Now that the pending bitmask of softirqs is saved, it clears the actual bitmask.<sup class="calibre8"><a id="filepos509392" href="#filepos509474">4</a></sup><br class="calibre1"/>
<p class="calibre_2"><sup class="calibre8"><a id="filepos509474" href="#filepos509392">4</a></sup>
<em class="calibre4">This actually occurs with local interrupts disabled, but that is omitted in this simplified example. If interrupts were not disabled, a softirq could have been raised (and thus be pending) in the intervening time between saving the mask and clearing it. This would result in incorrectly clearing a pending bit.</em></p><div class="calibre_3"> </div></li>
<li value="3" class="calibre14">The pointer <code class="calibre6"><span class="calibre7">h</span></code> is set to the first entry in the <code class="calibre6"><span class="calibre7">softirq_vec</span></code>.</li>
<li value="4" class="calibre14">If the first bit in <code class="calibre6"><span class="calibre7">pending</span></code> is set, <code class="calibre6"><span class="calibre7">h-&gt;action(h)</span></code> is called.</li>
<li value="5" class="calibre14">The pointer <code class="calibre6"><span class="calibre7">h</span></code> is incremented by one so that it now points to the second entry in the <code class="calibre6"><span class="calibre7">softirq_vec</span></code> array.</li>
<li value="6" class="calibre14">The bitmask <code class="calibre6"><span class="calibre7">pending</span></code> is right-shifted by one. This tosses the first bit away and moves all other bits one place to the right. Consequently, the second bit is now the first (and so on).</li>
<li value="7" class="calibre14">The pointer <code class="calibre6"><span class="calibre7">h</span></code> now points to the second entry in the array, and the <code class="calibre6"><span class="calibre7">pending</span></code> bitmask now has the second bit as the first. Repeat the previous steps.</li>
<li value="8" class="calibre14"><a id="filepos510859"></a>Continue repeating until <code class="calibre6"><span class="calibre7">pending</span></code> is zero, at which point there are no more pending softirqs and the work is done. Note, this check is sufficient to ensure <code class="calibre6"><span class="calibre7">h</span></code> always points to a valid entry in <code class="calibre6"><span class="calibre7">softirq_vec</span></code> because <code class="calibre6"><span class="calibre7">pending</span></code> has at most 32 set bits and thus this loop executes at most 32 times.</li>
</ol>
<p class="calibre_2"></p><div class="calibre_3" id="filepos511323"> </div>
<h4 class="calibre_27"><span class="calibre3">Using Softirqs</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">Softirqs are reserved for the most timing-critical and important bottom-half processing on the system. Currently, only two subsystems—networking and block devices—directly use softirqs. Additionally, kernel timers and tasklets are built on top of softirqs. If you add a new softirq, you normally want to ask yourself why using a tasklet is insufficient. Tasklets are dynamically created and are simpler to use because of their weaker locking requirements, and they still perform quite well. Nonetheless, for timing-critical applications that can do their own locking in an efficient way, softirqs might be the correct solution.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos512129"> </div>
<h5 class="calibre_29"><span class="calibre3">Assigning an Index</span></h5><div class="calibre_24"> </div>
<p class="calibre_2">You declare softirqs statically at compile time via an <code class="calibre6"><span class="calibre7">enum</span></code> in <code class="calibre6"><span class="calibre7">&lt;linux/interrupt.h&gt;</span></code>. The kernel uses this index, which starts at zero, as a relative priority. Softirqs with the lowest numerical priority execute before those with a higher numerical priority.</p><div class="calibre_3"> </div>
<p class="calibre_2">Creating a new softirq includes adding a new entry to this <code class="calibre6"><span class="calibre7">enum</span></code>. When adding a new softirq, you might not want to simply add your entry to the end of the list, as you would elsewhere. Instead, you need to insert the new entry depending on the priority you want to give it. By convention, <code class="calibre6"><span class="calibre7">HI_SOFTIRQ</span></code> is always the first and <code class="calibre6"><span class="calibre7">RCU_SOFTIRQ</span></code> is always the last entry. A new entry likely belongs in between <code class="calibre6"><span class="calibre7">BLOCK_SOFTIRQ</span></code> and <code class="calibre6"><span class="calibre7">TASKLET_SOFTIRQ</span></code>. <a href="#filepos513375">Table 8.2</a> contains a list of the existing tasklet types.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos513375"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Table 8.2. Softirq Types</span></span></p><div class="calibre_24"> </div>
<p class="calibre_23"><img alt="image" src="images/00090.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos513649"> </div>
<h5 class="calibre_29"><span class="calibre3">Registering Your Handler</span></h5><div class="calibre_24"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos513775"> </div>
<p class="calibre_2">Next, the softirq handler is registered at run-time via <code class="calibre6"><span class="calibre7">open_softirq()</span></code>, which takes two parameters: the softirq’s index and its handler function. The networking subsystem, for example, registers its softirqs like this, in <code class="calibre6"><span class="calibre7">net/core/dev.c</span></code>:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">open_softirq(NET_TX_SOFTIRQ, net_tx_action);<br class="calibre1"/>open_softirq(NET_RX_SOFTIRQ, net_rx_action);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">The softirq handlers run with interrupts enabled and cannot sleep. While a handler runs, softirqs on the current processor are disabled. Another processor, however, can execute other softirqs. If the same softirq is raised again while it is executing, another processor can run it simultaneously. This means that any shared data—even global data used only within the softirq handler—needs proper locking (as discussed in the next two chapters). This is an important point, and it is the reason tasklets are usually preferred. Simply preventing your softirqs from running concurrently is not ideal. If a softirq obtained a lock to prevent another instance of itself from running simultaneously, there would be no reason to use a softirq. Consequently, most softirq handlers resort to per-processor data (data unique to each processor and thus not requiring locking) and other tricks to avoid explicit locking and provide excellent scalability.</p><div class="calibre_3"> </div>
<p class="calibre_2">The <em class="calibre4">raison d’être</em> to softirqs is scalability. If you do not need to scale to infinitely many processors, then use a tasklet. Tasklets are essentially softirqs in which multiple instances of the same handler cannot run concurrently on multiple processors.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos515716"> </div>
<h5 class="calibre_29"><span class="calibre3">Raising Your Softirq</span></h5><div class="calibre_24"> </div>
<p class="calibre_2">After a handler is added to the <code class="calibre6"><span class="calibre7">enum</span></code> list and registered via <code class="calibre6"><span class="calibre7">open_softirq()</span></code>, it is ready to run. To mark it pending, so it is run at the next invocation of <code class="calibre6"><span class="calibre7">do_softirq()</span></code>, call <code class="calibre6"><span class="calibre7">raise_softirq()</span></code>. For example, the networking subsystem would call,</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">raise_softirq(NET_TX_SOFTIRQ);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">This raises the <code class="calibre6"><span class="calibre7">NET_TX_SOFTIRQ</span></code> softirq. Its handler, <code class="calibre6"><span class="calibre7">net_tx_action()</span></code>, runs the next time the kernel executes softirqs. This function disables interrupts prior to actually raising the softirq and then restores them to their previous state. If interrupts are already off, the function <code class="calibre6"><span class="calibre7">raise_softirq_irqoff()</span></code> can be used as a small optimization. For example</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">/*<br class="calibre1"/> * interrupts must already be off!<br class="calibre1"/> */<br class="calibre1"/>raise_softirq_irqoff(NET_TX_SOFTIRQ);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">Softirqs are most often raised from within interrupt handlers. In the case of interrupt handlers, the interrupt handler performs the basic hardware-related work, raises the softirq, and then exits. When processing interrupts, the kernel invokes <code class="calibre6"><span class="calibre7">do_softirq()</span></code>. The softirq then runs and picks up where the interrupt handler left off. In this example, the “top half” and “bottom half” naming should make sense.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos517634"> </div>
<h3 class="calibre_21"><span class="bold">Tasklets</span></h3><div class="calibre_22"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos517745"> </div>
<p class="calibre_2">Tasklets are a bottom-half mechanism built on top of softirqs. As mentioned, they have nothing to do with tasks. Tasklets are similar in nature and behavior to softirqs; however, they have a simpler interface and relaxed locking rules.</p><div class="calibre_3"> </div>
<p class="calibre_2">As a device driver author, the decision whether to use softirqs versus tasklets is simple: You almost always want to use tasklets. As we saw in the previous section, you can (almost) count on one hand the users of softirqs. Softirqs are required only for high-frequency and highly threaded uses. Tasklets, on the other hand, see much greater use. Tasklets work just fine for the vast majority of cases and are very easy to use.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos518560"> </div>
<h4 class="calibre_27"><span class="calibre3">Implementing Tasklets</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">Because tasklets are implemented on top of softirqs, they <em class="calibre4">are</em> softirqs. As discussed, tasklets are represented by two softirqs: <code class="calibre6"><span class="calibre7">HI_SOFTIRQ</span></code> and <code class="calibre6"><span class="calibre7">TASKLET_SOFTIRQ</span></code>. The only difference in these types is that the <code class="calibre6"><span class="calibre7">HI_SOFTIRQ</span></code>-based tasklets run prior to the <code class="calibre6"><span class="calibre7">TASKLET_SOFTIRQ</span></code>-based tasklets.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos519164"> </div>
<h5 class="calibre_29"><span class="calibre3">The Tasklet Structure</span></h5><div class="calibre_24"> </div>
<p class="calibre_2">Tasklets are represented by the <code class="calibre6"><span class="calibre7">tasklet_struct</span></code> structure. Each structure represents a unique tasklet. The structure is declared in <code class="calibre6"><span class="calibre7">&lt;linux/interrupt.h&gt;</span></code>:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00091.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">The <code class="calibre6"><span class="calibre7">func</span></code> member is the tasklet handler (the equivalent of <code class="calibre6"><span class="calibre7">action</span></code> to a softirq) and receives <code class="calibre6"><span class="calibre7">data</span></code> as its sole argument.</p><div class="calibre_3"> </div>
<p class="calibre_2">The <code class="calibre6"><span class="calibre7">state</span></code> member is exactly zero, <code class="calibre6"><span class="calibre7">TASKLET_STATE_SCHED</span></code>, or <code class="calibre6"><span class="calibre7">TASKLET_STATE_RUN</span></code>. <code class="calibre6"><span class="calibre7">TASKLET_STATE_SCHED</span></code> denotes a tasklet that is scheduled to run, and <code class="calibre6"><span class="calibre7">TASKLET_STATE_RUN</span></code> denotes a tasklet that is running. As an optimization, <code class="calibre6"><span class="calibre7">TASKLET_STATE_RUN</span></code> is used only on multiprocessor machines because a uniprocessor machine always knows whether the tasklet is running. (It is either the currently executing code, or not.)</p><div class="calibre_3"> </div>
<p class="calibre_2">The <code class="calibre6"><span class="calibre7">count</span></code> field is used as a reference count for the tasklet. If it is nonzero, the tasklet is disabled and cannot run; if it is zero, the tasklet is enabled and can run if marked pending.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos520866"> </div>
<h5 class="calibre_29"><span class="calibre3">Scheduling Tasklets</span></h5><div class="calibre_24"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos520987"> </div>
<p class="calibre_2"><em class="calibre4">Scheduled</em> tasklets (the equivalent of raised softirqs)<sup class="calibre8"><a id="filepos521106" href="#filepos521623">5</a></sup> are stored in two per-processor structures: <code class="calibre6"><span class="calibre7">tasklet_vec</span></code> (for regular tasklets) and <code class="calibre6"><span class="calibre7">tasklet_hi_vec</span></code> (for high-priority tasklets). Both of these structures are linked lists of <code class="calibre6"><span class="calibre7">tasklet_struct</span></code> structures. Each <code class="calibre6"><span class="calibre7">tasklet_struct</span></code> structure in the list represents a different tasklet.</p><div class="calibre_3"> </div>
<p class="calibre_2"><sup class="calibre8"><a id="filepos521623" href="#filepos521106">5</a></sup>
<em class="calibre4">Yet another example of the confusing naming schemes at work here. Why are softirqs raised but tasklets scheduled? Who knows? Both terms mean to mark that bottom half pending so that it is executed soon.</em></p><div class="calibre_3"> </div>
<p class="calibre_2">Tasklets are scheduled via the <code class="calibre6"><span class="calibre7">tasklet_schedule()</span></code> and <code class="calibre6"><span class="calibre7">tasklet_hi_schedule()</span></code> functions, which receive a pointer to the tasklet’s <code class="calibre6"><span class="calibre7">tasklet_struct</span></code> as their lone argument. Each function ensures that the provided tasklet is not yet scheduled and then calls <code class="calibre6"><span class="calibre7">__tasklet_schedule()</span></code> and <code class="calibre6"><span class="calibre7">__tasklet_hi_schedule()</span></code> as appropriate. The two functions are similar. (The difference is that one uses <code class="calibre6"><span class="calibre7">TASKLET_SOFTIRQ</span></code> and one uses <code class="calibre6"><span class="calibre7">HI_SOFTIRQ.</span></code>) Writing and using tasklets is covered in the next section. Now, let’s look at the steps <code class="calibre6"><span class="calibre7">tasklet_schedule()</span></code> undertakes:</p><div class="calibre_3"> </div>
<ol class="calibre13">
<li value="1" class="calibre14">Check whether the tasklet’s <code class="calibre6"><span class="calibre7">state</span></code> is <code class="calibre6"><span class="calibre7">TASKLET</span></code>_<code class="calibre6"><span class="calibre7">STATE_SCHED</span></code>. If it is, the tasklet is already scheduled to run and the function can immediately return.</li>
<li value="2" class="calibre14">Call <code class="calibre6"><span class="calibre7">__tasklet_schedule()</span></code>.</li>
<li value="3" class="calibre14">Save the state of the interrupt system, and then disable local interrupts. This ensures that nothing on this processor will mess with the tasklet code while <code class="calibre6"><span class="calibre7">tasklet_schedule()</span></code> is manipulating the tasklets.</li>
<li value="4" class="calibre14">Add the tasklet to be scheduled to the head of the <code class="calibre6"><span class="calibre7">tasklet_vec</span></code> or <code class="calibre6"><span class="calibre7">tasklet_hi_vec</span></code> linked list, which is unique to each processor in the system.</li>
<li value="5" class="calibre14">Raise the <code class="calibre6"><span class="calibre7">TASKLET_SOFTIRQ</span></code> or <code class="calibre6"><span class="calibre7">HI_SOFTIRQ</span></code> softirq, so <code class="calibre6"><span class="calibre7">do_softirq()</span></code> executes this tasklet in the near future.</li>
<li value="6" class="calibre14">Restore interrupts to their previous state and return.</li>
</ol>
<p class="calibre_2">At the next earliest convenience, <code class="calibre6"><span class="calibre7">do_softirq()</span></code> is run as discussed in the previous section. Because most tasklets and softirqs are marked pending in interrupt handlers, <code class="calibre6"><span class="calibre7">do_softirq()</span></code> most likely runs when the last interrupt returns. Because <code class="calibre6"><span class="calibre7">TASKLET_SOFTIRQ</span></code> or <code class="calibre6"><span class="calibre7">HI_SOFTIRQ</span></code> is now raised, <code class="calibre6"><span class="calibre7">do_softirq()</span></code> executes the associated handlers. These handlers, <code class="calibre6"><span class="calibre7">tasklet_action()</span></code> and <code class="calibre6"><span class="calibre7">tasklet_hi_action()</span></code>, are the heart of tasklet processing. Let’s look at the steps these handlers perform:</p><div class="calibre_3"> </div>
<ol class="calibre13">
<li value="1" class="calibre14">Disable local interrupt delivery (there is no need to first save their state because the code here is always called as a softirq handler and interrupts are always enabled) and retrieve the <code class="calibre6"><span class="calibre7">tasklet_vec</span></code> or <code class="calibre6"><span class="calibre7">tasklet_hi_vec</span></code> list for this processor.</li>
<li value="2" class="calibre14">Clear the list for this processor by setting it equal to <code class="calibre6"><span class="calibre7">NULL</span></code>.</li>
<li value="3" class="calibre14"><a id="filepos525209"></a>Enable local interrupt delivery. Again, there is no need to restore them to their previous state because this function knows that they were always originally enabled.</li>
<li value="4" class="calibre14">Loop over each pending tasklet in the retrieved list.</li>
<li value="5" class="calibre14">If this is a multiprocessing machine, check whether the tasklet is running on another processor by checking the <code class="calibre6"><span class="calibre7">TASKLET_STATE_RUN</span></code> flag. If it is currently running, do not execute it now and skip to the next pending tasklet. (Recall that only one tasklet of a given type may run concurrently.)</li>
<li value="6" class="calibre14">If the tasklet is not currently running, set the <code class="calibre6"><span class="calibre7">TASKLET_STATE_RUN</span></code> flag, so another processor will not run it.</li>
<li value="7" class="calibre14">Check for a zero <code class="calibre6"><span class="calibre7">count</span></code> value, to ensure that the tasklet is not disabled. If the tasklet is disabled, skip it and go to the next pending tasklet.</li>
<li value="8" class="calibre14">We now know that the tasklet is not running elsewhere, is marked as running so it will not start running elsewhere, and has a zero <code class="calibre6"><span class="calibre7">count</span></code> value. Run the tasklet handler.</li>
<li value="9" class="calibre14">After the tasklet runs, clear the <code class="calibre6"><span class="calibre7">TASKLET_STATE_RUN</span></code> flag in the tasklet’s <code class="calibre6"><span class="calibre7">state</span></code> field.</li>
<li value="10" class="calibre14">Repeat for the next pending tasklet, until there are no more scheduled tasklets waiting to run.</li>
</ol>
<p class="calibre_2">The implementation of tasklets is simple, but rather clever. As you saw, all tasklets are multiplexed on top of two softirqs, <code class="calibre6"><span class="calibre7">HI_SOFTIRQ</span></code> and <code class="calibre6"><span class="calibre7">TASKLET_SOFTIRQ</span></code>. When a tasklet is scheduled, the kernel raises one of these softirqs. These softirqs, in turn, are handled by special functions that then run any scheduled tasklets. The special functions ensure that only one tasklet of a given type runs at the same time. (But other tasklets can run simultaneously.) All this complexity is then hidden behind a clean and simple interface.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos527368"> </div>
<h4 class="calibre_27"><span class="calibre3">Using Tasklets</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">In most cases, tasklets are the preferred mechanism with which to implement your bottom half for a normal hardware device. Tasklets are dynamically created, easy to use, and quick. Moreover, although their name is mind-numbingly confusing, it grows on you: It is cute.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos527803"> </div>
<h5 class="calibre_29"><span class="calibre3">Declaring Your Tasklet</span></h5><div class="calibre_24"> </div>
<p class="calibre_2">You can create tasklets statically or dynamically. What option you choose depends on whether you have (or want) a direct or indirect reference to the tasklet. If you are going to statically create the tasklet (and thus have a direct reference to it), use one of two macros in <code class="calibre6"><span class="calibre7">&lt;linux/interrupt.h&gt;</span></code>:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">DECLARE_TASKLET(name, func, data)<br class="calibre1"/>DECLARE_TASKLET_DISABLED(name, func, data);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">Both these macros statically create a <code class="calibre6"><span class="calibre7">struct tasklet_struct</span></code> with the given name. When the tasklet is scheduled, the given function <code class="calibre6"><span class="calibre7">func</span></code> is executed and passed the <a id="filepos528732"></a>argument <code class="calibre6"><span class="calibre7">data</span></code>. The difference between the two macros is the initial reference count. The first macro creates the tasklet with a <code class="calibre6"><span class="calibre7">count</span></code> of zero, and the tasklet is enabled. The second macro sets <code class="calibre6"><span class="calibre7">count</span></code> to one, and the tasklet is disabled. Here is an example:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">DECLARE_TASKLET(my_tasklet, my_tasklet_handler, dev);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">This line is equivalent to</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00092.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">This creates a tasklet named <code class="calibre6"><span class="calibre7">my_tasklet</span></code> enabled with <code class="calibre6"><span class="calibre7">tasklet_handler</span></code> as its handler. The value of <code class="calibre6"><span class="calibre7">dev</span></code> is passed to the handler when it is executed.</p><div class="calibre_3"> </div>
<p class="calibre_2">To initialize a tasklet given an indirect reference (a pointer) to a dynamically created <code class="calibre6"><span class="calibre7">struct tasklet_struct</span></code>, <code class="calibre6"><span class="calibre7">t</span></code>, call <code class="calibre6"><span class="calibre7">tasklet_init()</span></code>:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">tasklet_init(t, tasklet_handler, dev);  /* dynamically as opposed to statically */</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos530253"> </div>
<h5 class="calibre_29"><span class="calibre3">Writing Your Tasklet Handler</span></h5><div class="calibre_24"> </div>
<p class="calibre_2">The tasklet handler must match the correct prototype:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">void tasklet_handler(unsigned long data)</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">As with softirqs, tasklets cannot sleep. This means you cannot use semaphores or other blocking functions in a tasklet. Tasklets also run with all interrupts enabled, so you must take precautions (for example, disable interrupts and obtain a lock) if your tasklet shares data with an interrupt handler. Unlike softirqs, however, two of the same tasklets never run concurrently—although two different tasklets can run at the same time on two different processors. If your tasklet shares data with another tasklet or softirq, you need to use proper locking (see <a href="index_split_018.html#filepos575425">Chapter 9</a>, “An Introduction to Kernel Synchronization,” and <a href="index_split_019.html#filepos613760">Chapter 10</a>, “Kernel Synchronization Methods”).</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos531431"> </div>
<h5 class="calibre_29"><span class="calibre3">Scheduling Your Tasklet</span></h5><div class="calibre_24"> </div>
<p class="calibre_2">To schedule a tasklet for execution, <code class="calibre6"><span class="calibre7">tasklet_schedule()</span></code> is called and passed a pointer to the relevant <code class="calibre6"><span class="calibre7">tasklet_struct</span></code>:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">tasklet_schedule(&amp;my_tasklet);    /* mark my_tasklet as pending */</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">After a tasklet is scheduled, it runs once at some time in the near future. If the same tasklet is scheduled again, before it has had a chance to run, it still runs only once. If it is already running, for example on another processor, the tasklet is rescheduled and runs again. As an optimization, a tasklet always runs on the processor that scheduled it—making better use of the processor’s cache, you hope.</p><div class="calibre_3"> </div>
<p class="calibre_2">You can disable a tasklet via a call to <code class="calibre6"><span class="calibre7">tasklet_disable()</span></code>, which disables the given tasklet. If the tasklet is currently running, the function will not return until it finishes executing. Alternatively, you can use <code class="calibre6"><span class="calibre7">tasklet_disable_nosync()</span></code>, which disables the given tasklet but does not wait for the tasklet to complete prior to returning. This is usually not safe because you cannot assume the tasklet is not still running. A call to <code id="filepos532965" class="calibre6"><span class="calibre7">tasklet_enable()</span></code> enables the tasklet. This function also must be called before a tasklet created with <code class="calibre6"><span class="calibre7">DECLARE_TASKLET_DISABLED()</span></code> is usable. For example:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00093.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">You can remove a tasklet from the pending queue via <code class="calibre6"><span class="calibre7">tasklet_kill()</span></code>. This function receives a pointer as a lone argument to the tasklet’s <code class="calibre6"><span class="calibre7">tasklet_struct</span></code>. Removing a scheduled tasklet from the queue is useful when dealing with a tasklet that often reschedules itself. This function first waits for the tasklet to finish executing and then it removes the tasklet from the queue. Nothing stops some other code from rescheduling the tasklet, of course. This function must not be used from interrupt context because it sleeps.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos533973"> </div>
<h4 class="calibre_27"><span class="calibre3">ksoftirqd</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">Softirq (and thus tasklet) processing is aided by a set of per-processor kernel threads. These kernel threads help in the processing of softirqs when the system is overwhelmed with softirqs. Because tasklets are implemented using softirqs, the following discussion applies equally to softirqs and tasklets. For brevity, we will refer mainly to softirqs.</p><div class="calibre_3"> </div>
<p class="calibre_2">As already described, the kernel processes softirqs in a number of places, most commonly on return from handling an interrupt. Softirqs might be raised at high rates (such as during heavy network traffic). Further, softirq functions can reactivate themselves. That is, while running, a softirq can raise itself so that it runs again (for example, the networking subsystem’s softirq raises itself). The possibility of a high frequency of softirqs in conjunction with their capability to remark themselves active can result in user-space programs being starved of processor time. Not processing the reactivated softirqs in a timely manner, however, is unacceptable. When softirqs were first designed, this caused a dilemma that needed fixing, and neither obvious solution was a good one. First, let’s look at each of the two obvious solutions.</p><div class="calibre_3"> </div>
<p class="calibre_2">The first solution is simply to keep processing softirqs as they come in and to recheck and reprocess any pending softirqs before returning. This ensures that the kernel processes softirqs in a timely manner and, most important, that any reactivated softirqs are also immediately processed. The problem lies in high load environments, in which many softirqs occur, that continually reactivate themselves. The kernel might continually service softirqs without accomplishing much else. User-space is neglected—indeed, nothing but softirqs and interrupt handlers run and, in turn, the system’s users get mad. This approach might work fine if the system is never under intense load; if the system experiences moderate interrupt levels, this solution is not acceptable. User-space cannot be starved for significant periods.</p><div class="calibre_3"> </div>
<p class="calibre_2">The second solution is <em class="calibre4">not</em> to handle reactivated softirqs. On return from interrupt, the kernel merely looks at all pending softirqs and executes them as normal. If any softirqs reactivate themselves, however, they will not run until the <em class="calibre4">next</em> time the kernel handles pending softirqs. This is most likely not until the next interrupt occurs, which can equate to a lengthy amount of time before any new (or reactivated) softirqs are executed. Worse, on an otherwise idle system, it is beneficial to process the softirqs right away. Unfortunately, this approach is oblivious to which processes are runnable. Therefore, although this method prevents starving user-space, it does starve the softirqs and does not take good advantage of an idle system.</p><div class="calibre_3"> </div>
<p class="calibre_2">In designing softirqs, the kernel developers realized that some sort of compromise was needed. The solution ultimately implemented in the kernel is to <em class="calibre4">not</em> immediately process reactivated softirqs. Instead, if the number of softirqs grows excessive, the kernel wakes up a family of kernel threads to handle the load. The kernel threads run with the lowest possible priority (nice value of 19), which ensures they do not run in lieu of anything important. This concession prevents heavy softirq activity from completely starving user-space of processor time. Conversely, it also ensures that “excess” softirqs do run eventually. Finally, this solution has the added property that on an idle system the softirqs are handled rather quickly because the kernel threads will schedule immediately.</p><div class="calibre_3"> </div>
<p class="calibre_2">There is one thread per processor. The threads are each named <code class="calibre6"><span class="calibre7">ksoftirqd/n</span></code> where <code class="calibre6"><span class="calibre7">n</span></code> is the processor number. On a two-processor system, you would have <code class="calibre6"><span class="calibre7">ksoftirqd/0</span></code> and <code class="calibre6"><span class="calibre7">ksoftirqd/1</span></code>. Having a thread on each processor ensures an idle processor, if available, can always service softirqs. After the threads are initialized, they run a tight loop similar to this:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00094.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">If any softirqs are pending (as reported by <code class="calibre6"><span class="calibre7">softirq_pending()</span></code>), <code class="calibre6"><span class="calibre7">ksoftirqd</span></code> calls <code class="calibre6"><span class="calibre7">do_softirq()</span></code> to handle them. Note that it does this repeatedly to handle any reactivated softirqs, too. After each iteration, <code class="calibre6"><span class="calibre7">schedule()</span></code> is called if needed, to enable more important processes to run. After all processing is complete, the kernel thread sets itself <code class="calibre6"><span class="calibre7">TASK_INTERRUPTIBLE</span></code> and invokes the scheduler to select a new runnable process.</p><div class="calibre_3"> </div>
<p class="calibre_2">The softirq kernel threads are awakened whenever <code class="calibre6"><span class="calibre7">do_softirq()</span></code> detects an executed kernel thread reactivating itself.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos539435"> </div>
<h4 class="calibre_27"><span class="calibre3">The Old BH Mechanism</span></h4><div class="calibre_24"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos539557"> </div>
<p class="calibre_2">Although the old BH interface, thankfully, is no longer present in 2.6, it was around for a <em class="calibre4">long</em> time—since the earliest versions of the kernel. Because it had immense staying power, it certainly carries some historical significance that requires more than a passing look. Nothing in this brief section actually pertains to 2.6, but the history is important.</p><div class="calibre_3"> </div>
<p class="calibre_2">The BH interface is ancient, and it showed. Each BH must be statically defined, and there are a maximum of 32. Because the handlers must all be defined at compile-time, modules could not directly use the BH interface. They could piggyback off an existing BH, however. Over time, this static requirement and the maximum of 32 bottom halves became a major hindrance to their use.</p><div class="calibre_3"> </div>
<p class="calibre_2">All BH handlers are strictly serialized—no two BH handlers, even of different types, can run concurrently. This made synchronization easy, but it wasn’t beneficial to multiprocessor scalability. Performance on large SMP machines was sub par. A driver using the BH interface did not scale well to multiple processors. The networking layer, in particular, suffered.</p><div class="calibre_3"> </div>
<p class="calibre_2">Other than these attributes, the BH mechanism is similar to tasklets. In fact, the BH interface was implemented on top of tasklets in 2.4. The 32 possible bottom halves were represented by constants defined in <code class="calibre6"><span class="calibre7">&lt;linux/interrupt.h&gt;</span></code>. To mark a BH as pending, the function <code class="calibre6"><span class="calibre7">mark_bh()</span></code> was called and passed the number of the BH. In 2.4, this in turn scheduled the BH tasklet, <code class="calibre6"><span class="calibre7">bh_action()</span></code>, to run. Before the 2.4 kernel, the BH mechanism was independently implemented and did not rely on any lower-level bottom-half mechanism, much as softirqs are implemented today.</p><div class="calibre_3"> </div>
<p class="calibre_2">Because of the shortcomings of this form of bottom half, kernel developers introduced task queues to replace bottom halves. Task queues never accomplished this goal, although they did win many new users. In 2.3, the softirq and tasklet mechanisms were introduced to put an end to the BH. The BH mechanism was reimplemented on top of tasklets. Unfortunately, it was complicated to port bottom halves from the BH interface to tasklets or softirqs because of the weaker inherent serialization of the new interfaces.<sup class="calibre8"><a id="filepos542124" href="#filepos542438">6</a></sup> During 2.5, however, the conversion did occur when timers and SCSI—the remaining BH users—finally moved over to softirqs. The kernel developers summarily removed the BH interface. Good riddance, BH!</p><div class="calibre_3"> </div>
<p class="calibre_2"><sup class="calibre8"><a id="filepos542438" href="#filepos542124">6</a></sup>
<em class="calibre4">That is, the weaker serialization was beneficial to performance but also harder to program. Converting a BH to a tasklet, for example, required careful thinking: Is this code safe running at the same time as any other tasklet? When finally converted, however, the performance was worth it.</em></p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos542839"> </div>
<h3 class="calibre_21"><span class="bold">Work Queues</span></h3><div class="calibre_22"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos542953"> </div>
<p class="calibre_2">Work queues are a different form of deferring work from what we have looked at so far. Work queues defer work into a kernel thread—this bottom half always runs in process context. Thus, code deferred to a work queue has all the usual benefits of process context. Most important, work queues are schedulable and can therefore sleep.</p><div class="calibre_3"> </div>
<p class="calibre_2">Normally, it is easy to decide between using work queues and softirqs/tasklets. If the deferred work needs to sleep, work queues are used. If the deferred work need not sleep, softirqs or tasklets are used. Indeed, the usual alternative to work queues is kernel threads. Because the kernel developers frown upon creating a new kernel thread (and, in some locales, it is a punishable offense), work queues are strongly preferred. They are <em class="calibre4">really</em> easy to use, too.</p><div class="calibre_3"> </div>
<p class="calibre_2">If you need a schedulable entity to perform your bottom-half processing, you need work queues. They are the only bottom-half mechanisms that run in process context, and thus, the only ones that can sleep. This means they are useful for situations in which you need to allocate a lot of memory, obtain a semaphore, or perform block I/O. If you do not need a kernel thread to handle your deferred work, consider a tasklet instead.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos544393"> </div>
<h4 class="calibre_27"><span class="calibre3">Implementing Work Queues</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">In its most basic form, the work queue subsystem is an interface for creating kernel threads to handle work queued from elsewhere. These kernel threads are called <em class="calibre4">worker threads</em>. Work queues let your driver create a special worker thread to handle deferred work. The work queue subsystem, however, implements and provides a default worker thread for handling work. Therefore, in its most common form, a work queue is a simple interface for deferring work to a generic kernel thread.</p><div class="calibre_3"> </div>
<p class="calibre_2">The default worker threads are called <code class="calibre6"><span class="calibre7">events/n</span></code> where <code class="calibre6"><span class="calibre7">n</span></code> is the processor number; there is one per processor. For example, on a uniprocessor system there is one thread, <code class="calibre6"><span class="calibre7">events/0</span></code>. A dual processor system would additionally have an <code class="calibre6"><span class="calibre7">events/1</span></code> thread. The default worker thread handles deferred work from multiple locations. Many drivers in the kernel defer their bottom-half work to the default thread. Unless a driver or subsystem has a strong requirement for creating its own thread, the default thread is preferred.</p><div class="calibre_3"> </div>
<p class="calibre_2">Nothing stops code from creating its own worker thread, however. This might be advantageous if you perform large amounts of processing in the worker thread. Processor-intense and performance-critical work might benefit from its own thread. This also lightens the load on the default threads, which prevents starving the rest of the queued work.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos546159"> </div>
<h5 class="calibre_29"><span class="calibre3">Data Structures Representing the Threads</span></h5><div class="calibre_24"> </div>
<p class="calibre_2">The worker threads are represented by the <code class="calibre6"><span class="calibre7">workqueue_struct</span></code> structure:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00095.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2"><a id="filepos546544"></a>This structure, defined in <code class="calibre6"><span class="calibre7">kernel/workqueue.c</span></code>, contains an array of <code class="calibre6"><span class="calibre7">struct cpu_workqueue_struct</span></code>, one per possible processor on the system. Because the worker threads exist on each processor in the system, there is one of these structures per worker thread, per processor, on a given machine. The <code class="calibre6"><span class="calibre7">cpu_workqueue_struct</span></code> is the core data structure and is also defined in <code class="calibre6"><span class="calibre7">kernel/workqueue.c</span></code>:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00096.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">Note that each <em class="calibre4">type</em> of worker thread has one <code class="calibre6"><span class="calibre7">workqueue_struct</span></code> associated to it. Inside, there is one <code class="calibre6"><span class="calibre7">cpu_workqueue_struct</span></code> for every thread and, thus, every processor, because there is one worker thread on each processor.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos547559"> </div>
<h5 class="calibre_29"><span class="calibre3">Data Structures Representing the Work</span></h5><div class="calibre_24"> </div>
<p class="calibre_2">All worker threads are implemented as normal kernel threads running the <code class="calibre6"><span class="calibre7">worker_thread()</span></code>function. After initial setup, this function enters an infinite loop and goes to sleep. When work is queued, the thread is awakened and processes the work. When there is no work left to process, it goes back to sleep.</p><div class="calibre_3"> </div>
<p class="calibre_2">The work is represented by the <code class="calibre6"><span class="calibre7">work_struct</span></code> structure, defined in <code class="calibre6"><span class="calibre7">&lt;linux/workqueue.h&gt;</span></code>:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">struct work_struct {<br class="calibre1"/>        atomic_long_t data;<br class="calibre1"/>        struct list_head entry;<br class="calibre1"/>        work_func_t func;<br class="calibre1"/>};</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">These structures are strung into a linked list, one for each type of queue on each processor. For example, there is one list of deferred work for the generic thread, per processor. When a worker thread wakes up, it runs any work in its list. As it completes <a id="filepos548906"></a>work, it removes the corresponding <code class="calibre6"><span class="calibre7">work_struct</span></code> entries from the linked list. When the list is empty, it goes back to sleep.</p><div class="calibre_3"> </div>
<p class="calibre_2">Let’s look at the heart of <code class="calibre6"><span class="calibre7">worker_thread()</span></code>, simplified:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00097.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">This function performs the following functions, in an infinite loop:</p><div class="calibre_3"> </div>
<ol class="calibre13">
<li value="1" class="calibre14">The thread marks itself sleeping (the task’s state is set to <code class="calibre6"><span class="calibre7">TASK_INTERRUPTIBLE)</span></code> and adds itself to a wait queue.</li>
<li value="2" class="calibre14">If the linked list of work is empty, the thread calls <code class="calibre6"><span class="calibre7">schedule()</span></code> and goes to sleep.</li>
<li value="3" class="calibre14">If the list is not empty, the thread does not go to sleep. Instead, it marks itself <code class="calibre6"><span class="calibre7">TASK_RUNNING</span></code> and removes itself from the wait queue.</li>
<li value="4" class="calibre14">If the list is nonempty, the thread calls <code class="calibre6"><span class="calibre7">run_workqueue()</span></code> to perform the deferred work.</li>
</ol>
<p class="calibre_2">The function <code class="calibre6"><span class="calibre7">run_workqueue()</span></code>, in turn, actually performs the deferred work:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00098.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">This function loops over each entry in the linked list of pending work and executes the <code class="calibre6"><span class="calibre7">func</span></code> member of the <code class="calibre6"><span class="calibre7">workqueue_struct</span></code> for each entry in the linked list:</p><div class="calibre_3"> </div>
<ol class="calibre13">
<li value="1" class="calibre14">While the list is not empty, it grabs the next entry in the list.</li>
<li value="2" class="calibre14">It retrieves the function that should be called, <code class="calibre6"><span class="calibre7">func</span></code>, and its argument, <code class="calibre6"><span class="calibre7">data</span></code>.</li>
<li value="3" class="calibre14">It removes this entry from the list and clears the pending bit in the structure itself.</li>
<li value="4" class="calibre14"><a id="filepos551008"></a>It invokes the function.</li>
<li value="5" class="calibre14">Repeat.</li>
</ol>
<p class="calibre_2"></p><div class="calibre_3" id="filepos551095"> </div>
<h5 class="calibre_29"><span class="calibre3">Work Queue Implementation Summary</span></h5><div class="calibre_24"> </div>
<p class="calibre_2">The relationship between the different data structures is admittedly a bit convoluted. <a href="#filepos551471">Figure 8.1</a> provides a graphical example, which should bring it all together.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos551471"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Figure 8.1. The relationship between work, work queues, and the worker threads.</span></span></p><div class="calibre_24"> </div>
<p class="calibre_23"><img alt="image" src="images/00099.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">At the highest level, there are worker threads. There can be multiple types of worker threads; there is one worker thread per processor of a given type. Parts of the kernel can create worker threads as needed. By default, there is the <em class="calibre4">events</em> worker thread. Each worker thread is represented by the <code class="calibre6"><span class="calibre7">cpu_workqueue_struct</span></code> structure. The <code class="calibre6"><span class="calibre7">workqueue_struct</span></code> structure represents all the worker threads of a given type.</p><div class="calibre_3"> </div>
<p class="calibre_2">For example, assume that in addition to the generic <em class="calibre4">events</em> worker type, you also create a <em class="calibre4">falcon</em> worker type. Also, assume you have a four-processor computer. Then there are four <em class="calibre4">events</em> threads (and thus four <code class="calibre6"><span class="calibre7">cpu_workqueue_struct</span></code> structures) and four <em class="calibre4">falcon</em> threads (and thus another four <code class="calibre6"><span class="calibre7">cpu_workqueue_struct</span></code> structures). There is one <code class="calibre6"><span class="calibre7">workqueue_struct</span></code> for the <em class="calibre4">events</em> type and one for the <em class="calibre4">falcon</em> type.</p><div class="calibre_3"> </div>
<p class="calibre_2">Now, let’s approach from the lowest level, which starts with work. Your driver creates work, which it wants to defer to later. The <code class="calibre6"><span class="calibre7">work_struct</span></code> structure represents this work. Among other things, this structure contains a pointer to the function that handles the <a id="filepos553255"></a>deferred work. The work is submitted to a <em class="calibre4">specific</em> worker thread—in this case, a specific falcon thread. The worker thread then wakes up and performs the queued work.</p><div class="calibre_3"> </div>
<p class="calibre_2">Most drivers use the existing default worker threads, named <em class="calibre4">events</em>. They are easy and simple. Some more serious situations, however, demand their own worker threads. The XFS filesystem, for example, creates two new types of worker threads.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos553786"> </div>
<h4 class="calibre_27"><span class="calibre3">Using Work Queues</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">Using work queues is easy. We cover the default <em class="calibre4">events</em> queue first and then look at creating new worker threads.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos554077"> </div>
<h5 class="calibre_29"><span class="calibre3">Creating Work</span></h5><div class="calibre_24"> </div>
<p class="calibre_2">The first step is actually creating some work to defer. To create the structure statically at runtime, use <code class="calibre6"><span class="calibre7">DECLARE_WORK</span></code>:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">DECLARE_WORK(name, void (*func)(void *), void *data);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">This statically creates a <code class="calibre6"><span class="calibre7">work_struct</span></code> structure named <code class="calibre6"><span class="calibre7">name</span></code> with handler function <code class="calibre6"><span class="calibre7">func</span></code> and argument <code class="calibre6"><span class="calibre7">data</span></code>.</p><div class="calibre_3"> </div>
<p class="calibre_2">Alternatively, you can create work at runtime via a pointer:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">INIT_WORK(struct work_struct *work, void (*func)(void *), void *data);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">This dynamically initializes the work queue pointed to by <code class="calibre6"><span class="calibre7">work</span></code> with handler function <code class="calibre6"><span class="calibre7">func</span></code> and argument <code class="calibre6"><span class="calibre7">data</span></code>.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos555397"> </div>
<h5 class="calibre_29"><span class="calibre3">Your Work Queue Handler</span></h5><div class="calibre_24"> </div>
<p class="calibre_2">The prototype for the work queue handler is</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">void work_handler(void *data)</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">A worker thread executes this function, and thus, the function runs in process context. By default, interrupts are enabled and no locks are held. If needed, the function can sleep. Note that, despite running in process context, the work handlers cannot access user-space memory because there is no associated user-space memory map for kernel threads. The kernel can access user memory only when running on behalf of a user-space process, such as when executing a system call. Only then is user memory mapped in.</p><div class="calibre_3"> </div>
<p class="calibre_2">Locking between work queues or other parts of the kernel is handled just as with any other process context code. This makes writing work handlers much easier. The next two chapters cover locking.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos556556"> </div>
<h5 class="calibre_29"><span class="calibre3">Scheduling Work</span></h5><div class="calibre_24"> </div>
<p class="calibre_2">Now that the work is created, we can schedule it. To queue a given work’s handler function with the default <em class="calibre4">events</em> worker threads, simply call</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">schedule_work(&amp;work);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">The work is scheduled immediately and is run as soon as the <em class="calibre4">events</em> worker thread on the current processor wakes up.</p><div class="calibre_3"> </div>
<p class="calibre_2"><a id="filepos557184"></a>Sometimes you do not want the work to execute immediately, but instead after some delay. In those cases, you can schedule work to execute at a given time in the future:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">schedule_delayed_work(&amp;work, delay);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">In this case, the <code class="calibre6"><span class="calibre7">work_struct</span></code> represented by <code class="calibre6"><span class="calibre7">&amp;work</span></code> will not execute for at least <code class="calibre6"><span class="calibre7">delay</span></code> timer ticks into the future. Using ticks as a unit of time is covered in <a href="index_split_019.html#filepos613760">Chapter 10</a>.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos557904"> </div>
<h5 class="calibre_29"><span class="calibre3">Flushing Work</span></h5><div class="calibre_24"> </div>
<p class="calibre_2">Queued work is executed when the worker thread next wakes up. Sometimes, you need to ensure that a given batch of work has completed before continuing. This is especially important for modules, which almost certainly want to call this function before unloading. Other places in the kernel also might need to make certain no work is pending, to prevent race conditions.</p><div class="calibre_3"> </div>
<p class="calibre_2">For these needs, there is a function to flush a given work queue:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">void flush_scheduled_work(void);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">This function waits until all entries in the queue are executed before returning. While waiting for any pending work to execute, the function sleeps. Therefore, you can call it only from process context.</p><div class="calibre_3"> </div>
<p class="calibre_2">Note that this function does not cancel any delayed work. That is, any work that was scheduled via <code class="calibre6"><span class="calibre7">schedule_delayed_work()</span></code>, and whose delay is not yet up, is not flushed via <code class="calibre6"><span class="calibre7">flush_scheduled_work()</span></code>. To cancel delayed work, call</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">int cancel_delayed_work(struct work_struct *work);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">This function cancels the pending work, if any, associated with the given <code class="calibre6"><span class="calibre7">work_struct</span></code>.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos559615"> </div>
<h5 class="calibre_29"><span class="calibre3">Creating New Work Queues</span></h5><div class="calibre_24"> </div>
<p class="calibre_2">If the default queue is insufficient for your needs, you can create a new work queue and corresponding worker threads. Because this creates one worker thread per processor, you should create unique work queues only if your code needs the performance of a unique set of threads.</p><div class="calibre_3"> </div>
<p class="calibre_2">You create a new work queue and the associated worker threads via a simple function:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">struct workqueue_struct *create_workqueue(const char *name);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">The parameter <code class="calibre6"><span class="calibre7">name</span></code> is used to name the kernel threads. For example, the default <em class="calibre4">events</em> queue is created via</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">struct workqueue_struct *keventd_wq;<br class="calibre1"/>keventd_wq = create_workqueue("events");</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">This function creates <em class="calibre4">all</em> the worker threads (one for each processor in the system) and prepares them to handle work.</p><div class="calibre_3"> </div>
<p class="calibre_2">Creating work is handled in the same manner regardless of the queue type. After the work is created, the following functions are analogous to <code class="calibre6"><span class="calibre7">schedule_work()</span></code> and <code id="filepos561127" class="calibre6"><span class="calibre7">schedule_delayed_work()</span></code>, except that they work on the given work queue and not the default <em class="calibre4">events</em> queue.</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00100.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">Finally, you can flush a wait queue via a call to the function</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">flush_workqueue(struct workqueue_struct *wq)</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">As previously discussed, this function works identically to <code class="calibre6"><span class="calibre7">flush_scheduled_work()</span></code>, except that it waits for the given queue to empty before returning.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos561911"> </div>
<h4 class="calibre_27"><span class="calibre3">The Old Task Queue Mechanism</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">Like the BH interface, which gave way to softirqs and tasklets, the work queue interface grew out of shortcomings in the task queue interface. The task queue interface (often called simply <em class="calibre4">tq</em> in the kernel), like tasklets, also has nothing to do with tasks in the process sense.<sup class="calibre8"><a id="filepos562333" href="#filepos562818">7</a></sup> The users of the task queue interface were ripped in half during the 2.5 development kernel. Half of the users were converted to tasklets, whereas the other half continued using the task queue interface. What was left of the task queue interface then became the work queue interface. Briefly looking at task queues, which were around for some time, is a useful historical exercise.</p><div class="calibre_3"> </div>
<p class="calibre_2"><sup class="calibre8"><a id="filepos562818" href="#filepos562333">7</a></sup>
<em class="calibre4">Bottom-half names are apparently a conspiracy to confuse new kernel developers. Seriously, these names are awful.</em></p><div class="calibre_3"> </div>
<p class="calibre_2">Task queues work by defining a bunch of queues. The queues have names, such as the scheduler queue, the immediate queue, or the timer queue. Each queue is run at a specific point in the kernel. A kernel thread, <em class="calibre4">keventd</em>, ran the work associated with the scheduler queue. This was the precursor to the full work queue interface. The timer queue was run at each tick of the system timer, and the immediate queue was run in a handful of different places to ensure it was run “immediately” (<em class="calibre4">hack!</em>). There were other queues, too. Additionally, you could dynamically create new queues.</p><div class="calibre_3"> </div>
<p class="calibre_2">All this might sound useful, but the reality is that the task queue interface was a mess. All the queues were essentially arbitrary abstractions, scattered about the kernel as if thrown in the air and kept where they landed. The only meaningful queue was the scheduler queue, which provided the only way to defer work to process context.</p><div class="calibre_3"> </div>
<p class="calibre_2">The other good thing about task queues was the brain-dead simple interface. Despite the myriad of queues and the arbitrary rules about when they ran, the interface was as simple as possible. But that’s about it—the rest of task queues needed to go.</p><div class="calibre_3"> </div>
<p class="calibre_2"><a id="filepos564401"></a>The various task queue users were converted to other bottom-half mechanisms. Most of them switched to tasklets. The scheduler queue users stuck around. Finally, the <code class="calibre6"><span class="calibre7">keventd</span></code> code was generalized into the excellent work queue mechanism we have today, and task queues were finally ripped out of the kernel.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos564790"> </div>
<h3 class="calibre_21"><span class="bold">Which Bottom Half Should I Use?</span></h3><div class="calibre_22"> </div>
<p class="calibre_2">The decision over which bottom half to use is important. In the current 2.6 kernel, you have three choices: softirqs, tasklets, and work queues. Tasklets are built on softirqs and, therefore, both are similar. The work queue mechanism is an entirely different creature and is built on kernel threads.</p><div class="calibre_3"> </div>
<p class="calibre_2">Softirqs, by design, provide the least serialization. This requires softirq handlers to go through extra steps to ensure that shared data is safe because two or more softirqs of the same type may run concurrently on different processors. If the code in question is already highly threaded, such as in a networking subsystem that is chest-deep in per-processor variables, softirqs make a good choice. They are certainly the fastest alternative for timing-critical and high-frequency uses.</p><div class="calibre_3"> </div>
<p class="calibre_2">Tasklets make more sense if the code is not finely threaded. They have a simpler interface and, because two tasklets of the same type might not run concurrently, they are easier to implement. Tasklets are effectively softirqs that do not run concurrently. A driver developer should always choose tasklets over softirqs, unless prepared to utilize per-processor variables or similar magic to ensure that the softirq can safely run concurrently on multiple processors.</p><div class="calibre_3"> </div>
<p class="calibre_2">If your deferred work needs to run in process context, your only choice of the three is work queues. If process context is not a requirement—specifically, if you have no need to sleep—softirqs or tasklets are perhaps better suited. Work queues involve the highest overhead because they involve kernel threads and, therefore, context switching. This is not to say that they are inefficient, but in light of thousands of interrupts hitting per second (as the networking subsystem might experience), other methods make more sense. For most situations, however, work queues are sufficient.</p><div class="calibre_3"> </div>
<p class="calibre_2">In terms of ease of use, work queues take the crown. Using the default <em class="calibre4">events</em> queue is child’s play. Next come tasklets, which also have a simple interface. Coming in last are softirqs, which need to be statically created and require careful thinking with their implementation.</p><div class="calibre_3"> </div>
<p class="calibre_2"><a href="#filepos567466">Table 8.3</a> is a comparison between the three bottom-half interfaces.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos567466"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Table 8.3. Bottom Half Comparison</span></span></p><div class="calibre_24"> </div>
<p class="calibre_23"><img alt="image" src="images/00101.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2"><a id="filepos567749"></a>In short, normal driver writers have two choices. First, do you need a schedulable entity to perform your deferred work—fundamentally, do you need to sleep for any reason? Then work queues are your only option. Otherwise, tasklets are preferred. Only if scalability becomes a concern do you investigate softirqs.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos568118"> </div>
<h3 class="calibre_21"><span class="bold">Locking Between the Bottom Halves</span></h3><div class="calibre_22"> </div>
<p class="calibre_2">We have not discussed locking yet, which is such a fun and expansive topic that we devote the next two chapters to it. Nonetheless, you need to understand that it is crucial to protect shared data from concurrent access while using bottom halves, even on a single processor machine. Remember, a bottom half can run at virtually any moment. You might want to come back to this section after reading the next two chapters if the concept of locking is foreign to you.</p><div class="calibre_3"> </div>
<p class="calibre_2">One of the benefits of tasklets is that they are serialized with respect to themselves: The same tasklet will not run concurrently, even on two different processors. This means you do not have to worry about intra-tasklet concurrency issues. Inter-tasklet concurrency (that is, when two different tasklets share the same data) requires proper locking.</p><div class="calibre_3"> </div>
<p class="calibre_2">Because softirqs provide no serialization, (even two instances of the same softirq might run simultaneously), all shared data needs an appropriate lock.</p><div class="calibre_3"> </div>
<p class="calibre_2">If process context code and a bottom half share data, you need to disable bottom-half processing and obtain a lock before accessing the data. Doing both ensures local and SMP protection and prevents a deadlock.</p><div class="calibre_3"> </div>
<p class="calibre_2">If interrupt context code and a bottom half share data, you need to disable interrupts and obtain a lock before accessing the data. This also ensures both local and SMP protection and prevents a deadlock.</p><div class="calibre_3"> </div>
<p class="calibre_2">Any shared data in a work queue requires locking, too. The locking issues are no different from normal kernel code because work queues run in process context.</p><div class="calibre_3"> </div>
<p class="calibre_2"><a href="index_split_018.html#filepos575425">Chapter 9</a>, “An Introduction to Kernel Synchronization,” provides a background on the issues surrounding concurrency, and <a href="index_split_019.html#filepos613760">Chapter 10</a> covers the kernel locking primitives. These chapters cover how to protect data that bottom halves use.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos570450"> </div>
<h3 class="calibre_21"><span class="bold">Disabling Bottom Halves</span></h3><div class="calibre_22"> </div>
<p class="calibre_2">Normally, it is not sufficient to only disable bottom halves. More often, to safely protect shared data, you need to obtain a lock <em class="calibre4">and</em> disable bottom halves. Such methods, which you might use in a driver, are covered in <a href="index_split_019.html#filepos613760">Chapter 10</a>. If you are writing core kernel code, however, you might need to disable just the bottom halves.</p><div class="calibre_3"> </div>
<p class="calibre_2">To disable all bottom-half processing (specifically, all softirqs and thus all tasklets), call <code class="calibre6"><span class="calibre7">local_bh_disable()</span></code>. To enable bottom-half processing, call <code class="calibre6"><span class="calibre7">local_bh_enable()</span></code>. Yes, the function is misnamed; no one bothered to change the name when the BH interface gave way to softirqs. <a href="#filepos571514">Table 8.4</a> is a summary of these functions.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos571463"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos571514"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Table 8.4. Bottom Half Control Methods</span></span></p><div class="calibre_24"> </div>
<p class="calibre_23"><img alt="image" src="images/00102.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">The calls can be nested—only the final call to <code class="calibre6"><span class="calibre7">local_bh_enable()</span></code> actually enables bottom halves. For example, the first time <code class="calibre6"><span class="calibre7">local_bh_disable()</span></code> is called, local softirq processing is disabled. If <code class="calibre6"><span class="calibre7">local_bh_disable()</span></code> is called three more times, local processing remains disabled. Processing is not reenabled until the fourth call to <code class="calibre6"><span class="calibre7">local_bh_enable()</span></code>.</p><div class="calibre_3"> </div>
<p class="calibre_2">The functions accomplish this by maintaining a per-task counter via the <code class="calibre6"><span class="calibre7">preempt_count</span></code> (interestingly, the same counter used by kernel preemption).<sup class="calibre8"><a id="filepos572534" href="#filepos572855">8</a></sup> When the counter reaches zero, bottom-half processing is possible. Because bottom halves were disabled, <code class="calibre6"><span class="calibre7">local_bh_enable()</span></code> also checks for any pending bottom halves and executes them.</p><div class="calibre_3"> </div>
<p class="calibre_2"><sup class="calibre8"><a id="filepos572855" href="#filepos572534">8</a></sup>
<em class="calibre4">This counter is used both by the interrupt and bottom-half subsystems. Thus, in Linux, a single per-task counter represents the atomicity of a task. This has proven useful for work such as debugging sleeping-while-atomic bugs.</em></p><div class="calibre_3"> </div>
<p class="calibre_2">The functions are unique to each supported architecture and are usually written as complicated macros in <code class="calibre6"><span class="calibre7">&lt;asm/softirq.h&gt;</span></code>. The following are close C representations for the curious:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00103.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">These calls do not disable the execution of work queues. Because work queues run in process context, there are no issues with asynchronous execution, and thus, there is no need to disable them. Because softirqs and tasklets can occur asynchronously (say, on return from handling an interrupt), however, kernel code may need to disable them. With work queues, on the other hand, protecting shared data is the same as in any process context. <a href="#filepos487358">Chapters 8</a> and <a href="index_split_018.html#filepos575425">9</a> give the details.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos574132"> </div>
<h3 class="calibre_21"><span class="bold">Conclusion</span></h3><div class="calibre_22"> </div>
<p class="calibre_2">In this chapter, we covered the three mechanisms used to defer work in the Linux kernel: softirqs, tasklets, and work queues. We went over their design and implementation. We discussed how to use them in your own code and we insulted their poorly conceived names. For historical completeness, we also looked at the bottom-half mechanisms that existed in previous versions of the Linux kernel: BH’s and task queues.</p><div class="calibre_3"> </div>
<p class="calibre_2">We talked a lot in this chapter about synchronization and concurrency because such topics apply quite a bit to bottom halves. We even wrapped up the chapter with a discussion on disabling bottom halves for reasons of concurrency protection. It is now time to dive head first into these topics. <a href="index_split_018.html#filepos575425">Chapter 9</a> discusses kernel synchronization and concurrency in the abstract, providing a foundation for understanding the issues at the heart of the problem. <a href="index_split_019.html#filepos613760">Chapter 10</a> discusses the specific interfaces provided by our beloved kernel to solve these problems. Armed with the next two chapters, the world is your oyster.</p><div class="calibre_3"> </div>  <div class="mbp_pagebreak" id="calibre_pb_48"></div>
</body></html>
