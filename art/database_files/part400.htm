<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>22.1  Overview</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part399.htm">&lt; 上一个</a><span> | </span><a href="../database.html">内容</a><span> | </span><a href="part401.htm">下一个 &gt;</a></p><p class="s65" style="padding-top: 6pt;padding-left: 72pt;text-indent: 0pt;text-align: left;">22.1  <span style=" color: #00AEEF;">Overview</span></p><p style="padding-top: 11pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">Parallel processing can be exploited in two distinct ways in a database system. One approach is <span class="s63">interquery parallelism</span>, which refers to the execution of multiple queries in parallel with each other, across multiple nodes. The second approach is <span class="s63">intraquery parallelism</span>, which refers to the processing of diﬀerent parts of the execution of a single query, in parallel across multiple nodes.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Interquery parallelism is essential for transaction processing systems. Transaction throughput can be increased by this form of parallelism. However, the response times of individual transactions are no faster than they would be if the transactions were run in isolation. Thus, the primary use of interquery parallelism is to scale up a transaction- processing system to support a larger number of transactions per second. Transaction processing systems are considered in Chapter 23.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">In contrast, intraquery parallelism is essential for speeding up long-running queries, and it is the focus of this chapter.</p><p class="s20" style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: right;">1039</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 17pt;text-align: justify;">Execution of a single query involves execution of multiple operations, such as se- lects, joins, or aggregate operations. The key to exploiting large-scale parallelism is to process each operation in parallel, across multiple nodes. Such parallelism is referred to as <span class="s63">intraoperation parallelism</span>. Since the number of tuples in a relation can be large, the degree of intraoperation parallelism is also potentially very large; thus, intraoperation parallelism is natural in a database system.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">To illustrate the parallel evaluation of a query, consider a query that requires a rela- tion to be sorted. Suppose that the relation has been partitioned across multiple disks by range partitioning on some attribute, and the sort is requested on the partitioning attribute. The sort operation can be implemented by sorting each partition in parallel, then concatenating the sorted partitions to get the ﬁnal sorted relation. Thus, we can parallelize a query by parallelizing individual operations.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">There is another source of parallelism in evaluating a query: The <i>operator tree </i>for a query can contain multiple operations. We can parallelize the evaluation of the op- erator tree by evaluating in parallel some of the operations that do not depend on one another. Further, as Chapter 15 mentions, we may be able to pipeline the output of one operation to another operation. The two operations can be executed in parallel on separate nodes, one generating output that is consumed by the other, even as it is generated. Both these forms of parallelism are examples of <span class="s63">interoperation parallelism</span>, which allows diﬀerent operators of a query to be executed in parallel.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">In summary, the execution of a single query can be parallelized in two diﬀerent ways:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s39" style="padding-left: 107pt;text-indent: -16pt;text-align: justify;">• <span class="s63">Intraoperation parallelism</span><span class="p">, which we consider in detail in the next few sections, where we study parallel implementations of common relational operations such as sort, join, aggregate and other operations.</span></p><p class="s39" style="padding-top: 4pt;padding-left: 91pt;text-indent: 0pt;text-align: justify;">• <span class="s63">Interoperation parallelism</span><span class="p">, which we consider in detail in Section 22.5.1.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The two forms of parallelism are complementary and can be used simultaneously on a query. Since the number of operations in a typical query is small, compared to the number of tuples processed by each operation, intraoperation parallelism can scale bet- ter with increasing parallelism. However, interoperation parallelism is also important, especially in shared memory systems with multiple cores.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">To simplify the presentation of the algorithms, we assume a shared nothing ar- chitecture with <i>n </i>nodes, <i>N</i><span class="s98">1</span>, <i>N</i><span class="s98">2</span>, <span class="s15">… </span>, <i>N</i><span class="s145">n</span>. Each node may have one or more disks, but typically the number of such disks is small. We do not address how to partition the data between the disks at a node; RAID organizations can be used with these disks to exploit parallelism at the storage level, rather than at the query processing level.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The choice of algorithms for parallelizing query evaluation depends on the ma- chine architecture. Rather than present algorithms for each architecture separately, we use a shared-nothing architecture in our description. Thus, we explicitly describe when data have to be transferred from one node to another.</p><p class="s66" style="padding-top: 3pt;padding-left: 119pt;text-indent: 0pt;text-align: right;"><a name="bookmark473">22.2 </a><span style=" color: #00AEEF;">Parallel Sort  </span><span class="s164">1041</span><a name="bookmark518">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">We can simulate this model easily by using the other architectures, since transfer of data can be done via shared memory in a shared-memory architecture, and via shared disks in a shared-disk architecture. Hence, algorithms for shared-nothing architectures can be used on the other architectures too. In Section 22.6, we discuss how some of the algorithms can be further optimized for shared-memory systems.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Current-generation parallel systems are typically based on a hybrid architecture, where each computer has multiple cores with a shared memory, and there are multiple computers organized in a shared-nothing fashion. For the purpose of our discussion, with such an architecture, each core can be considered a node in a shared-nothing system. Optimizations to exploit the fact that some of the cores share memory with other cores can be performed as discussed in Section 22.6.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part399.htm">&lt; 上一个</a><span> | </span><a href="../database.html">内容</a><span> | </span><a href="part401.htm">下一个 &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
