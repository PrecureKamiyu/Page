<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>22.3  Parallel Join</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part401.htm">&lt; 上一个</a><span> | </span><a href="../database.html">内容</a><span> | </span><a href="part403.htm">下一个 &gt;</a></p><p class="s65" style="padding-top: 8pt;padding-left: 72pt;text-indent: 0pt;text-align: left;">22.3  <span style=" color: #00AEEF;">Parallel Join</span></p><p style="padding-top: 12pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">Parallel join algorithms attempt to divide the tuples of the input relations over several nodes. Each node then computes part of the join locally. Then, the system collects the results from each node to produce the ﬁnal result. How exactly to divide the tuples depends on the join algorithm, as we see next.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 119pt;text-indent: 0pt;text-align: left;">22.3.1 Partitioned Join</p><p class="s169" style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;"><span class="p">For certain kinds of joins, it is possible to </span><span class="s13">partition </span><span class="p">the two input relations across the nodes and to compute the join locally at each node. The partitioned join technique can be used for inner joins, where the join condition is an equi-join (e.g., </span><span class="s13">r </span><span class="s86">⋈</span>r<span class="s170">.</span>A<span class="s171">=</span>s<span class="s170">.</span>B <span class="s168">s</span><span class="p">);</span></p><p style="padding-left: 119pt;text-indent: 0pt;line-height: 7pt;text-align: justify;">the relations <i>r </i>and <i>s </i>are partitioned by the same partitioning function on their join</p><p style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">attributes. The idea of partitioning is exactly the same as that behind the partitioning step of hash join. Partitioned join can also be used for outer joins, as we shall see shortly.</p><p class="s13" style="padding-left: 119pt;text-indent: 17pt;text-align: justify;"><span class="p">Suppose that we are using </span>m <span class="p">nodes to perform the join, and that the relations to be joined are </span>r <span class="p">and </span>s<span class="p">. </span><span class="s63">Partitioned join </span><span class="p">then works this way: The system partitions the relations </span>r <span class="p">and </span>s <span class="p">each into </span>m <span class="p">partitions, denoted </span>r<span class="s93">1</span><span class="s94">, </span>r<span class="s93">2</span><span class="s94">, </span><span class="s15">… </span><span class="p">, </span>r<span class="s145">m </span><span class="p">and </span>s<span class="s93">1</span><span class="s94">, </span>s<span class="s93">2</span><span class="s94">, </span><span class="s15">… </span><span class="p">, </span>s<span class="s145">m</span><span class="p">. In a partitioned join, however, there are two diﬀerent ways of partitioning </span>r <span class="p">and </span>s<span class="p">:</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s39" style="padding-top: 4pt;padding-left: 91pt;text-indent: 0pt;text-align: left;">• <span class="s40">Range partitioning on the join attributes.</span></p><p class="s39" style="padding-top: 3pt;padding-left: 91pt;text-indent: 0pt;text-align: left;">• <span class="s40">Hash partitioning on the join attributes.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 88pt;text-indent: 0pt;text-align: justify;">In either case, the same partitioning function must be used for both relations. For range partitioning, the same partition vector must be used for both relations. For hash partitioning, the same hash function must be used on both relations. Figure 22.2 depicts the partitioning in a partitioned parallel join.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The partitioned join algorithm ﬁrst partitions one of the relations by scanning its tuples and sending them to the appropriate node based on the partition function and the join attribute values of each tuple. Speciﬁcally, each node <i>N</i><span class="s97">i </span>reads in the tuples of</p><p style="padding-left: 88pt;text-indent: 0pt;line-height: 79%;text-align: justify;">one of the relations, say <i>r</i>, from local disk, computes for each tuple <i>t </i>the partition <i>r</i><span class="s97">j</span></p><p style="padding-left: 88pt;text-indent: 0pt;line-height: 94%;text-align: justify;">to which <i>t </i>belongs, and sends the tuple <i>t </i>to node <i>N</i><span class="s97">j </span>. Each node also simultaneously receives tuples that are sent to it and stores them on its local disk (this can be done by having separate threads for sending and receiving data). The process is repeated for all</p><p style="padding-left: 88pt;text-indent: 0pt;text-align: justify;">tuples from the other relation, <i>s</i>.</p><p style="padding-left: 88pt;text-indent: 17pt;line-height: 94%;text-align: justify;">Once both relations are partitioned, we can use any join technique locally at each node <i>N</i><span class="s97">i </span>to compute the join of <i>r</i><span class="s97">i </span>and <i>s</i><span class="s97">i</span>. Thus, we can use partitioning to parallelize any join technique.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Partitioned join can be used not only for inner joins, but also for all three forms of outer join (left, right and full outer join). Each node computes the corresponding outer join locally, after partitioning is done on the join attributes. Further, since natural join can be expressed as an equijoin followed by a projection, natural joins can also be computed using partitioned join.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">If one or both of the relations <i>r </i>and <i>s </i>are already partitioned on the join attributes (by either hash partitioning or range partitioning), the work needed for partitioning is reduced greatly. If the relations are not partitioned or are partitioned on attributes other than the join attributes, then the tuples need to be repartitioned.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="10" height="7" alt="image" src="Image_3182.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="10" height="7" alt="image" src="Image_3183.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="240" height="131" alt="image" src="Image_3184.png"/></span></p><p class="s109" style="text-indent: 0pt;line-height: 10pt;text-align: left;">r<span class="s476">1</span>΄</p><p style="text-indent: 0pt;text-align: left;"/><p class="s109" style="text-indent: 0pt;line-height: 10pt;text-align: left;">s<span class="s476">1</span>΄</p><p style="text-indent: 0pt;text-align: left;"/><p class="s109" style="text-indent: 0pt;line-height: 10pt;text-align: left;">r<span class="s476">2</span>΄</p><p style="text-indent: 0pt;text-align: left;"/><p class="s109" style="text-indent: 0pt;line-height: 93%;text-align: left;">s΄<span class="s476">2</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s109" style="text-indent: 0pt;line-height: 10pt;text-align: left;">r΄<span class="s476">3</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s109" style="text-indent: 0pt;line-height: 9pt;text-align: left;">s΄<span class="s479">3</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s109" style="text-indent: 0pt;line-height: 10pt;text-align: left;">r<span class="s476">m</span>΄</p><p style="text-indent: 0pt;text-align: left;"/><p class="s109" style="text-indent: 0pt;line-height: 10pt;text-align: left;">s<span class="s476">m</span>΄</p><p style="text-indent: 0pt;text-align: left;"/><p class="s109" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">s <span class="s476">n</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s109" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">r<span class="s479">n</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s109" style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">s <span class="s476">3</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s109" style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">r<span class="s476">3</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s109" style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">s <span class="s476">2</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s109" style="padding-top: 1pt;padding-left: 4pt;text-indent: 0pt;text-align: center;">r<span class="s477">2</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s109" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">s <span class="s476">1</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s109" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">r<span class="s476">1</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s469" style="padding-top: 4pt;padding-left: 194pt;text-indent: 0pt;text-align: left;">Step 1: Partition <span class="s200">r  </span>Step 2: Partition <span class="s200">s</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="10" height="7" alt="image" src="Image_3185.png"/></span></p><p class="s469" style="padding-top: 5pt;padding-left: 193pt;text-indent: 0pt;text-align: left;">Step 3: Each node N<span class="s480">i </span>computes <span class="s200">r</span><span class="s481">΄</span><span class="s171">i  </span><span class="s200">s</span><span class="s481">΄</span><span class="s171">i</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s73" style="padding-top: 4pt;padding-left: 59pt;text-indent: 0pt;text-align: center;">Figure 22.2 <span class="s74">Partitioned parallel join.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 119pt;text-indent: 17pt;text-align: justify;">We now consider issues speciﬁc to the join technique used locally at each node <i>N</i><span class="s145">i</span>. The local join operation can be optimized by performing some initial steps on tuples as they arrive at a node, instead of ﬁrst storing the tuples to disk and then reading them back to perform these initial steps. These optimizations, which we describe be-</p><p style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">low, are also used in nonparallel query processing, when results of an earlier operation are pipelined into a subsequent operation; thus, they are not speciﬁc to parallel query processing.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s39" style="padding-left: 139pt;text-indent: -16pt;text-align: justify;">• <span class="s40">If we use hash join locally, the resultant parallel join technique is called </span><span class="s63">partitioned parallel hash join</span><span class="p">.</span></p><p style="padding-left: 139pt;text-indent: 15pt;text-align: justify;">Recall that hash join ﬁrst partitions both input relations into smaller pieces such that each partition of the smaller relation (the build relation) ﬁts into mem- ory. Thus, to implement hash join, the partitions <i>r</i><span class="s145">i </span>and <i>s</i><span class="s145">i </span>received by node <i>N</i><span class="s145">i </span>must be repartitioned using a hash function, say <i>h</i>1(). If the partitioning of <i>r </i>and <i>s</i></p><p style="padding-top: 1pt;padding-left: 139pt;text-indent: 0pt;line-height: 93%;text-align: justify;">across the nodes was done by using a hash function <i>h</i>0(), the system must ensure that <i>h</i>1() is diﬀerent from <i>h</i>0(). Let the resultant partitions at node <i>N</i><span class="s97">i </span>be <i>r</i><span class="s97">i</span><span class="s130">,</span><span class="s149">j </span>and <i>s</i><span class="s97">i</span><span class="s130">,</span><span class="s149">j </span>for <i>j </i><span class="s15">= </span>1 <span class="s15">… </span><i>n</i><span class="s97">i</span>, where <i>n</i><span class="s97">i </span>denotes the number of local partitions at node <i>N</i><span class="s97">i</span>.</p><p style="padding-left: 154pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">Note that the tuples can be repartitioned based on the hash function used for</p><p style="padding-left: 139pt;text-indent: 0pt;text-align: justify;">the local hash join as they arrive and written out to the appropriate partitions, avoiding the need to write the tuples to disk and read them back in.</p><p style="padding-left: 139pt;text-indent: 15pt;text-align: justify;">Recall also that hash join then loads each partition of the build relation into memory, builds an in-memory index on the join attributes, and ﬁnally probes the in-memory index using each tuple of the other relation, called the probe relation. Assume that relation <i>s </i>is chosen as the build relation. Then each partition <i>s</i><span class="s97">i</span><span class="s130">,</span><span class="s149">j </span>is</p><p style="padding-left: 139pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">loaded in memory, with an index built on the join attributes, and the index is</p><p style="padding-left: 139pt;text-indent: 0pt;line-height: 14pt;text-align: justify;">probed with each tuple of <i>r</i><span class="s145">i</span><span class="s93">,</span><span class="s169">j </span>.</p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 12pt;text-align: justify;">Hybrid hash join (described in Section 15.5.5.5) can be used in case the parti-</p><p style="padding-left: 139pt;text-indent: 0pt;text-align: justify;">tions of one of the relations are small enough that a signiﬁcant part of the partition ﬁts in memory at each node. In this case, the smaller relation, say <i>s</i>, which is used as the build relation, should be partitioned ﬁrst, followed by the larger relation, say <i>r</i>, which is used as the probe relation. Recall that with hybrid hash join, the tuples in the partition <i>s</i><span class="s98">0</span> of the build relation <i>s </i>are retained in memory, and an in-memory index is built on these tuples. When the probe relation tuples arrive at the node, they are also repartitioned; tuples in the <i>r</i><span class="s98">0</span> partition are used directly to probe the index on the <i>s</i><span class="s98">0</span> tuples, instead of being written out to disk and read back in.</p><p style="padding-top: 4pt;padding-left: 139pt;text-indent: -16pt;line-height: 94%;text-align: justify;"><span class="s39">• </span><span class="s40">If we use merge join locally, the resultant technique is called </span><span class="s63">partitioned parallel merge join</span>. Each of the partitions <i>s</i><span class="s145">i </span>and <i>r</i><span class="s145">i </span>must be sorted, and merged locally, at node <i>N</i><span class="s145">i</span>.</p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">The ﬁrst step of sorting, namely, run generation, can directly consume incom-</p><p style="padding-left: 139pt;text-indent: 0pt;text-align: justify;">ing tuples to generate runs, avoiding a write to disk before run generation.</p><p class="s63" style="padding-top: 4pt;padding-left: 139pt;text-indent: -16pt;text-align: justify;"><span class="s39">• </span><span class="s40">If we use nested-loops or indexed nested-loops join locally, the resultant technique is called </span>partitioned parallel nested-loop join <span class="p">or </span>partitioned parallel indexed nested-</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 5pt;padding-left: 107pt;text-indent: 0pt;line-height: 90%;text-align: left;"><span class="s63">loops join</span>. Each node <i>N</i><span class="s145">i </span>performs a nested-loops (or indexed nested-loops) join on <i>s</i><span class="s145">i </span>and <i>r</i><span class="s145">i</span>.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 88pt;text-indent: 0pt;text-align: left;">22.3.2 Fragment-and-Replicate Join</p><p class="s149" style="padding-top: 7pt;padding-left: 88pt;text-indent: 0pt;line-height: 90%;text-align: left;"><span class="p">Partitioning is not applicable to all types of joins. For instance, if the join condition is an inequality, such as </span><span class="s13">r </span><span class="s86">⋈</span>r<span class="s167">.</span>a<span class="s167">&lt;</span>s<span class="s167">.</span>b <span class="s168">s</span><span class="p">, it is possible that all tuples in </span><span class="s13">r </span><span class="p">join with some tuple</span></p><p style="padding-left: 88pt;text-indent: 0pt;line-height: 7pt;text-align: left;">in <i>s </i>(and vice versa). Thus, there may be no nontrivial way of partitioning <i>r </i>and <i>s </i>so</p><p style="padding-left: 88pt;text-indent: 0pt;line-height: 14pt;text-align: left;">that tuples in partition <i>r</i><span class="s97">i </span>join with only tuples in partition <i>s</i><span class="s97">i</span>.</p><p style="padding-left: 106pt;text-indent: 0pt;line-height: 12pt;text-align: left;">We can parallelize such joins by using a technique called <i>fragment-and-replicate</i>.</p><p style="padding-left: 88pt;text-indent: 0pt;text-align: left;">We ﬁrst consider a special case of fragment-and-replicate— <span class="s63">asymmetric fragment-and- replicate join </span>— which works as follows:</p><p style="padding-top: 4pt;padding-left: 113pt;text-indent: -16pt;text-align: left;"><span class="s63">1. </span>The system partitions one of the relations— say, <i>r</i>. Any partitioning technique can be used on <i>r</i>, including round-robin partitioning.</p><p style="padding-top: 6pt;padding-left: 96pt;text-indent: 0pt;text-align: left;"><span class="s63">2. </span>The system replicates the other relation, <i>s</i>, across all the nodes.</p><p style="padding-top: 6pt;padding-left: 96pt;text-indent: 0pt;text-align: left;"><span class="s63">3. </span>Node <i>N</i><span class="s97">i </span>then locally computes the join of <i>r</i><span class="s97">i </span>with all of <i>s</i>, using any join technique.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 88pt;text-indent: 0pt;text-align: justify;">The asymmetric fragment-and-replicate scheme appears in Figure 22.3a. If <i>r </i>is already stored by partitioning, there is no need to partition it further in step 1. All that is required is to replicate <i>s </i>across all nodes.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The asymmetric fragment-and-replicate join technique is also referred to as <span class="s63">broad- cast join</span>. It is a very useful technique, even for equi-joins, if one of the relations, say <i>s</i>, is small, and the other relation, say <i>r</i>, is large, since replicating the small relation <i>s </i>across all nodes may be cheaper than repartitioning the large relation <i>r</i>.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The general case of <span class="s63">fragment-and-replicate join </span>(also called the <span class="s63">symmetric fragment- and-replicate join </span>appears in Figure 22.3b; it works this way: The system partitions relation <i>r </i>into <i>n </i>partitions, <i>r</i><span class="s130">1</span><span class="s94">, </span><i>r</i><span class="s130">2</span><span class="s94">, </span><span class="s15">… </span>, <i>r</i><span class="s97">n</span>, and partitions <i>s </i>into <i>m </i>partitions, <i>s</i><span class="s130">1</span><span class="s94">, </span><i>s</i><span class="s130">2</span><span class="s94">, </span><span class="s15">… </span>, <i>s</i><span class="s97">m</span>.</p><p style="padding-left: 88pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">As before, any partitioning technique may be used on <i>r </i>and on <i>s</i>. The values of <i>m </i>and</p><p class="s13" style="padding-left: 88pt;text-indent: 0pt;text-align: justify;">n <span class="p">do not need to be equal, but they must be chosen so that there are at least </span>m <span class="s15">∗ </span>n <span class="p">nodes. Asymmetric fragment-and-replicate is simply a special case of general fragment- and-replicate, where </span>m <span class="s15">= </span><span class="p">1. Fragment-and-replicate reduces the sizes of the relations at each node, compared to asymmetric fragment-and-replicate.</span></p><p class="s13" style="padding-left: 88pt;text-indent: 17pt;line-height: 87%;text-align: justify;"><span class="p">Let the nodes be </span>N<span class="s93">1,1</span><span class="s94">, </span>N<span class="s93">1,2</span><span class="s94">, </span><span class="s15">… </span><span class="p">, </span>N<span class="s93">1,</span><span class="s169">m</span><span class="p">, </span>N<span class="s93">2,1</span><span class="s94">, </span><span class="s15">… </span><span class="p">, </span>N<span class="s145">n</span><span class="s93">,</span><span class="s169">m</span><span class="p">. Node </span>N<span class="s145">i</span><span class="s93">,</span><span class="s169">j </span><span class="p">computes the join of </span>r<span class="s97">i </span><span class="p">with </span>s<span class="s97">j </span><span class="p">. To ensure that each node </span>N<span class="s97">i</span><span class="s130">,</span><span class="s149">j </span><span class="p">gets all tuples of </span>r<span class="s97">i </span><span class="p">and </span>s<span class="s97">j </span><span class="p">, the system replicates </span>r<span class="s97">i </span><span class="p">to nodes </span>N<span class="s97">i</span><span class="s130">,1</span><span class="s94">, </span>N<span class="s97">i</span><span class="s130">,2</span><span class="s94">, </span><span class="s15">… </span><span class="p">, </span>N<span class="s97">i</span><span class="s130">,</span><span class="s149">m </span><span class="p">(which form a row in Figure 22.3b), and replicates </span>s<span class="s97">i </span><span class="p">to nodes </span>N<span class="s130">1,</span><span class="s149">i</span><span class="p">, </span>N<span class="s130">2,</span><span class="s149">i</span><span class="p">, </span><span class="s15">… </span><span class="p">, </span>N<span class="s97">n</span><span class="s130">,</span><span class="s149">i </span><span class="p">(which form a column in Figure 22.3b). Any join technique can be used at each node </span>N<span class="s97">i</span><span class="s130">,</span><span class="s149">j </span><span class="p">.</span></p><p style="padding-left: 106pt;text-indent: 0pt;line-height: 10pt;text-align: justify;">Fragment-and-replicate works with any join condition, since every tuple in <i>r </i>can</p><p style="padding-left: 88pt;text-indent: 0pt;text-align: justify;">be tested with every tuple in <i>s</i>. Thus, it can be used where partitioning cannot be used. However, note that each tuple in <i>r </i>is replicated <i>m </i>times, and each tuple in <i>s </i>is replicated <i>n </i>times.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s200" style="text-indent: 0pt;text-align: right;">s</p><p style="text-indent: 0pt;text-align: left;"><span><img width="202" height="154" alt="image" src="Image_3186.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="19" alt="image" src="Image_3187.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="19" alt="image" src="Image_3188.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="19" alt="image" src="Image_3189.png"/></span></p><p class="s482" style="text-indent: 0pt;line-height: 12pt;text-align: left;">N<span class="s483">1,1   </span>N<span class="s483">1,2   </span>N<span class="s483">1,3   </span>N<span class="s483">1,4</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s482" style="text-indent: 0pt;line-height: 12pt;text-align: left;">N<span class="s483">2,1  </span>N<span class="s483">2,2  </span>N<span class="s483">2,3</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s482" style="text-indent: 0pt;line-height: 12pt;text-align: left;">N<span class="s483">3,1  </span>N<span class="s483">3,2</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s200" style="padding-top: 6pt;padding-left: 2pt;text-indent: 0pt;text-align: left;">r<span class="s484">3</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s200" style="padding-top: 6pt;padding-left: 2pt;text-indent: 0pt;text-align: left;">r<span class="s484">2</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s200" style="padding-top: 6pt;padding-left: 2pt;text-indent: 0pt;text-align: left;">r<span class="s484">1</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s200" style="padding-left: 8pt;text-indent: 0pt;line-height: 88%;text-align: center;">s<span class="s484">4</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s200" style="padding-left: 8pt;text-indent: 0pt;line-height: 88%;text-align: center;">s<span class="s484">3</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s200" style="padding-left: 8pt;text-indent: 0pt;line-height: 88%;text-align: center;">s<span class="s484">2</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s200" style="padding-left: 8pt;text-indent: 0pt;line-height: 88%;text-align: center;">s<span class="s484">1</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s200" style="padding-top: 6pt;padding-left: 2pt;text-indent: 0pt;text-align: left;">r<span class="s484">4</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s200" style="padding-left: 8pt;text-indent: 0pt;line-height: 88%;text-align: center;">s<span class="s485">m</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s469" style="padding-top: 3pt;padding-left: 119pt;text-indent: 0pt;text-align: right;">. . .</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="99" height="156" alt="image" src="Image_3190.png"/></span></p><p class="s200" style="text-indent: 0pt;line-height: 12pt;text-align: left;">N<span class="s484">1</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s200" style="text-indent: 0pt;line-height: 12pt;text-align: left;">N<span class="s484">2</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s200" style="text-indent: 0pt;line-height: 12pt;text-align: left;">N<span class="s484">3</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s200" style="text-indent: 0pt;line-height: 12pt;text-align: left;">N<span class="s484">4</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s200" style="padding-top: 7pt;padding-left: 2pt;text-indent: 0pt;text-align: left;">r<span class="s484">3</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s200" style="padding-top: 9pt;padding-left: 2pt;text-indent: 0pt;text-align: left;">r<span class="s484">2</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s200" style="padding-top: 7pt;padding-left: 2pt;text-indent: 0pt;text-align: left;">r<span class="s484">2</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s200" style="padding-top: 7pt;padding-left: 2pt;text-indent: 0pt;text-align: left;">r<span class="s484">1</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s469" style="text-indent: 0pt;text-align: right;">.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s469" style="padding-left: 449pt;text-indent: 0pt;text-align: left;">.</p><p class="s200" style="padding-top: 3pt;padding-left: 145pt;text-indent: 0pt;text-align: left;">r           s</p><p class="s486" style="padding-top: 8pt;padding-left: 249pt;text-indent: 0pt;text-align: left;">r                          <span class="s469">.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s469" style="padding-top: 7pt;padding-left: 449pt;text-indent: 0pt;text-align: left;">.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s469" style="text-indent: 0pt;line-height: 9pt;text-align: left;">.</p><p style="text-indent: 0pt;text-align: left;"/><p class="s469" style="padding-left: 161pt;text-indent: 0pt;line-height: 10pt;text-align: left;">.    .         <span class="s487">.</span></p><p class="s469" style="text-indent: 0pt;line-height: 9pt;text-align: left;">.</p><p style="text-indent: 0pt;text-align: left;"/><p class="s469" style="text-indent: 0pt;line-height: 9pt;text-align: left;">.</p><p style="text-indent: 0pt;text-align: left;"/><p class="s469" style="padding-left: 161pt;text-indent: 0pt;line-height: 6pt;text-align: left;">.   .</p><p class="s469" style="padding-left: 161pt;text-indent: 0pt;line-height: 8pt;text-align: left;">.   .</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s469" style="padding-left: 149pt;text-indent: 0pt;text-align: left;">(a) Asymmetric fragment and replicate</p><p class="s469" style="padding-top: 3pt;padding-left: 66pt;text-indent: 0pt;text-align: left;">.    .    .    .    .</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="17" height="39" alt="image" src="Image_3191.png"/></span></p><p class="s200" style="padding-left: 29pt;text-indent: 0pt;text-align: left;">r<span class="s485">n</span></p><p class="s469" style="padding-top: 3pt;padding-left: 75pt;text-indent: 0pt;text-align: left;">(b) Fragment and replicate</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 3pt;text-indent: 0pt;text-align: left;"><span><img width="34" height="24" alt="image" src="Image_3192.png"/></span></p><p class="s482" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">N<span class="s488">n</span><span class="s483">,</span><span class="s173">m</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s73" style="padding-top: 4pt;padding-left: 203pt;text-indent: 0pt;text-align: left;">Figure 22.3 <span class="s74">Fragment-and-replicate schemes.</span></p><p style="padding-top: 9pt;padding-left: 119pt;text-indent: 17pt;text-align: justify;">Fragment-and-replicate join has a higher cost than partitioning, since it involves replication of both relations, and is therefore used only if the join does not involve equi-join conditions. Asymmetric fragment-and-replicate, on the other hand, is useful even for equi-join conditions, if one of the relations is small, as discussed earlier.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Note that asymmetric fragment-and-replicate join can be used to compute the left outer join operation <i>r </i><span class="s15">⟕</span><span class="s137">θ</span><span class="s15"> </span><i>s </i>if <i>s </i>is replicated, by simply computing the left outer join locally at each node. There is no restriction on the join condition <span class="s15">θ</span>.</p><p class="s13" style="padding-left: 119pt;text-indent: 17pt;text-align: justify;"><span class="p">However, </span>r <span class="s15">⟕</span><span class="s137">θ</span><span class="s15"> </span>s <span class="p">cannot be computed locally if </span>s <span class="p">is fragmented and </span>r <span class="p">is replicated, since an </span>r <span class="p">tuple may have no matching tuple in partition </span>s<span class="s97">i</span><span class="p">, but may have a matching</span></p><p class="s13" style="padding-left: 119pt;text-indent: 0pt;line-height: 12pt;text-align: justify;"><span class="p">tuple in partition </span>s<span class="s97">j </span><span class="p">, </span>j <span class="s86">≠ </span>i<span class="p">. Thus, a decision on whether or not to output the </span>r <span class="p">tuple with</span></p><p style="padding-left: 119pt;text-indent: 0pt;line-height: 87%;text-align: justify;">null values for <i>s </i>attributes cannot be made locally at node <i>N</i><span class="s97">i</span>. For the same reason, asymmetric fragment-and-replicate cannot be used to compute the full outer join op-</p><p style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">eration, and symmetric fragment-and-replicate cannot be used to compute any of the outer join operations.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 119pt;text-indent: 0pt;text-align: left;">22.3.3 Handling Skew in Parallel Joins</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">Skew presents a special problem for parallel join techniques. If one of the nodes has a much heavier load than other nodes, the parallel join operation will take much longer to ﬁnish, with many idle nodes waiting for the heavily loaded node to ﬁnish its task.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 17pt;text-align: justify;"><a name="bookmark475">When partitioning data for storage, to minimize skew in storage we use a balanced partitioning vector that ensures all nodes get the same number of tuples. For parallel joins, we need to instead balance the execution time of join operations across all nodes. Hash partitioning using any good hash function usually works quite well at balancing the load across nodes, unless some join attribute values occur very frequently. Range partitioning, on the other hand, is more vulnerable to join skew, unless the ranges are carefully chosen to balance the load.</a><span class="s76">1</span><a name="bookmark520">&zwnj;</a></p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Virtual-node partitioning with, say, round-robin distribution of virtual nodes to real nodes, can help in reducing skew at the level of real nodes even if there is skew at the level of virtual nodes, since the skewed virtual nodes tend to get spread over multiple real nodes.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The preceding techniques are examples of <span class="s63">join skew avoidance</span>. Virtual-node parti- tioning, in particular, is very eﬀective at skew avoidance in most cases.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">However, there are cases with high skew, for example where some join attribute values are very frequent in both input relations, leading to a large join result size. In such cases, there could be signiﬁcant join skew, even with virtual-node partitioning.</p><p class="s63" style="padding-left: 88pt;text-indent: 17pt;text-align: right;">Dynamic handling of join skew <span class="p">is an alternative to skew avoidance. A dynamic ap- proach can be used to detect and handle skew in such situations. Virtual node partition- ing is used, and the system then monitors the join progress at each real node. Each real node schedules one virtual node at a time. Suppose that some real node has completed join processing for all virtual nodes assigned to it, and is thus idle, while some other real node has multiple virtual nodes waiting to be processed. Then, the idle node can get a copy of the data corresponding to one of the virtual nodes at the busy node and process the join for that virtual node. This process can be repeated whenever there is an idle real node, as long as some real node has virtual nodes waiting to be processed. This technique is an example of </span>work stealing<span class="p">, where a processor that is idle takes work that is in the queue of another processor that is busy. Work stealing is inexpensive in a shared-memory system, since all data can be accessed quickly from the shared memory, as discussed further in Section 22.6. In a shared-nothing environment, data movement may be required to move a task from one processor to another, but it is often</span></p><p style="padding-left: 88pt;text-indent: 0pt;text-align: left;">worth paying the overhead to reduce the completion time of a task.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part401.htm">&lt; 上一个</a><span> | </span><a href="../database.html">内容</a><span> | </span><a href="part403.htm">下一个 &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
