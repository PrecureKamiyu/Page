<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>7.6 Round Robin</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part70.htm">&lt; 上一个</a><span> | </span><a href="../ostep.html">内容</a><span> | </span><a href="part72.htm">下一个 &gt;</a></p><p class="s40" style="padding-left: 16pt;text-indent: 0pt;text-align: left;">7.6 Round Robin</p><p style="padding-top: 7pt;padding-left: 41pt;text-indent: 11pt;line-height: 89%;text-align: left;">To solve this problem, we will introduce a new scheduling algorithm. This approach is classically known as <b>Round-Robin (RR) </b>scheduling [K64]. The basic idea is simple: instead of running jobs to completion, RR runs a job for a <b>time slice </b>(sometimes called a <b>scheduling quantum</b>) and then switches to the next job in the run queue. It repeatedly does so un- til the jobs are finished. For this reason, RR is sometimes called <b>time- slicing</b>. Note that the length of a time slice must be a multiple of the timer-interrupt period; thus if the timer interrupts every 10 milliseconds, the time slice could be 10, 20, or any other multiple of 10 ms.</p><p style="padding-left: 41pt;text-indent: 11pt;line-height: 89%;text-align: justify;">To understand RR in more detail, let’s look at an example. Assume three jobs A, B, and C arrive at the same time in the system, and that they each wish to run for 5 seconds. An SJF scheduler runs each job to completion before running another (Figure <span style=" color: #00AEEF;">7.6</span>). In contrast, RR with a time-slice of 1 second would cycle through the jobs quickly (Figure <span style=" color: #00AEEF;">7.7</span>).</p><p class="s62" style="text-indent: 0pt;line-height: 6pt;text-align: left;">3</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 52pt;text-indent: 0pt;text-align: left;">The average response time of RR is: <span class="s63">0+1+2</span></p><p class="s44" style="padding-left: 3pt;text-indent: 0pt;text-align: left;">= 1<span class="p">; for SJF, average re-</span></p><p class="s62" style="text-indent: 0pt;line-height: 6pt;text-align: left;">3</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 41pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">sponse time is: <span class="s63">0+5+10</span><span class="s64"> </span><span class="s44">= 5</span>.</p><p style="padding-left: 41pt;text-indent: 11pt;line-height: 89%;text-align: justify;">As you can see, the length of the time slice is critical for RR. The shorter it is, the better the performance of RR under the response-time metric. However, making the time slice too short is problematic: suddenly the cost of context switching will dominate overall performance. Thus, de- ciding on the length of the time slice presents a trade-off to a system de- signer, making it long enough to <b>amortize </b>the cost of switching without making it so long that the system is no longer responsive.</p><p style="padding-left: 41pt;text-indent: 11pt;line-height: 89%;text-align: justify;">Note that the cost of context switching does not arise solely from the OS actions of saving and restoring a few registers. When programs run,</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 6pt;padding-left: 68pt;text-indent: 0pt;line-height: 11pt;text-align: left;">T<span class="s7">IP</span>: A<span class="s7">MORTIZATION </span>C<span class="s7">AN </span>R<span class="s7">EDUCE </span>C<span class="s7">OSTS</span></p><p style="padding-left: 8pt;text-indent: 0pt;line-height: 89%;text-align: justify;">The general technique of <b>amortization </b>is commonly used in systems when there is a fixed cost to some operation. By incurring that cost less often (i.e., by performing the operation fewer times), the total cost to the system is reduced. For example, if the time slice is set to 10 ms, and the context-switch cost is 1 ms, roughly 10% of time is spent context switch- ing and is thus wasted. If we want to <i>amortize </i>this cost, we can increase the time slice, e.g., to 100 ms. In this case, less than 1% of time is spent context switching, and thus the cost of time-slicing has been amortized.</p><p style="padding-left: 60pt;text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 68pt;text-indent: 0pt;line-height: 89%;text-align: justify;">they build up a great deal of state in CPU caches, TLBs, branch predictors, and other on-chip hardware. Switching to another job causes this state to be flushed and new state relevant to the currently-running job to be brought in, which may exact a noticeable performance cost [MB91].</p><p style="padding-left: 68pt;text-indent: 12pt;line-height: 89%;text-align: justify;">RR, with a reasonable time slice, is thus an excellent scheduler if re- sponse time is our only metric. But what about our old friend turnaround time? Let’s look at our example above again. A, B, and C, each with run- ning times of 5 seconds, arrive at the same time, and RR is the scheduler with a (long) 1-second time slice. We can see from the picture above that A finishes at 13, B at 14, and C at 15, for an average of 14. Pretty awful!</p><p style="padding-left: 68pt;text-indent: 12pt;line-height: 89%;text-align: justify;">It is not surprising, then, that RR is indeed one of the <i>worst </i>policies if turnaround time is our metric. Intuitively, this should make sense: what RR is doing is stretching out each job as long as it can, by only running each job for a short bit before moving to the next. Because turnaround time only cares about when jobs finish, RR is nearly pessimal, even worse than simple FIFO in many cases.</p><p style="padding-left: 68pt;text-indent: 12pt;line-height: 89%;text-align: justify;">More generally, any policy (such as RR) that is <b>fair</b>, i.e., that evenly di- vides the CPU among active processes on a small time scale, will perform poorly on metrics such as turnaround time. Indeed, this is an inherent trade-off: if you are willing to be unfair, you can run shorter jobs to com- pletion, but at the cost of response time; if you instead value fairness, response time is lowered, but at the cost of turnaround time. This type of <b>trade-off </b>is common in systems; you can’t have your cake and eat it too.</p><p style="padding-left: 68pt;text-indent: 12pt;line-height: 89%;text-align: justify;">We have developed two types of schedulers. The first type (SJF, STCF) optimizes turnaround time, but is bad for response time. The second type (RR) optimizes response time but is bad for turnaround. And we still have two assumptions which need to be relaxed: assumption 3 (that jobs do no I/O), and assumption 4 (that the run-time of each job is known). Let’s tackle those assumptions next.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part70.htm">&lt; 上一个</a><span> | </span><a href="../ostep.html">内容</a><span> | </span><a href="part72.htm">下一个 &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
