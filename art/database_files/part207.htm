<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>10.5  Streaming Data</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part206.htm">&lt; 上一个</a><span> | </span><a href="../database.html">内容</a><span> | </span><a href="part208.htm">下一个 &gt;</a></p><p class="s65" style="padding-top: 9pt;padding-left: 40pt;text-indent: 0pt;text-align: left;">10.5  <span style=" color: #00AEEF;">Streaming Data</span></p><p style="padding-top: 12pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">Querying of data can be done in an ad hoc manner— for example, whenever an analyst wants to extract some information from a database. It can also be done in a periodic manner— for example, queries may be executed at the beginning of each day to get a summary of transactions that happened on the previous day.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">However, there are many applications where queries need to be executed contin- uously, on data that arrive in a continuous fashion. The term <span class="s63">streaming data </span>refers to data that arrive in a continuous fashion. Many application domains need to process incoming data in real time (i.e., as they arrive, with delays, if any, guaranteed to be less than some bound).</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 88pt;text-indent: 0pt;text-align: left;">10.5.1 Applications of Streaming Data</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">Here are a few examples of streaming data, and the real-time needs of applications that use the data.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s39" style="padding-top: 4pt;padding-left: 139pt;text-indent: -16pt;text-align: justify;">• <span class="s46">Stock market</span><span class="p">: In a stock market, each trade that is made (i.e., a stock is sold by someone and bought by someone else) is represented by a tuple. Trades are sent as a stream to processing systems.</span></p><p style="padding-left: 139pt;text-indent: 15pt;text-align: justify;">Stock market traders analyze the stream of trades to look for patterns, and they make buy or sell decisions based on the patterns that they observe. Real-time requirements in such systems used to be of the order of seconds in earlier days, but many of today’s systems require delays to be of the order of tens of microseconds (usually to be able to react before others do, to the same patterns).</p><p style="padding-left: 139pt;text-indent: 14pt;text-align: justify;">Stock market regulators may use the same stream, but for a diﬀerent purpose: to see if there are patterns of trades that are indicative of illegal activities. In both cases, there is a need for continuous queries that look for patterns; the results of the queries are used to carry out further actions.</p><p class="s39" style="padding-top: 3pt;padding-left: 139pt;text-indent: -16pt;text-align: justify;">• <span class="s46">E-commerce</span><span class="p">: In an e-commerce site, each purchase made is represented as a tuple, and the sequence of all purchases forms a stream. Further, even the searches exe- cuted by a customer are of value to the e-commerce site, even if no actual purchase is made; thus, the searches executed by users form a stream.</span></p><p style="padding-left: 139pt;text-indent: 14pt;text-align: justify;">These streams can be used for multiple purposes. For example, if an advertising campaign is launched, the e-commerce site may wish to monitor in real time how the campaign is aﬀecting searches and purchases. The e-commerce site may also wish to detect any spikes in sales of speciﬁc products to which it may need to respond by ordering more of that product. Similarly, the site may wish to monitor users for patterns of activities such as frequently returning items, and block further returns or purchases by the user.</p><p class="s39" style="padding-top: 4pt;padding-left: 139pt;text-indent: -16pt;text-align: justify;">• <span class="s46">Sensors</span><span class="p">: Sensors are very widely used in systems such as vehicles, buildings, and factories. These sensors send readings periodically, and thus the readings form a stream. Readings in the stream are used to monitor the health of the system. If some readings are abnormal, actions may need to be taken to raise alarms, and to detect and ﬁx any underlying faults, with minimal delay.</span></p><p style="padding-left: 139pt;text-indent: 14pt;text-align: justify;">Depending on the complexity of the system and the required frequency of read- ings, the stream can be of very high volume. In many cases, the monitoring is done at a central facility in the cloud, which monitors a very large number of systems. Parallel processing is essential in such a system to handle very large volumes of data in the incoming streams.</p><p class="s39" style="padding-top: 3pt;padding-left: 139pt;text-indent: -16pt;text-align: justify;">• <span class="s46">Network data</span><span class="p">: Any organization that manages a large computer network needs to monitor activity on the network to detect network problems as well as attacks on the network by malicious software (malware). The underlying data being moni- tored can be represented as a stream of tuples containing data observed by each monitoring point (such as network switch). The tuples could contain information about individual network packets, such as source and destination addresses, size of the packet, and timestamp of packet generation. However, the rate of creation of tuples in such a stream is extremely high, and they cannot be handled except us-</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 107pt;text-indent: 0pt;text-align: justify;">ing special-purpose hardware. Instead, data can be aggregated to reduce the rate at which tuples are generated: for example, individual tuples could record data such as source and destination addresses, time interval, and total bytes transmitted in the time interval.</p><p style="padding-left: 107pt;text-indent: 14pt;text-align: justify;">This aggregated stream must then be processed to detect problems. For exam- ple, link failures could be detected by observing a sudden drop in tuples traversing a particular link. Excessive traﬃc from multiple hosts to a single or a few destina- tions could indicate a denial-of-service attack. Packets sent from one host to many other hosts in the network could indicate malware trying to propagate itself to other hosts in the network. Detection of such patterns must be done in real time so that links can be ﬁxed or action taken to stop the malware attack.</p><p class="s39" style="padding-top: 4pt;padding-left: 107pt;text-indent: -16pt;text-align: justify;">• <span class="s46">Social media</span><span class="p">: Social media such as Facebook and Twitter get a continuous stream of messages (such as posts or tweets) from users. Each message in the stream of messages must be routed appropriately, for example by sending it to friends or followers. The messages that can potentially be delivered to a subscriber are then ranked and delivered in rank order, based on user preferences, past interactions, or advertisement charges.</span></p><p style="padding-left: 107pt;text-indent: 15pt;text-align: justify;">Social-media streams can be consumed not just by humans, but also by soft- ware. For example, companies may keep a lookout for tweets regarding the com- pany and raise an alert if there are many tweets that reﬂect a negative sentiment about the company or its products. If a company launches an advertisement cam- paign, it may analyze tweets to see if the campaign had an impact on users.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">There are many more examples of the need to process and query streaming data across a variety of domains.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 88pt;text-indent: 0pt;text-align: left;">10.5.2 Querying Streaming Data</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">Data stored in a database are sometimes referred to as <span class="s63">data-at-rest</span>, in contrast to stream- ing data. In contrast to stored data, streams are unbounded, that is, conceptually they may never end. Queries that can output results only after seeing all the tuples in a stream would then never be able to output any result. As an example, a query that asks for the number of tuples in a stream can never give a ﬁnal result.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">One way to deal with the unbounded nature of streams is to deﬁne <span class="s63">windows </span>on the streams, where each window contains tuples with a certain timestamp range or a certain number of tuples. Given information about timestamps of incoming tuples (e.g., they are increasing), we can infer when all tuples in a particular window have been seen. Based on the above, some query languages for streaming data require that windows be deﬁned on streams, and queries can refer to one or a few windows of tuples rather than to a stream.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Another option is to output results that are correct at a particular point in the stream, but to output updates as more tuples arrive. For example, a count query can</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 119pt;text-indent: 0pt;text-align: left;">output the number of tuples seen at a particular point in time, and as more tuples arrive, the query updates its result based on the new count.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: left;">Several approaches have been developed for querying streaming data, based on the two options described above.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 7pt;padding-left: 145pt;text-indent: -16pt;text-align: justify;"><span class="s63">1. </span><b>Continuous queries</b>. In this approach the incoming data stream is treated as in- serts to a relation, and queries on the relations can be written in <span class="s44">SQL</span>, or using re- lational algebra operations. These queries can be registered as <span class="s63">continuous queries</span>, that is, queries that are running continuously. The result of the query on initial data are output when the system starts up. Each incoming tuple may result in insertion, update, or deletion of tuples in the result of the continuous query. The output of a continuous query is then a stream of updates to the query result, as the underlying database is updated by the incoming streams.</p><p style="padding-left: 145pt;text-indent: 14pt;text-align: justify;">This approach has some beneﬁts in applications where users wish to view all database inserts that satisfy some conditions. However, a major drawback of the approach is that consumers of a query result would be ﬂooded with a large num- ber of updates to continuous queries if the input rate is high. In particular, this approach is not desirable for applications that output aggregated values, where users may wish to see ﬁnal aggregates for some period of time, rather than every intermediate result as each incoming tuple is inserted.</p><p style="padding-top: 6pt;padding-left: 145pt;text-indent: -17pt;text-align: justify;"><span class="s63">2. </span><b>Stream query languages</b>. A second approach is to deﬁne a query language by extending <span class="s44">SQL </span>or relational algebra, where streams are treated diﬀerently from stored relations.</p><p style="padding-left: 145pt;text-indent: 15pt;text-align: justify;">Most stream query languages use window operations, which are applied to streams, and create relations corresponding to the contents of a window. For example, a window operation on a stream may create sets of tuples for each hour of the day; each such set is thus a relation. Relational operations can be executed on each such set of tuples, including aggregation, selection, and joins with stored relational data or with windows of other streams, to generate outputs.</p><p style="padding-left: 145pt;text-indent: 15pt;text-align: justify;">We provide an outline of stream query languages in Section 10.5.2.1. These languages separate streaming data from stored relations at the language level and require window operations to be applied before performing relational operations. Doing so ensures that results can be output after seeing only part of a stream. For example, if a stream guarantees that tuples have increasing timestamps, a window based on time can be deduced to have no more tuples oncea tuple with a higher timestamp than the window end has been seen. The aggregation result for the window can be output at this point.</p><p style="padding-left: 145pt;text-indent: 14pt;text-align: justify;">Some streams do not guarantee that tuples have increasing timestamps. How- ever, such streams would contain <span class="s63">punctuations</span>, that is, metadata tuples that state that all future tuples will have a timestamp greater than some value. Such punc- tuations are emitted periodically and can be used by window operators to decide</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 113pt;text-indent: 0pt;text-align: justify;">when an aggregate result, such as aggregates for an hourly window, is complete and can be output.</p><p class="s63" style="padding-top: 6pt;padding-left: 113pt;text-indent: -17pt;text-align: justify;">3. <span style=" color: #231F20;">Algebraic operators on streams</span><span class="p">. A third approach is to allow users to write oper- ators (user-deﬁned functions) that are executed on each incoming tuple. Tuples are routed from inputs to operators; outputs of an operator may be routed to another operator, to a system output, or may be stored in a database. Operators can maintain internal state across the tuples that are processed, allowing them to aggregate incoming data. They may also be permitted to store data persistently in a database, for long-term use.</span></p><p style="padding-left: 113pt;text-indent: 14pt;text-align: justify;">This approach has seen widespread adoption in recent years, and we describe it in more detail later.</p><p style="padding-top: 6pt;padding-left: 113pt;text-indent: -17pt;text-align: justify;"><span class="s63">4. </span><b>Pattern matching</b>. A fourth option is to deﬁne a pattern matching language and allow users to write multiple rules, each with a pattern and an action. When the system ﬁnds a subsequence of tuples that match a particular pattern, the action corresponding to the pattern is executed. Such systems are called <span class="s63">complex event processing </span>(<span class="s64">CEP</span>) systems. Popular complex event processing systems include Or- acle Event Processing, Microsoft StreamInsight, and FlinkCEP, which is part of the Apache Flink project,</p><p style="padding-left: 88pt;text-indent: 0pt;text-align: justify;">We discuss stream query languages and algebraic operations in more detail later in this section.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Many stream-processing systems keep data in-memory and do not provide persis- tence guarantees; their goal is to generate results with minimum delay, to enable fast response based on analysis of streaming data. On the other hand, the incoming data may also need to be stored in a database for later processing. To support both pat- terns of querying, many applications use a so-called <span class="s63">lambda architecture</span>, where a copy of the input data is provided to the stream-processing system and another copy is pro- vided to a database for storage and later processing. Such an architecture allows stream- processing systems to be developed rapidly, without worrying about persistence-related issues. However, the streaming system and database system are separate, resulting in these problems:</p><p class="s39" style="padding-top: 4pt;padding-left: 107pt;text-indent: -16pt;text-align: justify;">• <span class="s40">Queries may need to be written twice, once for the streaming system and once for the database system, in diﬀerent languages.</span></p><p class="s39" style="padding-top: 4pt;padding-left: 91pt;text-indent: 0pt;text-align: justify;">• <span class="s40">Streaming queries may not be able to access stored data eﬃciently.</span></p><p style="padding-top: 11pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">Systems that support streaming queries along with persistent storage and queries that span streams and stored data avoid these problems.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s183" style="padding-left: 88pt;text-indent: 0pt;text-align: justify;">10.5.2.1 Stream Extensions to SQL</p><p class="s42" style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">SQL <span class="s43">window operations were described in Section 5.5.2, but stream query languages support further window types that are not supported by </span>SQL <span class="s43">window functions. For</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">example, a window that contains tuples for each hour cannot be speciﬁed using <span class="s44">SQL </span>window functions; note, however, that aggregates on such windows can be speciﬁed in <span class="s44">SQL </span>in a more roundabout fashion, ﬁrst computing an extra attribute that contains just the hour component of a timestamp, and then grouping on the hour attribute. Win- dow functions in streaming query languages simplify speciﬁcation of such aggregation. Commonly supported window functions include:</p><p class="s39" style="padding-top: 10pt;padding-left: 139pt;text-indent: -16pt;text-align: justify;">• <span class="s63">Tumbling window</span><span class="p">: Hourly windows are an example of tumbling windows. Windows do not overlap but are adjacent to each other. Windows are speciﬁed by their win- dow size (for example, number of hours, minutes, or seconds).</span></p><p class="s39" style="padding-top: 4pt;padding-left: 139pt;text-indent: -16pt;text-align: justify;">• <span class="s63">Hopping window</span><span class="p">: An hourly window computed every 20 minutes would be an exam- ple of a hopping window; the window width is ﬁxed, similar to tumbling windows, but adjacent windows can overlap.</span></p><p style="padding-top: 4pt;padding-left: 139pt;text-indent: -16pt;text-align: justify;"><span class="s39">• </span><span class="s63">Sliding window</span>: Sliding windows are windows of a speciﬁed size (based on time, or number of tuples) around each incoming tuple. These are supported by the <span class="s44">SQL </span>standard.</p><p class="s39" style="padding-top: 4pt;padding-left: 139pt;text-indent: -16pt;text-align: justify;">• <span class="s63">Session window</span><span class="p">: Session windows model users who perform multiple operations as part of a session. A window is identiﬁed by a user and a time-out interval, and contains a sequence of operations such that each operation occurs within the time- out interval from the previous operation. For example, if the time-out is 5 minutes, and a user performs an operation at 10 AM, a second operation at 10:04 AM, and a third operation at 11 AM, then the ﬁrst two operations are part of one session, while the third is part of a diﬀerent session. A maximum duration may also be speciﬁed, so once that duration expires, the session window is closed even if some operations have been performed within the time-out interval.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">The exact syntax for specifying windows varies by implementation. Suppose we have a relation <i>order</i>(<i>orderid, datetime, itemid, amount</i>). In Azure Stream Analytics, the total order amount for each item for each hour can be speciﬁed by the following tumbling window:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_2358.png"/></span></p><p class="s13" style="padding-left: 177pt;text-indent: 0pt;text-align: left;"><b>select </b>item<span class="p">, </span>System.Timestamp <b>as </b>window end<span class="p">, </span><b>sum</b><span class="p">(</span>amount<span class="p">) </span><b>from </b>order <b>timestamp by </b>datetime</p><p style="padding-left: 177pt;text-indent: 0pt;text-align: left;"><b>group by </b><i>itemid</i>, <b>tumblingwindow</b>(<i>hour</i>, 1)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">Each output tuple has a timestamp whose value is equal to the timestamp of the end of the window; the timestamp can be accessed using the keyword <i>System.Timestamp </i>as shown in the query above.</p><p class="s42" style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">SQL <span class="s43">extensions to support streams diﬀerentiate between streams, where tuples have implicit timestamps and are expected to receive a potentially unbounded number of tuples and relations whose content is ﬁxed at any point. For example, customers, suppliers, and items associated with orders would be treated as relations, rather than</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">as streams. The results of queries with windowing are treated as relations, rather than as streams.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Joins are permitted between a stream and a relation, and the result is a stream; the timestamp of a join result tuple is the same as the timestamp of the input stream tuple. Joins between two streams have the problem that a tuple early in one stream may match a tuple that occurs much later in the other stream; such a join condition would require storing the entire stream for a potentially unbounded amount of time. To avoid this problem, streaming <span class="s44">SQL </span>systems allow stream-to-stream join only if there is a join condition that bounds the time diﬀerence between matching tuples. A condition that the timestamps of the two tuples diﬀer by at most 1 hour is an example of such a condition.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 88pt;text-indent: 0pt;text-align: left;">10.5.3 Algebraic Operations on Streams</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">While <span class="s44">SQL </span>queries on streaming data are quite useful, there are many applications where <span class="s44">SQL </span>queries are not a good ﬁt. With the algebraic operations approach to stream processing, user-deﬁned code can be provided for implementing an algebraic operation; a number of predeﬁned algebraic operations, such as selection and windowed aggrega- tion, are also provided.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">To perform computation, incoming tuples must be routed to operators that con- sume the tuples, and outputs of operators must be routed to their consumers. A key task of the implementation is to provide fault-tolerant routing of tuples between system in- put, operators, and outputs. <i>Apache Storm </i>and <i>Kafka </i>are widely used implementations that support such routing of data.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The <i>logical routing </i>of tuples is done by creating a directed acyclic graph (DAG) with operators as nodes. Edges between nodes deﬁne the ﬂow of tuples. Each tuple output by an operator is sent along all the out-edges of the operator, to the consuming operators. Each operator receives tuples from all its in-edges. Figure 10.11a depicts the logical</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s277" style="padding-left: 93pt;text-indent: 0pt;text-align: left;">	</p><p style="text-indent: 0pt;text-align: left;"><span><img width="191" height="170" alt="image" src="Image_2359.png"/></span></p><p class="s278" style="text-indent: 0pt;line-height: 8pt;text-align: left;">Op</p><p style="text-indent: 0pt;text-align: left;"/><p class="s278" style="text-indent: 0pt;line-height: 8pt;text-align: left;">Op</p><p style="text-indent: 0pt;text-align: left;"/><p class="s278" style="text-indent: 0pt;line-height: 8pt;text-align: left;">Op</p><p style="text-indent: 0pt;text-align: left;"/><p class="s278" style="text-indent: 0pt;line-height: 8pt;text-align: left;">Op</p><p style="text-indent: 0pt;text-align: left;"/><p class="s119" style="padding-top: 1pt;padding-left: 2pt;text-indent: 3pt;text-align: left;">Data Source</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s119" style="padding-left: 26pt;text-indent: -18pt;text-align: left;">Publish-Subscribe System</p><p style="text-indent: 0pt;text-align: left;"/><p class="s119" style="padding-top: 2pt;padding-left: 2pt;text-indent: 3pt;text-align: left;">Data Source</p><p style="text-indent: 0pt;text-align: left;"/><p class="s119" style="padding-top: 1pt;padding-left: 2pt;text-indent: 3pt;text-align: left;">Data Source</p><p style="text-indent: 0pt;text-align: left;"/><p class="s119" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Data Sink</p><p style="text-indent: 0pt;text-align: left;"/><p class="s119" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Data Sink</p><p style="text-indent: 0pt;text-align: left;"/><p class="s119" style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">Data Sink</p><p style="text-indent: 0pt;text-align: left;"/><p class="s119" style="padding-top: 1pt;padding-left: 2pt;text-indent: 3pt;text-align: left;">Data Source</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><span><img width="182" height="148" alt="image" src="Image_2360.png"/></span></p><p class="s278" style="text-indent: 0pt;line-height: 8pt;text-align: left;">Op</p><p style="text-indent: 0pt;text-align: left;"/><p class="s278" style="text-indent: 0pt;line-height: 8pt;text-align: left;">Op</p><p style="text-indent: 0pt;text-align: left;"/><p class="s278" style="text-indent: 0pt;line-height: 8pt;text-align: left;">Op</p><p style="text-indent: 0pt;text-align: left;"/><p class="s278" style="text-indent: 0pt;line-height: 8pt;text-align: left;">Op</p><p style="text-indent: 0pt;text-align: left;"/><p class="s119" style="padding-top: 1pt;padding-left: 2pt;text-indent: 3pt;text-align: left;">Data Source</p><p style="text-indent: 0pt;text-align: left;"/><p class="s119" style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Data Sink</p><p style="text-indent: 0pt;text-align: left;"/><p class="s119" style="padding-top: 2pt;padding-left: 2pt;text-indent: 3pt;text-align: left;">Data Source</p><p style="text-indent: 0pt;text-align: left;"/><p class="s119" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Data Sink</p><p style="text-indent: 0pt;text-align: left;"/><p class="s119" style="padding-top: 1pt;padding-left: 2pt;text-indent: 3pt;text-align: left;">Data Source</p><p style="text-indent: 0pt;text-align: left;"/><p class="s119" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Data Sink</p><p style="text-indent: 0pt;text-align: left;"/><p class="s119" style="padding-top: 1pt;padding-left: 2pt;text-indent: 3pt;text-align: left;">Data Source</p><p style="text-indent: 0pt;text-align: left;"/><p class="s119" style="padding-top: 6pt;padding-left: 96pt;text-indent: 0pt;text-align: left;">(a) DAG representation of streaming data flow     (b) Publish-subscribe representation of streaming data flow</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s73" style="padding-top: 6pt;padding-left: 59pt;text-indent: 0pt;text-align: center;">Figure 10.11 <span class="s74">Routing of streams using DAG and publish-subscribe representations.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">routing of stream tuples through a DAG structure. Operation nodes are denoted as “Op” nodes in the ﬁgure. The entry points to the stream-processing system are the data- source nodes of the DAG; these nodes consume tuples from the stream sources and inject them into the stream-processing system. The exit points of the stream-processing system are data-sink nodes; tuples exiting the system through a data sink may be stored in a data store or ﬁle system or may be output in some other manner.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">One way of implementing a stream-processing system is by specifying the graph as part of the system conﬁguration, which is read when the system starts processing tuples, and is then used to route tuples. The Apache Storm stream-processing system is an example of a system that uses a conﬁguration ﬁle to deﬁne the graph, which is called a <i>topology </i>in the Storm system. Data-source nodes are called <i>spouts </i>in the Storm system, while operator nodes are called <i>bolts</i>, and edges connect these nodes.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">An alternative way of creating such a routing graph is by using <span class="s63">publish-subscribe </span>systems. A publish-subscribe system allows publication of documents or other forms of data, with an associated topic. Subscribers correspondingly subscribe to speciﬁed topics. Whenever a document is published to a particular topic, a copy of the document is sent to all subscribers who have subscribed to that topic. Publish-subscribe systems are also referred to as <span class="s63">pub-sub </span>systems for short.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">When a publish-subscribe system is used for routing tuples in a stream-processing system, tuples are considered documents, and each tuple is tagged with a topic. The entry points to the system conceptually “publish” tuples, each with an associated topic. Operators subscribe to one or more topics; the system routes all tuples with a speciﬁc topic to all subscribers of that topic. Operators can also publish their outputs back to the publish-subscribe system, with an associated topic.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">A major beneﬁt of the publish-subscribe approach is that operators can be added to the system, or removed from it, with relative ease. Figure 10.11b depicts the routing of tuples using a publish-subscribe representation. Each data source is assigned a unique topic name; the output of each operator is also assigned a unique topic name. Each operator subscribes to the topics of its inputs and publishes to the topics corresponding to its output. Data sources publish to their associated topic, while data sinks subscribe to the topics of the operators whose output goes to the sink.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">The Apache Kafka system uses the publish-subscribe model to manage routing of tuples in streams. In the Kafka system, tuples published for a topic are retained for a speciﬁed period of time (called the retention period), even if there is currently no subscriber for the topic. Subscribers usually process tuples at the earliest possible time, but in case processing is delayed or temporarily stopped due to failures, the tuples are still available for processing until the retention time expires.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">More details of routing, and in particular how publish-subscribe is implemented in a parallel system, are provided in Section 22.8.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">The next detail to be addressed is how to implement the algebraic operations. We saw earlier how algebraic operations can be computed using data from ﬁles and other data sources as inputs.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 17pt;text-align: justify;"><a name="bookmark224">Apache Spark allows streaming data sources to be used as inputs for such opera- tions. The key issue is that some of the operations may not output any results at all until the entire stream is consumed, which may take potentially unbounded time. To avoid this problem, Spark breaks up streams into </a><span class="s63">discretized streams</span>, where the stream data for a particular time window are treated as a data input to algebraic operators. When the data in that window have been consumed, the operator generates its output, just as it would have if the data source were a ﬁle or a relation.<a name="bookmark242">&zwnj;</a></p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">However, the above approach has the problem that the discretization of streams has to be done before any algebraic operations are executed. Other systems such as Apache Storm and Apache Flink support stream operations, which take a stream as input and output another stream. This is straightforward for operations such as map or relational select operations; each output tuple inherits a timestamp from the input tuple. On the other hand, relational aggregate operations and reduce operations may be unable to generate any output until the entire stream is consumed. To support such operations, Flink supports a window operation which breaks up the stream into win- dows; aggregates are computed within each window and are output once the window is complete. Note that the output is treated as a stream, where tuples have a timestamp based on the end of the window.<span class="s76">3</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part206.htm">&lt; 上一个</a><span> | </span><a href="../database.html">内容</a><span> | </span><a href="part208.htm">下一个 &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
