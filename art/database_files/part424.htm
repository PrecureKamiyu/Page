<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>23.7  Coordinator Selection</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part423.htm">&lt; 上一个</a><span> | </span><a href="../database.html">内容</a><span> | </span><a href="part425.htm">下一个 &gt;</a></p><p class="s65" style="padding-left: 40pt;text-indent: 0pt;text-align: left;">23.7  <span style=" color: #00AEEF;">Coordinator Selection</span></p><p style="padding-top: 12pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">Several of the algorithms that we have presented require the use of a coordinator. If the coordinator fails because of a failure of the node at which it resides, the system can continue execution by restarting a new coordinator on another node. One way to continue execution is by maintaining a backup to the coordinator that is ready to assume responsibility if the coordinator fails. Another way is to “elect” a coordinator from among the nodes that are alive. We outline these options in this section. We then brieﬂy describe fault-tolerant distributed services that have been developed to help developers of distributed applications perform these tasks.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 88pt;text-indent: 0pt;text-align: left;">23.7.1 Backup Coordinator</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">A <span class="s63">backup coordinator </span>is a node that, in addition to other tasks, maintains enough infor- mation locally to allow it to assume the role of coordinator with minimal disruption to the distributed system. All messages directed to the coordinator are received by both the coordinator and its backup. The backup coordinator executes the same algorithms and maintains the same internal state information (such as, for a concurrency coordi- nator, the lock table) as does the actual coordinator. The only diﬀerence in function between the coordinator and its backup is that the backup does not take any action that aﬀects other nodes. Such actions are left to the actual coordinator.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">In the event that the backup coordinator detects the failure of the actual coordi- nator, it assumes the role of coordinator. Since the backup has all the information available to it that the failed coordinator had, processing can continue without inter- ruption.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The prime advantage of the backup approach is the ability to continue processing immediately. If a backup were not ready to assume the coordinator’s responsibility, a newly appointed coordinator would have to seek information from all nodes in the system so that it could execute the coordination tasks. Frequently, the only source of some of the requisite information is the failed coordinator. In this case, it may be necessary to abort several (or all) active transactions and to restart them under the control of the new coordinator.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 119pt;text-indent: 17pt;text-align: justify;">Thus, the backup-coordinator approach avoids a substantial amount of delay while the distributed system recovers from a coordinator failure. The disadvantage is the over- head of duplicate execution of the coordinator’s tasks. Furthermore, a coordinator and its backup need to communicate regularly to ensure that their activities are synchro- nized.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">In short, the backup-coordinator approach incurs overhead during normal process- ing to allow fast recovery from a coordinator failure.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 119pt;text-indent: 0pt;text-align: left;">23.7.2 Election of Coordinator</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">In the absence of a designated backup coordinator, or in order to handle multiple fail- ures, a new coordinator may be chosen dynamically by nodes that are live.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">One possible approach is to have a designated node choose a new coordinator, when the current coordinator has failed. However, this raises the question of what to do if the node that chooses replacement coordinators itself fails.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">If we have a fault-tolerant lock manager, a very eﬀective way of choosing a new coordinator for a task is to use <i>lock leases</i>. The current coordinator has a lock lease on a data item associated with the task. If the coordinator fails, the lease will expire. If a participant determines that the coordinator may have failed, it attempts to get a lock lease for the task. Note that multiple participants may attempt to get a lease, but the lock manager ensures that only one of them can get the lease. The participant that gets the lease becomes the new coordinator. As discussed in Section 23.3.3, this ensures that only one node that can be the coordinator at a given time. Lock leases are widely used to ensure that a single node gets chosen as coordinator. However, observe that there is an underlying assumption of a fault-tolerant lock manager.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">A participant determines that the coordinator may have failed if it is unable to communicate with the coordinator. Participants send periodic <span class="s63">heart-beat </span>messages to the coordinator and wait for an acknowledgment; if the acknowledgment is not received within a certain time, the coordinator is assumed to have failed.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Note that the participant cannot deﬁnitively distinguish a situation where the co- ordinator is dead from a situation where the network link between the node and the coordinator is cut. Thus, the system should be able to work correctly even if the current coordinator is alive, but another participant determines that the coordinator is dead. Lock leases ensure that at most one node can be the coordinator at any time; once a coordinator dies, another node can become the coordinator. However, lock leases work only if a fault-tolerant lock manager is available.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">This raises the question of how to implement such a lock manager. We return later, in Section 23.8.4, to the question of how to implement a fault-tolerant lock manager. But it turns out that to do so eﬃciently, we need to have a coordinator. And, lock leases cannot be used to choose the coordinator for the lock manager! The problem of how to choose a coordinator without depending on a lock manager is solved by <span class="s63">election algorithms</span>, which enable the participating nodes to choose a new coordinator in a decentralized manner.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 17pt;text-align: justify;">Suppose the goal is to elect a coordinator just once. Then, each node that wishes to become the coordinator proposes itself as a candidate to all the other nodes; such nodes are called <i>proposers</i>. The participating nodes then vote on which node among the candidates is to be chosen. If a majority of the participating nodes (called <i>acceptors</i>) vote for a particular candidate, it is chosen. A subset of nodes called <i>learners </i>ask the acceptor nodes for their vote and determine if a majority have voted for a particular candidate.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The problem with the above idea is that if there are multiple candidates, none of them may get a majority of votes. The question is what to do in such a situation. There are at least two approaches that have been proposed:</p><p style="padding-top: 4pt;padding-left: 107pt;text-indent: -16pt;text-align: justify;"><span class="s39">• </span><span class="s40">Nodes are given unique numbers; if more than one candidate proposes itself, ac- ceptors choose the highest-numbered candidate. Even then votes may be split with no majority decision, due to delayed or missing messages; in such a case, the elec- tion is run again. But if a node </span><i>N</i><span class="s98">1</span> that was a candidate ﬁnds that a higher-numbered node <i>N</i><span class="s98">2</span> has proposed itself as a candidate, then <i>N</i><span class="s98">1</span> withdraws from the next round of the election. The highest-numbered candidate will win the election. The <span class="s63">bully algorithm </span>for election is based on this idea.</p><p style="padding-left: 107pt;text-indent: 14pt;text-align: justify;">There are some subtle details due to the possibility that the highest-numbered candidate in one round may fail during a subsequent round, leading to there being no candidates at all! If a proposer observes that no coordinator was selected in a round where it withdrew itself as a candidate, it proposes itself as a candidate again in the next round.</p><p style="padding-left: 107pt;text-indent: 15pt;text-align: justify;">Note also that the election has multiple rounds; each round has a number, and a candidate attaches a round number with the proposal. The round number is chosen to be the maximum round that it has seen, plus 1. A node can give a vote to only one candidate in a particular round, but it may change its vote in the next round.</p><p class="s39" style="padding-top: 3pt;padding-left: 107pt;text-indent: -16pt;text-align: justify;">• <span class="s40">The second approach is based on </span><span class="s13">randomized retry</span><span class="p">, which works as follows: If there is no majority decision in a particular round, all participants wait for a randomly chosen amount of time; if by that time a coordinator has been chosen by a majority of nodes, it is accepted as a coordinator. Otherwise, after the timeout, the node proposes itself as a candidate. As long as the timeouts are chosen properly (large enough compared to network latency) with high likelihood only one node proposes itself at a particular time and will get votes from a majority of nodes in a particular round.</span></p><p style="padding-left: 107pt;text-indent: 15pt;text-align: justify;">If no candidate gets a majority vote in a round, the process is repeated. With very high probability, after a few rounds, one of the candidates gets a majority and is thus chosen as coordinator.</p><p style="padding-left: 107pt;text-indent: 15pt;text-align: justify;">The randomized-retry approach was popularized by the Raft consensus algo- rithm, and it is easier to reason about it and show not just correctness, but also bounds on the expected time for an election round to succeed in choosing a coor- dinator, as compared to the node- numbering-based approach.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 119pt;text-indent: 17pt;text-align: justify;">Note that the above description assumed that choosing a coordinator is a one-time activity. However, the chosen coordinator may fail, requiring a fresh election algorithm. The notion of a <span class="s63">term </span>is used to deal with this situation. As mentioned above, each time a node proposes itself as a coordinator, it associates the proposal with a round number, which is 1 more than the highest round number it has seen earlier, after ensuring that in the previous round no coordinator was chosen, or the chosen coordinator has subse- quently failed. The round number is henceforth referred to as a <span class="s63">term</span>. When the election succeeds, the chosen coordinator is the coordinator for the corresponding term. If the election fails, the corresponding term does not have any coordinator chosen, but the election should succeed in a subsequent term.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Note also that there are subtle issues that arise since a node <i>n </i>may be disconnected from the network for a while, and it may get reconnected without ever realizing that it was disconnected. In the interim, the coordinator may have changed. In particular, if the node <i>n </i>was the coordinator, it may continue to think it is the coordinator, and some other node, say <i>N</i><span class="s98">1</span>, which was also disconnected may think that <i>n </i>is still coordinator. However, if a coordinator was successfully elected, the majority of the nodes agree that some other node, say <i>N</i><span class="s98">2</span>, is the coordinator.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">In general, it is possible for more than one node to think that is the coordinator at the same time, although at most one of them can have the majority vote at that point in time.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">To avoid this problem, each coordinator can be given a lease for a speciﬁed period. The coordinator can extend the lease by requesting an extension from other nodes and getting conﬁrmation from a majority of the nodes. But if the coordinator is discon- nected from a majority of the nodes, it cannot renew its lease, and the lease expires. A node can vote for a new coordinator only if the last lease time that it conﬁrmed to the earlier coordinator has expired. Since a new coordinator needs a majority vote, it cannot get the vote until the lease time of the previous coordinator has expired.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">However, even if leases are used to ensure that two nodes cannot be coordinators at the same time, delayed messages can result in a node getting a message from an old coordinator after a new one has been elected.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">To deal with this problem, the current term of the sender is included with each message exchanged in the system. Note that when a node <i>n </i>is elected as coordinator, it has an associated term <i>t</i>; participant nodes that learn that <i>n </i>is the coordinator are aware of the current term <i>t</i>. A node may receive a message with an old term either because an old coordinator did not realize it has been replaced or because of message delivery delay; the latter problem can occur even if leases or other mechanisms ensure that only one node can be the coordinator at a time. In either case, a node that receives a <span class="s63">stale message</span>, that is, one with a term older than the current term of the node, it can ignore the message. If a node receives a message with a higher number, it is behind the rest of the system, and it needs to ﬁnd out the current term and coordinator by contacting other nodes.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Some protocols do not require the coordinator to store any state information; in such cases, the new coordinator can take over without any further actions. However,</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;"><a name="bookmark492">other protocols require coordinators to retain state information. In such cases, the new coordinator has to reconstruct the state information from persistent data and recovery logs created by the previous coordinator. Such logs, in turn, need to be replicated to multiple nodes so that the loss of a node does not result in the loss of access to the recovery data. We shall see how to ensure availability by means of data replication in subsequent sections.</a><a name="bookmark537">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s183" style="padding-left: 88pt;text-indent: 0pt;text-align: justify;">23.7.2.1 Distributed Coordination Services</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">There are a very large number of distributed applications that are in daily use today. Instead of each one having to implement its own mechanism for electing coordinators (among other tasks), it makes sense to develop a fault-tolerant coordination service that can be used by multiple distributed applications.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The <span class="s63">ZooKeeper </span>service is one such very widely used fault-tolerant distributed co- ordination service. The <span class="s63">Chubby </span>service developed earlier at Google is another such service, which is widely used for applications developed by Google. These services internally use consensus protocols to implement fault tolerance; we study consensus protocols in Section 23.8.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">These services provide a ﬁle-system-like <span class="s44">API</span>, which supports the following features, among others:</p><p class="s39" style="padding-top: 5pt;padding-left: 107pt;text-indent: -16pt;text-align: justify;">• <span class="s13">Store (small amounts of) data </span><span class="p">in ﬁles, with a hierarchical namespace. A typical use for such storage is to store conﬁguration information that can be used to start up a distributed application, or for new nodes to join a distributed application by ﬁnding out which node is currently the coordinator.</span></p><p class="s39" style="padding-top: 3pt;padding-left: 107pt;text-indent: -16pt;text-align: justify;">• <span class="s13">Create and delete files</span><span class="p">, which can be used to implement locking. For example, to get a lock, a process can attempt to create a ﬁle with a name corresponding to the lock. If another process has already created the ﬁle, the coordination service will return an error, so the process knows it could not get the lock.</span></p><p style="padding-left: 107pt;text-indent: 14pt;text-align: justify;">For example, a node that acts as a master for a tablet in a key-value store would get a lock on a ﬁle whose name is the identiﬁer of the tablet. This ensures that two nodes cannot be masters for the tablet at the same time.</p><p style="padding-left: 107pt;text-indent: 14pt;text-align: justify;">If an overall application master detects that a tablet master has died, it could re- lease the lock. If the service supports lock leases, this could happen automatically, if the tablet master does not renew its lease.</p><p class="s39" style="padding-top: 3pt;padding-left: 107pt;text-indent: -16pt;text-align: justify;">• <span class="s13">Watch for changes on a file</span><span class="p">, which can be used by a process to check if a lock has been released, or to be informed about other changes in the system that require action by the process.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part423.htm">&lt; 上一个</a><span> | </span><a href="../database.html">内容</a><span> | </span><a href="part425.htm">下一个 &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
