<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>20.3  Server System Architectures</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part367.htm">&lt; 上一个</a><span> | </span><a href="../database.html">内容</a><span> | </span><a href="part369.htm">下一个 &gt;</a></p><p class="s65" style="padding-left: 72pt;text-indent: 0pt;text-align: left;">20.3  <span style=" color: #00AEEF;">Server System Architectures</span></p><p class="s46" style="padding-top: 11pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">Server systems <span class="p">can be broadly categorized as transaction servers and data servers.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 139pt;text-indent: -16pt;text-align: justify;"><span class="s39">• </span><span class="s63">Transaction-server </span>systems, also called <span class="s63">query-server </span>systems, provide an interface to which clients can send requests to perform an action, in response to which they execute the action and send back results to the client. Usually, client machines ship transactions to the server systems, where those transactions are executed, and re- sults are shipped back to clients that are in charge of displaying the data. Requests may be speciﬁed through the use of <span class="s44">SQL </span>or through a specialized application pro- gram interface.</p><p class="s39" style="padding-top: 3pt;padding-left: 139pt;text-indent: -16pt;text-align: justify;">• <span class="s63">Data-server systems </span><span class="p">allow clients to interact with the servers by making requests to read or update data, in units such as ﬁles, pages, or objects. For example, ﬁle servers provide a ﬁle-system interface where clients can create, update, read, and</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 107pt;text-indent: 0pt;text-align: justify;">delete ﬁles. Data servers for database systems oﬀer much more functionality; they support units of data — such as pages, tuples, or objects — that are smaller than a ﬁle. They provide indexing facilities for data, and they provide transaction facilities so that the data are never left in an inconsistent state if a client machine or process fails.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 88pt;text-indent: 0pt;text-align: justify;">Of these, the transaction-server architecture is by far the more widely used architecture, although parallel data servers are widely used to handle traﬃc at web scale. We shall elaborate on the transaction-server and data-server architectures in Section 20.3.1 and Section 20.3.2.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 88pt;text-indent: 0pt;text-align: left;">20.3.1 Transaction-Server Architecture</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">A typical transaction-server system today consists of multiple processes accessing data in shared memory, as in Figure 20.1. The processes that form part of the database system include:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="284" height="383" alt="image" src="Image_3094.png"/></span></p><p class="s80" style="text-indent: 5pt;line-height: 107%;text-align: left;">user process</p><p style="text-indent: 0pt;text-align: left;"/><p class="s80" style="text-indent: 5pt;line-height: 107%;text-align: left;">user process</p><p style="text-indent: 0pt;text-align: left;"/><p class="s80" style="text-indent: 5pt;line-height: 107%;text-align: left;">user process</p><p style="text-indent: 0pt;text-align: left;"/><p class="s80" style="text-indent: 0pt;line-height: 9pt;text-align: left;">ODBC</p><p style="text-indent: 0pt;text-align: left;"/><p class="s80" style="text-indent: 0pt;line-height: 9pt;text-align: left;">JDBC</p><p style="text-indent: 0pt;text-align: left;"/><p class="s80" style="text-indent: 2pt;line-height: 107%;text-align: left;">server process</p><p style="text-indent: 0pt;text-align: left;"/><p class="s80" style="text-indent: 2pt;line-height: 107%;text-align: left;">server process</p><p style="text-indent: 0pt;text-align: left;"/><p class="s80" style="text-indent: 2pt;line-height: 107%;text-align: left;">server process</p><p style="text-indent: 0pt;text-align: left;"/><p class="s80" style="text-indent: 0pt;line-height: 9pt;text-align: left;">buﬀer pool</p><p style="text-indent: 0pt;text-align: left;"/><p class="s80" style="text-indent: 3pt;line-height: 107%;text-align: left;">shared memory</p><p style="text-indent: 0pt;text-align: left;"/><p class="s80" style="text-indent: 0pt;line-height: 107%;text-align: justify;">process monitor process</p><p style="text-indent: 0pt;text-align: left;"/><p class="s80" style="text-indent: 0pt;line-height: 9pt;text-align: left;">query plan cache</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s80" style="padding-left: 39pt;text-indent: 0pt;text-align: left;">lock table</p><p style="text-indent: 0pt;text-align: left;"/><p class="s80" style="text-indent: 0pt;line-height: 107%;text-align: left;">lock manager process</p><p style="text-indent: 0pt;text-align: left;"/><p class="s80" style="padding-left: 3pt;text-indent: -3pt;line-height: 107%;text-align: left;">log writer process</p><p style="text-indent: 0pt;text-align: left;"/><p class="s80" style="padding-left: 5pt;text-indent: -5pt;line-height: 107%;text-align: left;">checkpoint process</p><p style="text-indent: 0pt;text-align: left;"/><p class="s80" style="text-indent: 0pt;line-height: 107%;text-align: center;">database writer process</p><p style="text-indent: 0pt;text-align: left;"/><p class="s80" style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">log buﬀer</p><p style="text-indent: 0pt;text-align: left;"/><p class="s80" style="padding-top: 3pt;padding-left: 187pt;text-indent: 0pt;text-align: left;">log disks               data disks</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s73" style="padding-top: 4pt;padding-left: 59pt;text-indent: 0pt;text-align: center;">Figure 20.1 <span class="s74">Shared memory and process structure.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 139pt;text-indent: -16pt;text-align: justify;"><span class="s39">• </span><span class="s63">Server processes</span>: These are processes that receive user queries (transactions), exe- cute them, and send the results back. The queries may be submitted to the server processes from a user interface, or from a user process running embedded <span class="s44">SQL</span>, or via <span class="s44">JDBC</span>, <span class="s44">ODBC</span>, or similar protocols. Some database systems use a separate pro- cess for each user session, and a few use a single database process for all user ses- sions, but with multiple threads so that multiple queries can execute concurrently. (A <span class="s63">thread </span>is similar to a process, but multiple threads execute as part of the same process, and all threads within a process run in the same virtual-memory space. Multiple threads within a process can execute concurrently.) Many database sys- tems use a hybrid architecture, with multiple processes, each one running multiple threads.</p><p class="s39" style="padding-top: 3pt;padding-left: 139pt;text-indent: -16pt;text-align: justify;">• <span class="s63">Lock manager process</span><span class="p">: This process implements lock manager functionality, which includes lock grant, lock release, and deadlock detection.</span></p><p class="s39" style="padding-top: 4pt;padding-left: 139pt;text-indent: -16pt;text-align: justify;">• <span class="s63">Database writer process</span><span class="p">: There are one or more processes that output modiﬁed buﬀer blocks back to disk on a continuous basis.</span></p><p class="s39" style="padding-top: 4pt;padding-left: 139pt;text-indent: -16pt;text-align: justify;">• <span class="s63">Log writer process</span><span class="p">: This process outputs log records from the log record buﬀer to stable storage. Server processes simply add log records to the log record buﬀer in shared memory, and if a log force is required, they request the log writer process to output log records (recall that a log force causes the log contents in memory to be output to stable storage).</span></p><p class="s39" style="padding-top: 3pt;padding-left: 123pt;text-indent: 0pt;text-align: justify;">• <span class="s63">Checkpoint process</span><span class="p">: This process performs periodic checkpoints.</span></p><p class="s39" style="padding-top: 3pt;padding-left: 139pt;text-indent: -16pt;text-align: justify;">• <span class="s63">Process monitor process</span><span class="p">: This process monitors other processes, and if any of them fails, it takes recovery actions for the process, such as aborting any transaction being executed by the failed process and then restarting the process.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 20pt;text-indent: 0pt;text-align: center;">The shared memory contains all shared data, such as:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s39" style="padding-left: 123pt;text-indent: 0pt;text-align: left;">• <span class="s40">Buﬀer pool.</span></p><p class="s39" style="padding-top: 3pt;padding-left: 123pt;text-indent: 0pt;text-align: left;">• <span class="s40">Lock table.</span></p><p class="s39" style="padding-top: 3pt;padding-left: 123pt;text-indent: 0pt;text-align: left;">• <span class="s40">Log buﬀer, containing log records waiting to be output to the log on stable storage.</span></p><p class="s39" style="padding-top: 3pt;padding-left: 123pt;text-indent: 0pt;text-align: left;">• <span class="s40">Cached query plans, which can be reused if the same query is submitted again.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">All database processes can access the data in shared memory. Since multiple processes may read or perform updates on data structures in shared memory, there must be a mechanism to ensure <span class="s63">mutual exclusion</span>, that is, to ensure that a data structure is modi- ﬁed by at most one process at a time, and no process is reading a data structure while it is being written by other processes.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Such mutual exclusion can be implemented by means of operating system func- tions called semaphores. Alternative implementations, with less overhead, use one of</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="493" height="694" alt="image" src="Image_3095.png"/></span></p><p class="s73" style="padding-left: 59pt;text-indent: 0pt;text-align: center;">Note 20.1 <span class="s146">ATOMIC INSTRUCTIONS</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 123pt;text-indent: -16pt;text-align: justify;"><span class="s63">1. </span>The instruction <span class="s63">test-and-set </span>(<i>M </i>) performs the following two actions atomi- cally: (i) test, that is, read the value of memory location <i>M </i>, and then (ii) set it to 1; the test-and-set instruction returns the value that it read in step (i).</p><p style="padding-left: 123pt;text-indent: 14pt;text-align: justify;">Suppose a memory location <i>M </i>representing an exclusive lock is initially set to 0. A process that wishes to get the lock executes the test-and-set (<i>M </i>). If it is the only process executing the instruction on <i>M </i>, the value that is read and returned would be 0, indicating to the process that it has acquired the lock, and <i>M </i>would be set to 1. When the process is done using the lock, it releases the lock by setting <i>M </i>back to 0.</p><p style="padding-left: 123pt;text-indent: 14pt;text-align: justify;">If a second process executes test-and-set (<i>M </i>) before the lock is released, the value returned would be 1, indicating that some other process already has the lock. The process could repeat the execution of test-and-set on <i>M </i>periodically, until it gets a return value of 0, indicating that it has acquired the lock after it was released by another process.</p><p style="padding-left: 123pt;text-indent: 14pt;text-align: justify;">Now, if two processes execute test-and-set (<i>M </i>) concurrently, one of them would see a return value of 0, while the other would see a return value of 1; this is because the read operation and the set operation are executed together, atomically. The ﬁrst process to read the value would also set it to 1, and the second process would ﬁnd that <i>M </i>is already set to 1. Thus, only one process acquires the lock, ensuring mutual execution.</p><p style="padding-top: 7pt;padding-left: 123pt;text-indent: -17pt;line-height: 93%;text-align: justify;"><span class="s63">2. </span>The <span class="s63">compare-and-swap </span>instruction is another atomic instruction similar to the test-and-set instruction, but it takes the following operands: (<i>M </i>, <i>V</i><span class="s145">o</span>, <i>V</i><span class="s145">n</span>), where <i>M </i>is a memory location, and value <i>V</i><span class="s145">o </span>and <i>V</i><span class="s145">n </span>are two values (referred to as the old and new values). The instruction does the following atomically: it compares the value at <i>M </i>with <i>V</i><span class="s97">o</span>, and if it matches, it updates the value to <i>V</i><span class="s97">n </span>and returns success. If the values do not match, it does not update <i>M </i>, and it returns failure.</p><p style="padding-left: 123pt;text-indent: 15pt;text-align: justify;">Similar to the case of test-and-set, we have a memory location <i>M </i>repre- senting a lock, which is initially set to 0. A process that wants to acquire the lock executes compare-and-swap (<i>M </i>, 0, <i>id</i>) where <i>id </i>can be any nonzero value and is typically the process identiﬁer. If no process has the lock, the compare-and-swap operation returns success, after storing the process iden- tiﬁer in <i>M </i>; otherwise, the operation returns failure.</p><p style="padding-left: 123pt;text-indent: 15pt;text-align: justify;">A beneﬁt of compare-and-swap over the test-and-set implementation is that it is easy to ﬁnd out which process has acquired the lock by just reading the content of <i>M </i>, if the process identiﬁer is used as <i>V</i><span class="s145">n</span>.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">the <span class="s63">atomic instructions</span>, test-and-set, or compare-and-swap, which are supported by the computer hardware. See Note 20.1 on page 966 for details of these instructions. All multiprocessor systems today support either the test-and-set or the compare-and-swap atomic instructions. Further details on these instructions may be found in operating systems textbooks.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Note that the atomic instructions can be used for mutual exclusion, which is equiv- alent to supporting exclusive locks, but they do not directly support shared locks. Thus, they cannot be used directly to implement general-purpose locking in databases. Atomic instructions are, however, used to implement short-duration locks, also known as latches, which are used for mutual exclusion in databases.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">To avoid the overhead of message passing, in many database systems, server pro- cesses implement locking by directly updating the lock table (which is in shared mem- ory) instead of sending lock request messages to a lock manager process. (The lock table is shown in Figure 18.10.)</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Since multiple server processes may access the lock table in shared memory con- currently, processes must ensure mutual exclusion on access to the lock table. This is typically done by acquiring a mutex (also referred to as a latch) on the lock table, using the test-and-set or compare-and-swap instructions on a memory location representing a lock on the lock table.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">A transaction that wants to acquire a lock by directly updating the lock table in shared memory executes the following steps.</p><p class="s63" style="padding-top: 10pt;padding-left: 128pt;text-indent: 0pt;text-align: justify;">1. <span class="p">Acquire a mutex (latch) on the lock table.</span></p><p class="s63" style="padding-top: 6pt;padding-left: 145pt;text-indent: -17pt;text-align: justify;">2. <span class="p">Check if the requested lock can be allocated, using the procedure we saw in Sec- tion 18.1.4. If it can, update the lock table to indicate the lock is allocated. Oth- erwise, update the lock table to indicate that the lock request is in the queue for that lock.</span></p><p class="s63" style="padding-top: 6pt;padding-left: 128pt;text-indent: 0pt;text-align: justify;">3. <span class="p">Release the mutex on the lock table.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">If a lock cannot be obtained immediately because of a lock conﬂict, the transaction may periodically read the lock table to check if the lock has been allocated to it due to a lock release, which is described next.</p><p style="padding-left: 137pt;text-indent: 0pt;text-align: justify;">Lock release is done as follows:</p><p class="s63" style="padding-top: 10pt;padding-left: 128pt;text-indent: 0pt;text-align: justify;">1. <span class="p">Acquire a mutex on the lock table</span></p><p class="s63" style="padding-top: 6pt;padding-left: 128pt;text-indent: 0pt;text-align: justify;">2. <span class="p">Remove the entry in the lock table for the lock being released.</span></p><p class="s63" style="padding-top: 6pt;padding-left: 145pt;text-indent: -17pt;text-align: justify;">3. <span class="p">If there are any other lock requests pending for the data item that can now be allocated to the lock, the lock table is updated to mark those requests as allocated. The rules on which lock requests may be granted are as described in Section 18.1.4.</span></p><p class="s63" style="padding-top: 6pt;padding-left: 128pt;text-indent: 0pt;text-align: justify;">4. <span class="p">Release the mutex on the lock table.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 17pt;text-align: justify;">To avoid repeated checks on the lock table (an example of the phenomenon of <i>busy waiting</i>), operating system semaphores can be used by the lock request code to wait for a lock grant notiﬁcation. The lock release code must then use the semaphore mechanism to notify waiting transactions that their locks have been granted.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Even if the system handles lock requests through shared memory, it still uses the lock manager process for deadlock detection.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 88pt;text-indent: 0pt;text-align: left;">20.3.2 Data Servers and Data Storage Systems</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">Data-server systems were originally developed to support data access from object- oriented databases; object-oriented databases allow programmers to use a program- ming language that allows creation, retrieval, and update of persistent objects.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Many of the target applications of object-oriented databases, such as computer- aided design (CAD) systems, required extensive computation on the retrieved data. For example, the CAD system may store a model of a computer chip or a building, and it may perform computations such as simulations on the retrieved model, which may be expensive in terms of <span class="s44">CPU </span>time.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">If all the computation were done at the server, the server would be overloaded. Instead, in such an environment, it makes sense to store data on a separate data server machine, fetch data to client machines when needed, perform all processing at the client machines, and then to store new or updated data back on the data server ma- chine. Thus, the processing power of client machines can be used to carry out the computation, while the server needs only to store and fetch data, without performing any computation.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">More recently, a number of parallel data storage systems have been developed for handling very high volumes of data and transactions. Such systems do not necessarily support <span class="s44">SQL</span>, but instead provide <span class="s44">API</span>s for storing, retrieving, and updating data items. Data items stored in such systems they could be tuples, or could be objects represented in formats such as <span class="s44">JSON </span>or <span class="s44">XML</span>, or they could even be ﬁles or documents.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">We use the term <span class="s63">data item </span>to refer to tuples, objects, ﬁles, and documents. We also use the terms <i>data server </i>and <i>data storage system </i>interchangeably.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Data servers support communication of entire data items; in the case of very large data items, they may also support communication of only speciﬁed parts of the data item, for instance, speciﬁed blocks, instead of requiring that the entire data item be fetched or stored.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Data servers in earlier generations of storage systems supported a concept called <i>page shipping</i>, where the unit of communication is a database page that may potentially contain multiple data items. Page shipping is not used today, since storage systems do not expose the underlying storage layout to clients.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 88pt;text-indent: 0pt;text-align: left;">20.3.3 Caching at Clients</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">The time cost of communication between a client application and a server (whether a transaction server, or a data server) is high compared to that of a local memory</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">reference (milliseconds, versus less than 100 nanoseconds). The time to send a message over a network, and get a response back, called the <i>network round-trip time</i>, or <i>network latency</i>, can be nearly a millisecond even if the data server is in the same location as the client.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">As a result, applications running at the clients adopt several optimization strategies to reduce the eﬀects of network latency. The same strategies can also be useful in par- allel database systems, where some of the data required for processing a query may be stored on a diﬀerent machine from where it is consumed. The optimization strategies include the following:</p><p class="s39" style="padding-top: 6pt;padding-left: 139pt;text-indent: -16pt;text-align: justify;">• <span class="s63">Prefetching</span><span class="p">. If the unit of communication is a single small item, the overhead of message passing is high compared to the amount of data transmitted. In particu- lar, network latency can cause signiﬁcant delays if a transaction makes repeated requests for data items across a network.</span></p><p style="padding-left: 139pt;text-indent: 15pt;text-align: justify;">Thus, when an item is requested, it may make sense to also send other items that are likely to be used in the near future. Fetching items even before they are requested is called <span class="s63">prefetching</span>.</p><p class="s63" style="padding-top: 3pt;padding-left: 139pt;text-indent: -16pt;text-align: justify;"><span class="s39">• </span>Data caching<span class="p">. Data that are shipped to a client on behalf of a transaction can be </span>cached <span class="p">at the client within the scope of a single transaction. Data can be cached even after the transaction completes, allowing successive transactions at the same client to make use of the cached data.</span></p><p style="padding-left: 139pt;text-indent: 14pt;text-align: justify;">However, <span class="s63">cache coherency </span>is an issue: Even if a transaction ﬁnds cached data, it must make sure that those data are up to date, since they may have been updated, or even deleted, by a diﬀerent client after they were cached. Thus, a message must still be exchanged with the server to check validity of the data and to acquire a lock on the data, unless the application is willing to live with potentially stale data. Further, new tuples may have been inserted after a transaction caches data, which may not be in the cache. The transaction may have to contact the server to ﬁnd such tuples.</p><p class="s63" style="padding-top: 4pt;padding-left: 139pt;text-indent: -16pt;text-align: justify;"><span class="s39">• </span>Lock caching<span class="p">. If the usage of data is mostly partitioned among the clients, with clients rarely requesting data that are also requested by other clients, locks can also be cached at the client machine. Suppose that a client ﬁnds a data item in the cache, and that it also ﬁnds the lock required for an access to the data item in the cache. Then, the access can proceed without any communication with the server. However, the server must keep track of cached locks; if a client requests a lock from the server, the server must </span>call back <span class="p">all conﬂicting locks on the data item from any other client machines that have cached the locks. The task becomes more complicated when machine failures are taken into account.</span></p><p class="s39" style="padding-top: 3pt;padding-left: 139pt;text-indent: -16pt;text-align: justify;">• <span class="s63">Adaptive lock granularity</span><span class="p">. If a transaction requires locks on multiple data items, discovered in the course of a transaction, and each lock acquisition requires a round trip to a data server, the transaction may waste a good deal of time on</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 107pt;text-indent: 0pt;text-align: justify;"><a name="bookmark453">just lock acquisition. In such a situation, multi-granularity locking can be used to avoid multiple requests. For example, if multiple data items are stored ina page, a single page lock (which is at a coarser granularity) can avoid the need to acquire multiple data-item locks (which are at a ﬁner granularity). This strategy works well if there is very little lock contention, but with higher contention, acquiring a coarse granularity lock can aﬀect concurrency signiﬁcantly.</a><a name="bookmark500">&zwnj;</a></p><p class="s63" style="padding-left: 107pt;text-indent: 13pt;text-align: justify;">Lock de-escalation<span class="p">, is a way of adaptively decreasing the lock granularity if there is higher contention. Lock de-escalation is initiated by the data server sending a request to the client to de-escalate a lock, and the client responds by acquiring ﬁner-granularity locks and then releasing the coarser-granularity lock.</span></p><p style="padding-left: 107pt;text-indent: 14pt;text-align: justify;">When switching to a ﬁner granularity, if some of the locks were for cached data items that are not currently locked by any transaction at a client, the data item can be removed from the cache instead of acquiring a ﬁner-granularity lock on it.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part367.htm">&lt; 上一个</a><span> | </span><a href="../database.html">内容</a><span> | </span><a href="part369.htm">下一个 &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
