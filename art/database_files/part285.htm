<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>15.6  Other Operations</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part284.htm">&lt; 上一个</a><span> | </span><a href="../database.html">内容</a><span> | </span><a href="part286.htm">下一个 &gt;</a></p><p class="s65" style="padding-left: 72pt;text-indent: 0pt;text-align: left;">15.6  <span style=" color: #00AEEF;">Other Operations</span></p><p style="padding-top: 12pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">Other relational operations and extended relational operations— such as duplicate elim- ination, projection, set operations, outer join, and aggregation — can be implemented as outlined in Section 15.6.1 through Section 15.6.5.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 119pt;text-indent: 0pt;text-align: left;">15.6.1 Duplicate Elimination</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">We can implement duplicate elimination easily by sorting. Identical tuples will appear adjacent to each other as a result of sorting, and all but one copy can be removed. With external sort–merge, duplicates found while a run is being created can be removed before the run is written to disk, thereby reducing the number of block transfers. The remaining duplicates can be eliminated during merging, and the ﬁnal sorted run has no duplicates. The worst-case cost estimate for duplicate elimination is the same as the worst-case cost estimate for sorting of the relation.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">We can also implement duplicate elimination by hashing, as in the hash-join algo- rithm. First, the relation is partitioned on the basis of a hash function on the whole tuple. Then, each partition is read in, and an in-memory hash index is constructed.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">While constructing the hash index, a tuple is inserted only if it is not already present. Otherwise, the tuple is discarded. After all tuples in the partition have been processed, the tuples in the hash index are written to the result. The cost estimate is the same as that for the cost of processing (partitioning and reading each partition) of the build relation in a hash join.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Because of the relatively high cost of duplicate elimination, <span class="s44">SQL </span>requires an explicit request by the user to remove duplicates; otherwise, the duplicates are retained.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 88pt;text-indent: 0pt;text-align: left;">15.6.2 Projection</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">We can implement projection easily by performing projection on each tuple, which gives a relation that could have duplicate records, and then removing duplicate rec- ords. Duplicates can be eliminated by the methods described in Section 15.6.1. If the at- tributes in the projection list include a key of the relation, no duplicates will exist; hence, duplicate elimination is not required. Generalized projection can be implemented in the same way as projection.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 88pt;text-indent: 0pt;text-align: left;">15.6.3 Set Operations</p><p class="s13" style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;"><span class="p">We can implement the </span>union<span class="p">, </span>intersection<span class="p">, and </span>set-diﬀerence <span class="p">operations by ﬁrst sorting both relations, and then scanning once through each of the sorted relations to produce the result. In </span>r <span class="s15">∪ </span>s<span class="p">, when a concurrent scan of both relations reveals the same tuple in both ﬁles, only one of the tuples is retained. The result of </span>r <span class="s15">∩ </span>s <span class="p">will contain only those tuples that appear in both relations. We implement </span>set diﬀerence<span class="p">, </span>r <span class="s15">− </span>s<span class="p">, similarly, by retaining tuples in </span>r <span class="p">only if they are absent in </span>s<span class="p">.</span></p><p class="s13" style="padding-top: 1pt;padding-left: 88pt;text-indent: 17pt;line-height: 90%;text-align: justify;"><span class="p">For all these operations, only one scan of the two sorted input relations is required, so the cost is </span>b<span class="s97">r </span><span class="s15">+ </span>b<span class="s97">s </span><span class="p">block transfers if the relations are sorted in the same order. As- suming a worst case of one block buﬀer for each relation, a total of </span>b<span class="s97">r </span><span class="s15">+ </span>b<span class="s97">s </span><span class="p">disk seeks would be required in addition to </span>b<span class="s145">r </span><span class="s15">+ </span>b<span class="s145">s </span><span class="p">block transfers. The number of seeks can be reduced by allocating extra buﬀer blocks.</span></p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">If the relations are not sorted initially, the cost of sorting has to be included. Any sort order can be used in the evaluation of set operations, provided that both inputs have that same sort order.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Hashing provides another way to implement these set operations. The ﬁrst step in each case is to partition the two relations by the same hash function and thereby create</p><p class="s106" style="text-indent: 0pt;line-height: 6pt;text-align: left;">h</p><p style="text-indent: 0pt;text-align: left;"/><p class="s106" style="text-indent: 0pt;line-height: 6pt;text-align: left;">h</p><p style="text-indent: 0pt;text-align: left;"/><p class="s13" style="padding-left: 59pt;text-indent: 0pt;line-height: 12pt;text-align: center;"><span class="p">the partitions </span>r<span class="s93">0</span><span class="s94">, </span>r<span class="s93">1</span><span class="s94">, </span><span class="s15">… </span><span class="p">, </span>r<span class="s145">n </span><span class="p">and </span>s<span class="s93">0</span><span class="s94">, </span>s<span class="s93">1</span><span class="s94">, </span><span class="s15">… </span><span class="p">, </span>s<span class="s145">n </span><span class="p">. Depending on the operation, the system</span></p><p style="padding-left: 88pt;text-indent: 0pt;text-align: left;">then takes these steps on each partition <i>i </i><span class="s15">= </span>0, 1, <span class="s15">… </span>, <i>n</i><span class="s145">h</span>:</p><p class="s13" style="padding-top: 11pt;padding-left: 91pt;text-indent: 0pt;text-align: left;"><span class="s39">• </span>r <span class="s15">∪ </span>s</p><p style="padding-top: 7pt;padding-left: 122pt;text-indent: 0pt;text-align: left;"><span class="s63">1. </span>Build an in-memory hash index on <i>r</i><span class="s145">i</span>.</p><p style="padding-top: 4pt;padding-left: 121pt;text-indent: 0pt;text-align: left;"><span class="s63">2. </span>Add the tuples in <i>s</i><span class="s97">i </span>to the hash index only if they are not already present.</p><p class="s63" style="padding-top: 4pt;padding-left: 121pt;text-indent: 0pt;text-align: left;">3. <span class="p">Add the tuples in the hash index to the result.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="493" height="616" alt="image" src="Image_2780.png"/></span></p><p class="s73" style="padding-left: 229pt;text-indent: 0pt;text-align: justify;">Note 15.1 <span class="s146">Answering Keyword Queries</span></p><p style="padding-top: 3pt;padding-left: 129pt;text-indent: 3pt;text-align: justify;">Keyword search on documents is widely used in the context of web search. In its simplest form, a keyword query provides a set of words <i>K</i><span class="s98">1</span>, <i>K</i><span class="s98">2</span>, <span class="s15">… </span>, <i>K</i><span class="s97">n</span>, and the goal is to ﬁnd documents <i>d</i><span class="s97">i </span>from a collection of documents <i>D </i>such that <i>d</i><span class="s97">i </span>con- tains all the keywords in the query. Real-life keyword search is more complicated, since it requires ranking of documents based on various metrics such <span class="s44">TF–IDF </span>and PageRank, as we saw earlier in Section 8.3.</p><p class="s13" style="padding-top: 1pt;padding-left: 129pt;text-indent: 17pt;line-height: 91%;text-align: justify;"><span class="p">Documents that contain a speciﬁed keyword can be located eﬃciently by using an index (often referred to as an </span><span class="s63">inverted index</span><span class="p">) that maps each keyword </span>K<span class="s97">i </span><span class="p">to a list </span>S<span class="s97">i </span><span class="p">of identiﬁers of the documents that contain </span>K<span class="s97">i</span><span class="p">. The list is kept sorted. For example, if documents </span>d<span class="s130">1</span><span class="s94">, </span>d<span class="s130">9 </span><span class="s94">and </span>d<span class="s130">21 </span><span class="s94">contain the term “Silberschatz”, the inverted list for the keyword Silberschatz would be “</span>d<span class="s130">1</span><span class="s94">; </span>d<span class="s130">9</span><span class="s94">; </span>d<span class="s130">21</span><span class="s94">”. Compression techniques are used to reduce the size of the inverted lists. A B</span><span class="s181">+</span><span class="p">-tree index can be used to map each keyword </span>K<span class="s145">i </span><span class="p">to its associated inverted list </span>S<span class="s145">i</span><span class="p">.</span></p><p class="s13" style="padding-left: 129pt;text-indent: 17pt;line-height: 82%;text-align: justify;"><span class="p">To answer a query with keyword </span>K<span class="s130">1</span><span class="s94">, </span>K<span class="s130">2</span><span class="s94">, </span><span class="s15">… </span><span class="p">, </span>K<span class="s97">n</span><span class="p">, we retrieve the inverted list </span>S<span class="s97">i </span><span class="p">for each keyword </span>K<span class="s97">i</span><span class="p">, and then compute the intersection </span>S<span class="s130">1 </span><span class="s15">∩ </span>S<span class="s130">2 </span><span class="s15">∩ </span><span class="s86">⋯ </span><span class="s15">∩ </span>S<span class="s97">n </span><span class="p">to ﬁnd documents that appear in all the lists. Since the lists are sorted, the intersection can</span></p><p style="padding-left: 129pt;text-indent: 0pt;text-align: justify;">be eﬃciently implemented by merging the lists using concurrent scans of all the lists. Many information-retrieval systems return documents that contain several, even if not all, of the keywords; the merge step can be easily modiﬁed to output documents that contain at least <i>k </i>of the <i>n </i>keywords.</p><p style="padding-left: 129pt;text-indent: 17pt;text-align: justify;">To support ranking of keyword-query results, extra information can be stored in each inverted list, including the inverse document frequency of the term, and for each document the PageRank, the term frequency of the term, as well as the positions within the document where the term occurs. This information can be used to compute scores that are then used to rank the documents. For example, documents where the keywords occur close to each other may receive a higher score for keyword proximity than those where they occur farther from each other. The keyword proximity score may be combined with the <span class="s44">TF–IDF </span>score, and PageR- ank to compute an overall score. Documents are then ranked on this score. Since most web searches retrieve only the top few answers, search engines incorporate a number of optimizations that help to ﬁnd the top few answers eﬃciently, without computing the full list and then ﬁnding the ranking. References providing further details may be found in the Further Reading section at the end of the chapter.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-left: 123pt;text-indent: 0pt;text-align: left;"><span class="s39">• </span>r <span class="s15">∩ </span>s</p><p style="padding-top: 6pt;padding-left: 153pt;text-indent: 0pt;text-align: left;"><span class="s63">1. </span>Build an in-memory hash index on <i>r</i><span class="s97">i</span>.</p><p style="padding-top: 4pt;padding-left: 165pt;text-indent: -11pt;line-height: 90%;text-align: left;"><span class="s63">2. </span>For each tuple in <i>s</i><span class="s145">i</span>, probe the hash index and output the tuple to the result only if it is already present in the hash index.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-top: 4pt;padding-left: 91pt;text-indent: 0pt;text-align: left;"><span class="s39">• </span>r <span class="s15">− </span>s</p><p style="padding-top: 7pt;padding-left: 122pt;text-indent: 0pt;text-align: left;"><span class="s63">1. </span>Build an in-memory hash index on <i>r</i><span class="s145">i</span>.</p><p style="padding-top: 5pt;padding-left: 133pt;text-indent: -11pt;line-height: 87%;text-align: left;"><span class="s63">2. </span>For each tuple in <i>s</i><span class="s97">i</span>, probe the hash index, and, if the tuple is present in the hash index, delete it from the hash index.</p><p class="s63" style="padding-top: 6pt;padding-left: 121pt;text-indent: 0pt;text-align: left;">3. <span class="p">Add the tuples remaining in the hash index to the result.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 88pt;text-indent: 0pt;text-align: left;">15.6.4 Outer Join</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">Recall the <i>outer-join operations </i>described in Section 4.1.3. For example, the natural left outer join <i>takes </i><span class="s15">⟕ </span><i>student </i>contains the join of <i>takes </i>and <i>student</i>, and, in addition, for each <i>takes </i>tuple <i>t </i>that has no matching tuple in <i>student </i>(i.e, where <span class="s69">ID </span>is not in <i>student</i>), the following tuple <i>t</i><span class="s98">1</span> is added to the result. For all attributes in the schema of <i>takes</i>, tuple <i>t</i><span class="s98">1</span> has the same values as tuple <i>t</i>. The remaining attributes (from the schema of <i>student</i>) of tuple <i>t</i><span class="s98">1</span> contain the value null.</p><p style="padding-left: 106pt;text-indent: 0pt;text-align: justify;">We can implement the outer-join operations by using one of two strategies:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-left: 113pt;text-indent: -16pt;line-height: 92%;text-align: justify;"><span class="s63">1. </span><span class="p">Compute the corresponding join, and then add further tuples to the join result to get the outer-join result. Consider the left outer-join operation and two relations: </span>r<span class="p">(</span>R<span class="p">) and </span>s<span class="p">(</span>S<span class="p">). To evaluate </span>r <span class="s15">⟕</span><span class="s137">θ</span><span class="s15"> </span>s<span class="p">, we ﬁrst compute </span>r <span class="s86">⋈</span><span class="s171">θ </span>s <span class="p">and save that result as temporary relation </span>q<span class="s98">1</span><span class="p">. Next, we compute </span>r <span class="s15">− Π</span><span class="s123">R</span><span class="p">(</span>q<span class="s98">1</span><span class="p">) to obtain those tuples in</span></p><p class="s13" style="padding-left: 113pt;text-indent: 0pt;text-align: justify;">r <span class="p">that do not participate in the theta join. We can use any of the algorithms for computing the joins, projection, and set diﬀerence described earlier to compute the outer joins. We pad each of these tuples with null values for attributes from </span>s<span class="p">, and add it to </span>q<span class="s98">1</span><span class="p"> to get the result of the outer join.</span></p><p class="s13" style="padding-left: 113pt;text-indent: 14pt;line-height: 92%;text-align: justify;"><span class="p">The right outer-join operation </span>r <span class="s15">⟖ </span><span class="s137">θ</span><span class="s15"> </span>s <span class="p">is equivalent to </span>s <span class="s15">⟕</span><span class="s137">θ</span><span class="s15"> </span>r <span class="p">and can therefore be implemented in a symmetric fashion to the left outer join. We can implement the full outer-join operation </span>r <span class="s15">⟗ </span><span class="s137">θ</span><span class="s15"> </span>s <span class="p">by computing the join </span>r <span class="s86">⋈ </span>s <span class="p">and then adding the extra tuples of both the left and right outer-join operations, as before.</span></p><p class="s63" style="padding-top: 6pt;padding-left: 113pt;text-indent: -17pt;text-align: justify;">2. <span class="p">Modify the join algorithms. It is easy to extend the nested-loop join algorithms to compute the left outer join: Tuples in the outer relation that do not match any tuple in the inner relation are written to the output after being padded with null values. However, it is hard to extend the nested-loop join to compute the full outer join.</span></p><p style="padding-left: 113pt;text-indent: 15pt;text-align: justify;">Natural outer joins and outer joins with an equi-join condition can be com- puted by extensions of the merge-join and hash-join algorithms. Merge join can be extended to compute the full outer join as follows: When the merge of the two relations is being done, tuples in either relation that do not match any tuple in the other relation can be padded with nulls and written to the output. Similarly, we can extend merge join to compute the left and right outer joins by writing out nonmatching tuples (padded with nulls) from only one of the relations. Since the relations are sorted, it is easy to detect whether or not a tuple matches any tuples</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 145pt;text-indent: 0pt;text-align: justify;">from the other relation. For example, when a merge join of <i>takes </i>and <i>student </i>is done, the tuples are read in sorted order of <span class="s69">ID</span>, and it is easy to check, for each tuple, whether there is a matching tuple in the other.</p><p style="padding-left: 145pt;text-indent: 15pt;text-align: justify;">The cost estimates for implementing outer joins using the merge-join algo- rithm are the same as are those for the corresponding join. The only diﬀerence lies in the size of the result, and therefore in the block transfers for writing it out, which we did not count in our earlier cost estimates.</p><p style="padding-left: 145pt;text-indent: 14pt;text-align: justify;">The extension of the hash-join algorithm to compute outer joins is left for you to do as an exercise (Exercise 15.21).</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 119pt;text-indent: 0pt;text-align: left;">15.6.5 Aggregation</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: left;">Recall the aggregation function (operator), discussed in Section 3.7. For example, the function</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_2781.png"/></span></p><p style="padding-left: 243pt;text-indent: 0pt;text-align: left;"><b>select </b><i>dept name</i>, <b>avg </b>(<i>salary</i>)</p><p class="s46" style="padding-left: 243pt;text-indent: 0pt;text-align: left;">from <i>instructor</i></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_2782.png"/></span></p><p class="s46" style="padding-left: 243pt;text-indent: 0pt;text-align: left;">group by <i>dept name</i><span class="p">;</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 119pt;text-indent: 0pt;text-align: left;">computes the average salary in each university department.</p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_2783.png"/></span></p><p style="padding-left: 119pt;text-indent: 17pt;text-align: right;">The aggregation operation can be implemented in the same way as duplicate elim- ination. We use either sorting or hashing, just as we did for duplicate elimination, but based on the grouping attributes (<i>dept name </i>in the preceding example). However, in- stead of eliminating tuples with the same value for the grouping attribute, we gather them into groups and apply the aggregation operations on each group to get the result. The cost estimate for implementing the aggregation operation is the same as the cost of duplicate elimination for aggregate functions such as <b>min</b>, <b>max</b>, <b>sum</b>, <b>count</b>, and</p><p class="s46" style="padding-left: 119pt;text-indent: 0pt;text-align: left;">avg<span class="p">.</span></p><p style="padding-left: 119pt;text-indent: 17pt;text-align: right;">Instead of gathering all the tuples in a group and then applying the aggregation operations, we can implement the aggregation operations <b>sum</b>, <b>min</b>, <b>max</b>, <b>count</b>, and <b>avg </b>on the ﬂy as the groups are being constructed. For the case of <b>sum</b>, <b>min</b>, and <b>max</b>, when two tuples in the same group are found, the system replaces them with a single tuple containing the <b>sum</b>, <b>min</b>, or <b>max</b>, respectively, of the columns being aggregated. For the <b>count </b>operation, it maintains a running count for each group for which a tuple has been found. Finally, we implement the <b>avg </b>operation by computing the sum and the count values on the ﬂy, and ﬁnally dividing the sum by the count to get the average. If all tuples of the result ﬁt in memory, the sort-based and the hash-based imple- mentations do not need to write any tuples to disk. As the tuples are read in, they can be inserted in a sorted tree structure or in a hash index. When we use on-the-ﬂy ag- gregation techniques, only one tuple needs to be stored for each of the groups. Hence, the sorted tree structure or hash index ﬁts in memory, and the aggregation can be pro- cessed with just <i>b</i><span class="s97">r </span>block transfers (and 1 seek) instead of the 3<i>b</i><span class="s97">r </span>transfers (and a worst</p><p style="padding-left: 119pt;text-indent: 0pt;line-height: 13pt;text-align: left;">case of up to 2<i>b</i><span class="s97">r </span>seeks) that would be required otherwise.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part284.htm">&lt; 上一个</a><span> | </span><a href="../database.html">内容</a><span> | </span><a href="part286.htm">下一个 &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
