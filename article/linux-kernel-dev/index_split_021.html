<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>Linux Kernel Development, Third Edition</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
<div id="filepos778361" style="height:0pt"></div><h2 class="calibre_4" id="calibre_pb_59"><span class="bold">12. Memory Management</span></h2><div class="calibre_5"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos778524"> </div>
<p class="calibre_2">Memory allocation inside the kernel is not as easy as memory allocation outside the kernel. Simply put, the kernel lacks luxuries enjoyed by user-space. Unlike user-space, the kernel is not always afforded the capability to easily allocate memory. For example, the kernel cannot easily deal with memory allocation errors, and the kernel often cannot sleep. Because of these limitations, and the need for a lightweight memory allocation scheme, getting hold of memory in the kernel is more complicated than in user-space. This is not to say that, from a programmer’s point of view, kernel memory allocations are difficult—just different.</p><div class="calibre_3"> </div>
<p class="calibre_2">This chapter discusses the methods used to obtain memory inside the kernel. Before you can delve into the actual allocation interfaces, however, you need to understand how the kernel handles memory.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos779523"> </div>
<h3 class="calibre_21"><span class="bold">Pages</span></h3><div class="calibre_22"> </div>
<p class="calibre_2">The kernel treats physical pages as the basic unit of memory management. Although the processor’s smallest addressable unit is a byte or a word, the memory management unit (MMU, the hardware that manages memory and performs virtual to physical address translations) typically deals in pages. Therefore, the MMU maintains the system’s page tables with page-sized granularity (hence their name). In terms of virtual memory, pages are the smallest unit that matters.</p><div class="calibre_3"> </div>
<p class="calibre_2">As you can see in <a href="index_split_028.html#filepos1252328">Chapter 19</a>, “Portability,” each architecture defines its own page size. Many architectures even support multiple page sizes. Most 32-bit architectures have 4KB pages, whereas most 64-bit architectures have 8KB pages. This implies that on a machine with 4KB pages and 1GB of memory, physical memory is divided into 262,144 distinct pages.</p><div class="calibre_3"> </div>
<p class="calibre_2">The kernel represents <em class="calibre4">every</em> physical page on the system with a <code class="calibre6"><span class="calibre7">struct page</span></code> structure. This structure is defined in <code class="calibre6"><span class="calibre7">&lt;linux/mm_types.h&gt;</span></code>. I’ve simplified the definition, removing two confusing unions that do not help color our discussion of the basics:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00162.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2"><a id="filepos781081"></a>Let’s look at the important fields. The <code class="calibre6"><span class="calibre7">flags</span></code> field stores the status of the page. Such flags include whether the page is dirty or whether it is locked in memory. Bit flags represent the various values, so at least 32 different flags are simultaneously available. The flag values are defined in <code class="calibre6"><span class="calibre7">&lt;linux/page-flags.h&gt;</span></code>.</p><div class="calibre_3"> </div>
<p class="calibre_2">The <code class="calibre6"><span class="calibre7">_count</span></code> field stores the usage count of the page—that is, how many references there are to this page. When this count reaches negative one, no one is using the page, and it becomes available for use in a new allocation. Kernel code should not check this field directly but instead use the function <code class="calibre6"><span class="calibre7">page_count()</span></code>, which takes a <code class="calibre6"><span class="calibre7">page</span></code> structure as its sole parameter. Although internally <code class="calibre6"><span class="calibre7">_count</span></code> is negative one when the page is free, <code class="calibre6"><span class="calibre7">page_count()</span></code> returns zero to indicate free and a positive nonzero integer when the page is in use. A page may be used by the page cache (in which case the <code class="calibre6"><span class="calibre7">mapping</span></code> field points to the <code class="calibre6"><span class="calibre7">address_space</span></code> object associated with this page), as private data (pointed at by <code class="calibre6"><span class="calibre7">private</span></code>), or as a mapping in a process’s page table.</p><div class="calibre_3"> </div>
<p class="calibre_2">The <code class="calibre6"><span class="calibre7">virtual</span></code> field is the page’s virtual address. Normally, this is simply the address of the page in virtual memory. Some memory (called high memory) is not permanently mapped in the kernel’s address space. In that case, this field is <code class="calibre6"><span class="calibre7">NULL</span></code>, and the page must be dynamically mapped if needed. We discuss high memory shortly.</p><div class="calibre_3"> </div>
<p class="calibre_2">The important point to understand is that the <code class="calibre6"><span class="calibre7">page</span></code> structure is associated with physical pages, not virtual pages. Therefore, what the structure describes is transient at best. Even if the data contained in the page continues to exist, it might not always be associated with the same <code class="calibre6"><span class="calibre7">page</span></code> structure because of swapping and so on. The kernel uses this data structure to describe the associated physical page. The data structure’s goal is to describe physical memory, not the data contained therein.</p><div class="calibre_3"> </div>
<p class="calibre_2">The kernel uses this structure to keep track of all the pages in the system, because the kernel needs to know whether a page is free (that is, if the page is not allocated). If a page is not free, the kernel needs to know who owns the page. Possible owners include user-space processes, dynamically allocated kernel data, static kernel code, the page cache, and so on.</p><div class="calibre_3"> </div>
<p class="calibre_2">Developers are often surprised that an instance of this structure is allocated for each physical page in the system. They think, “<em class="calibre4">What a lot of memory wasted!”</em> Let’s look at just how bad (or good) the space consumption is from all these pages. Assume struct <code class="calibre6"><span class="calibre7">page</span></code> consumes 40 bytes of memory, the system has 8KB physical pages, and the system has 4GB of physical memory. In that case, there are about 524,288 pages and <code class="calibre6"><span class="calibre7">page</span></code> structures on the system. The <code class="calibre6"><span class="calibre7">page</span></code> structures consume 20MB: perhaps a surprisingly large number <a id="filepos784771"></a>in absolute terms, but only a small fraction of a percent relative to the system’s 4GB—not too high a cost for managing all the system’s physical pages.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos784992"> </div>
<h3 class="calibre_21"><span class="bold">Zones</span></h3><div class="calibre_22"> </div>
<p class="calibre_2">Because of hardware limitations, the kernel cannot treat all pages as identical. Some pages, because of their physical address in memory, cannot be used for certain tasks. Because of this limitation, the kernel divides pages into different <em class="calibre4">zones</em>. The kernel uses the zones to group pages of similar properties. In particular, Linux has to deal with two shortcomings of hardware with respect to memory addressing:</p><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• Some hardware devices can perform DMA (direct memory access) to only certain memory addresses.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• Some architectures can physically addressing larger amounts of memory than they can virtually address. Consequently, some memory is not permanently mapped into the kernel address space.</p></blockquote><div class="calibre_3"> </div>
<p class="calibre_2">Because of these constraints, Linux has four primary memory zones:</p><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• <code class="calibre6"><span class="calibre7">ZONE_DMA</span></code>—This zone contains pages that can undergo DMA.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• <code class="calibre6"><span class="calibre7">ZONE_DMA32</span></code>—Like <code class="calibre6"><span class="calibre7">ZOME_DMA</span></code>, this zone contains pages that can undergo DMA. Unlike <code class="calibre6"><span class="calibre7">ZONE_DMA</span></code>, these pages are accessible only by 32-bit devices. On some architectures, this zone is a larger subset of memory.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• <code class="calibre6"><span class="calibre7">ZONE_NORMAL</span></code>—This zone contains normal, regularly mapped, pages.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• <code class="calibre6"><span class="calibre7">ZONE_HIGHMEM</span></code>—This zone contains “high memory,” which are pages not permanently mapped into the kernel’s address space.</p></blockquote><div class="calibre_3"> </div>
<p class="calibre_2">These zones, and two other, less notable ones, are defined in <code class="calibre6"><span class="calibre7">&lt;linux/mmzone.h&gt;</span></code>.</p><div class="calibre_3"> </div>
<p class="calibre_2">The actual use and layout of the memory zones is architecture-dependent. For example, some architectures have no problem performing DMA into any memory address. In those architectures, <code class="calibre6"><span class="calibre7">ZONE_DMA</span></code> is empty and <code class="calibre6"><span class="calibre7">ZONE_NORMAL</span></code> is used for allocations regardless of their use. As a counterexample, on the x86 architecture, ISA devices cannot perform DMA into the full 32-bit address space<sup class="calibre8"><a id="filepos787800" href="#filepos788091">1</a></sup> because ISA devices can access only the first 16MB of physical memory. Consequently, <code class="calibre6"><span class="calibre7">ZONE_DMA</span></code> on x86 consists of all memory in the range 0MB–16MB.</p><div class="calibre_3"> </div>
<p class="calibre_2"><sup class="calibre8"><a id="filepos788091" href="#filepos787800">1</a></sup>
<em class="calibre4">Similarly, some broken PCI devices can perform DMA into only a 24-bit address space.</em></p><div class="calibre_3"> </div>
<p class="calibre_2"><code class="calibre6"><span class="calibre7">ZONE_HIGHMEM</span></code> works in the same regard. What an architecture can and cannot directly map varies. On 32-bit x86 systems, <code class="calibre6"><span class="calibre7">ZONE_HIGHMEM</span></code> is all memory above the physical 896MB mark. On other architectures, <code class="calibre6"><span class="calibre7">ZONE_HIGHMEM</span></code> is empty because all memory is <a id="filepos788637"></a>directly mapped. The memory contained in <code class="calibre6"><span class="calibre7">ZONE_HIGHMEM</span></code> is called <em class="calibre4">high memory</em>.<sup class="calibre8"><a id="filepos788762" href="#filepos788934">2</a></sup> The rest of the system’s memory is called <em class="calibre4">low memory</em>.</p><div class="calibre_3"> </div>
<p class="calibre_2"><sup class="calibre8"><a id="filepos788934" href="#filepos788762">2</a></sup>
<em class="calibre4">Linux’s high memory has nothing to do with high memory in DOS, which works around limitations of DOS and x86’s “real mode” processor state.</em></p><div class="calibre_3"> </div>
<p class="calibre_2"><code class="calibre6"><span class="calibre7">ZONE_NORMAL</span></code> tends to be whatever is left over after the previous two zones claim their requisite shares. On x86, for example, <code class="calibre6"><span class="calibre7">ZONE_NORMAL</span></code> is all physical memory from 16MB to 896MB. On other (more fortunate) architectures, <code class="calibre6"><span class="calibre7">ZONE_NORMAL</span></code> is all available memory. <a href="#filepos789721">Table 12.1</a> is a listing of each zone and its consumed pages on x86-32.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos789721"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Table 12.1. Zones on x86-32</span></span></p><div class="calibre_24"> </div>
<p class="calibre_23"><img alt="image" src="images/00163.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">Linux partitions the system’s pages into zones to have a pooling in place to satisfy allocations as needed. For example, having a <code class="calibre6"><span class="calibre7">ZONE_DMA</span></code> pool gives the kernel the capability to satisfy memory allocations needed for DMA. If such memory is needed, the kernel can simply pull the required number of pages from <code class="calibre6"><span class="calibre7">ZONE_DMA</span></code>. Note that the zones do not have any physical relevance but are simply logical groupings used by the kernel to keep track of pages.</p><div class="calibre_3"> </div>
<p class="calibre_2">Although some allocations may require pages from a particular zone, other allocations may pull from multiple zones. For example, although an allocation for DMA-able memory must originate from <code class="calibre6"><span class="calibre7">ZONE_DMA</span></code>, a normal allocation can come from <code class="calibre6"><span class="calibre7">ZONE_DMA</span></code> or <code class="calibre6"><span class="calibre7">ZONE_NORMAL</span></code> but not both; allocations cannot cross zone boundaries. The kernel prefers to satisfy normal allocations from the normal zone, of course, to save the pages in <code class="calibre6"><span class="calibre7">ZONE_DMA</span></code> for allocations that need it. But if push comes to shove (say, if memory should get low), the kernel can dip its fingers in whatever zone is available and suitable.</p><div class="calibre_3"> </div>
<p class="calibre_2">Not all architectures define all zones. For example, a 64-bit architecture such as Intel’s x86-64 can fully map and handle 64-bits of memory. Thus, x86-64 has no <code class="calibre6"><span class="calibre7">ZONE_HIGHMEM</span></code> and all physical memory is contained within <code class="calibre6"><span class="calibre7">ZONE_DMA</span></code> and <code class="calibre6"><span class="calibre7">ZONE_NORMAL</span></code>.</p><div class="calibre_3"> </div>
<p class="calibre_2">Each zone is represented by <code class="calibre6"><span class="calibre7">struct zone</span></code>, which is defined in <code class="calibre6"><span class="calibre7">&lt;linux/mmzone.h&gt;</span></code>:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00164.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2"><a id="filepos792056"></a>The structure is big, but only three zones are in the system and, thus, only three of these structures. Let’s look at the more important fields.</p><div class="calibre_3"> </div>
<p class="calibre_2">The <code class="calibre6"><span class="calibre7">lock</span></code> field is a spin lock that protects the structure from concurrent access. Note that it protects just the structure and not all the pages that reside in the zone. A specific lock does not protect individual pages, although parts of the kernel may lock the data that happens to reside in said pages.</p><div class="calibre_3"> </div>
<p class="calibre_2">The <code class="calibre6"><span class="calibre7">watermark</span></code> array holds the minimum, low, and high watermarks for this zone. The kernel uses watermarks to set benchmarks for suitable per-zone memory consumption, varying its aggressiveness as the watermarks vary vis-à-vis free memory.</p><div class="calibre_3"> </div>
<p class="calibre_2">The <code class="calibre6"><span class="calibre7">name</span></code> field is, unsurprisingly, a <code class="calibre6"><span class="calibre7">NULL</span></code>-terminated string representing the name of this zone. The kernel initializes this value during boot in <code class="calibre6"><span class="calibre7">mm/page_alloc.c</span></code>, and the three zones are given the names DMA, Normal, and HighMem.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos793360"> </div>
<h3 class="calibre_21"><span class="bold">Getting Pages</span></h3><div class="calibre_22"> </div>
<p class="calibre_2">Now with an understanding of how the kernel manages memory—via pages, zones, and so on—let’s look at the interfaces the kernel implements to enable you to allocate and free memory within the kernel.</p><div class="calibre_3"> </div>
<p class="calibre_2">The kernel provides one low-level mechanism for requesting memory, along with several interfaces to access it. All these interfaces allocate memory with page-sized granularity and are declared in <code class="calibre6"><span class="calibre7">&lt;linux/gfp.h&gt;</span></code>. The core function is</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">struct page * alloc_pages(gfp_t gfp_mask, unsigned int order)</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2"><a id="filepos794230"></a>This allocates 2<sup class="calibre8">order</sup> (that is, <code class="calibre6"><span class="calibre7">1 &lt;&lt; order</span></code>) contiguous physical pages and returns a pointer to the first page’s <code class="calibre6"><span class="calibre7">page</span></code> structure; on error it returns <code class="calibre6"><span class="calibre7">NULL</span></code>. We look at the <code class="calibre6"><span class="calibre7">gfp_t</span></code> type and <code class="calibre6"><span class="calibre7">gfp_mask</span></code> parameter in a later section. You can convert a given page to its logical address with the function</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">void * page_address(struct page *page)</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">This returns a pointer to the logical address where the given physical page currently resides. If you have no need for the actual <code class="calibre6"><span class="calibre7">struct page</span></code>, you can call</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">unsigned long __get_free_pages(gfp_t gfp_mask, unsigned int order)</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">This function works the same as <code class="calibre6"><span class="calibre7">alloc_pages()</span></code>, except that it directly returns the logical address of the first requested page. Because the pages are contiguous, the other pages simply follow from the first.</p><div class="calibre_3"> </div>
<p class="calibre_2">If you need only one page, two functions are implemented as wrappers to save you a bit of typing:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">struct page * alloc_page(gfp_t gfp_mask)<br class="calibre1"/>unsigned long __get_free_page(gfp_t gfp_mask)</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">These functions work the same as their brethren but pass zero for the order (2<sup class="calibre8">0</sup> = one page).</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos796110"> </div>
<h4 class="calibre_27"><span class="calibre3">Getting Zeroed Pages</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">If you need the returned page filled with zeros, use the function</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">unsigned long get_zeroed_page(unsigned int gfp_mask)</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">This function works the same as <code class="calibre6"><span class="calibre7">__get_free_page()</span></code>, except that the allocated page is then zero-filled—every bit of every byte is unset. This is useful for pages given to user-space because the random garbage in an allocated page is not so random; it might contain sensitive data. All data must be zeroed or otherwise cleaned before it is returned to user-space to ensure system security is not compromised. <a href="#filepos797098">Table 12.2</a> is a listing of all the low-level page allocation methods.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos797098"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Table 12.2. Low-Level Page Allocation Methods</span></span></p><div class="calibre_24"> </div>
<p class="calibre_23"><img alt="image" src="images/00165.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos797393"> </div>
<h4 class="calibre_27"><span class="calibre3">Freeing Pages</span></h4><div class="calibre_24"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos797508"> </div>
<p class="calibre_2">A family of functions enables you to free allocated pages when you no longer need them:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">void __free_pages(struct page *page, unsigned int order)<br class="calibre1"/>void free_pages(unsigned long addr, unsigned int order)<br class="calibre1"/>void free_page(unsigned long addr)</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">You must be careful to free only pages you allocate. Passing the wrong <code class="calibre6"><span class="calibre7">struct page</span></code> or address, or the incorrect <code class="calibre6"><span class="calibre7">order</span></code>, can result in corruption. Remember, the kernel trusts itself. Unlike with user-space, the kernel will happily hang itself if you ask it.</p><div class="calibre_3"> </div>
<p class="calibre_2">Let’s look at an example. Here, we want to allocate eight pages:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00166.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">And here we free the eight pages, after we are done using them:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">free_pages(page, 3);<br class="calibre1"/><br class="calibre1"/>/*<br class="calibre1"/> * our pages are now freed and we should no<br class="calibre1"/> * longer access the address stored in 'page'<br class="calibre1"/> */</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">The <code class="calibre6"><span class="calibre7">GFP_KERNEL</span></code> parameter is an example of a <code class="calibre6"><span class="calibre7">gfp_mask</span></code> flag. It is discussed shortly.</p><div class="calibre_3"> </div>
<p class="calibre_2">Make note of the error checking after the call to <code class="calibre6"><span class="calibre7">__get_free_pages()</span></code>. A kernel allocation <em class="calibre4">can</em> fail, and your code <em class="calibre4">must</em> check for and handle such errors. This might mean unwinding everything you have done thus far. It therefore often makes sense to allocate your memory at the start of the routine to make handling the error easier. Otherwise, by the time you attempt to allocate memory, it may be rather hard to bail out.</p><div class="calibre_3"> </div>
<p class="calibre_2">These low-level page functions are useful when you need page-sized chunks of physically contiguous pages, especially if you need exactly a single page or two. For more general byte-sized allocations, the kernel provides <code class="calibre6"><span class="calibre7">kmalloc()</span></code>.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos799955"> </div>
<h3 class="calibre_21"><span class="bold"><code class="calibre18"><span class="calibre15">kmalloc()</span></code></span></h3><div class="calibre_22"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos800102"> </div>
<p class="calibre_2">The <code class="calibre6"><span class="calibre7">kmalloc()</span></code> function’s operation is similar to that of user-space’s familiar <code class="calibre6"><span class="calibre7">malloc()</span></code> routine, with the exception of the additional <code class="calibre6"><span class="calibre7">flags</span></code> parameter. The <code class="calibre6"><span class="calibre7">kmalloc()</span></code> function is a simple interface for obtaining kernel memory in byte-sized chunks. If you need whole pages, the previously discussed interfaces might be a better choice. For most kernel allocations, however, <code class="calibre6"><span class="calibre7">kmalloc()</span></code> is the preferred interface.</p><div class="calibre_3"> </div>
<p class="calibre_2">The function is declared in <code class="calibre6"><span class="calibre7">&lt;linux/slab.h&gt;</span></code>:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">void * kmalloc(size_t size, gfp_t flags)</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">The function returns a pointer to a region of memory that is at <em class="calibre4">least</em>
<code class="calibre6"><span class="calibre7">size</span></code> bytes in length.<sup class="calibre8"><a id="filepos801217" href="#filepos801693">3</a></sup> The region of memory allocated is physically contiguous. On error, it returns <code class="calibre6"><span class="calibre7">NULL</span></code>. Kernel allocations always succeed, unless an insufficient amount of memory is available. Thus, you must check for <code class="calibre6"><span class="calibre7">NULL</span></code> after all calls to <code class="calibre6"><span class="calibre7">kmalloc()</span></code> and handle the error appropriately.</p><div class="calibre_3"> </div>
<p class="calibre_2"><sup class="calibre8"><a id="filepos801693" href="#filepos801217">3</a></sup>
<em class="calibre4"><code class="calibre6"><span class="calibre7">kmalloc()</span></code> may allocate more than you asked, although you have no way of knowing how much more! Because at its heart the kernel allocator is page-based, some allocations may be rounded up to fit within the available memory. The kernel never returns less memory than requested. If the kernel is unable to find at least the requested amount, the allocation fails and the function returns <code class="calibre6"><span class="calibre7">NULL</span></code>.</em></p><div class="calibre_3"> </div>
<p class="calibre_2">Let’s look at an example. Assume you need to dynamically allocate enough room for a fictional <code class="calibre6"><span class="calibre7">dog</span></code> structure:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">struct dog *p;<br class="calibre1"/><br class="calibre1"/>p = kmalloc(sizeof(struct dog), GFP_KERNEL);<br class="calibre1"/>if (!p)<br class="calibre1"/>        /* handle error ... */</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">If the <code class="calibre6"><span class="calibre7">kmalloc()</span></code> call succeeds, <code class="calibre6"><span class="calibre7">p</span></code> now points to a block of memory that is at least the requested size. The <code class="calibre6"><span class="calibre7">GFP_KERNEL</span></code> flag specifies the behavior of the memory allocator while trying to obtain the memory to return to the caller of <code class="calibre6"><span class="calibre7">kmalloc()</span></code>.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos803155"> </div>
<h4 class="calibre_27"><span class="calibre3"><code class="calibre6"><span class="calibre7">gfp_mask</span></code> Flags</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">You’ve seen various examples of allocator flags in both the low-level page allocation functions and <code class="calibre6"><span class="calibre7">kmalloc()</span></code>. Now it’s time to discuss these flags in depth. Flags are represented by the <code class="calibre6"><span class="calibre7">gfp_t</span></code> type, which is defined in <code class="calibre6"><span class="calibre7">&lt;linux/types.h&gt;</span></code> as an <code class="calibre6"><span class="calibre7">unsigned int</span></code>. <em class="calibre4">gfp</em> stands for <code class="calibre6"><span class="calibre7">__get_free_pages()</span></code>, one of the memory allocation routines we discussed earlier.</p><div class="calibre_3"> </div>
<p class="calibre_2">The flags are broken up into three categories: action modifiers, zone modifiers, and types. Action modifiers specify <em class="calibre4">how</em> the kernel is supposed to allocate the requested memory. In certain situations, only certain methods can be employed to allocate memory. For <a id="filepos804179"></a>example, interrupt handlers must instruct the kernel not to sleep (because interrupt handlers cannot reschedule) in the course of allocating memory. Zone modifiers specify from <em class="calibre4">where</em> to allocate memory. As you saw earlier in this chapter, the kernel divides physical memory into multiple zones, each of which serves a different purpose. Zone modifiers specify from which of these zones to allocate. Type flags specify a combination of action and zone modifiers as needed by a certain <em class="calibre4">type</em> of memory allocation. Type flags simplify the specification of multiple modifiers; instead of providing a combination of action and zone modifiers, you can specify just one type flag. The <code class="calibre6"><span class="calibre7">GFP_KERNEL</span></code> is a type flag, which is used for code in process context inside the kernel. Let’s look at the flags.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos805078"> </div>
<h5 class="calibre_29"><span class="calibre3">Action Modifiers</span></h5><div class="calibre_24"> </div>
<p class="calibre_2">All the flags, the action modifiers included, are declared in <code class="calibre6"><span class="calibre7">&lt;linux/gfp.h&gt;</span></code>. The file <code class="calibre6"><span class="calibre7">&lt;linux/slab.h&gt;</span></code> includes this header, however, so you often need not include it directly. In reality, you usually use only the type modifiers, which are discussed later. Nonetheless, it is good to have an understanding of these individual flags. <a href="#filepos805732">Table 12.3</a> is a list of the action modifiers.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos805732"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Table 12.3. Action Modifiers</span></span></p><div class="calibre_24"> </div>
<p class="calibre_23"><img alt="image" src="images/00167.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2"><a id="filepos806010"></a>These allocations can be specified together. For example</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">ptr = kmalloc(size, __GFP_WAIT | __GFP_IO | __GFP_FS);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">This call instructs the page allocator (ultimately <code class="calibre6"><span class="calibre7">alloc_pages()</span></code>) that the allocation can block, perform I/O, and perform filesystem operations, if needed. This enables the kernel great freedom in how it can find the free memory to satisfy the allocation.</p><div class="calibre_3"> </div>
<p class="calibre_2">Most allocations specify these modifiers but do so indirectly by way of the type flags we discuss shortly. Don’t worry—you won’t have to figure out which of these weird flags to use every time you allocate memory!</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos806897"> </div>
<h5 class="calibre_29"><span class="calibre3">Zone Modifiers</span></h5><div class="calibre_24"> </div>
<p class="calibre_2">Zone modifiers specify from which memory zone the allocation should originate. Normally, allocations can be fulfilled from any zone. The kernel prefers <code class="calibre6"><span class="calibre7">ZONE_NORMAL</span></code>, however, to ensure that the other zones have free pages when they are needed.</p><div class="calibre_3"> </div>
<p class="calibre_2">There are only three zone modifiers because there are only three zones other than <code class="calibre6"><span class="calibre7">ZONE_NORMAL</span></code> (which is where, by default, allocations originate). <a href="#filepos807647">Table 12.4</a> is a listing of the zone modifiers.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos807647"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Table 12.4. Zone Modifiers</span></span></p><div class="calibre_24"> </div>
<p class="calibre_23"><img alt="image" src="images/00168.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">Specifying one of these three flags modifies the zone from which the kernel attempts to satisfy the allocation. The <code class="calibre6"><span class="calibre7">__GFP_DMA</span></code> flag forces the kernel to satisfy the request from <code class="calibre6"><span class="calibre7">ZONE_DMA</span></code>. This flag says, <em class="calibre4">I absolutely must have memory into which I can perform DMA</em>. Conversely, the <code class="calibre6"><span class="calibre7">__GFP_HIGHMEM</span></code> flag instructs the allocator to satisfy the request from either <code class="calibre6"><span class="calibre7">ZONE_NORMAL</span></code> or (preferentially) <code class="calibre6"><span class="calibre7">ZONE_HIGHMEM</span></code>. This flag says, <em class="calibre4">I can use high memory, so I can be a doll and hand you back some of that, but normal memory works, too</em>. If neither flag is specified, the kernel fulfills the allocation from either <code class="calibre6"><span class="calibre7">ZONE_DMA</span></code> or <code class="calibre6"><span class="calibre7">ZONE_NORMAL</span></code>, with a strong preference to satisfy the allocation from <code class="calibre6"><span class="calibre7">ZONE_NORMAL</span></code>.</p><div class="calibre_3"> </div>
<p class="calibre_2">You cannot specify <code class="calibre6"><span class="calibre7">__GFP_HIGHMEM</span></code> to either <code class="calibre6"><span class="calibre7">__get_free_pages()</span></code> or <code class="calibre6"><span class="calibre7">kmalloc()</span></code>. Because these both return a logical address, and not a <code class="calibre6"><span class="calibre7">page</span></code> structure, it is possible that these functions would allocate memory not currently mapped in the kernel’s virtual address space and, thus, does not have a logical address. Only <code class="calibre6"><span class="calibre7">alloc_pages()</span></code> can allocate high memory. The majority of your allocations, however, will not specify a zone modifier because <code class="calibre6"><span class="calibre7">ZONE_NORMAL</span></code> is sufficient.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos809695"> </div>
<h5 class="calibre_29"><span class="calibre3">Type Flags</span></h5><div class="calibre_24"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos809807"> </div>
<p class="calibre_2">The type flags specify the required action and zone modifiers to fulfill a particular type of transaction. Therefore, kernel code tends to use the correct type flag and not specify the myriad of other flags it might need. This is both simpler and less error-prone. <a href="#filepos810340">Table 12.5</a> is a list of the type flags, and <a href="#filepos810612">Table 12.6</a> shows which modifiers are associated with each type flag.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos810340"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Table 12.5. Type Flags</span></span></p><div class="calibre_24"> </div>
<p class="calibre_23"><img alt="image" src="images/00169.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos810612"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Table 12.6. Modifiers Behind Each Type Flag</span></span></p><div class="calibre_24"> </div>
<p class="calibre_23"><img alt="image" src="images/00170.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">Let’s look at the frequently used flags and when and why you might need them. The vast majority of allocations in the kernel use the <code class="calibre6"><span class="calibre7">GFP_KERNEL</span></code> flag. The resulting allocation is a normal priority allocation that might sleep. Because the call can block, this flag can be used only from process context that can safely reschedule. (That is, no locks are held and so on.) Because this flag does not make any stipulations as to how the kernel may obtain the requested memory, the memory allocation has a high probability of succeeding.</p><div class="calibre_3"> </div>
<p class="calibre_2">On the far other end of the spectrum is the <code class="calibre6"><span class="calibre7">GFP_ATOMIC</span></code> flag. Because this flag specifies a memory allocation that cannot sleep, the allocation is restrictive in the memory it can obtain for the caller. If no sufficiently sized contiguous chunk of memory is available, the kernel is not likely to free memory because it cannot put the caller to sleep. Conversely, the <code class="calibre6"><span class="calibre7">GFP_KERNEL</span></code> allocation can put the caller to sleep to swap inactive pages to disk, flush dirty pages to disk, and so on. Because <code class="calibre6"><span class="calibre7">GFP_ATOMIC</span></code> cannot perform any of these actions, it has less of a chance of succeeding (at least when memory is low) compared to <code class="calibre6"><span class="calibre7">GFP_KERNEL</span></code> allocations. Nonetheless, the <code class="calibre6"><span class="calibre7">GFP_ATOMIC</span></code> flag is the only option when the current code cannot sleep, such as with interrupt handlers, softirqs, and tasklets.</p><div class="calibre_3"> </div>
<p class="calibre_2">In between these two flags are <code class="calibre6"><span class="calibre7">GFP_NOIO</span></code> and <code class="calibre6"><span class="calibre7">GFP_NOFS</span></code>. Allocations initiated with these flags might block, but they refrain from performing certain other operations. A <code class="calibre6"><span class="calibre7">GFP_NOIO</span></code> allocation does not initiate any disk I/O whatsoever to fulfill the request. On the other hand, <code class="calibre6"><span class="calibre7">GFP_NOFS</span></code> might initiate disk I/O, but does not initiate filesystem I/O. Why might you need these flags? They are needed for certain low-level block I/O or filesystem code, respectively. Imagine if a common path in the filesystem code allocated memory <em class="calibre4">without</em> the <code class="calibre6"><span class="calibre7">GFP_NOFS</span></code> flag. The allocation could result in <em class="calibre4">more</em> filesystem operations, which would then beget other allocations and, thus, more filesystem operations! This could continue indefinitely. Code such as this that invokes the allocator must ensure that the allocator also does not execute it, or else the allocation can create a deadlock. Not surprisingly, the kernel uses these two flags only in a handful of places.</p><div class="calibre_3"> </div>
<p class="calibre_2">The <code class="calibre6"><span class="calibre7">GFP_DMA</span></code> flag is used to specify that the allocator must satisfy the request from <code class="calibre6"><span class="calibre7">ZONE_DMA</span></code>. This flag is used by device drivers, which need DMA-able memory for their devices. Normally, you combine this flag with the <code class="calibre6"><span class="calibre7">GFP_ATOMIC</span></code> or <code class="calibre6"><span class="calibre7">GFP_KERNEL</span></code> flag.</p><div class="calibre_3"> </div>
<p class="calibre_2"><a id="filepos814178"></a>In the vast majority of the code that you write, you use either <code class="calibre6"><span class="calibre7">GFP_KERNEL</span></code> or <code class="calibre6"><span class="calibre7">GFP_ATOMIC</span></code>. <a href="#filepos814558">Table 12.7</a> is a list of the common situations and the flags to use. Regardless of the allocation type, you must check for and handle failures.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos814558"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Table 12.7. Which Flag to Use When</span></span></p><div class="calibre_24"> </div>
<p class="calibre_23"><img alt="image" src="images/00171.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos814842"> </div>
<h4 class="calibre_27"><span class="calibre3"><code class="calibre6"><span class="calibre7">kfree()</span></code></span></h4><div class="calibre_24"> </div>
<p class="calibre_2">The counterpart to <code class="calibre6"><span class="calibre7">kmalloc()</span></code> is <code class="calibre6"><span class="calibre7">kfree()</span></code>, which is declared in <code class="calibre6"><span class="calibre7">&lt;linux/slab.h&gt;</span></code>:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">void kfree(const void *ptr)</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">The <code class="calibre6"><span class="calibre7">kfree()</span></code> method frees a block of memory previously allocated with <code class="calibre6"><span class="calibre7">kmalloc()</span></code>. Do not call this function on memory not previously allocated with <code class="calibre6"><span class="calibre7">kmalloc()</span></code>, or on memory that has already been freed. Doing so is a bug, resulting in bad behavior such as freeing memory belonging to another part of the kernel. As in user-space, be careful to balance your allocations with your deallocations to prevent memory leaks and other bugs. Note that calling <code class="calibre6"><span class="calibre7">kfree(NULL)</span></code> is explicitly checked for and safe.</p><div class="calibre_3"> </div>
<p class="calibre_2">Let’s look at an example of allocating memory in an interrupt handler. In this example, an interrupt handler wants to allocate a buffer to hold incoming data. The preprocessor macro <code class="calibre6"><span class="calibre7">BUF_SIZE</span></code> is the size in bytes of this desired buffer, which is presumably larger than just a couple of bytes.</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">char *buf;<br class="calibre1"/><br class="calibre1"/>buf = kmalloc(BUF_SIZE, GFP_ATOMIC);<br class="calibre1"/>if (!buf)<br class="calibre1"/>        /* error allocating memory ! */</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2"><a id="filepos816680"></a>Later, when you no longer need the memory, do not forget to free it:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">kfree(buf);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos816913"> </div>
<h3 class="calibre_21"><span class="bold"><code class="calibre18"><span class="calibre15">vmalloc()</span></code></span></h3><div class="calibre_22"> </div>
<p class="calibre_2">The <code class="calibre6"><span class="calibre7">vmalloc()</span></code> function works in a similar fashion to <code class="calibre6"><span class="calibre7">kmalloc()</span></code>, except it allocates memory that is only virtually contiguous and not necessarily physically contiguous. This is how a user-space allocation function works: The pages returned by <code class="calibre6"><span class="calibre7">malloc()</span></code> are contiguous within the virtual address space of the processor, but there is no guarantee that they are actually contiguous in physical RAM. The <code class="calibre6"><span class="calibre7">kmalloc()</span></code> function guarantees that the pages are physically contiguous (and virtually contiguous). The <code class="calibre6"><span class="calibre7">vmalloc()</span></code> function ensures only that the pages are contiguous within the virtual address space. It does this by allocating potentially noncontiguous chunks of physical memory and “fixing up” the page tables to map the memory into a contiguous chunk of the logical address space.</p><div class="calibre_3"> </div>
<p class="calibre_2">For the most part, only hardware devices require physically contiguous memory allocations. On many architectures, hardware devices live on the other side of the memory management unit and, thus, do not understand virtual addresses. Consequently, any regions of memory that hardware devices work with must exist as a physically contiguous block and not merely a virtually contiguous one. Blocks of memory used only by software—for example, process-related buffers—are fine using memory that is only virtually contiguous. In your programming, you never know the difference. All memory appears to the kernel as logically contiguous.</p><div class="calibre_3"> </div>
<p class="calibre_2">Despite the fact that physically contiguous memory is required in only certain cases, most kernel code uses <code class="calibre6"><span class="calibre7">kmalloc()</span></code> and not <code class="calibre6"><span class="calibre7">vmalloc()</span></code> to obtain memory. Primarily, this is for performance. The <code class="calibre6"><span class="calibre7">vmalloc()</span></code> function, to make nonphysically contiguous pages contiguous in the virtual address space, must specifically set up the page table entries. Worse, pages obtained via <code class="calibre6"><span class="calibre7">vmalloc()</span></code> must be mapped by their individual pages (because they are not physically contiguous), which results in much greater TLB<sup class="calibre8"><a id="filepos819413" href="#filepos819893">4</a></sup> thrashing than you see when directly mapped memory is used. Because of these concerns, <code class="calibre6"><span class="calibre7">vmalloc()</span></code> is used only when absolutely necessary—typically, to obtain large regions of memory. For example, when modules are dynamically inserted into the kernel, they are loaded into memory created via <code class="calibre6"><span class="calibre7">vmalloc()</span></code>.</p><div class="calibre_3"> </div>
<p class="calibre_2"><sup class="calibre8"><a id="filepos819893" href="#filepos819413">4</a></sup>
<em class="calibre4">The TLB (translation lookaside buffer) is a hardware cache used by most architectures to cache the mapping of virtual addresses to physical addresses. This greatly improves the performance of the system, because most memory access is done via virtual addressing.</em></p><div class="calibre_3"> </div>
<p class="calibre_2">The <code class="calibre6"><span class="calibre7">vmalloc()</span></code> function is declared in <code class="calibre6"><span class="calibre7">&lt;linux/vmalloc.h&gt;</span></code> and defined in <code class="calibre6"><span class="calibre7">mm/vmalloc.c</span></code>. Usage is identical to user-space’s <code class="calibre6"><span class="calibre7">malloc()</span></code>:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">void * vmalloc(unsigned long size)</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2"><a id="filepos820736"></a>The function returns a pointer to at least <code class="calibre6"><span class="calibre7">size</span></code> bytes of virtually contiguous memory. On error, the function returns <code class="calibre6"><span class="calibre7">NULL</span></code>. The function might sleep and thus cannot be called from interrupt context or other situations in which blocking is not permissible.</p><div class="calibre_3"> </div>
<p class="calibre_2">To free an allocation obtained via <code class="calibre6"><span class="calibre7">vmalloc()</span></code>, use</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">void vfree(const void *addr)</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">This function frees the block of memory beginning at <code class="calibre6"><span class="calibre7">addr</span></code> that was previously allocated via <code class="calibre6"><span class="calibre7">vmalloc()</span></code>. The function can also sleep and, thus, cannot be called from interrupt context. It has no return value.</p><div class="calibre_3"> </div>
<p class="calibre_2">Usage of these functions is simple:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00172.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">After you finish with the memory, make sure to free it by using</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">vfree(buf);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos822106"> </div>
<h3 class="calibre_21"><span class="bold">Slab Layer</span></h3><div class="calibre_22"> </div>
<p class="calibre_2">Allocating and freeing data structures is one of the most common operations inside any kernel. To facilitate frequent allocations and deallocations of data, programmers often introduce <em class="calibre4">free lists</em>. A free list contains a block of available, already allocated, data structures. When code requires a new instance of a data structure, it can grab one of the structures off the free list rather than allocate the sufficient amount of memory and set it up for the data structure. Later, when the data structure is no longer needed, it is returned to the free list instead of deallocated. In this sense, the free list acts as an object cache, caching a frequently used <em class="calibre4">type</em> of object.</p><div class="calibre_3"> </div>
<p class="calibre_2">One of the main problems with free lists in the kernel is that there exists no global control. When available memory is low, there is no way for the kernel to communicate to every free list that it should shrink the sizes of its cache to free up memory. The kernel has no understanding of the random free lists at all. To remedy this, and to consolidate code, the Linux kernel provides the slab layer (also called the slab allocator). The slab layer acts as a generic data structure-caching layer.</p><div class="calibre_3"> </div>
<p class="calibre_2"><a id="filepos823513"></a>The concept of a slab allocator was first implemented in Sun Microsystem’s SunOS 5.4 operating system.<sup class="calibre8"><a id="filepos823626" href="#filepos823807">5</a></sup> The Linux data structure caching layer shares the same name and basic design.</p><div class="calibre_3"> </div>
<p class="calibre_2"><sup class="calibre8"><a id="filepos823807" href="#filepos823626">5</a></sup>
<em class="calibre4">And subsequently documented in Bonwick, J. “The Slab Allocator: An Object-Caching Kernel Memory Allocator,” USENIX, 1994.</em></p><div class="calibre_3"> </div>
<p class="calibre_2">The slab layer attempts to leverage several basic tenets:</p><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• Frequently used data structures tend to be allocated and freed often, so cache them.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• Frequent allocation and deallocation can result in memory fragmentation (the inability to find large contiguous chunks of available memory). To prevent this, the cached free lists are arranged contiguously. Because freed data structures return to the free list, there is no resulting fragmentation.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• The free list provides improved performance during frequent allocation and deallocation because a freed object can be immediately returned to the next allocation.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• If the allocator is aware of concepts such as object size, page size, and total cache size, it can make more intelligent decisions.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• If part of the cache is made per-processor (separate and unique to each processor on the system), allocations and frees can be performed without an SMP lock.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• If the allocator is NUMA-aware, it can fulfill allocations from the same memory node as the requestor.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• Stored objects can be <em class="calibre4">colored</em> to prevent multiple objects from mapping to the same cache lines.</p></blockquote><div class="calibre_3"> </div>
<p class="calibre_2">The slab layer in Linux was designed and implemented with these premises in mind.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos825932"> </div>
<h4 class="calibre_27"><span class="calibre3">Design of the Slab Layer</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">The slab layer divides different objects into groups called <em class="calibre4">caches</em>, each of which stores a different type of object. There is one cache per object type. For example, one cache is for process descriptors (a free list of <code class="calibre6"><span class="calibre7">task_struct</span></code> structures), whereas another cache is for inode objects (<code class="calibre6"><span class="calibre7">struct inode)</span></code>. Interestingly, the <code class="calibre6"><span class="calibre7">kmalloc()</span></code> interface is built on top of the slab layer, using a family of general purpose caches.</p><div class="calibre_3"> </div>
<p class="calibre_2">The caches are then divided into <em class="calibre4">slabs</em> (hence the name of this subsystem). The slabs are composed of one or more physically contiguous pages. Typically, slabs are composed of only a single page. Each cache may consist of multiple slabs.</p><div class="calibre_3"> </div>
<p class="calibre_2">Each slab contains some number of <em class="calibre4">objects</em>, which are the data structures being cached. Each slab is in one of three states: full, partial, or empty. A full slab has no free objects. (All objects in the slab are allocated.) An empty slab has no allocated objects. (All objects in the slab are free.) A partial slab has some allocated objects and some free objects. When some part of the kernel requests a new object, the request is satisfied from a partial slab, if one exists. Otherwise, the request is satisfied from an empty slab. If there exists no empty <a id="filepos827504"></a>slab, one is created. Obviously, a full slab can never satisfy a request because it does not have any free objects. This strategy reduces fragmentation.</p><div class="calibre_3"> </div>
<p class="calibre_2">Let’s look at the <code class="calibre6"><span class="calibre7">inode</span></code> structure as an example, which is the in-memory representation of a disk inode (see <a href="index_split_022.html#filepos870716">Chapter 13</a>, “The Virtual Filesystem”). These structures are frequently created and destroyed, so it makes sense to manage them via the slab allocator. Thus, <code class="calibre6"><span class="calibre7">struct inode</span></code> is allocated from the <code class="calibre6"><span class="calibre7">inode_cachep</span></code> cache. (Such a naming convention is standard.) This cache is made up of one or more slabs—probably a lot of slabs because there are a lot of objects. Each slab contains as many <code class="calibre6"><span class="calibre7">struct inode</span></code> objects as possible. When the kernel requests a new <code class="calibre6"><span class="calibre7">inode</span></code> structure, the kernel returns a pointer to an already allocated, but unused structure from a partial slab or, if there is no partial slab, an empty slab. When the kernel is done using the <code class="calibre6"><span class="calibre7">inode</span></code> object, the slab allocator marks the object as free. <a href="#filepos828927">Figure 12.1</a> diagrams the relationship between caches, slabs, and objects.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos828927"> </div>
<p class="calibre_23"><span class="calibre9"><span class="calibre3">Figure 12.1. The relationship between caches, slabs, and objects.</span></span></p><div class="calibre_24"> </div>
<p class="calibre_23"><img alt="image" src="images/00173.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">Each cache is represented by a <code class="calibre6"><span class="calibre7">kmem_cache</span></code> structure. This structure contains three lists—<code class="calibre6"><span class="calibre7">slabs_full</span></code>, <code class="calibre6"><span class="calibre7">slabs_partial</span></code>, and <code class="calibre6"><span class="calibre7">slabs_empty</span></code>—stored inside a <code class="calibre6"><span class="calibre7">kmem_list3</span></code> structure, which is defined in <code class="calibre6"><span class="calibre7">mm/slab.c</span></code>. These lists contain all the slabs associated with the cache. A slab descriptor, <code class="calibre6"><span class="calibre7">struct slab</span></code>, represents each slab:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00174.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">Slab descriptors are allocated either outside the slab in a general cache or inside the slab itself, at the beginning. The descriptor is stored inside the slab if the total size of the slab is sufficiently small, or if internal slack space is sufficient to hold the descriptor.</p><div class="calibre_3"> </div>
<p class="calibre_2">The slab allocator creates new slabs by interfacing with the low-level kernel page allocator via <code class="calibre6"><span class="calibre7">__get_free_pages()</span></code>:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00175.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">This function uses <code class="calibre6"><span class="calibre7">__get_free_pages()</span></code> to allocate memory sufficient to hold the cache. The first parameter to this function points to the specific cache that needs more pages. The second parameter points to the flags given to <code class="calibre6"><span class="calibre7">__get_free_pages()</span></code>. Note how this value is binary OR’ed against another value. This adds default flags that the cache requires to the <code class="calibre6"><span class="calibre7">flags</span></code> parameter. The power-of-two size of the allocation is stored in <code class="calibre6"><span class="calibre7">cachep-&gt;gfporder</span></code>. The previous function is a bit more complicated than one might expect because code that makes the allocator NUMA-aware. When <code class="calibre6"><span class="calibre7">nodeid</span></code> is not negative one, the allocator attempts to fulfill the allocation from the same memory node that <a id="filepos831436"></a>requested the allocation. This provides better performance on NUMA systems, in which accessing memory outside your node results in a performance penalty.</p><div class="calibre_3"> </div>
<p class="calibre_2">For educational purposes, we can ignore the NUMA-aware code and write a simple <code class="calibre6"><span class="calibre7">kmem_getpages()</span></code>:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00176.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">Memory is then freed by <code class="calibre6"><span class="calibre7">kmem_freepages()</span></code>, which calls <code class="calibre6"><span class="calibre7">free_pages()</span></code> on the given cache’s pages. Of course, the point of the slab layer is to refrain from allocating and freeing pages. In turn, the slab layer invokes the page allocation function only when there does not exist any partial or empty slabs in a given cache. The freeing function is called only when available memory grows low and the system is attempting to free memory, or when a cache is explicitly destroyed.</p><div class="calibre_3"> </div>
<p class="calibre_2">The slab layer is managed on a per-cache basis through a simple interface, which is exported to the entire kernel. The interface enables the creation and destruction of new caches and the allocation and freeing of objects within the caches. The sophisticated management of caches and the slabs within is entirely handled by the internals of the slab layer. After you create a cache, the slab layer works just like a specialized allocator for the specific type of object.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos833030"> </div>
<h4 class="calibre_27"><span class="calibre3">Slab Allocator Interface</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">A new cache is created via</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00177.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">The first parameter is a string storing the name of the cache. The second parameter is the size of each element in the cache. The third parameter is the offset of the first object within a slab. This is done to ensure a particular alignment within the page. Normally, zero is sufficient, which results in the standard alignment. The <code class="calibre6"><span class="calibre7">flags</span></code> parameter specifies optional settings controlling the cache’s behavior. It can be zero, specifying no special behavior, or one or more of the following flags OR’ed together:</p><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• <code class="calibre6"><span class="calibre7">SLAB_HWCACHE_ALIGN</span></code>—This flag instructs the slab layer to align each object within a slab to a cache line. This prevents “false sharing” (two or more objects mapping to the same cache line despite existing at different addresses in memory). This improves performance but comes at a cost of increased memory footprint because the stricter alignment results in more wasted slack space. How large the increase in memory consumption is depends on the size of the objects and how they naturally align with respect to the system’s cache lines. For frequently used caches in performance-critical code, setting this option is a good idea; otherwise, think twice.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• <code class="calibre6"><span class="calibre7">SLAB_POISON</span></code>—This flag causes the slab layer to fill the slab with a known value (<em class="calibre4">a5a5a5a5</em>). This is called <em class="calibre4">poisoning</em> and is useful for catching access to uninitialized memory.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• <code class="calibre6"><span class="calibre7">SLAB_RED_ZONE</span></code>—This flag causes the slab layer to insert “red zones” around the allocated memory to help detect buffer overruns.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• <code class="calibre6"><span class="calibre7">SLAB_PANIC</span></code>—This flag causes the slab layer to panic if the allocation fails. This flag is useful when the allocation <em class="calibre4">must not fail</em>, as in, say, allocating the VMA structure cache (see <a href="index_split_024.html#filepos1011741">Chapter 15</a>, “The Process Address Space”) during bootup.</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• <code class="calibre6"><span class="calibre7">SLAB_CACHE_DMA</span></code>—This flag instructs the slab layer to allocate each slab in DMA-able memory. This is needed if the allocated object is used for DMA and must reside in <code class="calibre6"><span class="calibre7">ZONE_DMA</span></code>. Otherwise, you do not need this and you should not set it.</p></blockquote><div class="calibre_3"> </div>
<p class="calibre_2">The final parameter, <code class="calibre6"><span class="calibre7">ctor</span></code>, is a constructor for the cache. The constructor is called whenever new pages are added to the cache. In practice, caches in the Linux kernel do not often utilize a constructor. In fact, there once was a deconstructor parameter, too, but it was removed because no kernel code used it. You can pass <code class="calibre6"><span class="calibre7">NULL</span></code> for this parameter.</p><div class="calibre_3"> </div>
<p class="calibre_2">On success, <code class="calibre6"><span class="calibre7">kmem_cache_create()</span></code> returns a pointer to the created cache. Otherwise, it returns <code class="calibre6"><span class="calibre7">NULL</span></code>. This function must not be called from interrupt context because it can sleep.</p><div class="calibre_3"> </div>
<p class="calibre_2">To destroy a cache, call</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">int kmem_cache_destroy(struct kmem_cache *cachep)</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">As the name implies, this function destroys the given cache. It is generally invoked from module shutdown code in modules that create their own caches. It must not be called from interrupt context because it may sleep. The caller of this function must ensure two conditions are true prior to invoking this function:</p><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• All slabs in the cache are empty. Indeed, if an object in one of the slabs were still allocated and in use, how could the cache be destroyed?</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• No one accesses the cache during (and obviously after) a call to <code class="calibre6"><span class="calibre7">kmem_cache_destroy()</span></code>. The caller must ensure this synchronization.</p></blockquote><div class="calibre_3"> </div>
<p class="calibre_2">On success, the function returns zero; it returns nonzero otherwise.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos838083"> </div>
<h5 class="calibre_29"><span class="calibre3">Allocating from the Cache</span></h5><div class="calibre_24"> </div>
<p class="calibre_2">After a cache is created, an object is obtained from the cache via</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">void * kmem_cache_alloc(struct kmem_cache *cachep, gfp_t flags)</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">This function returns a pointer to an object from the given cache <code class="calibre6"><span class="calibre7">cachep</span></code>. If no free objects are in any slabs in the cache, and the slab layer must obtain new pages via <code class="calibre6"><span class="calibre7">kmem_getpages()</span></code>, the value of <code class="calibre6"><span class="calibre7">flags</span></code> is passed to <code class="calibre6"><span class="calibre7">__get_free_pages()</span></code>. These are the same flags we looked at earlier. You probably want <code class="calibre6"><span class="calibre7">GFP_KERNEL</span></code> or <code class="calibre6"><span class="calibre7">GFP_ATOMIC</span></code>.</p><div class="calibre_3"> </div>
<p class="calibre_2">To later free an object and return it to its originating slab, use the function</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">void kmem_cache_free(struct kmem_cache *cachep, void *objp)</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">This marks the object <code class="calibre6"><span class="calibre7">objp</span></code> in <code class="calibre6"><span class="calibre7">cachep</span></code> as free.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos839540"> </div>
<h5 class="calibre_29"><span class="calibre3">Example of Using the Slab Allocator</span></h5><div class="calibre_24"> </div>
<p class="calibre_2">Let’s look at a real-life example that uses the <code class="calibre6"><span class="calibre7">task_struct</span></code> structure (the process descriptor). This code, in slightly more complicated form, is in <code class="calibre6"><span class="calibre7">kernel/fork.c</span></code>.</p><div class="calibre_3"> </div>
<p class="calibre_2">First, the kernel has a global variable that stores a pointer to the <code class="calibre6"><span class="calibre7">task_struct</span></code> cache:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">struct kmem_cache *task_struct_cachep;</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">During kernel initialization, in <code class="calibre6"><span class="calibre7">fork_init()</span></code>, defined in <code class="calibre6"><span class="calibre7">kernel/fork.c</span></code>, the cache is created:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00178.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">This creates a cache named <code class="calibre6"><span class="calibre7">task_struct</span></code>, which stores objects of type <code class="calibre6"><span class="calibre7">struct task_struct</span></code>. The objects are created with an offset of <code class="calibre6"><span class="calibre7">ARCH_MIN_TASKALIGN</span></code> bytes within the slab. This preprocessor definition is an architecture-specific value. It is usually defined as <code class="calibre6"><span class="calibre7">L1_CACHE_BYTES</span></code>—the size in bytes of the L1 cache. There is no constructor. Note that the return value is not checked for <code class="calibre6"><span class="calibre7">NULL</span></code>, which denotes failure, because the <code class="calibre6"><span class="calibre7">SLAB_PANIC</span></code> flag was given. If the allocation fails, the slab allocator calls <code class="calibre6"><span class="calibre7">panic()</span></code>. If you do not provide this flag, you must check the return! The <code class="calibre6"><span class="calibre7">SLAB_PANIC</span></code> flag is used here because this is a requisite cache for system operation. (The machine is not much good without process descriptors.)</p><div class="calibre_3"> </div>
<p class="calibre_2">Each time a process calls <code class="calibre6"><span class="calibre7">fork()</span></code>, a new process descriptor must be created (recall <a href="index_split_012.html#filepos167044">Chapter 3</a>, “Process Management”). This is done in <code class="calibre6"><span class="calibre7">dup_task_struct()</span></code>, which is called from <code class="calibre6"><span class="calibre7">do_fork()</span></code>:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">struct task_struct *tsk;<br class="calibre1"/><br class="calibre1"/>tsk = kmem_cache_alloc(task_struct_cachep, GFP_KERNEL);<br class="calibre1"/>if (!tsk)<br class="calibre1"/>        return NULL;</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2"><a id="filepos842286"></a>After a task dies, if it has no children waiting on it, its process descriptor is freed and returned to the <code class="calibre6"><span class="calibre7">task_struct_cachep</span></code> slab cache. This is done in <code class="calibre6"><span class="calibre7">free_task_struct()</span></code> (in which <code class="calibre6"><span class="calibre7">tsk</span></code> is the exiting task):</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">kmem_cache_free(task_struct_cachep, tsk);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">Because process descriptors are part of the core kernel and always needed, the <code class="calibre6"><span class="calibre7">task_struct_cachep</span></code> cache is never destroyed. If it were, however, you would destroy the cache via</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">int err;<br class="calibre1"/><br class="calibre1"/>err = kmem_cache_destroy(task_struct_cachep);<br class="calibre1"/>if (err)<br class="calibre1"/>        /* error destroying cache */</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">Easy enough? The slab layer handles all the low-level alignment, coloring, allocations, freeing, and reaping during low-memory conditions. If you frequently create many objects of the same type, consider using the slab cache. Definitely do not implement your own free list!</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos843641"> </div>
<h3 class="calibre_21"><span class="bold">Statically Allocating on the Stack</span></h3><div class="calibre_22"> </div>
<p class="calibre_2">In user-space, allocations such as some of the examples discussed thus far could have occurred on the stack because we knew the size of the allocation a priori. User-space is afforded the luxury of a large, dynamically growing stack, whereas the kernel has no such luxury—the kernel’s stack is small and fixed. When each process is given a small, fixed stack, memory consumption is minimized, and the kernel need not burden itself with stack management code.</p><div class="calibre_3"> </div>
<p class="calibre_2">The size of the per-process kernel stacks depends on both the architecture and a compile-time option. Historically, the kernel stack has been two pages per process. This is usually 8KB for 32-bit architectures and 16KB for 64-bit architectures because they usually have 4KB and 8KB pages, respectively.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos844652"> </div>
<h4 class="calibre_27"><span class="calibre3">Single-Page Kernel Stacks</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">Early in the 2.6 kernel series, however, an option was introduced to move to single-page kernel stacks. When enabled, each process is given only a single page—4KB on 32-bit architectures and 8KB on 64-bit architectures. This was done for two reasons. First, it results in a page with less memory consumption per process. Second and most important is that as uptime increases, it becomes increasingly hard to find two physically contiguous unallocated pages. Physical memory becomes fragmented, and the resulting VM pressure from allocating a single new process is expensive.</p><div class="calibre_3"> </div>
<p class="calibre_2">There is one more complication. Keep with me: We have almost grasped the entire universe of knowledge with respect to kernel stacks. Now, each process’s entire call chain has to fit in its kernel stack. Historically, however, interrupt handlers also used the kernel <a id="filepos845682"></a>stack of the process they interrupted, thus they too had to fit. This was efficient and simple, but it placed even tighter constraints on the already meager kernel stack. When the stack moved to only a single page, interrupt handlers no longer fit.</p><div class="calibre_3"> </div>
<p class="calibre_2">To rectify this problem, the kernel developers implemented a new feature: interrupt stacks. Interrupt stacks provide a single per-processor stack used for interrupt handlers. With this option, interrupt handlers no longer share the kernel stack of the interrupted process. Instead, they use their own stacks. This consumes only a single page per processor.</p><div class="calibre_3"> </div>
<p class="calibre_2">To summarize, kernel stacks are either one or two pages, depending on compile-time configuration options. The stack can therefore range from 4KB to 16KB. Historically, interrupt handlers shared the stack of the interrupted process. When single page stacks are enabled, interrupt handlers are given their own stacks. In any case, unbounded recursion and <code class="calibre6"><span class="calibre7">alloca()</span></code> are obviously not allowed.</p><div class="calibre_3"> </div>
<p class="calibre_2">Okay. Got it?</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos846926"> </div>
<h4 class="calibre_27"><span class="calibre3">Playing Fair on the Stack</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">In any given function, you must keep stack usage to a minimum. There is no hard and fast rule, but you should keep the sum of all local (that is, automatic) variables in a particular function to a maximum of a couple hundred bytes. Performing a large static allocation on the stack, such as of a large array or structure, is dangerous. Otherwise, stack allocations are performed in the kernel just as in user-space. Stack overflows occur silently and will undoubtedly result in problems. Because the kernel does not make any effort to manage the stack, when the stack overflows, the excess data simply spills into whatever exists at the tail end of the stack. The first thing to eat it is the <code class="calibre6"><span class="calibre7">thread_info</span></code> structure. (Recall from <a href="index_split_012.html#filepos167044">Chapter 3</a> that this structure is allocated at the end of each process’s kernel stack.) Beyond the stack, any kernel data might lurk. At best, the machine will crash when the stack overflows. At worst, the overflow will silently corrupt data.</p><div class="calibre_3"> </div>
<p class="calibre_2">Therefore, it is wise to use a dynamic allocation scheme, such as one of those previously discussed in this chapter for any large memory allocations.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos848342"> </div>
<h3 class="calibre_21"><span class="bold">High Memory Mappings</span></h3><div class="calibre_22"> </div>
<p class="calibre_2">By definition, pages in high memory might not be permanently mapped into the kernel’s address space. Thus, pages obtained via <code class="calibre6"><span class="calibre7">alloc_pages()</span></code> with the <code class="calibre6"><span class="calibre7">__GFP_HIGHMEM</span></code> flag might not have a logical address.</p><div class="calibre_3"> </div>
<p class="calibre_2">On the x86 architecture, all physical memory beyond the 896MB mark is high memory and is not permanently or automatically mapped into the kernel’s address space, despite x86 processors being capable of physically addressing up to 4GB (64GB with PAE<sup class="calibre8"><a id="filepos849052" href="#filepos849353">6</a></sup>) of physical RAM. After they are allocated, these pages must be mapped into the <a id="filepos849180"></a>kernel’s logical address space. On x86, pages in high memory are mapped somewhere between the 3GB and 4GB mark.</p><div class="calibre_3"> </div>
<p class="calibre_2"><sup class="calibre8"><a id="filepos849353" href="#filepos849052">6</a></sup>
<em class="calibre4">PAE stands for Physical Address Extension. It is a feature of x86 processors that enables them to physically address 36 bits (64GB) worth of memory, despite having only a 32-bit virtual address space.</em></p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos849665"> </div>
<h4 class="calibre_27"><span class="calibre3">Permanent Mappings</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">To map a given <code class="calibre6"><span class="calibre7">page</span></code> structure into the kernel’s address space, use this function, declared in <code class="calibre6"><span class="calibre7">&lt;linux/highmem.h&gt;</span></code>:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">void *kmap(struct page *page)</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">This function works on either high or low memory. If the <code class="calibre6"><span class="calibre7">page</span></code> structure belongs to a page in low memory, the page’s virtual address is simply returned. If the page resides in high memory, a permanent mapping is created and the address is returned. The function may sleep, so <code class="calibre6"><span class="calibre7">kmap()</span></code> works only in process context.</p><div class="calibre_3"> </div>
<p class="calibre_2">Because the number of permanent mappings are limited (if not, we would not be in this mess and could just permanently map all memory), high memory should be unmapped when no longer needed. This is done via the following function, which unmaps the given <code class="calibre6"><span class="calibre7">page</span></code>:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">void kunmap(struct page *page)</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos851078"> </div>
<h4 class="calibre_27"><span class="calibre3">Temporary Mappings</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">For times when a mapping must be created but the current context cannot sleep, the kernel provides <em class="calibre4">temporary mappings</em> (which are also called <em class="calibre4">atomic mappings</em>). These are a set of reserved mappings that can hold a temporary mapping. The kernel can atomically map a high memory page into one of these reserved mappings. Consequently, a temporary mapping can be used in places that cannot sleep, such as interrupt handlers, because obtaining the mapping never blocks.</p><div class="calibre_3"> </div>
<p class="calibre_2">Setting up a temporary mapping is done via</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">void *kmap_atomic(struct page *page, enum km_type type)</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">The <code class="calibre6"><span class="calibre7">type</span></code> parameter is one of the following enumerations, which describe the purpose of the temporary mapping. They are defined in <code class="calibre6"><span class="calibre7">&lt;asm-generic/kmap_types.h&gt;</span></code>:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00179.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2"><a id="filepos852353"></a>This function does not block and thus can be used in interrupt context and other places that cannot reschedule. It also disables kernel preemption, which is needed because the mappings are unique to each processor. (And a reschedule might change which task is running on which processor.)</p><div class="calibre_3"> </div>
<p class="calibre_2">The mapping is undone via</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">void kunmap_atomic(void *kvaddr, enum km_type type)</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">This function also does not block. In many architectures it does not do anything at all except enable kernel preemption, because a temporary mapping is valid only until the next temporary mapping. Thus, the kernel can just “forget about” the <code class="calibre6"><span class="calibre7">kmap_atomic()</span></code> mapping, and <code class="calibre6"><span class="calibre7">kunmap_atomic()</span></code> does not need to do anything special. The next atomic mapping then simply overwrites the previous one.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos853442"> </div>
<h3 class="calibre_21"><span class="bold">Per-CPU Allocations</span></h3><div class="calibre_22"> </div>
<p class="calibre_2">Modern SMP-capable operating systems use per-CPU data—data that is unique to a given processor—extensively. Typically, per-CPU data is stored in an array. Each item in the array corresponds to a possible processor on the system. The current processor number indexes this array, which is how the 2.4 kernel handles per-CPU data. Nothing is wrong with this approach, so plenty of 2.6 kernel code still uses it. You declare the data as</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">unsigned long my_percpu[NR_CPUS];</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">Then you access it as</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00180.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">Note that no lock is required because this data is unique to the current processor. If no processor touches this data except the current, no concurrency concerns exist, and the current processor can safely access the data without lock.</p><div class="calibre_3"> </div>
<p class="calibre_2"><a id="filepos854641"></a>Kernel preemption is the only concern with per-CPU data. Kernel preemption poses two problems, listed here:</p><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• If your code is preempted and reschedules on another processor, the <code class="calibre6"><span class="calibre7">cpu</span></code> variable is no longer valid because it points to the wrong processor. (In general, code cannot sleep after obtaining the current processor.)</p></blockquote><div class="calibre_3"> </div>
<blockquote class="calibre10"><p class="calibre_25">• If another task preempts your code, it can concurrently access <code class="calibre6"><span class="calibre7">my_percpu</span></code> on the <em class="calibre4">same</em> processor, which is a race condition.</p></blockquote><div class="calibre_3"> </div>
<p class="calibre_2">Any fears are unwarranted, however, because the call <code class="calibre6"><span class="calibre7">get_cpu()</span></code>, on top of returning the current processor number, also disables kernel preemption. The corresponding call to <code class="calibre6"><span class="calibre7">put_cpu()</span></code> enables kernel preemption. Note that if you use a call to <code class="calibre6"><span class="calibre7">smp_processor_id()</span></code> to get the current processor number, kernel preemption is not disabled; always use the aforementioned methods to remain safe.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos855925"> </div>
<h3 class="calibre_21"><span class="bold">The New <code class="calibre18"><span class="calibre15">percpu</span></code> Interface</span></h3><div class="calibre_22"> </div>
<p class="calibre_2">The 2.6 kernel introduced a new interface, known as <em class="calibre4">percpu</em>, for creating and manipulating per-CPU data. This interface generalizes the previous example. Creation and manipulation of per-CPU data is simplified with this new approach.</p><div class="calibre_3"> </div>
<p class="calibre_2">The previously discussed method of creating and accessing per-CPU data is still valid and accepted. This new interface, however, grew out of the needs for a simpler and more powerful method for manipulating per-CPU data on large symmetrical multiprocessing computers.</p><div class="calibre_3"> </div>
<p class="calibre_2">The header <code class="calibre6"><span class="calibre7">&lt;linux/percpu.h&gt;</span></code> declares all the routines. You can find the actual definitions there, in <code class="calibre6"><span class="calibre7">mm/slab.c</span></code>, and in <code class="calibre6"><span class="calibre7">&lt;asm/percpu.h&gt;</span></code>.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos856999"> </div>
<h4 class="calibre_27"><span class="calibre3">Per-CPU Data at Compile-Time</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">Defining a per-CPU variable at compile time is quite easy:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">DEFINE_PER_CPU(type, name);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">This creates an instance of a variable of type <code class="calibre6"><span class="calibre7">type</span></code>, named <code class="calibre6"><span class="calibre7">name</span></code>, for each processor on the system. If you need a declaration of the variable elsewhere, to avoid compile warnings, the following macro is your friend:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">DECLARE_PER_CPU(type, name);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">You can manipulate the variables with the <code class="calibre6"><span class="calibre7">get_cpu_var()</span></code> and <code class="calibre6"><span class="calibre7">put_cpu_var()</span></code> routines. A call to <code class="calibre6"><span class="calibre7">get_cpu_var()</span></code> returns an lvalue for the given variable on the current processor. It also disables preemption, which <code class="calibre6"><span class="calibre7">put_cpu_var()</span></code> correspondingly enables.</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">get_cpu_var(name)++;    /* increment name on this processor */<br class="calibre1"/>put_cpu_var(name);      /* done; enable kernel preemption */</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2"><a id="filepos858553"></a>You can obtain the value of <em class="calibre4">another</em> processor’s per-CPU data, too:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">per_cpu(name, cpu)++;   /* increment name on the given processor */</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">You need to be careful with this approach because <code class="calibre6"><span class="calibre7">per_cpu()</span></code> neither disables kernel preemption nor provides any sort of locking mechanism. The lockless nature of per-CPU data exists only if the current processor is the only manipulator of the data. If other processors touch other processors’ data, you need locks. Be careful. <a href="index_split_018.html#filepos575425">Chapter 9</a>, “An Introduction to Kernel Synchronization,” and <a href="index_split_019.html#filepos613760">Chapter 10</a>, “Kernel Synchronization Methods,” discuss locking.</p><div class="calibre_3"> </div>
<p class="calibre_2">Another subtle note: These compile-time per-CPU examples do not work for modules because the linker actually creates them in a unique executable section (for the curious, <code class="calibre6"><span class="calibre7">.data.percpu</span></code>). If you need to access per-CPU data from modules, or if you need to create such data dynamically, there is hope.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos859872"> </div>
<h4 class="calibre_27"><span class="calibre3">Per-CPU Data at Runtime</span></h4><div class="calibre_24"> </div>
<p class="calibre_2">The kernel implements a dynamic allocator, similar to <code class="calibre6"><span class="calibre7">kmalloc()</span></code>, for creating per-CPU data. This routine creates an instance of the requested memory for each processor on the systems. The prototypes are in <code class="calibre6"><span class="calibre7">&lt;linux/percpu.h&gt;</span></code>:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">void *alloc_percpu(type);  /* a macro */<br class="calibre1"/>void *__alloc_percpu(size_t size, size_t align);<br class="calibre1"/>void free_percpu(const void *);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">The <code class="calibre6"><span class="calibre7">alloc_percpu()</span></code> macro allocates one instance of an object of the given type for every processor on the system. It is a wrapper around <code class="calibre6"><span class="calibre7">__alloc_percpu()</span></code>, which takes the actual number of bytes to allocate as a parameter and the number of bytes on which to align the allocation. The <code class="calibre6"><span class="calibre7">alloc_percpu()</span></code> macro aligns the allocation on a byte boundary that is the natural alignment of the given type. Such alignment is the usual behavior. For example,</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">struct rabid_cheetah = alloc_percpu(struct rabid_cheetah);</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">is the same as</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00181.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">The <code class="calibre6"><span class="calibre7">__alignof__</span></code> construct is a gcc feature that returns the required (or recommended, in the case of weird architectures with no alignment requirements) alignment in bytes for a given type or lvalue. Its syntax is just like that of <code class="calibre6"><span class="calibre7">sizeof</span></code>. For example, the following would return four on x86:</p><div class="calibre_3"> </div>
<p class="calibre_28"><tt class="calibre6"><span class="calibre12">__alignof__ (unsigned long)</span></tt></p><div class="calibre_22"> </div>
<p class="calibre_2">When given an lvalue, the return value is the largest alignment that the lvalue might have. For example, an lvalue inside a structure could have a greater alignment requirement than if an instance of the same type were created outside of the structure, because of structure alignment requirements. Issues of alignment are further discussed in <a href="index_split_028.html#filepos1252328">Chapter 19</a>.</p><div class="calibre_3"> </div>
<p class="calibre_2"><a id="filepos862478"></a>A corresponding call to <code class="calibre6"><span class="calibre7">free_percpu()</span></code> frees the given data on all processors.</p><div class="calibre_3"> </div>
<p class="calibre_2">A call to <code class="calibre6"><span class="calibre7">alloc_percpu()</span></code> or <code class="calibre6"><span class="calibre7">__alloc_percpu()</span></code> returns a pointer, which is used to indirectly reference the dynamically created per-CPU data. The kernel provides two macros to make this easy:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00182.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2">The <code class="calibre6"><span class="calibre7">get_cpu_var()</span></code> macro returns a pointer to the specific instance of the current processor’s data. It also disables kernel preemption, which a call to <code class="calibre6"><span class="calibre7">put_cpu_var()</span></code> then enables.</p><div class="calibre_3"> </div>
<p class="calibre_2">Let’s look at a full example of using these functions. Of course, this example is a bit silly because you would normally allocate the memory once (perhaps in some initialization function), use it in various places, and free it once (perhaps in some shutdown function). Nevertheless, this example should make usage quite clear:</p><div class="calibre_3"> </div>
<p class="calibre_31"><img alt="image" src="images/00183.jpg" class="calibre2"/></p><div class="calibre_7"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos863816"> </div>
<h3 class="calibre_21"><span class="bold">Reasons for Using Per-CPU Data</span></h3><div class="calibre_22"> </div>
<p class="calibre_2">There are several benefits to using per-CPU data. The first is the reduction in locking requirements. Depending on the semantics by which processors access the per-CPU data, you might not need any locking at all. Keep in mind that the <em class="calibre4">“only this processor accesses this data”</em> rule is only a programming convention. You need to ensure that the local processor accesses only its unique data. Nothing stops you from cheating.</p><div class="calibre_3"> </div>
<p class="calibre_2">Second, per-CPU data greatly reduces cache invalidation. This occurs as processors try to keep their caches in sync. If one processor manipulates data held in another processor’s cache, that processor must flush or otherwise update its cache. Constant cache invalidation is called <em class="calibre4">thrashing the cache</em> and wreaks havoc on system performance. The use of per-CPU data keeps cache effects to a minimum because processors ideally access only their own data. The <em class="calibre4">percpu</em> interface cache-aligns all data to ensure that accessing one processor’s data does not bring in another processor’s data on the same cache line.</p><div class="calibre_3"> </div>
<p class="calibre_2">Consequently, the use of per-CPU data often removes (or at least minimizes) the need for locking. The only safety requirement for the use of per-CPU data is disabling kernel preemption, which is much cheaper than locking, and the interface does so automatically. Per-CPU data can safely be used from either interrupt or process context. Note, however, <a id="filepos865490"></a>that you cannot sleep in the middle of accessing per-CPU data (or else you might end up on a different processor).</p><div class="calibre_3"> </div>
<p class="calibre_2">No one is currently required to use the new per-CPU interface. Doing things manually (with an array as originally discussed) is fine, as long as you disable kernel preemption. The new interface, however, is much easier to use and might gain additional optimizations in the future. If you do decide to use per-CPU data in your kernel code, consider the new interface. One caveat <em class="calibre4">against</em> its use is that it is not backward compatible with earlier kernels.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos866168"> </div>
<h3 class="calibre_21"><span class="bold">Picking an Allocation Method</span></h3><div class="calibre_22"> </div>
<p class="calibre_2">With myriad allocations methods and approaches, it is not always obvious how to get at memory in the kernel—but it sure is important! If you need contiguous physical pages, use one of the low-level page allocators or <code class="calibre6"><span class="calibre7">kmalloc()</span></code>. This is the standard manner of allocating memory from within the kernel, and most likely, how you will allocate most of your memory. Recall that the two most common flags given to these functions are <code class="calibre6"><span class="calibre7">GFP_ATOMIC</span></code> and <code class="calibre6"><span class="calibre7">GFP_KERNEL</span></code>. Specify the <code class="calibre6"><span class="calibre7">GFP_ATOMIC</span></code> flag to perform a high priority allocation that will not sleep. This is a requirement of interrupt handlers and other pieces of code that cannot sleep. Code that can sleep, such as process context code that does not hold a spin lock, should use <code class="calibre6"><span class="calibre7">GFP_KERNEL</span></code>. This flag specifies an allocation that can sleep, if needed, to obtain the requested memory.</p><div class="calibre_3"> </div>
<p class="calibre_2">If you want to allocate from high memory, use <code class="calibre6"><span class="calibre7">alloc_pages()</span></code>. The <code class="calibre6"><span class="calibre7">alloc_pages()</span></code> function returns a <code class="calibre6"><span class="calibre7">struct page</span></code> and not a pointer to a logical address. Because high memory might not be mapped, the only way to access it might be via the corresponding <code class="calibre6"><span class="calibre7">struct page</span></code> structure. To obtain an actual pointer, use <code class="calibre6"><span class="calibre7">kmap()</span></code> to map the high memory into the kernel’s logical address space.</p><div class="calibre_3"> </div>
<p class="calibre_2">If you do not need physically contiguous pages—only virtually contiguous—use <code class="calibre6"><span class="calibre7">vmalloc()</span></code>, although bear in mind the slight performance hit taken with <code class="calibre6"><span class="calibre7">vmalloc()</span></code> over <code class="calibre6"><span class="calibre7">kmalloc()</span></code>. The <code class="calibre6"><span class="calibre7">vmalloc()</span></code> function allocates kernel memory that is virtually contiguous but not, per se, physically contiguous. It performs this feat much as user-space allocations do, by mapping chunks of physical memory into a contiguous logical address space.</p><div class="calibre_3"> </div>
<p class="calibre_2">If you are creating and destroying many large data structures, consider setting up a slab cache. The slab layer maintains a per-processor object cache (a free list), which might greatly enhance object allocation and deallocation performance. Rather than frequently allocate and free memory, the slab layer stores a cache of already allocated objects for you. When you need a new chunk of memory to hold your data structure, the slab layer often does not need to allocate more memory and instead simply can return an object from the cache.</p><div class="calibre_3"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos869180"> </div>
<h3 class="calibre_21"><span class="bold">Conclusion</span></h3><div class="calibre_22"> </div>
<p class="calibre_2"></p><div class="calibre_3" id="filepos869293"> </div>
<p class="calibre_2">In this chapter, we studied how the Linux kernel manages memory. We looked at the various units and categorizations of memory, including bytes, pages, and zones. (<a href="index_split_024.html#filepos1011741">Chapter 15</a> looks at a fourth categorization, the process address space.) We then discussed various mechanisms for obtaining memory, including the page allocator and the slab allocator. Obtaining memory inside the kernel is not always easy because you must be careful to ensure that the allocation process respects certain kernel conditions, such as an inability to block or access the filesystem. To that end, we discussed the <code class="calibre6"><span class="calibre7">gfp</span></code> flags and the various use cases and requirements for each flag. The relative difficulty in getting hold of memory in the kernel is one of the largest differences between kernel and user-space development. While much of this chapter discussed the family of interfaces used to obtain memory, you should now also wield an understanding of <em class="calibre4">why</em> memory allocation in a kernel is difficult.</p><div class="calibre_3"> </div>
<p class="calibre_2">With this chapter under our belt, the next chapter discusses the virtual filesystem (VFS), the kernel subsystem responsible for managing filesystems and providing a unified, consistent file API to user-space applications. Onward!</p><div class="calibre_3"> </div>  <div class="mbp_pagebreak" id="calibre_pb_60"></div>
</body></html>
