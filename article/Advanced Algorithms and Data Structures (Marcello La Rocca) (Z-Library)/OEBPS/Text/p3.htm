<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>Part 3</title>
    
  <link href="../../stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="../../page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
  <div class="tocheadb">
    <h1 class="tochead" id="heading_id_2"><a id="pgfId-1014422"></a><a id="pgfId-1014406"></a>Part 3. Planar graphs and minimum crossing number</h1>
  </div>

  <p class="body"><a id="pgfId-1014448"></a><span class="fm-part-initial-cap">T</span>he final part of this book has a single data structure as its main thread: <i class="calibre17">graphs</i>. They will be used, however, more as a touchstone to compare different techniques throughout chapters whose main focus will be on <i class="calibre17">optimization algorithms</i>.</p>

  <p class="body"><a id="pgfId-1014449"></a>We won’t delve into the basics of graphs, but we still start this part with a brief introduction to their basic concepts and a few cornerstone algorithms to traverse graphs.</p>

  <p class="body"><a id="pgfId-1014450"></a>These are necessary to describe an interesting, often neglected problem that has broad application in our industry: displaying graphs in the two-dimensional plane. This is a difficult problem that can’t be solved efficiently on classical computers. Nevertheless, it’s one for which approximate solutions are often enough, and this gives us a good reason to introduce <i class="calibre17">optimization algorithms</i>, the real star of part 3.</p>

  <p class="body"><a id="pgfId-1014451"></a>The final chapters of this book will describe three optimization techniques that are widely used to tackle optimization problems and drive today’s AI and big data effort: <i class="calibre17">gradient descent</i>, <i class="calibre17">simulated annealing</i>, and <i class="calibre17">genetic algorithms</i>.</p>

  <p class="body"><a id="pgfId-1014452"></a>Chapter 14 is a short introduction to <i class="calibre17">graphs</i>, condensing the basics of this fundamental data structure needed to understand part 3. It also illustrates <i class="calibre17">DFS</i>, <i class="calibre17">BFS</i>, <i class="calibre17">Dijkstra’s,</i> and <i class="calibre17">A*</i> algorithms, and describes how to use them to solve the “minimum-distance path” problem.</p>

  <p class="body"><a id="pgfId-1014453"></a>Chapter 15 introduces <i class="calibre17">graph embeddings</i>, planarity, and a couple of problems we will try to solve in the remaining chapters: finding the <a id="id_Hlk55894079"></a><i class="calibre17">minimum crossing number (MCN)</i>, embedding a graph, and drawing a graph nicely.</p>

  <p class="body"><a id="pgfId-1014455"></a>Chapter 16 describes a fundamental algorithm in machine learning, <i class="calibre17">gradient descent</i>, and shows how it can be applied to graphs and embeddings.</p>

  <p class="body"><a id="pgfId-1014456"></a>Chapter 17 builds on the previous chapter and presents <i class="calibre17">simulated annealing</i>, a more powerful optimization technique that tries to overcome gradient descent shortcomings when we have to deal with non-differentiable functions or functions with multiple local minima.</p>

  <p class="body"><a id="pgfId-1014441"></a>Chapter 18, finally, describes <i class="calibre17">genetic algorithms</i>, an even more advanced optimization technique that helps with faster convergence.</p>

  <p class="calibre16">  </p>
</body>
</html>
