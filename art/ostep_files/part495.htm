<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>44.2 Handling Latent Sector Errors</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part494.htm">&lt; 上一个</a><span> | </span><a href="../ostep.html">内容</a><span> | </span><a href="part496.htm">下一个 &gt;</a></p><p class="s40" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">44.2 Handling Latent Sector Errors</p><p style="padding-top: 7pt;padding-left: 41pt;text-indent: 11pt;line-height: 89%;text-align: justify;">Given these two new modes of partial disk failure, we should now try to see what we can do about them. Let’s first tackle the easier of the two, namely latent sector errors.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 6pt;padding-left: 24pt;text-indent: 0pt;line-height: 11pt;text-align: center;">C<span class="s7">RUX</span>: H<span class="s7">OW </span>T<span class="s7">O </span>H<span class="s7">ANDLE </span>L<span class="s7">ATENT </span>S<span class="s7">ECTOR </span>E<span class="s7">RRORS</span></p><p style="padding-left: 9pt;text-indent: 11pt;line-height: 89%;text-align: left;">How should a storage system handle latent sector errors? How much extra machinery is needed to handle this form of partial failure?</p><p style="padding-left: 32pt;text-indent: 0pt;text-align: left;"/><p style="padding-top: 7pt;padding-left: 41pt;text-indent: 11pt;line-height: 89%;text-align: justify;">As it turns out, latent sector errors are rather straightforward to han- dle, as they are (by definition) easily detected. When a storage system tries to access a block, and the disk returns an error, the storage system should simply use whatever redundancy mechanism it has to return the correct data. In a mirrored RAID, for example, the system should access the alternate copy; in a RAID-4 or RAID-5 system based on parity, the system should reconstruct the block from the other blocks in the parity group. Thus, easily detected problems such as LSEs are readily recovered through standard redundancy mechanisms.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 68pt;text-indent: 12pt;line-height: 89%;text-align: justify;">The growing prevalence of LSEs has influenced RAID designs over the years. One particularly interesting problem arises in RAID-4/5 systems when both full-disk faults and LSEs occur in tandem. Specifically, when an entire disk fails, the RAID tries to <b>reconstruct </b>the disk (say, onto a hot spare) by reading through all of the other disks in the parity group and recomputing the missing values. If, during reconstruction, an LSE is encountered on any one of the other disks, we have a problem: the reconstruction cannot successfully complete.</p><p style="padding-left: 68pt;text-indent: 12pt;line-height: 89%;text-align: justify;">To combat this issue, some systems add an extra degree of redundancy. For example, NetApp’s <b>RAID-DP </b>has the equivalent of two parity disks instead of one [C+04]. When an LSE is discovered during reconstruction, the extra parity helps to reconstruct the missing block. As always, there is a cost, in that maintaining two parity blocks for each stripe is more costly; however, the log-structured nature of the NetApp <b>WAFL </b>file system mit- igates that cost in many cases [HLM94]. The remaining cost is space, in the form of an extra disk for the second parity block.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part494.htm">&lt; 上一个</a><span> | </span><a href="../ostep.html">内容</a><span> | </span><a href="part496.htm">下一个 &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
