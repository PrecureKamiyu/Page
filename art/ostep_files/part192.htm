<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>19.2 Example: Accessing An Array</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part191.htm">&lt; 上一个</a><span> | </span><a href="../ostep.html">内容</a><span> | </span><a href="part193.htm">下一个 &gt;</a></p><p class="s40" style="padding-top: 8pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">19.2 Example: Accessing An Array</p><p style="padding-top: 7pt;padding-left: 41pt;text-indent: 11pt;line-height: 89%;text-align: justify;">To make clear the operation of a TLB, let’s examine a simple virtual address trace and see how a TLB can improve its performance. In this example, let’s assume we have an array of 10 4-byte integers in memory, starting at virtual address 100. Assume further that we have a small 8-bit virtual address space, with 16-byte pages; thus, a virtual address breaks down into a 4-bit VPN (there are 16 virtual pages) and a 4-bit offset (there are 16 bytes on each of those pages).</p><p style="padding-left: 41pt;text-indent: 11pt;line-height: 88%;text-align: left;">Figure <span style=" color: #00AEEF;">19.2 </span>shows the array laid out on the 16 16-byte pages of the sys- tem. As you can see, the array’s first entry (<span class="s41">a[0]</span>) begins on (VPN=06, off- set=04); only three 4-byte integers fit onto that page. The array continues onto the next page (VPN=07), where the next four entries (<span class="s41">a[3] </span>... <span class="s41">a[6]</span>) are found. Finally, the last three entries of the 10-entry array (<span class="s41">a[7] </span>... <span class="s41">a[9]</span>) are located on the next page of the address space (VPN=08).</p><p style="padding-left: 41pt;text-indent: 11pt;line-height: 89%;text-align: left;">Now let’s consider a simple loop that accesses each array element, something that would look like this in C:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="padding-left: 41pt;text-indent: 0pt;text-align: left;">int sum = 0;</p><p class="s38" style="padding-left: 57pt;text-indent: -16pt;text-align: left;">for (i = 0; i &lt; 10; i++) { sum += a[i];</p><p class="s38" style="padding-left: 41pt;text-indent: 0pt;text-align: left;">}</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 68pt;text-indent: 12pt;line-height: 88%;text-align: justify;">For the sake of simplicity, we will pretend that the only memory ac- cesses the loop generates are to the array (ignoring the variables <span class="s41">i </span>and <span class="s41">sum</span>, as well as the instructions themselves). When the first array element (<span class="s41">a[0]</span>) is accessed, the CPU will see a load to virtual address 100. The hardware extracts the VPN from this (VPN=06), and uses that to check the TLB for a valid translation. Assuming this is the first time the pro- gram accesses the array, the result will be a TLB miss.</p><p style="padding-left: 68pt;text-indent: 12pt;line-height: 89%;text-align: justify;">The next access is to <span class="s41">a[1]</span>, and there is some good news here: a TLB hit! Because the second element of the array is packed next to the first, it lives on the same page; because we’ve already accessed this page when accessing the first element of the array, the translation is already loaded into the TLB. And hence the reason for our success. Access to <span class="s41">a[2] </span>en- counters similar success (another hit), because it too lives on the same page as <span class="s41">a[0] </span>and <span class="s41">a[1]</span>.</p><p style="padding-left: 68pt;text-indent: 12pt;line-height: 88%;text-align: justify;">Unfortunately, when the program accesses <span class="s41">a[3]</span>, we encounter an- other TLB miss. However, once again, the next entries (<span class="s41">a[4] </span>... <span class="s41">a[6]</span>) will hit in the TLB, as they all reside on the same page in memory.</p><p style="padding-left: 68pt;text-indent: 12pt;line-height: 88%;text-align: justify;">Finally, access to <span class="s41">a[7] </span>causes one last TLB miss. The hardware once again consults the page table to figure out the location of this virtual page in physical memory, and updates the TLB accordingly. The final two ac- cesses (<span class="s41">a[8] </span>and <span class="s41">a[9]</span>) receive the benefits of this TLB update; when the hardware looks in the TLB for their translations, two more hits result.</p><p style="padding-left: 68pt;text-indent: 12pt;line-height: 89%;text-align: justify;">Let us summarize TLB activity during our ten accesses to the array: <b>miss</b>, hit, hit, <b>miss</b>, hit, hit, hit, <b>miss</b>, hit, hit. Thus, our TLB <b>hit rate</b>, which is the number of hits divided by the total number of accesses, is 70%. Although this is not too high (indeed, we desire hit rates that ap- proach 100%), it is non-zero, which may be a surprise. Even though this is the first time the program accesses the array, TLB performance gains benefit from <b>spatial locality</b>. The elements of the array are packed tightly into pages (i.e., they are close to one another in <b>space</b>), and thus only the first access to an element on a page yields a TLB miss.</p><p style="padding-left: 68pt;text-indent: 12pt;line-height: 89%;text-align: justify;">Also note the role that page size plays in this example. If the page size had simply been twice as big (32 bytes, not 16), the array access would suffer even fewer misses. As typical page sizes are more like 4KB, these types of dense, array-based accesses achieve excellent TLB performance, encountering only a single miss per page of accesses.</p><p style="padding-left: 68pt;text-indent: 12pt;line-height: 89%;text-align: justify;">One last point about TLB performance: if the program, soon after this loop completes, accesses the array again, we’d likely see an even bet- ter result, assuming that we have a big enough TLB to cache the needed translations: hit, hit, hit, hit, hit, hit, hit, hit, hit, hit. In this case, the TLB hit rate would be high because of <b>temporal locality</b>, i.e., the quick re-referencing of memory items in <b>time</b>. Like any cache, TLBs rely upon both spatial and temporal locality for success, which are program proper- ties. If the program of interest exhibits such locality (and many programs do), the TLB hit rate will likely be high.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="408" height="412" alt="image" src="Image_253.png"/></span></p><p style="padding-left: 111pt;text-indent: 0pt;line-height: 11pt;text-align: left;">T<span class="s7">IP</span>: U<span class="s7">SE </span>C<span class="s7">ACHING </span>W<span class="s7">HEN </span>P<span class="s7">OSSIBLE</span></p><p style="padding-left: 41pt;text-indent: 0pt;line-height: 89%;text-align: justify;">Caching is one of the most fundamental performance techniques in com- puter systems, one that is used again and again to make the “common- case fast” [HP06]. The idea behind hardware caches is to take advantage of <b>locality </b>in instruction and data references. There are usually two types of locality: <b>temporal locality </b>and <b>spatial locality</b>. With temporal locality, the idea is that an instruction or data item that has been recently accessed will likely be re-accessed soon in the future. Think of loop variables or in- structions in a loop; they are accessed repeatedly over time. With spatial locality, the idea is that if a program accesses memory at address <span class="s43">x</span>, it will likely soon access memory near <span class="s43">x</span>. Imagine here streaming through an array of some kind, accessing one element and then the next. Of course, these properties depend on the exact nature of the program, and thus are not hard-and-fast laws but more like rules of thumb.</p><p style="padding-top: 1pt;padding-left: 41pt;text-indent: 0pt;line-height: 89%;text-align: justify;">Hardware caches, whether for instructions, data, or address translations (as in our TLB) take advantage of locality by keeping copies of memory in small, fast on-chip memory. Instead of having to go to a (slow) memory to satisfy a request, the processor can first check if a nearby copy exists in a cache; if it does, the processor can access it quickly (i.e., in a few cy- cles) and avoid spending the costly time it takes to access memory (many nanoseconds).</p><p style="padding-top: 1pt;padding-left: 41pt;text-indent: 0pt;line-height: 89%;text-align: justify;">You might be wondering: if caches (like the TLB) are so great, why don’t we just make bigger caches and keep all of our data in them? Unfor- tunately, this is where we run into more fundamental laws like those of physics. If you want a fast cache, it has to be small, as issues like the speed-of-light and other physical constraints become relevant. Any large cache by definition is slow, and thus defeats the purpose. Thus, we are stuck with small, fast caches; the question that remains is how to best use them to improve performance.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part191.htm">&lt; 上一个</a><span> | </span><a href="../ostep.html">内容</a><span> | </span><a href="part193.htm">下一个 &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
