<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>13.5  Database Buffer</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part249.htm">&lt; 上一个</a><span> | </span><a href="../database.html">内容</a><span> | </span><a href="part251.htm">下一个 &gt;</a></p><p class="s65" style="padding-top: 7pt;padding-left: 40pt;text-indent: 0pt;text-align: left;">13.5  <span style=" color: #00AEEF;">Database Buffer</span></p><p style="padding-top: 12pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">The size of main memory on servers has increased greatly over the years, and many medium-sized databases can ﬁt in memory. However, a server has many demands on its memory, and the amount of memory it can give to a database may be much smaller than the database size even for medium-sized databases. And many large databases are much larger than the available memory on servers.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Thus, even today, database data reside primarily on disk in most databases, and they must be brought into memory to be read or updated; updated data blocks must be written back to disk subsequently.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Since data access from disk is much slower than in-memory data access, a major goal of the database system is to minimize the number of block transfers between the disk and memory. One way to reduce the number of disk accesses is to keep as many blocks as possible in main memory. The goal is to maximize the chance that, when a block is accessed, it is already in main memory, and, thus, no disk access is required.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Since it is not possible to keep all blocks in main memory, we need to manage the allocation of the space available in main memory for the storage of blocks. The <span class="s63">buﬀer </span>is that part of main memory available for storage of copies of disk blocks. There is always a copy kept on disk of every block, but the copy on disk may be a version of the block older than the version in the buﬀer. The subsystem responsible for the allocation of buﬀer space is called the <span class="s63">buﬀer manager</span>.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 88pt;text-indent: 0pt;text-align: left;">13.5.1 Buffer Manager</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">Programs in a database system make requests (i.e., calls) on the buﬀer manager when they need a block from disk. If the block is already in the buﬀer, the buﬀer manager passes the address of the block in main memory to the requester. If the block is not in the buﬀer, the buﬀer manager ﬁrst allocates space in the buﬀer for the block, throwing out some other block, if necessary, to make space for the new block. The thrown-out block is written back to disk only if it has been modiﬁed since the most recent time that it was written to the disk. Then, the buﬀer manager reads in the requested block from the disk to the buﬀer, and passes the address of the block in main memory to the</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">requester. The internal actions of the buﬀer manager are transparent to the programs that issue disk-block requests.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">If you are familiar with operating-system concepts, you will note that the buﬀer manager appears to be nothing more than a virtual-memory manager, like those found in most operating systems. One diﬀerence is that the size of the database might be larger than the hardware address space of a machine, so memory addresses are not suﬃcient to address all disk blocks. Further, to serve the database system well, the buﬀer manager must use techniques more sophisticated than typical virtual-memory management schemes:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s183" style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">13.5.1.1 Buﬀer replacement strategy</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">When there is no room left in the buﬀer, a block must be <span class="s63">evicted</span>, that is, removed, from the buﬀer before a new one can be read in. Most operating systems use a <span class="s63">least recently used </span>(<span class="s64">LRU</span>) scheme, in which the block that was referenced least recently is written back to disk and is removed from the buﬀer. This simple approach can be improved on for database applications(see Section 13.5.2).</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s183" style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">13.5.1.2 Pinned blocks</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">Once a block has been brought into the buﬀer, a database process can read the con- tents of the block from the buﬀer memory. However, while the block is being read, if a concurrent process evicts the block and replaces it with a diﬀerent block, the reader that was reading the contents of the old block will see incorrect data; if the block was being written when it was evicted, the writer would end up damaging the contents of the replacement block.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">It is therefore important that before a process reads data from a buﬀer block, it ensures that the block will not get evicted. To do so, the process executes a <span class="s63">pin </span>operation on the block; the buﬀer manager never evicts a pinned block. When it has ﬁnished reading data, the process should execute an <span class="s63">unpin </span>operation, allowing the block to be evicted when required. The database code should be written carefully to avoid pinning too many blocks: if all the blocks in the buﬀer get pinned, no blocks can be evicted, and no other block can be brought into the buﬀer. If this happens, the database will be unable to carry out any further processing!</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Multiple processes can read data from a block that is in the buﬀer. Each of them is required to execute a pin operation before accessing data, and an unpin after completing access. The block cannot be evicted until all processes that have executed a pin have then executed an unpin operation. A simple way to ensure this property is to keep a <span class="s63">pin count </span>for each buﬀer block. Each pin operation increments the count, and an unpin operation decrements the count. A page can be evicted only if the pin count equals 0.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s183" style="padding-left: 119pt;text-indent: 0pt;text-align: left;">13.5.1.3 Shared and Exclusive Locks on Buﬀer</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">A process that adds or deletes a tuple froma page may need to move the page contents around; during this period, no other process should read the contents of the page, since</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">they may be inconsistent. Database buﬀer managers allow processes to get shared and exclusive locks on the buﬀer.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">We will study locking in more detail in Chapter 18, but here we discuss a limited form of locking in the context of the buﬀer manager. The locking system provided by the buﬀer manager allows a database process to lock a buﬀer block either in shared mode or in exclusive mode before accessing the block, and to release the lock later, after the access is completed. Here are the rules for locking:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s39" style="padding-left: 91pt;text-indent: 0pt;text-align: justify;">• <span class="s40">Any number of processes may have shared locks on a block at the same time.</span></p><p class="s39" style="padding-top: 3pt;padding-left: 107pt;text-indent: -16pt;text-align: justify;">• <span class="s40">Only one process is allowed to get an exclusive lock at a time, and further when a process has an exclusive lock, no other process may have a shared lock on the block. Thus, an exclusive lock can be granted only when no other process has a lock on the buﬀer block.</span></p><p class="s39" style="padding-top: 4pt;padding-left: 107pt;text-indent: -16pt;text-align: justify;">• <span class="s40">If a process requests an exclusive lock when a block is already locked in shared or exclusive mode, the request is kept pending until all earlier locks are released.</span></p><p class="s39" style="padding-top: 4pt;padding-left: 107pt;text-indent: -16pt;text-align: justify;">• <span class="s40">If a process requests a shared lock when a block is not locked, or already shared locked, the lock may be granted; however, if another process has an exclusive lock, the shared lock is granted only after the exclusive lock has been released.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 106pt;text-indent: 0pt;text-align: left;">Locks are acquired and released as follows:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s39" style="padding-left: 107pt;text-indent: -16pt;text-align: justify;">• <span class="s40">Before carrying out any operation on a block, a process must pin the block as we saw earlier. Locks are obtained subsequently and must be released before unpin- ning the block.</span></p><p class="s39" style="padding-top: 4pt;padding-left: 107pt;text-indent: -16pt;text-align: justify;">• <span class="s40">Before reading data from a buﬀer block, a process must get a shared lock on the block. When it is done reading the data, the process must release the lock.</span></p><p class="s39" style="padding-top: 4pt;padding-left: 107pt;text-indent: -16pt;text-align: justify;">• <span class="s40">Before updating the contents of a buﬀer block, a process must get an exclusive lock on the block; the lock must be released after the update is complete.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">These rules ensure that a block cannot be updated while another process is reading it, and conversely, a block cannot be read while another process is updating it. These rules are required for safety of buﬀer access; however, to protect a database system from problems due to concurrent access, these steps are not suﬃcient: further steps need to be taken. These are discussed further in Chapter 17 and Chapter 18.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s183" style="padding-left: 88pt;text-indent: 0pt;text-align: justify;">13.5.1.4 Output of blocks</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">It is possible to output a block only when the buﬀer space is needed for another block. However, it makes sense to not wait until the buﬀer space is needed, but to rather write out updated blocks ahead of such a need. Then, when space is required in the buﬀer,</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">a block that has already been written out can be evicted, provided it is not currently pinned.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">However, for the database system to be able to recover from crashes (Chapter 19), it is necessary to restrict those times when a block may be written back to disk. For instance, most recovery systems require that a block should not be written to disk while an update on the block is in progress. To enforce this requirement, a process that wishes to write the block to disk must obtain a shared lock on the block.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Most databases have a process that continually detects updated blocks and writes them back to disk.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s183" style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">13.5.1.5 Forced output of blocks</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">There are situations in which it is necessary to write a block to disk, to ensure that certain data on disk are in a consistent state. Such a write is called a <span class="s63">forced output </span>of a block. We shall see the reason for forced output in Chapter 19.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Memory contents and thus buﬀer contents are lost in a crash, whereas data on disk (usually) survive a crash. Forced output is used in conjunction with a logging mechanism to ensure that when a transaction that has performed updates commits, enough data has been written to disk to ensure the updates of the transaction are not lost. How exactly this is done is covered in detail in Chapter 19.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">13.5.2 Buffer-Replacement Strategies</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">The goal of a replacement strategy for blocks in the buﬀer is to minimize accesses to the disk. For general-purpose programs, it is not possible to predict accurately which blocks will be referenced. Therefore, operating systems use the past pattern of block references as a predictor of future references. The assumption generally made is that blocks that have been referenced recently are likely to be referenced again. Therefore, if a block must be replaced, the least recently referenced block is replaced. This approach is called the <span class="s63">least recently used </span>(<span class="s64">LRU</span>) block-replacement scheme.</p><p class="s42" style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">LRU <span class="s43">is an acceptable replacement scheme in operating systems. However, a data- base system is able to predict the pattern of future references more accurately than an operating system. A user request to the database system involves several steps. The database system is often able to determine in advance which blocks will be needed by looking at each of the steps required to perform the user-requested operation. Thus, unlike operating systems, which must rely on the past to predict the future, database systems may have information regarding at least the short-term future.</span></p><p style="padding-left: 137pt;text-indent: 0pt;text-align: justify;">To illustrate how information about future block access allows us to improve the</p><p class="s42" style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">LRU <span class="s43">strategy, consider the processing of the </span>SQL <span class="s43">query:</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s46" style="padding-left: 219pt;text-indent: 0pt;text-align: left;">select <span class="p">*</span></p><p class="s46" style="padding-left: 219pt;text-indent: 0pt;text-align: left;">from <i>instructor </i>natural join <i>department</i><span class="p">;</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 17pt;text-align: justify;">Assume that the strategy chosen to process this request is given by the pseudocode program shown in Figure 13.13. (We shall study other, more eﬃcient, strategies in Chapter 15.)</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Assume that the two relations of this example are stored in separate ﬁles. In this example, we can see that, once a tuple of <i>instructor </i>has been processed, that tuple is not needed again. Therefore, once processing of an entire block of <i>instructor </i>tuples is completed, that block is no longer needed in main memory, even though it has been used recently. The buﬀer manager should be instructed to free the space occupied by an <i>instructor </i>block as soon as the ﬁnal tuple has been processed. This buﬀer-management strategy is called the <span class="s63">toss-immediate </span>strategy.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Now consider blocks containing <i>department </i>tuples. We need to examine every block of <i>department </i>tuples once for each tuple of the <i>instructor </i>relation. When process- ing of a <i>department </i>block is completed, we know that that block will not be accessed again until all other <i>department </i>blocks have been processed. Thus, the most recently used <i>department </i>block will be the ﬁnal block to be re-referenced, and the least recently used <i>department </i>block is the block that will be referenced next. This assumption set is the exact opposite of the one that forms the basis for the <span class="s44">LRU </span>strategy. Indeed, the optimal strategy for block replacement for the above procedure is the <span class="s63">most recently used </span>(<span class="s64">MRU</span>) strategy. If a <i>department </i>block must be removed from the buﬀer, the <span class="s44">MRU </span>strategy chooses the most recently used block (blocks are not eligible for replacement while they are being used).</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 88pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="494" height="1" alt="image" src="Image_2590.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;"><b>for each </b>tuple <i>i </i>of <i>instructor </i><b>do</b></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_2591.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_2592.png"/></span></p><p class="s13" style="padding-left: 143pt;text-indent: -12pt;text-align: justify;"><b>for each </b><span class="p">tuple </span>d <span class="p">of </span>department <b>do if </b>i<span class="p">[</span>dept name<span class="p">]= </span>d<span class="p">[</span>dept name<span class="p">] </span><b>then begin</b></p><p style="padding-left: 180pt;text-indent: 0pt;text-align: justify;">let <i>x </i>be a tuple deﬁned as follows:</p><p style="padding-left: 180pt;text-indent: 0pt;text-align: justify;"><i>x</i>[<span class="s69">ID</span>] := <i>i</i>[<span class="s69">ID</span>]</p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_2593.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_2594.png"/></span></p><p class="s13" style="padding-left: 180pt;text-indent: 0pt;text-align: left;">x<span class="p">[</span>dept name<span class="p">] := </span>i<span class="p">[</span>dept name<span class="p">] </span>x<span class="p">[</span>name<span class="p">] := </span>i<span class="p">[</span>name<span class="p">] </span>x<span class="p">[</span>salary<span class="p">] := </span>i<span class="p">[</span>salary<span class="p">] </span>x<span class="p">[</span>building<span class="p">] := </span>d<span class="p">[</span>building<span class="p">] </span>x<span class="p">[</span>budget<span class="p">] := </span>d<span class="p">[</span>budget<span class="p">]</span></p><p class="s13" style="padding-left: 180pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="p">include tuple </span>x <span class="p">as part of result of </span>instructor <span class="s86">⋈ </span>department</p><p class="s46" style="padding-left: 165pt;text-indent: 0pt;line-height: 12pt;text-align: left;">end</p><p class="s46" style="padding-left: 119pt;text-indent: 12pt;text-align: left;">end end</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 88pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="494" height="1" alt="image" src="Image_2595.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s73" style="padding-top: 4pt;padding-left: 59pt;text-indent: 0pt;text-align: center;">Figure 13.13 <span class="s74">Procedure for computing join.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 119pt;text-indent: 17pt;text-align: justify;">For the <span class="s44">MRU </span>strategy to work correctly for our example, the system must pin the <i>department </i>block currently being processed. After the ﬁnal <i>department </i>tuple has been processed, the block is unpinned, and it becomes the most recently used block.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">In addition to using knowledge that the system may have about the request being processed, the buﬀer manager can use statistical information about the probability that a request will reference a particular relation. For example, the data dictionary, which we saw in Section 13.4, is one of the most frequently accessed parts of the database, since the processing of every query needs to access the data dictionary. Thus, the buﬀer manager should try not to remove data-dictionary blocks from main memory, unless other factors dictate that it do so. In Chapter 14, we discuss indices for ﬁles. Since an index for a ﬁle may be accessed more frequently than the ﬁle itself, the buﬀer man- ager should, in general, not remove index blocks from main memory if alternatives are available.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">The ideal database block-replacement strategy needs knowledge of the database operations — both those being performed and those that will be performed in the fu- ture. No single strategy is known that handles all the possible scenarios well. Indeed, a surprisingly large number of database systems use <span class="s44">LRU</span>, despite that strategy’s faults. The practice questions and exercises explore alternative strategies.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">The strategy that the buﬀer manager uses for block replacement is inﬂuenced by factors other than the time at which the block will be referenced again. If the system is processing requests by several users concurrently, the concurrency-control subsystem (Chapter 18) may need to delay certain requests, to ensure preservation of database consistency. If the buﬀer manager is given information from the concurrency-control subsystem indicating which requests are being delayed, it can use this information to alter its block-replacement strategy. Speciﬁcally, blocks needed by active (nondelayed) requests can be retained in the buﬀer at the expense of blocks needed by the delayed requests.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">The crash-recovery subsystem (Chapter 19) imposes stringent constraints on block replacement. If a block has been modiﬁed, the buﬀer manager is not allowed to write back the new version of the block in the buﬀer to disk, since that would destroy the old version. Instead, the block manager must seek permission from the crash-recovery subsystem before writing out a block. The crash-recovery subsystem may demand that certain other blocks be force-output before it grants permission to the buﬀer manager to output the block requested. In Chapter 19, we deﬁne precisely the interaction between the buﬀer manager and the crash-recovery subsystem.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-top: 7pt;padding-left: 119pt;text-indent: 0pt;text-align: left;">13.5.3 Reordering of Writes and Recovery</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">Database buﬀers allow writes to be performed in-memory and output to disk at a later time, possibly in an order diﬀerent from the order in which the writes were performed. File systems, too, routinely reorder write operations. However, such reordering can lead to inconsistent data on disk in the event of a system crash.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 17pt;text-align: justify;">To understand the problem in the context of a ﬁle system, suppose that a ﬁle system uses a linked list to track which blocks are part of a ﬁle. Suppose also that it inserts a new node at the end of the list by ﬁrst writing the data for the new node, then updating the pointer from the previous node. Suppose further that the writes were reordered, so the pointer was updated ﬁrst, and the system crashes before the new node is written. The contents of the node would then be whatever happened to be on that disk earlier, resulting in a corrupted data structure.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">To deal with the possibility of such data structure corruption, earlier-generation ﬁle systems had to perform a <i>ﬁle system consistency check </i>on system restart, to ensure that the data structures were consistent. And if they were not, extra steps had to be taken to restore them to consistency. These checks resulted in long delays in system restart after a crash, and the delays became worse as disk systems grew to higher capacities.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The ﬁle system can avoid inconsistencies in many cases if it writes updates to meta- data in a carefully chosen order. But doing so would mean that optimizations such as disk arm scheduling cannot be done, aﬀecting the eﬃciency of the update. If a non- volatile write buﬀer were available, it could be used to perform the writes in order to non-volatile <span class="s44">RAM </span>and later reorder the writes when writing them to disk.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">However, most disks do not come with a non-volatile write buﬀer; instead, mod- ern ﬁle systems assign a disk for storing a log of the writes in the order that they are performed. Such a disk is called a <span class="s63">log disk</span>. For each write, the log contains the block number to be written to, and the data to be written, in the order in which the writes were performed. All access to the log disk is sequential, essentially eliminating seek time, and several consecutive blocks can be written at once, making writes to the log disk several times faster than random writes. As before, the data have to be written to their actual location on disk as well, but the write to the actual location can be done later; the writes can be reordered to minimize disk-arm movement.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">If the system crashes before some writes to the actual disk location have been completed, when the system comes back up it reads the log disk to ﬁnd those writes that had not been completed and carries them out then. After the writes have been performed, the records are deleted from the log disk.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">File systems that support log disks as above are called <span class="s63">journaling ﬁle systems</span>. Jour- naling ﬁle systems can be implemented even without a separate log disk, keeping data and the log on the same disk. Doing so reduces the monetary cost at the expense of lower performance.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Most modern ﬁle systems implement journaling and use the log disk when writing ﬁle system metadata such as ﬁle allocation information. Journaling ﬁle systems allow quick restart without the need for such ﬁle system consistency checks.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">However, writes performed by applications are usually not written to the log disk. Database systems instead implement their own forms of logging, which we study in Chapter 19, to ensure that the contents of a database can be safely recovered in the event of a failure, even if writes were reordered.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part249.htm">&lt; 上一个</a><span> | </span><a href="../database.html">内容</a><span> | </span><a href="part251.htm">下一个 &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
