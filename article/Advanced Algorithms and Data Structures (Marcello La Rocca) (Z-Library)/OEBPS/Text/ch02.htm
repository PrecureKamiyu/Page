<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>Part 1</title>
    
  <link href="../../stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="../../page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
  <div class="tocheadb">
    <h1 class="tochead" id="heading_id_3"><a id="pgfId-998526"></a><a id="pgfId-998538"></a>2 Improving priority queues: d-way heaps</h1>
  </div>

  <p class="co-summary-head"><a id="pgfId-1021616"></a>This chapter covers</p>

  <ul class="calibre19">
    <li class="co-summary-bullet"><a class="calibre14" id="pgfId-1021648"></a>Solving the problem of serving tasks based on priority</li>

    <li class="co-summary-bullet"><a class="calibre14" id="pgfId-1021649"></a>Using priority queues to solve our problem</li>

    <li class="co-summary-bullet"><a class="calibre14" id="pgfId-1021650"></a>Implementing a priority queue with a heap</li>

    <li class="co-summary-bullet"><a class="calibre14" id="pgfId-1021651"></a>Introducing and analyzing d-way heaps</li>

    <li class="co-summary-bullet"><a class="calibre14" id="pgfId-1021637"></a>Recognizing use cases where heaps improve performance</li>
  </ul>

  <p class="body"><a id="pgfId-998644"></a>In the previous chapter we introduced some basic concepts about data structures and programming techniques, described the structure of this book, and hopefully raised your interest. You should now be aware of why developers need to know about data structures.</p>

  <p class="body"><a id="pgfId-998661"></a>In this chapter, we will further develop those ideas and refine our narration. This chapter is meant to be a soft introduction to what is presented in this book; we have chosen a topic that should be familiar to readers with some background in algorithms, while providing a review of heaps along with some new insight on branching factors.</p>

  <p class="body"><a id="pgfId-998690"></a>To this end, however, we assume that the reader is familiar with some basic concepts traditionally taught in CS 101 courses: big-O notation, the RAM model, and simple data structures such as arrays, lists, and trees. These building blocks will be leveraged throughout the book to build increasingly complex structures and algorithms, and it’s important that you familiarize yourself with such concepts in order to be able to go through the next chapters. This is why we provided a recap of these fundamental topics in the appendices at the end of the book; feel free to take a look or skim through them in order to make sure you have a good understanding of the material.</p>

  <p class="body"><a id="pgfId-998710"></a>Now that we have settled the basics, we will start with the core focus of this book, and in section 2.1 we describe the structure that we will use for each of the remaining chapters.</p>

  <p class="body"><a id="pgfId-998719"></a>Section 2.2 introduces the problem we are going to use in this chapter (how to efficiently handle events with priority), while section 2.3 outlines possible solutions, including priority queues, and explains why the latter are better than more basic data structures.</p>

  <p class="body"><a id="pgfId-998730"></a>Next, in section 2.4 we describe the priority queue API,<a href="#pgfId-1012948"><sup class="footnotenumber">1</sup></a> and we show an example of how to use it as a black box, before delving into its internals in sections 2.5 and 2.6. In the former we analyze in detail how a d-ary heap works, describing the functioning of its methods. In section 2.6 we delve into the implementation of a d-way heap.</p>

  <p class="body"><a id="pgfId-998745"></a>Sections 2.7 and 2.8 describe use cases where heaps and priority queues make a difference and allow speeding up applications or other algorithms.</p>

  <p class="body"><a id="pgfId-998756"></a>Finally, the focus of section 2.9 is understanding the optimal branching factor for a heap. Although it can be considered optional, I suggest you at least try to read it through to gain a deeper understanding of how a heap works and why you might want to choose a ternary heap instead of a binary heap, or vice versa.</p>

  <p class="body"><a id="pgfId-998771"></a>This is a long chapter, and it might look intimidating, but hang in there; we are going to cover a lot of ground and lay the foundations for the whole book.</p>

  <h2 class="fm-head" id="heading_id_4"><a id="pgfId-998782"></a>2.1 Structure of this chapter</h2>

  <p class="body"><a id="pgfId-998794"></a>Starting with the current chapter, we will embrace a schematic way to present our data structures.</p>

  <p class="body"><a id="pgfId-998803"></a>Each chapter will be driven by a practical use case for its main topic, a real-world problem showing how the data structure is used in practice, but also a step-by-step explanation of how operations are performed. We also provide code samples showing how to use the algorithms we will focus on next.</p>

  <p class="body"><a id="pgfId-998816"></a>So, first we are going to introduce a problem, one that is typically solved using the main topic of the chapter.</p>

  <p class="body"><a id="pgfId-998827"></a>Then we present one or more ways to solve it. There might be several possible solutions to the same problem, and if that’s the case, we explain when and why using a particular data structure is a good idea. At this point, usually, we still treat our data structure as a black box: we focus on how to use it and ignore the details of its implementation.</p>

  <p class="body"><a id="pgfId-998844"></a>Only in the next section do we start discussing how a data structure works. We focus on describing the mechanism, using figures and pseudo-code examples to clarify how it works.</p>

  <p class="body"><a id="pgfId-998855"></a>After the code section, we are going to discuss advanced theory topics such as performance or mathematical proofs for the algorithms.</p>

  <p class="body"><a id="pgfId-998866"></a>Usually we also provide a list of additional applications that use the algorithms presented, although for most of these further examples we have to omit coding for the sake of space.</p>

  <h2 class="fm-head" id="heading_id_5"><a id="pgfId-998876"></a><a id="id_Toc507447604"></a>2.2 The problem: Handling priority</h2>

  <p class="body"><a id="pgfId-998891"></a>The <a id="marker-999051"></a><a id="marker-999055"></a>first problem we are going to tackle is handling tasks based on priority. This is something all of us are familiar with in some way.</p>

  <p class="body"><a id="pgfId-998903"></a>The problem can be described in these terms: given a collection of tasks with different priorities, determine which task should be executed next.</p>

  <p class="body"><a id="pgfId-998914"></a>We can find many examples in the real world where we apply, consciously or not, techniques that help us decide what to do next. Our daily lives are full of tasks; usually the order in which we run them is a result of time constraints and the importance we assign to those tasks.</p>

  <p class="body"><a id="pgfId-998925"></a>A common example of an environment where tasks are executed by priority is an emergency room, where patients are seen, not according to the order in which they arrived, but instead depending on how urgent their conditions are. If we move closer to our IT domain, there are many tools and systems that have the same behavior. Think, for instance, about your operating system scheduler. Or maybe you are using a mobile app to take a to-do list.</p>

  <h3 class="fm-head2" id="heading_id_6"><a id="pgfId-998944"></a><a id="id_Toc507447605"></a><a id="id_Toc498966648"></a>2.2.1 Priority in practice: Bug tracking</h3>

  <p class="body"><a id="pgfId-998958"></a>The <a id="marker-999059"></a>example I’d like to use in this chapter, though, is a bug-tracking suite. You are probably already familiar with such a tool. When you work in teams, you need a way to track bugs and tasks so that no two people work on the same issue and duplicate effort, while making sure issues are tackled in the right order (whatever that is, depending on your business model).</p>

  <p class="body"><a id="pgfId-998979"></a>To simplify our example, let’s restrict it to the case of a bug-tracking tool where each bug is associated with a priority, expressed as the number of days within which it needs to be solved (lower numbers mean higher priority). Also, let’s assume that bugs are independent, so no bug requires solving another bug as a prerequisite.</p>

  <p class="body"><a id="pgfId-998994"></a>For our example, let’s consider the following list of bugs (in sparse order) for a single-page web application.</p>

  <p class="body"><a id="pgfId-999003"></a>Each bug will look like a tuple:</p>
  <pre class="programlisting">&lt;task description, importance of missing the deadline&gt;</pre>

  <p class="body"><a id="pgfId-999023"></a>So, for instance we could have this.</p>

  <table border="1" class="contenttable" width="100%">
    <colgroup class="calibre1">
      <col class="calibre2" span="1" width="75%"/>
      <col class="calibre2" span="1" width="25%"/>
    </colgroup>

    <tr class="calibre8">
      <th class="fm-contenttable" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1022250"></a><code class="fm-code-in-text">Task description</code></p>
      </th>

      <th class="fm-contenttable" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1022252"></a><code class="fm-code-in-text">Severity (1-10)</code></p>
      </th>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022254"></a><code class="fm-code-in-text2">Page loads take 2+ seconds</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022256"></a><code class="fm-code-in-text2">7</code></p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022258"></a><code class="fm-code-in-text2">UI breaks on browser X</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022260"></a><code class="fm-code-in-text2">9</code></p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022262"></a><code class="fm-code-in-text2">Optional form field blocked when using browser X on Friday the 13th</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022264"></a><code class="fm-code-in-text2">1</code></p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022266"></a><code class="fm-code-in-text2">CSS style causes misalignment</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022268"></a><code class="fm-code-in-text2">8</code></p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022270"></a><code class="fm-code-in-text2">CSS style causes 1px misalignment on browser X</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022272"></a><code class="fm-code-in-text2">5</code></p>
      </td>
    </tr>
  </table>

  <p class="body"><a id="pgfId-999066"></a>Whenever resources (for example, developers) are limited, there comes the need to prioritize bugs. Therefore, some bugs are more urgent than others: that’s why we associate priorities to them.</p>

  <p class="body"><a id="pgfId-999221"></a>Now, suppose a developer on our team completes her current task. She asks our suite for the next bug that needs to be solved. If this list were static, our suite’s software could just sort the bugs once, and return them in order.<a href="#pgfId-1012974"><sup class="footnotenumber">2</sup></a></p>

  <table border="1" class="contenttable" width="100%">
    <colgroup class="calibre1">
      <col class="calibre2" span="1" width="75%"/>
      <col class="calibre2" span="1" width="25%"/>
    </colgroup>

    <tr class="calibre8">
      <th class="fm-contenttable" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1022313"></a><code class="fm-code-in-text">Task description</code></p>
      </th>

      <th class="fm-contenttable" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1022315"></a><code class="fm-code-in-text">Severity (1-10)</code></p>
      </th>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022317"></a><code class="fm-code-in-text2">UI breaks on browser X</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022319"></a><code class="fm-code-in-text2">9</code></p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022321"></a><code class="fm-code-in-text2">CSS style causes misalignment</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022323"></a><code class="fm-code-in-text2">8</code></p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022325"></a><code class="fm-code-in-text2">Page loads take 2+ seconds</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022327"></a><code class="fm-code-in-text2">7</code></p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022329"></a><code class="fm-code-in-text2">CSS style causes 1px misalignment on browser X</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022331"></a><code class="fm-code-in-text2">5</code></p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022333"></a><code class="fm-code-in-text2">Optional form field blocked when using browser X on Friday the 13th</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022335"></a><code class="fm-code-in-text2">1</code></p>
      </td>
    </tr>
  </table>

  <p class="body"><a id="pgfId-999238"></a>As you can imagine, though, this is not the case. First, new bugs are discovered all the time, and so new items will be added to the list. Say a nasty encryption bug is found—you’d need to have it solved by yesterday! Moreover, priority for bugs can change over time. For instance, your CEO might decide that you are going after the market share that’s mostly using browser X, and you have a big feature launch next Friday, the 13th, so you really need to solve that bug at the bottom within a couple of <a id="marker-999412"></a>days<a id="marker-999416"></a><a id="marker-999420"></a>.</p>

  <table border="1" class="contenttable" width="100%">
    <colgroup class="calibre1">
      <col class="calibre2" span="1" width="75%"/>
      <col class="calibre2" span="1" width="25%"/>
    </colgroup>

    <tr class="calibre8">
      <th class="fm-contenttable" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1022376"></a><code class="fm-code-in-text">Task description</code></p>
      </th>

      <th class="fm-contenttable" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1022378"></a><code class="fm-code-in-text">Severity (1-10)</code></p>
      </th>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022380"></a><code class="fm-code-in-text2">Unencrypted password on DB</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022382"></a><code class="fm-code-in-text2">10</code></p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022384"></a><code class="fm-code-in-text2">UI breaks on browser X</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022386"></a><code class="fm-code-in-text2">9</code></p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022388"></a><code class="fm-code-in-text2">Optional form field blocked when using browser X on Friday the 13th</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022390"></a><code class="fm-code-in-text2">8</code></p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022392"></a><code class="fm-code-in-text2">CSS style causes misalignment</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022394"></a><code class="fm-code-in-text2">8</code></p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022396"></a><code class="fm-code-in-text2">Page loads take 2+ seconds</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022398"></a><code class="fm-code-in-text2">7</code></p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022400"></a><code class="fm-code-in-text2">CSS style causes 1px misalignment on browser X</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022402"></a><code class="fm-code-in-text2">5</code></p>
      </td>
    </tr>
  </table>

  <h2 class="fm-head" id="heading_id_7"><a id="pgfId-999421"></a><a id="id_Toc507447606"></a><a id="id_Toc498966649"></a>2.3 Solutions at hand: Keeping a sorted list</h2>

  <p class="body"><a id="pgfId-999588"></a>We <a id="marker-999939"></a><a id="marker-999943"></a><a id="marker-999947"></a>could, obviously, update our sorted list every time we have an item inserted, removed, or modified. This can work well if these operations are infrequent and the size of our list is small.</p>

  <p class="body"><a id="pgfId-999603"></a>Any of these operations, in fact, would require a linear number of elements changing position, both in worst cases and in the average case.<a href="#pgfId-1012988"><sup class="footnotenumber">3</sup></a></p>

  <p class="body"><a id="pgfId-999616"></a>For this use case, it could probably work. But if our list had millions or billions of elements, then we would most likely be in trouble.</p>

  <h3 class="fm-head2" id="heading_id_8"><a id="pgfId-999625"></a><a id="id_Toc507447607"></a><a id="id_Toc498966650"></a>2.3.1 From sorted lists to priority queues</h3>

  <p class="body"><a id="pgfId-999637"></a>Luckily for us, there is a better solution. This is the perfect use case for one of the core data structures. A priority queue will keep a partial ordering of the elements, with the guarantee that the next element returned from the queue will hold the highest priority.</p>

  <p class="body"><a id="pgfId-999664"></a>By giving up the requirement of a total ordering (which we wouldn’t need in this case, because we only consume tasks one by one), we gain in performance: each of the operations on the queue can now require only logarithmic time.</p>

  <p class="body"><a id="pgfId-999679"></a>As a side note, this reminds us how important it is to get our requirements right before implementing any solution. We need to make sure we don’t overcomplicate our work and requirements: for example, keeping a list of elements sorted when all we need is a partial ordering wastes resources and complicates our code, making it harder to maintain and <a id="marker-999951"></a><a id="marker-999955"></a><a id="marker-999959"></a>scale.</p>

  <h2 class="fm-head" id="heading_id_9"><a id="pgfId-999698"></a><a id="id_Toc507447608"></a><a id="id_Toc498966654"></a><a id="id_Toc497797684"></a>2.4 Describing the data structure API: Priority queues</h2>

  <p class="body"><a id="pgfId-999710"></a>Before delving into the topic of the chapter, let’s take a step back.</p>

  <p class="body"><a id="pgfId-999719"></a>As explained in appendix C, each data structure can be broken down into a few lower-level components:</p>

  <ul class="calibre19">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre14" id="pgfId-999732"></a><i class="calibre15">API</i><a class="calibre14" id="marker-999963"></a>—The API is the contract that a data structure <i class="fm-italics1">(DS</i><a class="calibre14" id="marker-999967"></a><i class="fm-italics1">)</i> makes with external clients. It includes method definitions, as well as some guarantees about the methods’ behavior that are provided in the DS’s specification. For example, a priority queue <i class="fm-italics1">(PQ</i><a class="calibre14" id="marker-999971"></a><i class="fm-italics1">)</i> (see table 2.1) provides these methods and guarantees:</p>

      <ul class="calibre20">
        <li class="fm-list-bullet1">
          <p class="list"><a class="calibre14" id="pgfId-999762"></a><code class="calibre24">top<a class="calibre14" id="marker-999975"></a><a class="calibre14" id="marker-999979"></a>()</code>—Returns and extracts the element with the highest priority.</p>
        </li>

        <li class="fm-list-bullet1">
          <p class="list"><a class="calibre14" id="pgfId-999779"></a><code class="calibre24">peek<a class="calibre14" id="marker-999983"></a><a class="calibre14" id="marker-999987"></a>()</code>—Like top it returns the element with the highest priority, but without extracting it from the queue.</p>
        </li>

        <li class="fm-list-bullet1">
          <p class="list"><a class="calibre14" id="pgfId-999798"></a><code class="calibre24">insert(e, p<a class="calibre14" id="marker-999991"></a>)</code>—Adds a new element <code class="fm-code-in-text">e</code> with priority <code class="calibre24">p</code> to the PQ.</p>
        </li>

        <li class="fm-list-bullet1">
          <p class="list"><a class="calibre14" id="pgfId-999819"></a><code class="calibre24">remove(e)</code>—Removes element <code class="fm-code-in-text">e</code> from the queue.</p>
        </li>

        <li class="fm-list-bullet1">
          <p class="list"><a class="calibre14" id="pgfId-999836"></a><code class="calibre24">update(e, p<a class="calibre14" id="marker-999995"></a>)</code>—Changes the priority for element <code class="calibre24">e</code> and sets it to <code class="calibre24">p</code>.</p>
        </li>
      </ul>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-999857"></a><i class="calibre15">Invariants</i><a class="calibre14" id="marker-999999"></a>—(Optional) internal properties that always hold true throughout the life of the data structure. For instance, a sorted list would have one invariant: every element is not greater than its successor. The purpose of invariants is making sure the conditions necessary to live up to the contract with the external clients are always met. They are the internal counterparts of the guarantees in the API.</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-999878"></a><i class="calibre15">Data model</i><a class="calibre14" id="marker-1022425"></a>—To host the data. This can be a raw chunk of memory, a list, a tree, etc.</p>
    </li>

    <li class="fm-list-numbered-last">
      <p class="list"><a class="calibre14" id="pgfId-999898"></a><i class="calibre15">Algorithms</i><a class="calibre14" id="marker-1022427"></a>—The internal logic that is used to update the data structure while making sure that the invariants are not violated.</p>
    </li>
  </ul>

  <p class="fm-table-caption"><a id="pgfId-1022470"></a>Table 2.1 API and contract for priority queue</p>

  <table border="1" class="contenttable" width="100%">
    <tr class="calibre8">
      <th class="fm-contenttable" colspan="2" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1022474"></a>Abstract data structure: Priority queue</p>
      </th>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022478"></a>API</p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <pre class="programlisting">class PriorityQueue {
  top() <span class="cambria">→</span> element
  peek() <span class="cambria">→</span> element
  insert(element, priority)
  remove(element)
  update(element, newPriority)
  size() <span class="cambria">→</span> int
}</pre>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022482"></a>Contract with client</p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022484"></a>The top element returned by the queue is always the element with highest priority currently stored in the queue</p>
      </td>
    </tr>
  </table>

  <p class="body"><a id="pgfId-1000022"></a>In appendix C we also clarify how there is a difference <i class="fm-italics">between an abstract data structure and concrete data structures</i><a id="marker-1000266"></a><a id="marker-1000270"></a>. The former includes the API and invariants, describing at a high level how clients will interact with it and the results and performance of operations. The latter builds on the principles and API expressed by the abstract description, adding a concrete implementation for its structure and algorithms (data model and algorithms).</p>

  <p class="body"><a id="pgfId-1000202"></a>This is exactly the relationship between <i class="fm-italics">priority queues and heaps</i><a id="marker-1000274"></a><a id="marker-1000278"></a>. A priority queue is an abstract data structure that can be implemented in many ways (including as a sorted list). A heap is a concrete implementation of the priority queue using an array to hold elements and specific algorithms to enforce invariants.</p>

  <h3 class="fm-head2" id="heading_id_10"><a id="pgfId-1000217"></a><a id="id_Toc507447609"></a><a id="id_Toc498966655"></a>2.4.1 Priority queue at work</h3>

  <p class="body"><a id="pgfId-1000231"></a>Imagine <a id="marker-1000282"></a><a id="marker-1000286"></a>you are provided with a priority queue. It can come from a third-party library or from a standard library (many languages, such as C++ or Scala, provide an implementation for priority queues in their standard container lib).</p>

  <p class="body"><a id="pgfId-1000245"></a>You don’t need to know the internals of the library at this point; you just need to follow its public API and use it, confident it’s properly implemented. This is the black box approach (figure 2.1).</p>

  <p class="body"><a id="pgfId-1000254"></a>For instance, let’s suppose we add our bugs to our PQ in the same order we have seen before.</p>

  <table border="1" class="contenttable" width="100%">
    <colgroup class="calibre1">
      <col class="calibre2" span="1" width="75%"/>
      <col class="calibre2" span="1" width="25%"/>
    </colgroup>

    <tr class="calibre8">
      <th class="fm-contenttable" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1022564"></a><code class="fm-code-in-text">Task description</code></p>
      </th>

      <th class="fm-contenttable" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1022566"></a><code class="fm-code-in-text">Severity (1-10)</code></p>
      </th>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022568"></a><code class="fm-code-in-text2">Page loads take 2+ seconds</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022570"></a><code class="fm-code-in-text2">7</code></p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022572"></a><code class="fm-code-in-text2">UI breaks on browser X</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022574"></a><code class="fm-code-in-text2">9</code></p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022576"></a><code class="fm-code-in-text2">Optional form field blocked when using browser X on Friday the 13th</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022578"></a><code class="fm-code-in-text2">1</code></p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022580"></a><code class="fm-code-in-text2">CSS style causes misalignment</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022582"></a><code class="fm-code-in-text2">8</code></p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022584"></a><code class="fm-code-in-text2">CSS style causes 1px misalignment on browser X</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022586"></a><code class="fm-code-in-text2">5</code></p>
      </td>
    </tr>
  </table>

  <p class="body"><a id="pgfId-1000291"></a>If we returned the tasks in the same order as we inserted them, we would just implement as a plain queue (see figure 2.2 for a quick glance at how a queue works, and appendix C for a description of basic containers). Instead, let’s assume that now we have our priority queue containing those five elements; we still don’t know the internals of the PQ, but we can query it through its API.</p>

  <p class="fm-figure"><img alt="" class="calibre23" src="../Images/ch02_F1.png"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1045915"></a>Figure 2.1 Representation of a priority queue as a black box. If we employ an implementation of a priority queue provided by a third-party library (or from standard libraries), and we trust this implementation to be correct, we can use it as a black box. In other words, we can ignore its internals, and just interact with it through its API.</p>

  <p class="body"><a id="pgfId-1000461"></a>For instance, we can check how many elements it contains and even take a peek at the one at the top (figure 2.1). Or we can directly ask it to return us the top element (the one with the highest priority) and remove it from the queue.</p>

  <p class="body"><a id="pgfId-1000479"></a>If, after inserting the five elements in figure 2.1, we call <code class="fm-code-in-text">top</code><a id="marker-1000766"></a>, the element returned will be “UI breaks on browser X” and the size of the queue will become 4. If we call <code class="fm-code-in-text">top</code> again, the next element will be “CSS style causes misalignment” and the size will become 3.</p>

  <p class="body"><a id="pgfId-1000500"></a>As long as the priority queue is implemented correctly and given the priorities in our examples, we can be sure those two elements will be the ones returned first, independently of the order in which they are <a id="marker-1000770"></a><a id="marker-1000774"></a><a id="marker-1000778"></a><a id="marker-1000782"></a>inserted.</p>

  <p class="fm-figure"><img alt="" class="calibre23" src="../Images/ch02_F2.png"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1046025"></a>Figure 2.2 Operations on a queue: elements are generic integers, but they could be any value here, because in plain queues priority is only given by the order of insertion (see appendix D). Insertion (enqueue) adds an element to the front of the queue. Deletion (dequeue) removes the last element in the queue and returns it. With some caution, both operations can be performed in constant time.</p>

  <h3 class="fm-head2" id="heading_id_11"><a id="pgfId-1000536"></a><a id="id_Toc507447610"></a>2.4.2 Priority matters: Generalize FIFO</h3>

  <p class="body"><a id="pgfId-1000551"></a>Now the question is how we choose the priority of an element. Often, the natural ordering given by how much time an element waits in a line can be considered the fairest. Sometimes, however, there is something special about some elements that might suggest they should be served sooner than others that waited longer. For instance, you don’t always read your emails in the order you received them, but often you skip newsletters or “funny” jokes from friends to read work-related messages first. Likewise, in an emergency room, the next case treated is not necessarily going to be one that has been waiting for the longest time. Rather, every case is evaluated at arrival and assigned a priority, and the highest priority one is going to be called in when a doctor becomes available.</p>

  <p class="body"><a id="pgfId-1000560"></a>That’s the idea behind priority queues: they behave like regular, plain queues, except that the front of the queue is dynamically determined based on some kind of priority. The differences caused to the implementation by the introduction of priority are profound, enough to deserve a special kind of data structure.</p>

  <p class="body"><a id="pgfId-1000573"></a>But that’s not all: we can even define basic containers as <i class="calibre17">bag</i> or <i class="calibre17">stack</i> as special cases of priority queues; appendix D explores how this is possible. This is an interesting topic to help you gain a deeper understanding of how priority queues work, although in practice those containers are usually implemented ad hoc, because we can achieve better performance by leveraging their <a id="marker-1000786"></a><a id="marker-1000790"></a>specific characteristics.</p>

  <h2 class="fm-head" id="heading_id_12"><a id="pgfId-1000604"></a><a id="id_Toc507447611"></a><a id="id_Toc507447612"></a>2.5 Concrete data structures</h2>

  <p class="body"><a id="pgfId-1000620"></a>Let’s <a id="marker-1000794"></a><a id="marker-1000798"></a><a id="marker-1000802"></a><a id="marker-1000806"></a>now move from abstract to concrete data structures. Knowing how the API of a priority queue works is good enough to use it, but often it is not enough to use it well. Especially on time-critical components or in data-intensive applications, we often need to understand the internals of the data structures and the details of its implementation to make sure we can integrate it in our solution without introducing a bottleneck.<a href="#pgfId-1013002"><sup class="footnotenumber">4</sup></a></p>

  <p class="body"><a id="pgfId-1000636"></a>Every abstraction needs to be implemented using a concrete data structure. For example, a stack can be implemented using a list, an array, or in theory even a heap (although this would be silly, as will be clear in a few sections). The choice of the underlying data structure used to implement a container will only influence the container’s performance. Choosing the best implementation is usually a tradeoff: some data structures speed up some operations but will make other operations slower.</p>

  <h3 class="fm-head2" id="heading_id_13"><a id="pgfId-1000654"></a>2.5.1 Comparing performance</h3>

  <p class="body"><a id="pgfId-1000669"></a>For <a id="marker-1000810"></a><a id="marker-1000814"></a><a id="marker-1000818"></a>the implementation of a priority queue, we will initially consider three naïve alternatives using core data structures discussed in appendix C: an unsorted array, where we just add elements to its end; a sorted array, where we make sure the ordering is reinstated every time we add a new element; and balanced trees, of which heaps are a special case. Let’s compare, in table 2.2, the running times<a href="#pgfId-1013016"><sup class="footnotenumber">5</sup></a> for basic operations implemented with these data <a id="marker-1000822"></a><a id="marker-1000826"></a><a id="marker-1000830"></a>structures.</p>

  <h3 class="fm-head2" id="heading_id_14"><a id="pgfId-1000696"></a>2.5.2 What’s the right concrete data structure?</h3>

  <p class="body"><a id="pgfId-1000708"></a>From <a id="marker-1000834"></a><a id="marker-1000838"></a><a id="marker-1000842"></a>table 2.2 we can see that naïve choices would lead to a linear time requirement for at least one of the core operations, while a balanced tree would always guarantee a logarithmic worst case. Although linear time is usually regarded as “feasible,” there is still a tremendous difference between logarithmic and linear: for a billion elements, the difference is between 1 billion operations and a few dozens. If each operation takes 1 millisecond, that means going from 11 days to less than a second.</p>

  <p class="fm-table-caption"><a id="pgfId-1022669"></a>Table 2.2 Performance for operations provided by PQs, broken bown by underlying data structure</p>

  <table border="1" class="contenttable" width="100%">
    <tr class="calibre8">
      <th class="fm-contenttable" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1022677"></a>Operation</p>
      </th>

      <th class="fm-contenttable" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1022679"></a>Unsorted array</p>
      </th>

      <th class="fm-contenttable" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1022681"></a>Sorted array</p>
      </th>

      <th class="fm-contenttable" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1022683"></a>Balanced tree</p>
      </th>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022685"></a><code class="fm-code-in-text2">Insert</code><a id="marker-1022708"></a></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022687"></a>O(1)</p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022689"></a>O(n)</p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022691"></a>O(log n)</p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022693"></a><code class="fm-code-in-text2">Find-Minimum</code><a id="marker-1022709"></a></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022695"></a>O(1) <a href="#pgfId-1022736"><sup class="footnotenumber1">a</sup></a></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022697"></a>O(1)</p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022699"></a>O(1) <a href="#pgfId-1022736"><sup class="footnotenumber1">a</sup></a></p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022701"></a><code class="fm-code-in-text2">Delete-Minimum</code><a id="marker-1022710"></a></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022703"></a>O(n) <a href="#pgfId-1022783"><sup class="footnotenumber1">b</sup></a></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022705"></a>O(1) <a href="#pgfId-1022813"><sup class="footnotenumber1">c</sup></a></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022707"></a>O(log n)</p>
      </td>
    </tr>
  </table>

  <p class="fm-footnote"><sup class="footnotenumber">a</sup> <a id="pgfId-1022736"></a>By saving an extra value with the minimum and charging the cost of maintaining its value on insert and delete.</p>

  <p class="fm-footnote"><sup class="footnotenumber">b</sup> <a id="pgfId-1022783"></a>If we use a buffer to speed up find-minimum, then we need to find the next minimum on delete. Unfortunately, nothing comes for free. Alternatively, we could have constant-time delete by giving up the buffer and swapping the deleted element with the last in the array, and linear time find-minimum.</p>

  <p class="fm-footnote"><sup class="footnotenumber">c</sup> <a id="pgfId-1022813"></a>Storing the array in reverse order, deleting the last element might just be a matter of shrinking the size of the array, or somehow keeping track of what’s the last element in the array.</p>

  <p class="body"><a id="pgfId-1001094"></a>Moreover, consider that most of the times containers, and priority queues in particular, are used as support structures, meaning that they are part of more complex algorithms/ data structures and each cycle of the main algorithm can call operations on the PQ several times. For example, for a sorting algorithm, this could mean going from <code class="fm-code-in-text">O(n2),</code> which usually means unfeasible for <code class="fm-code-in-text">n</code> as large as 1 million, or even less, to <code class="fm-code-in-text">O(n*log(n))</code>, which is still tractable for inputs of size 1 billion or more.<a href="#pgfId-1013030"><sup class="footnotenumber">6</sup></a> However, this would come at a cost, because the implementation of balanced binary trees is usually not trivial.</p>

  <p class="body"><a id="pgfId-1001134"></a>Next, we present a way to efficiently implement a generic priority <a id="marker-1001487"></a><a id="marker-1001491"></a><a id="marker-1001495"></a>queue.</p>

  <h3 class="fm-head2" id="heading_id_15"><a id="pgfId-1001147"></a>2.5.3 <a id="id_Toc507447613"></a>Heap</h3>

  <p class="body"><a id="pgfId-1001159"></a>A <a id="marker-1001499"></a><a id="marker-1001503"></a><a id="marker-1001507"></a>binary heap is the most used version of priority queues. It allows elements to be inserted and retrieved in either ascending or descending order, one at a time.</p>

  <p class="body"><a id="pgfId-1001175"></a>While in reality an underlying array is used to store heap’s elements, it can conceptually be represented as a particular kind of binary tree, abiding by three invariants:</p>

  <ul class="calibre19">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre14" id="pgfId-1001190"></a>Every node has at most two children.</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-1001205"></a>The heap tree is complete and left-adjusted. Complete (see figure 2.3) means that if the heap has height <code class="fm-code-in-text">H</code>, every leaf node is either at level <code class="fm-code-in-text">H</code> or <code class="fm-code-in-text">H-1</code>. All the levels are left-adjusted, which means that no right sub-tree has a height greater than its left sibling. So, if a leaf is at the same height as an internal node,<a class="calibre14" href="#pgfId-1013046"><sup class="footnotenumber">7</sup></a> the leaf can’t be on the left of that node. Invariant numbers 1 and 2 are the structural invariants for heaps.</p>
    </li>

    <li class="fm-list-numbered-last">
      <p class="list"><a class="calibre14" id="pgfId-1001234"></a>Every node holds the highest priority in the subtree rooted at that node.</p>

      <p class="fm-figure"><img alt="" class="calibre23" src="../Images/ch02_F3.png"/></p>

      <p class="fm-figure-caption"><a id="pgfId-1046201"></a>Figure 2.3 Two examples of complete binary trees. All levels in the tree have the maximum possible number of nodes, except (possibly) the last one. All leaves in the last level are left-adjusted; at the previous level, no right subtree has more nodes than its left sibling.</p>
    </li>
  </ul>

  <p class="body"><a id="pgfId-1001271"></a>Properties (1) and (2) allow for the array representation of the heap. Supposing we need to store <code class="fm-code-in-text">N</code> elements, the tree structure is directly and compactly represented using an array of <code class="fm-code-in-text">N</code> elements, without pointers to children or parents. Figure 2.4 shows how the tree and array representation of a heap are equivalent.</p>

  <p class="body"><a id="pgfId-1001296"></a>In the array representation, if we are starting to count indices from <code class="fm-code-in-text">0</code>, the children of the <code class="fm-code-in-text">i</code>-th node are stored in the positions<a href="#pgfId-1013060"><sup class="footnotenumber">8</sup></a> <code class="fm-code-in-text">(2 * i) + 1</code> and <code class="fm-code-in-text">2 * (i + 1)</code>, while the parent of node <code class="fm-code-in-text">i</code> is at index <code class="fm-code-in-text">(i - 1) / 2</code> (except for the root, which has no parent). For example, looking at figure 2.4, the node at index <code class="fm-code-in-text">1</code> (whose priority is <code class="fm-code-in-text">3</code>) has two children at indices <code class="fm-code-in-text">3</code> and <code class="fm-code-in-text">4</code>, and its parent is at index <code class="fm-code-in-text">0</code>; if we consider a node at position <code class="fm-code-in-text">5</code>, its parent is the element at index <code class="fm-code-in-text">2</code> and its children (not shown in the picture) would be at indices <code class="fm-code-in-text">11</code> and <code class="fm-code-in-text">12</code>.</p>

  <p class="body"><a id="pgfId-1001363"></a>It might seem counterintuitive that we use an array to represent a tree. After all, trees were invented to overcome array limitations. This is generally true, and trees have a number of advantages: they are more flexible and, if balanced, allow for better performance, with worst-case logarithmic search, insertion, and delete.</p>

  <p class="fm-figure"><img alt="" class="calibre23" src="../Images/ch02_F4.png"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1046241"></a>Figure 2.4 A binary heap. Only priorities are shown for the nodes (elements are irrelevant here).The numbers inside the small squares show the indices of the heap elements in the array. Nodes are matched into array elements top to bottom, left to right. Top: the tree representation for the heap. Notice how every parent is smaller than (or at most equal to) its children and, in turn, all elements in its subtree. Bottom: the same heap in its array representation.</p>

  <p class="body"><a id="pgfId-1001413"></a>But the improvement we get with trees comes with a price, of course. First, as with any data structure that uses pointers (lists, graphs, trees, and so on) we have a memory overhead in comparison to arrays. While with the latter we just need to reserve space for the data (plus maybe, depending on the implementation details, some constant space for pointers and the node structure itself), every tree node requires extra space for the pointers to its children and possibly to its parent.</p>

  <p class="body"><a id="pgfId-1001429"></a>Without getting into too much detail, arrays also tend to be better at exploiting <i class="calibre17">memory locality</i><a id="marker-1001511"></a>: all the elements in the array are contiguous in memory, and this means lower latency when reading them.</p>

  <p class="body"><a id="pgfId-1001443"></a>Table 2.3 shows how a heap matches a priority queue for its abstract part, and what its concrete data model and invariants <a id="marker-1001515"></a><a id="marker-1001519"></a><a id="marker-1001523"></a><a id="marker-1001527"></a>are.</p>

  <p class="fm-table-caption"><a id="pgfId-1022956"></a>Table 2.3 Underlying components for a heap</p>

  <table border="1" class="contenttable" width="100%">
    <tr class="calibre8">
      <th class="fm-contenttable" colspan="2" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1022960"></a>Concrete data structure: Heap</p>
      </th>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022964"></a>API<a id="marker-1022983"></a></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <pre class="programlisting">Heap {
  top() <span class="cambria">→</span> element
  peek()<span class="cambria">→</span> element
  insert(element, priority)
  remove(element)
  update(element, newPriority)
}</pre>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022968"></a>Contract with client</p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022970"></a>The top element returned by the queue is always the element with highest priority currently stored in the queue.</p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022972"></a>Data model</p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022974"></a>An array whose elements are the items stored in the heap.</p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022980"></a>Invariants</p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1022982"></a>Every element has two “children.” For the element at position i, its children are located at indices 2*i+1 and 2*(i+1).</p>

        <p class="fm-table-body"><a id="pgfId-1023037"></a>Every element has higher priority than its children.</p>
      </td>
    </tr>
  </table>

  <h3 class="fm-head2" id="heading_id_16"><a id="pgfId-1001530"></a><a id="id_Toc507447614"></a><a id="id_Toc498966657"></a><a id="id_Toc497797686"></a>2.5.4 Priority, min-heap, and max-heap</h3>

  <p class="body"><a id="pgfId-1001749"></a>When <a id="marker-1006330"></a><a id="marker-1006334"></a><a id="marker-1006338"></a><a id="marker-1006342"></a><a id="marker-1006346"></a><a id="marker-1006350"></a><a id="marker-1006354"></a>we stated the three heap’s properties, we used the wording “highest priority.” In a heap, we can always say that the highest priority element will be at the top, without raising any ambiguity.</p>

  <p class="body"><a id="pgfId-1001770"></a>Then when it comes to practice, we will have to define what priority means, but if we implement a general-purpose heap, we can safely parameterize it with a custom priority function, taking an element and returning its priority. As long as our implementation abides by the three laws as stated in section 2.5.3, we will be sure our heap works as expected.</p>

  <p class="body"><a id="pgfId-1001785"></a>Sometimes, however, it’s better to have specialized implementations that leverage the domain knowledge and avoid the overhead of a custom priority function. For instance, if we store tasks in a heap, we can use tuples (<code class="fm-code-in-text">priority, task</code>) as elements, and rely on the natural ordering of tuples.<a href="#pgfId-1013079"><sup class="footnotenumber">9</sup></a></p>

  <p class="body"><a id="pgfId-1001800"></a>Either way, we still need to define what highest priority means. If we assume that highest priority means a larger number, that is, if p<sub class="subscript">1</sub> &gt; p<sub class="subscript">2</sub> means p<sub class="subscript">1</sub> is the highest priority, then we call our heap a max-heap<a id="marker-1006358"></a>.</p>

  <p class="body"><a id="pgfId-1001820"></a>At other times we need to return smallest numbers first, so we assume instead that p<sub class="subscript">1</sub> &gt; p<sub class="subscript">2</sub> means p<sub class="subscript">2</sub> is the highest priority. In this case, we are using a min-heap. In the rest of the book, and in particular in the coding section, assume we are implementing a <i class="calibre17">max-heap</i>.</p>

  <p class="body"><a id="pgfId-1001846"></a>The implementation of a min-heap differs only slightly from a max-heap, the code is pretty much symmetric, and you just need to exchange all occurrences of &lt; and <span class="cambria">≤</span> to &gt; and ≥ respectively, and swap <code class="fm-code-in-text">min</code><a id="marker-1006362"></a> with <code class="fm-code-in-text">max</code><a id="marker-1006366"></a>.</p>

  <p class="body"><a id="pgfId-1001861"></a>Or, alternatively, it’s even easier if you have an implementation of one to get the other by simply taking the reciprocal of priorities (either in your priority function or when you pass priority explicitly).</p>

  <p class="body"><a id="pgfId-1001872"></a>To give you a concrete example, suppose you have a min-heap that you use to store <code class="fm-code-in-text">(age</code>, <code class="fm-code-in-text">task)</code> pairs: a min-heap will return the task with smallest ages first. Because we might instead be interested in having the oldest task returned first, we would rather need a max-heap; it turns out we can get the same result without changing any code for out heap! We just need to store elements as tuples <code class="fm-code-in-text">(-age, task)</code> instead. If <code class="fm-code-in-text">x.age &lt; y.age</code>, in fact, then <code class="fm-code-in-text">-x.age &gt; -y.age</code>, and thus the min-heap will return first the tasks whose age have the largest absolute value.</p>

  <p class="body"><a id="pgfId-1001904"></a>For instance, if we have task <code class="fm-code-in-text">A</code> with age 2 (days) and task <code class="fm-code-in-text">B</code> with age 3, then we create the tuples <code class="fm-code-in-text">(-2, A)</code> and <code class="fm-code-in-text">(-3, B)</code>; when extracting them from a min-heap, we can check that <code class="fm-code-in-text">(-3, B) &lt; (-2, A)</code> and so the former will be returned before the <a id="marker-1006370"></a><a id="marker-1006374"></a><a id="marker-1006378"></a><a id="marker-1006382"></a><a id="marker-1006386"></a><a id="marker-1006390"></a><a id="marker-1006394"></a>latter.</p>

  <h3 class="fm-head2" id="heading_id_17"><a id="pgfId-1001931"></a>2.5.5 Advanced variant: d-ary heap</h3>

  <p class="body"><a id="pgfId-1001945"></a>One <a id="marker-1006398"></a><a id="marker-1006402"></a><a id="marker-1006406"></a><a id="marker-1006410"></a><a id="marker-1006414"></a>could think that heaps needs to be binary trees. After all, binary search trees are the most common kind of trees, intrinsically associated with ordering. It turns out that there is no reason to keep our branching factor<a href="#pgfId-1013124"><sup class="footnotenumber">10</sup></a> fixed and equal to 2. On the contrary, we can use any value greater than 2, and use the same array representation for the heap.</p>

  <p class="body"><a id="pgfId-1001967"></a>For a branching factor 3, the children of the i-th node are at indices <code class="fm-code-in-text">3*i + 1</code>, <code class="fm-code-in-text">3*i + 2</code> and <code class="fm-code-in-text">3*(i + 1)</code>, while the parent of node <code class="fm-code-in-text">i</code> is at position <code class="fm-code-in-text">(i - 1)/3</code>.</p>

  <p class="fm-figure"><img alt="" class="calibre23" src="../Images/ch02_F5.png"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1046285"></a>Figure 2.5 A three-way heap. Only priorities are shown for the nodes (values are irrelevant here). The smaller squares next to the elements show the indices of the heap elements in the array. Top: the tree representation for a min-heap. Notice how every parent is smaller than (or at most equal to) its children and, in turn, all elements in its subtree. Bottom: the same heap in its array representation.</p>

  <p class="body"><a id="pgfId-1002027"></a>Figure 2.5 shows both the tree and array representation of a 3-ary heap. The same idea holds for branching factors 4, 5, and so on.</p>

  <p class="body"><a id="pgfId-1002041"></a>For a <i class="calibre17">d-ary</i> heap, where the branching factor is the integer <code class="fm-code-in-text">D &gt; 1</code>, our three heap <a id="marker-1006418"></a><a id="marker-1006422"></a><a id="marker-1006426"></a><a id="marker-1006430"></a><a id="marker-1006434"></a>invariants <a id="marker-1006438"></a><a id="marker-1006442"></a><a id="marker-1006446"></a><a id="marker-1006450"></a>become</p>

  <ul class="calibre19">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre14" id="pgfId-1002067"></a>Every node has at most <code class="fm-code-in-text">D</code> children.</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-1002081"></a>The heap tree is complete, with all the levels that are left-adjusted. That is, the <code class="fm-code-in-text">i</code>-th sub-tree has a height at most equal to its siblings on its left (from <code class="fm-code-in-text">0</code> to <code class="fm-code-in-text">i-1</code>, <code class="fm-code-in-text">1 &lt; i &lt;= D</code>).</p>
    </li>

    <li class="fm-list-numbered-last">
      <p class="list"><a class="calibre14" id="pgfId-1002107"></a>Every node holds the highest priority in the subtree rooted at that node.</p>
    </li>
  </ul>

  <p class="fm-callout"><a id="pgfId-1002121"></a><span class="fm-callout-head">Fun fact</span> It’s worth noting that for <code class="fm-code-in-text2">D = 1</code>, the heap becomes a sorted array (or a sorted doubly linked list in its tree representation). The heap construction will be the insertion sort algorithm and requires quadratic time. Every other operation requires linear time.</p>

  <h2 class="fm-head" id="heading_id_18"><a id="pgfId-1002140"></a>2.6 How to implement a heap</h2>

  <p class="body"><a id="pgfId-1002152"></a>At <a id="marker-1006454"></a><a id="marker-1006458"></a><a id="marker-1006462"></a>this point we have a good idea of how a priority queue should be used and its internal representation. It’s about time we delve into the details of the implementation for a heap.</p>

  <p class="body"><a id="pgfId-1002169"></a>Before we go, let’s once again take a look at our API:</p>
  <pre class="programlisting">class Heap {
  top()
  peek()
  insert(element, priority)
  remove(element)
  update(element, newPriority)
}</pre>

  <p class="body"><a id="pgfId-1002249"></a>These are just the public methods defining the API of our class.</p>

  <p class="body"><a id="pgfId-1002259"></a>But first things first. We will assume, hereafter, that we store all the <code class="fm-code-in-text">(element</code>, <code class="fm-code-in-text">priority)</code> tuples added to the heap in an array named <code class="fm-code-in-text">pairs</code><a id="marker-1023604"></a>, as shown in listing 2.1.</p>

  <p class="fm-code-listing-caption"><a id="pgfId-1023208"></a>Listing 2.1 The <code class="fm-code-in-text">DHeap</code> class properties</p>
  <pre class="programlisting"><b class="strong">class</b> DHeap
  <b class="strong">#type</b> Array[Pair]
  pairs 
  <b class="strong">function</b> DHeap(pairs=[])</pre>

  <p class="body"><a id="pgfId-1002336"></a>This is the first time we see a code snippet in this book. It might be a good chance for you to review <i class="fm-italics">appendix A</i>, where we explain the syntax used. For instance, if we have a variable <code class="fm-code-in-text">p</code> holding such a tuple, we embrace a specific syntax for destructured assignment of its fields into two variables:</p>
  <pre class="programlisting">(element, priority) ← p</pre>

  <p class="body"><a id="pgfId-1002362"></a>We also assume that the tuple’s fields are named, so that we can access, in turn, <code class="fm-code-in-text">p.element</code> and <code class="fm-code-in-text">p.priority</code>, or create a tuple <code class="fm-code-in-text">p</code> with this syntax:</p>
  <pre class="programlisting">p ← (element=’x’, priority=1)</pre>

  <p class="body"><a id="pgfId-1002384"></a>In many figures in this section, we will only show an element’s priorities or, to see it in another way, we assume that elements and priorities are the same. This is just for the sake of space and clarity in diagrams, but it also highlights an important characteristic of heaps: in all their methods, we only need to access and move priorities. This can be important when elements are large objects, especially if they are so large that they won’t fit in cache/memory or for any reason they are stored on disk; then the concrete implementation can just store and access a reference to the elements and its priority.</p>

  <p class="body"><a id="pgfId-1002404"></a>Now, before delving into the API methods, we need to define two helper functions that will be used to reinstate the heap properties whenever a change is performed. The possible changes for a heap are</p>

  <ul class="calibre19">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre14" id="pgfId-1002414"></a>Adding a new element to the heap</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-1002426"></a>Removing the top element of the heap</p>
    </li>

    <li class="fm-list-numbered-last">
      <p class="list"><a class="calibre14" id="pgfId-1002438"></a>Updating an element’s priority</p>
    </li>
  </ul>

  <p class="body"><a id="pgfId-1002450"></a>Any of these operations can cause a heap element to have higher priority than its parent or a lower priority than (one of) its children.</p>

  <h3 class="fm-head2" id="heading_id_19"><a id="pgfId-1002461"></a><a id="id_Toc507447815"></a>2.6.1 BubbleUp</h3>

  <p class="body"><a id="pgfId-1002473"></a>When <a id="marker-1026259"></a><a id="marker-1026260"></a><a id="marker-1026261"></a>an element has a higher priority than its parent, it is necessary to call the <code class="fm-code-in-text">bubbleUp</code> method<a id="marker-1026263"></a>, as shown in listing 2.2. Figure 2.6 shows an example based on our task management tool: the priority of the element at index 7 is higher than its parent (at index 2) and thus these two elements need to be swapped.</p>

  <p class="fm-code-listing-caption"><a id="pgfId-1023240"></a>Listing 2.2 The <code class="fm-code-in-text">bubbleUp</code> method</p>
  <pre class="programlisting"><b class="strong">function</b> bubbleUp(pairs, index=|pairs|-1)                                <span class="fm-combinumeral">❶</span>
  parentIndex ← index                                                    <span class="fm-combinumeral">❷</span>
  <b class="strong">while</b> parentIndex &gt; 0 <b class="calibre21">do</b>                                               <span class="fm-combinumeral">❸</span>
    currentIndex ← parentIndex
    parentIndex ← getParentIndex(parentIndex)                            <span class="fm-combinumeral">❹</span>
    <b class="strong">if</b> pairs[parentIndex].priority &lt; pairs[currentIndex].priority <b class="strong">then</b>   <span class="fm-combinumeral">❺</span>
      swap(pairs, currentIndex, parentIndex)                             <span class="fm-combinumeral">❻</span>
    <b class="strong">else</b>                                                                 <span class="fm-combinumeral">❼</span>
      <b class="strong">break</b></pre>

  <p class="fm-code-annotation"><a id="pgfId-1037508"></a><span class="fm-combinumeral">❶</span> We explicitly pass the array with all pairs and the index (by default the last element) as arguments. In this context, <code class="fm-code-in-text2">|A|</code> means the size of an array <code class="fm-code-in-text2">A</code>.</p>

  <p class="fm-code-annotation"><a id="pgfId-1037529"></a><span class="fm-combinumeral">❷</span> Start from the element at the index passed as argument (by default the last element of <code class="fm-code-in-text2">A</code>).</p>

  <p class="fm-code-annotation"><a id="pgfId-1037549"></a><span class="fm-combinumeral">❸</span> Check if the current element is already at the root of the heap. If so, we are finished.</p>

  <p class="fm-code-annotation"><a id="pgfId-1037566"></a><span class="fm-combinumeral">❹</span> Compute the index of the parent of current element in the heap. The formula can vary with the type of implementation. For a heap with branching factor <code class="fm-code-in-text2">D</code> and array’s indices starting at zero, it’s <code class="fm-code-in-text2">(parentIndex-1)/D</code>.</p>

  <p class="fm-code-annotation"><a id="pgfId-1037583"></a><span class="fm-combinumeral">❺</span> If the parent has lower priority than the current element <code class="fm-code-in-text2">p</code> . . .</p>

  <p class="fm-code-annotation"><a id="pgfId-1037600"></a><span class="fm-combinumeral">❻</span> . . . then swaps parent and children.</p>

  <p class="fm-code-annotation"><a id="pgfId-1037617"></a><span class="fm-combinumeral">❼</span> Otherwise, we are sure that heap’s properties are reinstated, and we can exit the loop and return.</p>

  <p class="body"><a id="pgfId-1002696"></a>As listing 2.2 shows, we keep swapping elements until either current element gets assigned to the root (line #3), or its priority is lower than its next ancestor (line #6-#9). This means that each call to this method can involve at most <code class="fm-code-in-text">log<sub class="subscript1">D</sub>(n)</code> comparisons and exchanges, because it’s upper-bounded by the height of the heap.</p>

  <p class="fm-figure"><img alt="" class="calibre23" src="../Images/ch02_F6.png"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1046327"></a>Figure 2.6 The bubbleUp method in action on a ternary max-heap. (A) The element at index 7 has a higher priority (9) than its parent (whose priority is 8). (B) We swap element at index 7 with its parent at index 2. The element now at index 7 has certainly found its final position, while the one bubbled up needs to be compared to its new parent. In this case, the root has a higher priority, so bubbling up stops.</p>

  <p class="body"><a id="pgfId-1002736"></a>Remember we are implementing a max-heap, so higher numbers mean higher priority. Then, as shown in figure 2.6 (A), the element at index [7] is out of place, because its parent, “Optional form field blocked . . . ” at index [2], has priority 8 &lt; 9.</p>

  <p class="body"><a id="pgfId-1002756"></a>At this point, to fix things we need to call <code class="fm-code-in-text">bubbleUp(pairs, 7)</code>. We enter the loop at line #3, because <code class="fm-code-in-text">parentIndex</code><a id="marker-1006494"></a> is <code class="fm-code-in-text">7 &gt; 0</code>, compute the new parent’s index, which is 2, and hence the condition at line #6 is also <code class="fm-code-in-text">true</code><a id="marker-1006498"></a>, so at line #7 the two elements will be swapped. After the update, the heap’s array will look like figure 2.6 (B).</p>

  <p class="body"><a id="pgfId-1002787"></a>At the next iteration of the loop (<code class="fm-code-in-text">parentIndex</code> is still <code class="fm-code-in-text">2 &gt; 0</code>, so the loop will be entered at least once more), the new values for <code class="fm-code-in-text">currentIndex</code> and <code class="fm-code-in-text">parentIndex</code> will evaluate, at lines #4-5, to 2 and 0, respectively.</p>

  <p class="body"><a id="pgfId-1002809"></a>Since elements’ priorities are now, in turn, 9 and 10 for child and parent, the condition at line #6 is not met anymore, and the function will break out of the loop and return.</p>

  <p class="body"><a id="pgfId-1002842"></a>Notice that this method, if the height of the tree is <code class="fm-code-in-text">H</code>, requires at most <code class="fm-code-in-text">H</code> swaps, because each time we swap two elements, we move one level up in the tree, toward its root.</p>

  <p class="body"><a id="pgfId-1002855"></a>This result is an important result, as we will see in section 2.7. Because heaps are balanced binary trees, their height is logarithmic in the number of elements.</p>

  <p class="body"><a id="pgfId-1002866"></a>But we can add a further improvement with just a small change. If you notice, we are repeatedly swapping the same element with its current parent; this element, the one on which <code class="fm-code-in-text">bubbleUp</code><a id="marker-1006506"></a> is initially called, keeps moving toward the root. You can see in figure 2.6 that it “bubbles up,” like a soap bubble floating toward the top of the heap. Each swap requires three assignments (and the use of a temporary variable), so the naïve implementation in listing 2.2 would require (at most) <code class="fm-code-in-text">3*H</code> assignments.</p>

  <p class="body">While both indices, the current and the parent node’s, change at each iteration, the value of the current element is always the same.</p>

  <p class="body"><a id="pgfId-1002901"></a>Figure 2.7 highlights the path that such an element has to travel. In the worst case it travels up to the root, as shown in the picture, but possibly bubbling up could stop at an intermediate node. It turns out that bubbling up an element in the path <code class="fm-code-in-text">P</code> to the heap’s root is equivalent to inserting that element in the (sub)array obtained by only considering those elements in <code class="fm-code-in-text">P</code> (see figure 2.7 (B)).</p>

  <p class="fm-figure"><img alt="" class="calibre23" src="../Images/ch02_F7.png"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1046381"></a>Figure 2.7 Bubbling up of an element in a max-heap, using the method that reduces the number of assignments to one-third. The figure shows a call to <code class="fm-code-in-text">bubbleUp(pairs, 7)</code> displaying the tree representation (A) and the array representation (B) for a max-heap, and filtered elements (C) in the path <code class="fm-code-in-text">P</code> from the element to the root.</p>

  <p class="body"><a id="pgfId-1002922"></a>Referring to figure 2.7, the first action needed is saving to a temporary variable the element <code class="fm-code-in-text">X</code> that will move up (step 1). Then, starting with its parent, we compare all elements in the path to the temporary variable and copy them over in case they have lower priority (steps 1–3). At each time, we copy the parent element over its one child that is on the path <code class="fm-code-in-text">P</code>. It’s like we filter out all the elements in the heap’s array that are not part of <code class="fm-code-in-text">P: t</code>His is highlighted in 2.7 (C).</p>

  <p class="body"><a id="pgfId-1002943"></a>Finally, when we find an element <code class="fm-code-in-text">Y</code> along <code class="fm-code-in-text">P</code> that has higher priority than our temporary, we can copy element <code class="fm-code-in-text">X</code> from the temporary variable to the one child of <code class="fm-code-in-text">Y</code> that belongs to <code class="fm-code-in-text">P</code> (step 4).</p>

  <p class="body"><a id="pgfId-1002963"></a>Now, this can be done efficiently, in the same way each iteration of the insertion sort<a id="marker-1006510"></a> algorithm works. We initially save in a temporary variable a copy of the element to bubble up (call it <code class="fm-code-in-text">X</code>), and then check the elements on its left in the array. We “move” the elements to their right (check figure 2.7 (C)) by copying them to the next position on their left, until we find an element with a priority higher than <code class="fm-code-in-text">X</code>’s. This can be done with just (at most) <code class="fm-code-in-text">H+1</code> assignments for a path of length <code class="fm-code-in-text">H</code>, thus saving about 66% of the assignments.</p>

  <p class="body"><a id="pgfId-1002985"></a>Listing 2.3 shows the improved version of the <code class="fm-code-in-text">bubbleUp</code> method<a id="marker-1006514"></a>. Notice how, at some point, there will momentarily be two copies of the element originally at index [3] (and later, of the element at index [1]). This is because rather than actually swapping elements, we can just overwrite the current element with its parent at each iteration (line #6) and write the element bubbling up just once at the end as the last action in the method. This works because bubbling up an element is conceptually equivalent to the inner loop of <i class="calibre17">insertion sort</i><a id="marker-1006518"></a>, where we are looking for the right position to insert the current element into the path connecting it to heap’s <a id="marker-1006522"></a><a id="marker-1006526"></a>root.</p>

  <p class="fm-code-listing-caption"><a id="pgfId-1023266"></a>Listing 2.3 An optimization of the bubbleUp method</p>
  <pre class="programlisting"><b class="strong">function</b> bubbleUp(pairs, index=|pairs|-1)                     <span class="fm-combinumeral">❶</span>
  current ← pairs[index]                                      <span class="fm-combinumeral">❷</span>
  <b class="strong">while</b> index &gt; 0 <b class="strong">do</b>                                          <span class="fm-combinumeral">❸</span>
    parentIndex ← getParentIndex(index)                       <span class="fm-combinumeral">❹</span>
    <b class="strong">if</b> pairs[parentIndex].priority &lt; current.priority <b class="strong">then</b>    <span class="fm-combinumeral">❺</span>
      pairs[index] ← pairs[parentIndex]                       <span class="fm-combinumeral">❻</span>
      index ← parentIndex                                     <span class="fm-combinumeral">❼</span>
    <b class="strong">else</b>                                                      <span class="fm-combinumeral">❽</span>
      <b class="strong">break</b>
  pairs[index] ← current                                      <span class="fm-combinumeral">❾</span></pre>

  <p class="fm-code-annotation"><a id="pgfId-1036813"></a><span class="fm-combinumeral">❶</span> We explicitly pass the array with all pairs and the index (by default the last element) as arguments.</p>

  <p class="fm-code-annotation"><a id="pgfId-1036834"></a><span class="fm-combinumeral">❷</span> Starts from the element at the index passed as argument (by default the last element of <code class="fm-code-in-text2">A</code>)</p>

  <p class="fm-code-annotation"><a id="pgfId-1036854"></a><span class="fm-combinumeral">❸</span> Checks if the current element is already at the root of the heap. If so, we are finished.</p>

  <p class="fm-code-annotation"><a id="pgfId-1036871"></a><span class="fm-combinumeral">❹</span> Computes the index of the parent of current element in the heap. The formula can vary with the type of implementation. For a heap with branching factor <code class="fm-code-in-text2">D</code> and array’s indices starting at zero, it’s <code class="fm-code-in-text2">(parentIndex-1) / D</code>.</p>

  <p class="fm-code-annotation"><a id="pgfId-1036888"></a><span class="fm-combinumeral">❺</span> If the parent has lower priority than the current element . . .</p>

  <p class="fm-code-annotation"><a id="pgfId-1036905"></a><span class="fm-combinumeral">❻</span> . . . then moves the parent one position down (implicitly the current element goes one up).</p>

  <p class="fm-code-annotation"><a id="pgfId-1036922"></a><span class="fm-combinumeral">❼</span> Updates the index of the current element for next iteration</p>

  <p class="fm-code-annotation"><a id="pgfId-1036939"></a><span class="fm-combinumeral">❽</span> Otherwise, we have found the right place for current, and we can exit the loop.</p>

  <p class="fm-code-annotation"><a id="pgfId-1036956"></a><span class="fm-combinumeral">❾</span> At this point, <code class="fm-code-in-text2">index</code> is the right position for current.</p>

  <h3 class="fm-head2" id="heading_id_20"><a id="pgfId-1003268"></a>2.6.2 PushDown</h3>

  <p class="body"><a id="pgfId-1003280"></a>The <a id="marker-1006538"></a><a id="marker-1006542"></a><code class="fm-code-in-text">pushDown</code> method<a id="marker-1006546"></a> handles the symmetric case where we need to move an element down toward the leaves of the heap, because it might be larger than (at least) one of its children. An implementation is shown in listing 2.4.</p>

  <p class="body"><a id="pgfId-1003302"></a>There are two differences with the “bubble up” case:</p>

  <ul class="calibre19">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre14" id="pgfId-1003315"></a><i class="calibre15">The triggering condition</i><a class="calibre14" id="marker-1006550"></a>—In this case, the altered node doesn’t violate invariant 3 with respect to its parent but might violate it when compared to its children. This would happen, for instance, when the root is extracted from the heap and replaced with the last leaf in the array, or when a node priority is changed by assigning it a lower priority.</p>
    </li>

    <li class="fm-list-numbered-last">
      <p class="list"><a class="calibre14" id="pgfId-1003330"></a><i class="calibre15">The algorithm</i><a class="calibre14" id="marker-1006554"></a>—For every level the element we are pushing down goes through, we need to find its highest-priority child, in order to find where the element could land without violating any property.</p>
    </li>
  </ul>

  <p class="fm-code-listing-caption"><a id="pgfId-1023292"></a>Listing 2.4 The <code class="fm-code-in-text">pushDown</code> method</p>
  <pre class="programlisting"><b class="strong">function</b> pushDown(pairs, index=0)
 currentIndex ← index                                         <span class="fm-combinumeral">❶</span>
  <b class="strong">while</b> currentIndex &lt; firstLeafIndex(pairs) <b class="strong">do</b>               <span class="fm-combinumeral">❷</span>
    (child, childIndex) ← highestPriorityChild(currentIndex)  <span class="fm-combinumeral">❸</span>
    <b class="strong">if</b> child.priority &gt; pairs[currentIndex].priority <b class="strong">then</b>     <span class="fm-combinumeral">❹</span>
      swap(pairs, currentIndex, childIndex)                   <span class="fm-combinumeral">❺</span>
      currentIndex ← childIndex
    <b class="strong">else</b>                                                      <span class="fm-combinumeral">❻</span>
      <b class="strong">break</b></pre>

  <p class="fm-code-annotation"><a id="pgfId-1036383"></a><span class="fm-combinumeral">❶</span> Starts at the index passed as argument (by default at the first element of the array <code class="fm-code-in-text2">A</code>)</p>

  <p class="fm-code-annotation"><a id="pgfId-1036404"></a><span class="fm-combinumeral">❷</span> Leaves have no children, so can’t be pushed down anymore. <code class="fm-code-in-text2">firstLeafIndex</code><a id="marker-1036409"></a> returns the index of the first leaf in the heap. If <code class="fm-code-in-text2">D</code> is the branching factor, and array’s indices starting at zero, then it’s <code class="fm-code-in-text2">(|pairs| - 2) / D + 1</code>.</p>

  <p class="fm-code-annotation"><a id="pgfId-1036422"></a><span class="fm-combinumeral">❸</span> We need to identify the current node’s children with the highest priority, because that will be the only element that is safe to move up without breaking heap properties.</p>

  <p class="fm-code-annotation"><a id="pgfId-1036439"></a><span class="fm-combinumeral">❹</span> If the highest priority child has higher priority than the current element <code class="fm-code-in-text2">p</code> . . .</p>

  <p class="fm-code-annotation"><a id="pgfId-1036456"></a><span class="fm-combinumeral">❺</span> . . . then swaps the current element with the one among its children with highest priority.</p>

  <p class="fm-code-annotation"><a id="pgfId-1036473"></a><span class="fm-combinumeral">❻</span> Otherwise, the heap properties have been reinstated, and we can break out and exit the function.</p>

  <p class="body"><a id="pgfId-1003538"></a>This method’s running time, while asymptotically equivalent to <code class="fm-code-in-text">bubbleUp</code><a id="marker-1033752"></a><code class="fm-code-in-text">’</code>s, requires a slightly larger number of comparisons. In the worst case, <code class="fm-code-in-text">D * log<sub class="subscript1">D</sub>(n)</code>, for a heap with branching factor <code class="fm-code-in-text">D</code> and containing <code class="fm-code-in-text">n</code> elements. This is also the reason why increasing the branching factor (the max number of children for each node) indefinitely is not a good idea: we’ll see this in section 2.10.</p>

  <p class="body"><a id="pgfId-1003597"></a>To stick to our tasks example, let’s consider the case where the root’s priority is lower than its children, shown in figure 2.8. Working on a ternary Heap, its first leaf is stored at index 4.</p>

  <p class="calibre16"><img alt="" class="calibre6" src="../Images/ch02_F8.png"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1046434"></a>Figure 2.8 An example of applying the <code class="fm-code-in-text">pushDown</code> method<a id="marker-1046433"></a> to the root of a ternary heap. (A) The root of the tree violates heap’s properties, being smaller than one of its children. The algorithm finds the child with the highest priority, and then compares it to current node (the root, in this example). (B) We swapped the root with its highest-priority children: the node at index 1. Now, in turn, we compare the updated child with its children: since none of them has a higher priority than current node, we can stop.</p>

  <p class="body"><a id="pgfId-1003610"></a>We call <code class="fm-code-in-text">pushDown(pairs, 0)</code> to fix the third heap’s property; helper function <code class="fm-code-in-text">firstLeafIndex</code><a id="marker-1006574"></a> at line #3 will return 3 (because the element at index [7], the last one in the array, is a child of the node at index [2], which is the last internal node), and so we will enter the loop.</p>

  <p class="body"><a id="pgfId-1003633"></a>The children of element [0] are at positions [1], [2], and [3], and among them we’ll choose the highest priority child of the root, at line #4. It turns out to be the element <code class="fm-code-in-text">&lt;Unencrypted password on DB, 10&gt;</code>. Its priority is higher than current element’s, so at line #6 we will swap it with current element.</p>

  <p class="body"><a id="pgfId-1003655"></a>Overall, after one iteration of the <code class="fm-code-in-text">while</code> loop, we have the situation illustrated by sub-figure 2.8.B, and <code class="fm-code-in-text">currentIndex</code> is set to 1.</p>

  <p class="body"><a id="pgfId-1003667"></a>Therefore, when we enter the loop for the second time, at line #3 <code class="fm-code-in-text">currentIndex</code> evaluates to 1, which is still less than 3, the index of the first leaf. The children of the element at index [1] are at indices [4], [5], and [6]. Among those elements we look for the node with highest priority among the current node’s children, at line #4 in listing 2.4; it turns out it is the element at index [4], <code class="fm-code-in-text">&lt;Page loads take 2+ seconds, 7&gt;</code>.</p>

  <p class="body"><a id="pgfId-1003697"></a>Therefore, at line #5, we find out that this time, all children’s priorities are lower than the current element’s, and we break out of the loop and return without any further change.</p>

  <p class="body"><a id="pgfId-1003708"></a>Similar to <code class="fm-code-in-text">bubbleUp</code><a id="marker-1006578"></a>, <code class="fm-code-in-text">pushDown</code><a id="marker-1006582"></a> can be improved by simply keeping the current element in a temporary variable and avoiding swaps at each iteration.</p>

  <p class="body"><a id="pgfId-1003723"></a>Listing 2.5 shows the final improved version of the method. We encourage the reader to work our example out line by line, similar to what we have done in the previous section for <code class="fm-code-in-text">bubbleUp</code><a id="marker-1023320"></a>, to have a better grasp of how it works.</p>

  <p class="fm-code-listing-caption"><a id="pgfId-1023326"></a>Listing 2.5 Optimizing the <code class="fm-code-in-text">pushDown</code> method</p>
  <pre class="programlisting"><b class="strong">function</b> pushDown(pairs, index=0)
  current ← pairs[index]                                   <span class="fm-combinumeral">❶</span>
  <b class="strong">while</b> index &lt; firstLeafIndex(pairs) <b class="strong">do</b>                   <span class="fm-combinumeral">❷</span>
       (child, childIndex) ← highestPriorityChild(index)   <span class="fm-combinumeral">❸</span>
    <b class="strong">if</b> child.priority &gt; current.priority <b class="strong">then</b>              <span class="fm-combinumeral">❹</span>
      pairs[index] ← pairs[childIndex]                     <span class="fm-combinumeral">❺</span>
      index ← childIndex
    <b class="strong">else</b>                                                   <span class="fm-combinumeral">❻</span>
      <b class="strong">break</b>
  pairs[index] ← current                                   <span class="fm-combinumeral">❼</span></pre>

  <p class="fm-code-annotation"><a id="pgfId-1035869"></a><span class="fm-combinumeral">❶</span> Starts at the index passed as argument (by default at the first element of the array <code class="fm-code-in-text2">A</code>)</p>

  <p class="fm-code-annotation"><a id="pgfId-1035890"></a><span class="fm-combinumeral">❷</span> Leaves have no children, so they can’t be pushed down anymore. <code class="fm-code-in-text2">firstLeafIndex</code><a id="marker-1035895"></a> returns the index of the first leaf in the heap.</p>

  <p class="fm-code-annotation"><a id="pgfId-1035911"></a><span class="fm-combinumeral">❸</span> We need to identify among the current node’s children the one with the highest priority, because that will be the only element that is safe to move up without breaking heap properties.</p>

  <p class="fm-code-annotation"><a id="pgfId-1035928"></a><span class="fm-combinumeral">❹</span> If the highest priority child has higher priority than the current element . . .</p>

  <p class="fm-code-annotation"><a id="pgfId-1035945"></a><span class="fm-combinumeral">❺</span> . . . then moves that child one position up (implicitly current goes one down).</p>

  <p class="fm-code-annotation"><a id="pgfId-1035962"></a><span class="fm-combinumeral">❻</span> Otherwise, we have found the right place for the current element.</p>

  <p class="fm-code-annotation"><a id="pgfId-1035979"></a><span class="fm-combinumeral">❼</span> Arrived at this line, <code class="fm-code-in-text2">index</code> is the right position for current.</p>

  <p class="body"><a id="pgfId-1003954"></a>Now that we have defined all the helper methods we need, we can finally implement the API methods. As a spoiler, you will notice how all the logic about priority and max-heap vs min-heap is encapsulated into <code class="fm-code-in-text">bubbleUp</code><a id="marker-1006598"></a> and <code class="fm-code-in-text">pushDown</code><a id="marker-1006602"></a>, so by defining these two helper methods, we greatly simplify our life whenever it comes to adapting our code to different <a id="marker-1006606"></a><a id="marker-1006610"></a>situations.</p>

  <h3 class="fm-head2" id="heading_id_21"><a id="pgfId-1003980"></a>2.6.3 Insert</h3>

  <p class="body"><a id="pgfId-1003992"></a>Let’s <a id="marker-1006614"></a><a id="marker-1006618"></a><a id="marker-1006622"></a>start with insertion. Listing 2.6 describes the pseudocode for inserting a new <code class="fm-code-in-text">(element, priority)</code> pair into a heap.</p>

  <p class="body"><a id="pgfId-1004014"></a>As mentioned at the end of the previous section, the <code class="fm-code-in-text">insert</code> method can be written by leveraging our helper methods, and as such its code is valid independent of whether we use a min-heap or a max-heap and of the definition of priority.</p>

  <p class="fm-code-listing-caption"><a id="pgfId-1023352"></a>Listing 2.6 The <code class="fm-code-in-text">insert</code> method</p>
  <pre class="programlisting"><b class="calibre21">function</b> insert(element, priority)
  p ← Pair(element, priority)         <span class="fm-combinumeral">❶</span>
  pairs.append(p)                     <span class="fm-combinumeral">❷</span>
  bubbleUp(pairs, |pairs| – 1)        <span class="fm-combinumeral">❸</span></pre>

  <p class="fm-code-annotation"><a id="pgfId-1035696"></a><span class="fm-combinumeral">❶</span> Creates a new pair holding our new element and priority</p>

  <p class="fm-code-annotation"><a id="pgfId-1035717"></a><span class="fm-combinumeral">❷</span> Adds the newly created pair at the end of our heap’s array, incrementing the array’s size</p>

  <p class="fm-code-annotation"><a id="pgfId-1035734"></a><span class="fm-combinumeral">❸</span> After adding the new element, we need to make sure that the heap’s properties are reinstated.</p>

  <p class="body"><a id="pgfId-1004129"></a>The first two steps in listing 2.6 are self-explanatory: we are just performing some maintenance on our data model, creating a pair from the two arguments and appending it to the tail of our array. Depending on the programming language and the type of container used for pairs, we might have to manually resize it (statically dimensioned arrays) or just add the element (dynamic arrays or lists).<a href="#pgfId-1013138"><sup class="footnotenumber">11</sup></a></p>

  <p class="body"><a id="pgfId-1004140"></a>The last step is needed because the new pair might violate the heap’s properties we defined in section 2.5.3. In particular, its priority could be higher than its parent’s. To reinstate heap properties, we then need to “bubble it up” toward the root of the heap, until we find the right spot in the tree structure.</p>

  <p class="body"><a id="pgfId-1004182"></a>Insert operations, just like delete or update, or even heap’s construction, will have to make sure the heaps properties holds on completion.</p>

  <p class="body"><a id="pgfId-1004191"></a>Because of the compact array implementation there will be no pointers to redirect, and the structure will be guaranteed to be consistent with properties 1 (by construction) and 2 (unless you have bugs in your code, of course).</p>

  <p class="body"><a id="pgfId-1004200"></a>So, we have to guarantee property 3, or in other words that each node is larger (for a max-heap) than each one of its <code class="fm-code-in-text">D</code> children. To do so, as we mentioned in previous sections, we might have to push it down (on deletes, and possibly updates), or bubble it up toward the root (on insert, and updates as well), whenever heap invariants are violated.</p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title"><a class="calibre14" id="pgfId-1046517"></a>What’s the running time for insertion?</p>

    <p class="fm-sidebar-text"><a id="pgfId-1046518"></a>How many swaps will we need to perform in order to reinstate the heap properties? That depends on the concrete case, but since we move one level up at each swap, it can’t be more than the heap’s height. And since a heap is a balanced complete tree, that means no more than <code class="fm-code-in-text2">log<sub class="calibre25">D</sub>(n)</code> swaps for a <code class="fm-code-in-text2">D</code>-way heap<a id="marker-1046519"></a> with <code class="fm-code-in-text2">n</code> elements.</p>

    <p class="fm-sidebar-text"><a id="pgfId-1046520"></a>The caveat here is that in any concrete implementation we need to expand the array beyond its current size. If we use a fixed-size static array, we will need to allocate it when the heap is created and set the max number of elements it can hold. In this case, however, the method is logarithmic in the worst case.</p>

    <p class="fm-sidebar-text"><a id="pgfId-1046521"></a>If we use a dynamic array, then the logarithmic bound becomes amortized and not worst-case, because we will periodically need to resize the array (see appendix C to check out more on dynamic arrays performance).</p>
  </div>

  <p class="fm-figure"><img alt="" class="calibre23" src="../Images/ch02_F9.png"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1046479"></a>Figure 2.9 Adding a new element to a ternary max-heap. (A) The initial state of the heap; we first add the new element, with priority 9.5 at the end of the heap’s array. (B) Then we bubble it up until we find the right spot for it; that is, the first spot where it does not violate the heap’s properties.</p>

  <p class="body"><a id="pgfId-1004285"></a><a id="id_Toc507447619"></a><a id="id_Toc498966662"></a>If we go back to our task management example, we can see how insert works on a ternary max-heap. Suppose we have the initial state shown in figure 2.9 (A), describing the heap right after a call to <code class="fm-code-in-text">insert(“Add exception for Superbowl”, 9.5)</code> to add a particularly urgent task that marketing is pushing to have fixed by the end of the day. (And yes, they do cheat using fractional numbers for priority! But that’s probably not the first time you’ve seen someone changing requirements after you’ve pulled up a lot of work, is it?). After executing line #3 in listing 2.6, in fact, the list would be in this intermediate state (where heap properties are still violated).</p>

  <p class="body"><a id="pgfId-1004303"></a>Line #4 is then executed to reinstate heap property number 3, as we saw in section 2.6.2, and the final result is shown in figure 2.9 (B). Notice the order in which the children of the root appear in the array: siblings are not ordered, and in fact a heap doesn’t keep a total ordering on its elements like a BST <a id="marker-1006630"></a><a id="marker-1006634"></a>would.</p>

  <h3 class="fm-head2" id="heading_id_22"><a id="pgfId-1004321"></a>2.6.4 Top</h3>

  <p class="body"><a id="pgfId-1004333"></a>Now <a id="marker-1006638"></a><a id="marker-1006642"></a>that we have seen how to insert a new element, let’s define the <code class="fm-code-in-text">top</code> method<a id="marker-1006646"></a> that will extract the heap’s root and return it to the caller.</p>

  <p class="body"><a id="pgfId-1004349"></a>Figure 2.10 shows an example of a max-heap, highlighting the steps that are performed in listing 2.7.</p>

  <p class="fm-figure"><img alt="" class="calibre23" src="../Images/ch02_F10.png"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1046550"></a>Figure 2.10 Removing the top element from a binary heap. (A) From a valid ternary heap, we remove the root of the heap (storing it in a temporary location, in order to return it at the end). (B) We replace the old root with the last element in the array (which is also removed from its tail). The new root might violate heap’s properties (and it does, in this example), so we need to push it down, comparing it to its children to check that the heap’s properties are not violated. (C) We move the new root down toward the heap’s leaves, until we find a valid spot for it (that is, the first one that does not violate the heap’s properties).</p>

  <p class="body"><a id="pgfId-1004381"></a>The first thing we do is check that the heap is not empty. If it is, we certainly can’t extract the top element, so we need to issue an error.</p>

  <p class="body"><a id="pgfId-1004396"></a>The idea is that since we will remove the root of the heap, and by doing so we leave a “hole” in the array, we need to replace it with another element.</p>

  <p class="body"><a id="pgfId-1004405"></a>We could “promote” one of its children as the new root, as shown in listing 2.7. (One of them will certainly be the next-highest priority element; try to prove it as an exercise.)</p>

  <p class="fm-code-listing-caption"><a id="pgfId-1023378"></a>Listing 2.7 The <code class="fm-code-in-text">top</code> method</p>
  <pre class="programlisting"><b class="strong">function</b> top()
  <b class="strong">if</b> pairs.isEmpty() <b class="strong">then error()</b>   <span class="fm-combinumeral">❶</span>
  p ← pairs.removeLast()            <span class="fm-combinumeral">❷</span>
  <b class="strong">if</b> pairs.isEmpty() <b class="strong">then</b>           <span class="fm-combinumeral">❸</span>
    <b class="strong">return</b> p.element
  <b class="strong">else</b>  
   (element, priority) ← pairs[0]   <span class="fm-combinumeral">❹</span>
    pairs[0] ← p                    <span class="fm-combinumeral">❺</span>
    pushDown(pairs, 0)              <span class="fm-combinumeral">❻</span>
    <b class="strong">return</b> element</pre>

  <p class="fm-code-annotation"><a id="pgfId-1035331"></a><span class="fm-combinumeral">❶</span> We need to check that the heap is not empty. Otherwise, we throw an error (or return <code class="fm-code-in-text2">null</code>).</p>

  <p class="fm-code-annotation"><a id="pgfId-1035352"></a><span class="fm-combinumeral">❷</span> Remove the last element in the <code class="fm-code-in-text2">pairs</code> array<a id="marker-1035356"></a> and store it in a temporary variable.</p>

  <p class="fm-code-annotation"><a id="pgfId-1035370"></a><span class="fm-combinumeral">❸</span> Now check again whether there are more elements left; if not, just return <code class="fm-code-in-text2">p</code>.</p>

  <p class="fm-code-annotation"><a id="pgfId-1035387"></a><span class="fm-combinumeral">❹</span> Otherwise we store the top pair (the first in the pairs array) in temporary variables . . .</p>

  <p class="fm-code-annotation"><a id="pgfId-1035404"></a><span class="fm-combinumeral">❺</span> . . . and overwrite the first pair in the array with the previously saved <code class="fm-code-in-text2">p</code>.</p>

  <p class="fm-code-annotation"><a id="pgfId-1035421"></a><span class="fm-combinumeral">❻</span> The last element was a leaf, so it likely had a low priority. Now that it sits at the root, it might violate the heap properties, so we need to move it towards the leaves, until both its children have a lower priority than it.</p>

  <p class="body"><a id="pgfId-1004631"></a>However, we would then only move the problem to the subtree rooted at this node that we moved to the root, and then to the next level, and so on.</p>

  <p class="body"><a id="pgfId-1004642"></a>Instead, since we also have to shrink the array, and since it’s easier to add or remove the array’s elements from its tail, we can simply pop the last element in the array and use it to replace the root.</p>

  <p class="body"><a id="pgfId-1004651"></a>The caveat is that this new root might violate heap’s properties. As a matter of fact, being a leaf, the probability is pretty high that there is a violation. Therefore, we need to reinstate them using a utility method, <code class="fm-code-in-text">pushDown</code><a id="marker-1006654"></a>.</p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title"><a class="calibre14" id="pgfId-1046605"></a>Running time for <code class="fm-code-in-text3">top()</code></p>

    <p class="fm-sidebar-text"><a id="pgfId-1046606"></a>Similar to what happens for insertion, the nature of the heap and the fact that we move one step toward the leaves at every swap guarantee that no more than a logarithmic number of swaps is required, in the worst case.</p>

    <p class="fm-sidebar-text"><a id="pgfId-1046607"></a>In this case as well, concrete implementations have to deal with array sizing, and we can only guarantee an amortized logarithmic upper bound (if we need a worst-case logarithmic bound, we need to use static arrays with all the disadvantages they carry).</p>
  </div>

  <p class="body"><a id="pgfId-1004719"></a>Back to our task management example. Let’s see what happens when calling <code class="fm-code-in-text">top</code><a id="marker-1006658"></a><a id="marker-1006662"></a><code class="fm-code-in-text">()</code> on the ternary heap shown at the end of figure 2.9 (B).</p>

  <p class="body"><a id="pgfId-1004733"></a>First, at line #3 we remove the last element of the heap, at index [8], and save it to a temporary variable; at line #4 we check whether the remaining array is empty. If that had been the case, the last element in the array would also have been the top of the heap (its only element!) and we could have just returned it.</p>

  <p class="body"><a id="pgfId-1004748"></a>But this is clearly not the case in this example, so we move on to line #7, where we store the first element of the heap, <code class="fm-code-in-text">&lt;Unencrypted password on DB, 10&gt;</code>, to a temporary variable, which will be returned by the method. At this point, we can imagine the heap to be like what’s shown in figure 2.10 (A), three disconnected branches without a root. To sew them together, we add a new root, using the element we had saved at line #3, the one entry that used to be the last in the array, at index <code class="fm-code-in-text">[8]</code>. Figure 2.10 (B) shows the situation at this point.</p>

  <p class="body"><a id="pgfId-1004773"></a>This new root, however, is violating heap’s properties, so we need to call <code class="fm-code-in-text">pushDown</code><a id="marker-1006666"></a> at line #8 to reinstate them by swapping it with its second children, whose priority is <code class="fm-code-in-text">9.5</code>, and producing the heap shown in figure 2.10 (C); the <code class="fm-code-in-text">pushDown</code> method will handle this phase, stopping when the right position for element <code class="fm-code-in-text">&lt;Memory Leak, 9&gt;</code> is found.</p>

  <p class="body"><a id="pgfId-1004794"></a>To conclude this sub-section, it’s worth noting that the <code class="fm-code-in-text">peek</code> method<a id="marker-1006674"></a> returns the top element in the heap, but it just returns it without any side effects on the data structure. Its logic is therefore trivial, so we will skip its <a id="marker-1006678"></a><a id="marker-1006682"></a>implementation.</p>

  <h3 class="fm-head2" id="heading_id_23"><a id="pgfId-1004814"></a>2.6.5 Update</h3>

  <p class="body"><a id="pgfId-1004826"></a>This <a id="marker-1006686"></a><a id="marker-1006690"></a><a id="marker-1006694"></a>is arguably the most interesting of heap’s public methods, even if it’s not always directly provided in implementations.<a href="#pgfId-1013170"><sup class="footnotenumber">12</sup></a></p>

  <p class="body"><a id="pgfId-1004851"></a>When we change an element, its priority could stay unchanged, and in that case, we don’t need any further action. See listing 2.8. But it could also become lower or higher. If an element’s priority becomes higher, we need to check that it doesn’t violate the third invariant for its parents; if it becomes lower, it could violate the same invariant for its children.</p>

  <p class="fm-code-listing-caption"><a id="pgfId-1023404"></a>Listing 2.8 The <code class="fm-code-in-text">update</code> method</p>
  <pre class="programlisting"><b class="strong">function</b> update(oldValue, newPriority)
  index ← pairs.find(oldValue)                     <span class="fm-combinumeral">❶</span>
  <b class="strong">if</b> index ≥ 0 <b class="strong">then</b>                                <span class="fm-combinumeral">❷</span>
    oldPriority ← pairs[index].priority
    pairs[index] ← Pair(oldValue, newPriority)
    <b class="strong">if</b> (newPriority &lt; oldPriority) <b class="strong">then</b>            <span class="fm-combinumeral">❸</span>
      bubbleUp(pairs, index)                       <span class="fm-combinumeral">❹</span>
    <b class="strong">elsif</b> (newPriority &gt; oldPriority) <b class="strong">then</b>        
      pushDown(pairs, index)                       <span class="fm-combinumeral">❺</span></pre>

  <p class="fm-code-annotation"><a id="pgfId-1035024"></a><span class="fm-combinumeral">❶</span> Get the position of the element to update.,</p>

  <p class="fm-code-annotation"><a id="pgfId-1035045"></a><span class="fm-combinumeral">❷</span> Check whether the element is actually stored in the heap, and update it with the new value/priority.</p>

  <p class="fm-code-annotation"><a id="pgfId-1035062"></a><span class="fm-combinumeral">❸</span> Check whether the new priority is higher than the old one.</p>

  <p class="fm-code-annotation"><a id="pgfId-1035082"></a><span class="fm-combinumeral">❹</span> If so, bubble up the element towards the root.</p>

  <p class="fm-code-annotation"><a id="pgfId-1035099"></a><span class="fm-combinumeral">❺</span> Otherwise, push it down toward the leaves.</p>

  <p class="body"><a id="pgfId-1005041"></a>In the former situation, we need to bubble up the modified element until we find a higher-priority ancestor or until we reach the root. In the latter, we instead push it down until all its children are lower priority, or we reach a leaf.</p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title"><a class="calibre14" id="pgfId-1046636"></a>Running time for <code class="fm-code-in-text3">update</code></p>

    <p class="fm-sidebar-text"><a id="pgfId-1046637"></a>From a performance point of view, the challenge of this method is in line #2: the search for the old element can take linear time in the worst case, because on a failed search (when the element is not actually in the heap), we will have to search the whole heap.</p>

    <p class="fm-sidebar-text"><a id="pgfId-1046638"></a>To improve this worst-case scenario, it is possible to use auxiliary data structures that will help us in performing searches more efficiently. For instance, we can store a <code class="fm-code-in-text2">map</code><a id="marker-1046639"></a> associating each element in the heap with its index. If implemented with a hash table, the lookup would only need an amortized <code class="fm-code-in-text2">O(1)</code> time.</p>

    <p class="fm-sidebar-text"><a id="pgfId-1046641"></a>We will see this in further detail when describing the <code class="fm-code-in-text2">contains</code> method<a id="marker-1046640"></a>. For now, let’s just remember that if the <code class="fm-code-in-text2">find</code> operation<a id="marker-1046642"></a> takes at most logarithmic time, the whole method is also logarithmic.</p>
  </div>

  <p class="body"><a id="pgfId-1005149"></a>As we saw, the first case can always be implemented more efficiently<a href="#pgfId-1013199"><sup class="footnotenumber">13</sup></a> and luckily for us, most algorithms only require us to reduce elements’ <a id="marker-1006710"></a><a id="marker-1006714"></a><a id="marker-1006718"></a>priority.</p>

  <h3 class="fm-head2" id="heading_id_24"><a id="pgfId-1005164"></a>2.6.6 Dealing with duplicates</h3>

  <p class="body"><a id="pgfId-1005178"></a>So <a id="marker-1006722"></a><a id="marker-1006726"></a>far, we’ve also assumed that our heap doesn’t hold duplicates. We will have to tackle further challenges if this assumption doesn’t hold true. In particular, we will need to figure out the order we use in case there are duplicates. To show why this is important, we will abandon our example for an easier configuration, illustrated in figure 2.11. For the sake of space we will only show priorities in nodes.</p>

  <p class="fm-figure"><img alt="" class="calibre23" src="../Images/ch02_F11.png"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1046674"></a>Figure 2.11 Updating an element in a binary max-heap with duplicates.</p>

  <p class="body"><a id="pgfId-1005232"></a>We could have two duplicates—call them <code class="fm-code-in-text">X</code> and <code class="fm-code-in-text">Y</code>—one being the child of the other. Let’s consider the case where <code class="fm-code-in-text">X</code> is a child of <code class="fm-code-in-text">Y</code>, and we call update to change their priority to a higher one. Inside <code class="fm-code-in-text">update</code>, after updating the two elements’ priorities, there would have to be two calls to <code class="fm-code-in-text">bubbleUp</code><a id="marker-1006730"></a>, one for <code class="fm-code-in-text">X</code>, and one for <code class="fm-code-in-text">Y</code>. The catch is that if we run them in the wrong order, we will end with an inconsistent heap, which violates the heap’s properties.</p>

  <p class="body"><a id="pgfId-1005276"></a>Suppose we bubble up <code class="fm-code-in-text">X</code>, the children, first: then it will immediately find its parent (which is <code class="fm-code-in-text">Y</code>) and stop (because it has the same value). When we call <code class="fm-code-in-text">bubbleUp(Y),</code> we will discover that its parent now has lower priority, so we do need to move it toward the root. Unfortunately, we will never check <code class="fm-code-in-text">X</code> again, so it will never be moved up together with <code class="fm-code-in-text">Y</code> and heap’s property won’t be correctly reinstated.</p>

  <p class="body"><a id="pgfId-1005299"></a>Figure 2.11 provides a step-by-step description of how the <code class="fm-code-in-text">update</code><a id="marker-1006738"></a> method could violate heap’s constraints if it’s not implemented in such a way to avoid duplicates:</p>

  <ul class="calibre19">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre14" id="pgfId-1005311"></a>In step 1, we can see the initial max-heap.</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-1005329"></a>In step 2, all occurrences are changed from 4 to 8.</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-1005350"></a>In step 3, you see bubbling up the deepest node updated at index <code class="fm-code-in-text">3</code>. It will stop immediately because its parent has the same priority (it just updated together with current node). The nodes involved in the call to <code class="fm-code-in-text">bubbleUp</code><a class="calibre14" id="marker-1006742"></a> are highlighted with a red outline.</p>
    </li>

    <li class="fm-list-numbered-last">
      <p class="list"><a class="calibre14" id="pgfId-1005386"></a>In step 4, you see bubbling up the other node that was updated at index <code class="fm-code-in-text">1</code>. This time some swaps are actually performed as the node’s new priority, <code class="fm-code-in-text">8</code>, is higher than its parent’s (just <code class="fm-code-in-text">7</code>). The node that was bubbled up first, at step 3, will never be updated again, and so the heap’s properties will be violated.</p>
    </li>
  </ul>

  <p class="body"><a id="pgfId-1005429"></a>How can we solve this issue? Following a left-to-right order for the calls to <code class="fm-code-in-text">bubbleUp</code> will guarantee that the heap properties are properly reinstated.</p>

  <p class="body"><a id="pgfId-1005442"></a>As an alternative, we could change the conditions in <code class="fm-code-in-text">bubbleUp</code> and <code class="fm-code-in-text">pushDown</code><a id="marker-1006746"></a>, and only stop when we find a strictly higher-priority parent and strictly lower-priority children, respectively. Yet another alternative could be bubbling up (or pushing down) the nodes as we update them. Both these solutions, however, would be far from ideal for many reasons, not least performance-wise, because they would require a larger bound for the worst-case number of swaps (the proof is easy enough if you count the worst-case possible number of swaps in a path where all elements are the same—details are left to the <a id="marker-1006750"></a><a id="marker-1006754"></a>reader).</p>

  <h3 class="fm-head2" id="heading_id_25"><a id="pgfId-1005476"></a><a id="id_Toc507447623"></a><a id="id_Toc498966666"></a>2.6.7 Heapify</h3>

  <p class="body"><a id="pgfId-1005488"></a>Priority <a id="marker-1006758"></a><a id="marker-1006762"></a>queues can be created empty, but they are also often initialized with a set of elements. If that’s the case, and if we need to initialize the heap with <code class="fm-code-in-text">n</code> elements, we can still obviously create an empty heap and add those elements one by one.</p>

  <p class="body"><a id="pgfId-1005504"></a>To do so, we will need at most <code class="fm-code-in-text">O(n)</code> time to allocate the heap array, and then repeat <code class="fm-code-in-text">n</code> insertions. Every insertion is logarithmic, so we have an upper bound of <code class="fm-code-in-text">O(n log n)</code>.</p>

  <p class="body"><a id="pgfId-1005522"></a>Is this the best we can do? Turns out that we can do better. Suppose that we initialize the heap with the whole sets of <code class="fm-code-in-text">n</code> elements, in any order.</p>

  <p class="body"><a id="pgfId-1005542"></a>As we have seen, each position of the array can be seen as the root of a sub-heap. So, leaves, for example, are trivial sub-heaps, containing only one element. Being singletons, they are valid heaps.</p>

  <p class="body"><a id="pgfId-1005553"></a>How many leaves are there in a heap? That depends on the branching factor. In a binary heap, half the nodes are leaves. In a 4-way heap, the last three-fourths of the array contain leaves.</p>

  <p class="body"><a id="pgfId-1005562"></a>Let’s stick to the case of a binary heap, for the sake of simplicity. We can see an example of a min-heap in figure 2.12, where we can follow step by step how <code class="fm-code-in-text">heapify</code><a id="marker-1006766"></a> works.</p>

  <p class="body"><a id="pgfId-1005578"></a>If we start at the last internal node for the heap—let’s call it <code class="fm-code-in-text">X</code>—it will have at most two children, both leaves, and hence both valid heaps.</p>

  <p class="fm-figure"><img alt="" class="calibre23" src="../Images/ch02_F12.png"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1046716"></a>Figure 2.12 Heapification of a small array. The boxes with rounded corners surround valid sub-heaps; that is, portions of the tree for which we have verified that they abide by the heap properties. Step 1: Initially, only leaves are valid min-heap; here, smaller numbers mean higher priority. Step 2: The element from which we start our iteration is the first internal node in the heap, at index 2 in our array. In the bottom part of the leftmost figure, it is pointed at by an arrow. We repair the heap properties for the sub-heap rooted at this node by swapping its content with its child’s. Step 3: We move the arrow pointing to the current element one position to the left and repeat the operation for the sub-heap rooted at index 1. Step 4: Finally, the whole array is heapified, by pushing down the temporary root (with priority 5) until we find its right place.</p>

  <p class="body"><a id="pgfId-1005645"></a>We can’t say yet if <code class="fm-code-in-text">X</code> is the root of a valid heap, but we can try to push it down and possibly swap it with the smallest of its children. Once we have done that, we are sure that the sub-heap rooted at <code class="fm-code-in-text">X</code> is a valid heap. This happens because <code class="fm-code-in-text">pushDown</code><a id="marker-1006770"></a>, by construction, reinstates the heap properties on a sub-heap where all children are valid heaps, and only the root might be misplaced.</p>

  <p class="body"><a id="pgfId-1005663"></a>If we now move one position left in the array, we can repeat the procedure, and get another valid sub-heap. Continuing on, at some point we visit all internal nodes that only have leaves as their children. And after that, we’ll start with the first internal node that’s the root of a sub-heap with height 2. Let’s name it <code class="fm-code-in-text">Y</code>. If we tackle elements in a right-to-left order in the array, we have the guarantee that <code class="fm-code-in-text">Y</code>’s children are sub-heaps that</p>

  <ul class="calibre19">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre14" id="pgfId-1005685"></a>Have at most height 1 and</p>
    </li>

    <li class="fm-list-numbered-last">
      <p class="list"><a class="calibre14" id="pgfId-1005698"></a>Whose properties have already been fixed</p>
    </li>
  </ul>

  <p class="body"><a id="pgfId-1005711"></a>Once again, we can use <code class="fm-code-in-text">pushDown</code><a id="marker-1006774"></a> and be sure the sub-heap rooted at <code class="fm-code-in-text">Y</code> will be a valid heap afterward.</p>

  <p class="body"><a id="pgfId-1005728"></a>If we repeat these steps for all nodes until we reach the root of our heap, we have the guarantee that we will end up with a valid heap, as shown in listing 2.9.</p>

  <p class="fm-code-listing-caption"><a id="pgfId-1023430"></a>Listing 2.9 The <code class="fm-code-in-text">heapify</code> method</p>
  <pre class="programlisting"><b class="strong">function</b> heapify(pairs)
  <b class="strong">for</b> index <b class="strong">in</b> {(|pairs|-1)/D .. 0} <b class="strong">do</b>     <span class="fm-combinumeral">❶</span>
    pushDown(pairs, index)                 <span class="fm-combinumeral">❷</span></pre>

  <p class="fm-code-annotation"><a id="pgfId-1034912"></a><span class="fm-combinumeral">❶</span> We start at the first internal node of the heap (<code class="fm-code-in-text2">D</code> is the branching factor) and iterate until the root.</p>

  <p class="fm-code-annotation"><a id="pgfId-1034933"></a><span class="fm-combinumeral">❷</span> Ensures the sub-heap rooted at index is a valid heap</p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title"><a class="calibre14" id="pgfId-1046756"></a>Running time for <code class="fm-code-in-text3">heapify</code></p>

    <p class="fm-sidebar-text"><a id="pgfId-1046758"></a>In total, in a binary heap, we will call <code class="fm-code-in-text2">pushDown n/2</code><a id="marker-1046757"></a> times, with an initial estimate of the upper bound of <code class="fm-code-in-text2">O(n*log(n))</code>.</p>

    <p class="fm-sidebar-text"><a id="pgfId-1046759"></a>However, notice that the sub-heaps that only have leaves as children have a height equal to 1, so they only need at most one swap to be fixed. And there is <code class="fm-code-in-text2">n/2</code> of them. Likewise, sub-heaps with height 2 only need at most two swaps, and we have <code class="fm-code-in-text2">n/4</code> of them.</p>

    <p class="fm-sidebar-text"><a id="pgfId-1046760"></a>Going up toward the root, the number of swaps increases but the number of calls to <code class="fm-code-in-text2">pushDown</code><a id="marker-1046761"></a> decreases at the same rate. Finally, we’ll have only two calls for <code class="fm-code-in-text2">pushDown</code> that requires at most <code class="fm-code-in-text2">log<sub class="subscript">2</sub>(n)–1</code> swaps, and only one call, the one on the root, that requires <code class="fm-code-in-text2">log<sub class="subscript">2</sub>(n)</code> swaps in the worst case.</p>

    <p class="fm-sidebar-text"><a id="pgfId-1046765"></a>Putting all these together, we see that the total number of swaps is given by</p>

    <p class="fm-figure"><img alt="" class="calibre23" src="../Images/ch02_F_EQ1.png"/></p>

    <p class="fm-sidebar-text"><a id="pgfId-1046769"></a>Since the last summation is limited by geometric series with seed 2, we have</p>

    <p class="fm-figure"><img alt="" class="calibre23" src="../Images/ch02_F_EQ2.png"/></p>

    <p class="fm-sidebar-text"><a id="pgfId-1046770"></a>and therefore, the total number of swaps is linear in the worst case (at most <code class="fm-code-in-text2">2n</code>).</p>

    <p class="fm-sidebar-text"><a id="pgfId-1046771"></a>So, our final analysis is that heapify’s complexity is <code class="fm-code-in-text2">O(n)</code>.</p>
  </div>

  <p class="body"><a id="pgfId-1006012"></a>We leave the computation for a d-ary heap as an exercise. It is similar to the previous one, replacing the branching <a id="marker-1006786"></a><a id="marker-1006790"></a>factor.</p>

  <h3 class="fm-head2" id="heading_id_26"><a id="pgfId-1006030"></a><a id="Contains"></a>2.6.8 <a id="id_Toc507447624"></a>Beyond API methods: Contains</h3>

  <p class="body"><a id="pgfId-1006046"></a>One <a id="marker-1006794"></a><a id="marker-1006798"></a>thing that heaps are definitely not good for is checking whether or not an element is stored in them. We have no other choice than going through all the elements until we find the one we were looking for, or we get to the end of the array. This means a linear time algorithm. Compare it with a hash table’s optimal average constant time, or even <code class="fm-code-in-text">O(log(n))</code> for binary search trees (average) or balanced binary search trees (worst case).</p>

  <p class="body"><a id="pgfId-1006071"></a>However, we also would like to support priority increment/decrement. As we saw in section 2.6.5, it’s paramount for these operations to efficiently retrieve the element whose priority needs to be changed. Therefore, when implementing heaps, we might add an auxiliary field, a <code class="fm-code-in-text">HashMap</code><a id="marker-1006802"></a> from elements to positions, that allows us to check whether an element is in the heap (or get its position) in constant time, on average. See a possible implementation of <code class="fm-code-in-text">contains</code><a id="marker-1006806"></a> in <a id="marker-1006810"></a><a id="marker-1006814"></a>listing 2.10.</p>

  <p class="fm-code-listing-caption"><a id="pgfId-1023466"></a>Listing 2.10 The <code class="fm-code-in-text">contains</code> method</p>
  <pre class="programlisting"><b class="calibre21">function</b> contains(elem) 
  index ← elementToIndex[elem]
  <b class="calibre21">return</b> index &gt;= 0</pre>

  <p class="body"><a id="pgfId-1006148"></a>The function uses an extra field <code class="fm-code-in-text">elementToIndex</code> we can add to our heap. This is possible under two assumptions:</p>

  <p class="body"></p>

  <ul class="calibre19">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre14" id="pgfId-1006166"></a>That <code class="fm-code-in-text">elementToIndex[elem]</code> by default returns <code class="fm-code-in-text">-1</code> if <code class="fm-code-in-text">elem</code> is not stored in the heap.</p>
    </li>

    <li class="fm-list-numbered-last">
      <p class="list"><a class="calibre14" id="pgfId-1006186"></a>That we don’t allow duplicate keys in the heap; otherwise, we will need to store a list of indices for each key.</p>
    </li>
  </ul>

  <h3 class="fm-head2" id="heading_id_27"><a id="pgfId-1006200"></a>2.6.9 Performance recap</h3>

  <p class="body"><a id="pgfId-1006212"></a>With <a id="marker-1006818"></a><a id="marker-1006822"></a>the description of the <code class="fm-code-in-text">contains</code> method<a id="marker-1006826"></a>, we have concluded our overview of this data structure.</p>

  <p class="body"><a id="pgfId-1006228"></a>We have presented several operations on heaps, so it feels like the right time to order and recap their running time (table 2.4), and as importantly, show the amount of extra memory they need.</p>

  <p class="fm-table-caption"><a id="pgfId-1024359"></a>Table 2.4 Operations provided by heaps, and their cost on a heap with n elements</p>

  <table border="1" class="contenttable" width="100%">
    <tr class="calibre8">
      <th class="fm-contenttable" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1024365"></a>Operation</p>
      </th>

      <th class="fm-contenttable" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1024367"></a>Running time</p>
      </th>

      <th class="fm-contenttable" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1024369"></a>Extra space</p>
      </th>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024371"></a><code class="fm-code-in-text2">Insert</code><a id="marker-1024418"></a></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024373"></a><code class="fm-code-in-text2">O(log(n))</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024375"></a><code class="fm-code-in-text2">O(1)</code></p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024377"></a><code class="fm-code-in-text2">Top</code><a id="marker-1024419"></a></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024379"></a><code class="fm-code-in-text2">O(log(n))</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024381"></a><code class="fm-code-in-text2">O(1)</code></p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024383"></a><code class="fm-code-in-text2">Remove</code><a id="marker-1024420"></a></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024385"></a><code class="fm-code-in-text2">O(log(n))<a class="calibre14" href="#pgfId-1024451"><sup class="footnotenumber2">a</sup></a></code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024387"></a><code class="fm-code-in-text2">O(n)<a class="calibre14" href="#pgfId-1024451"><sup class="footnotenumber2">a</sup></a></code></p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024389"></a><code class="fm-code-in-text2">Peek</code><a id="marker-1024421"></a></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024391"></a><code class="fm-code-in-text2">O(1)</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024393"></a><code class="fm-code-in-text2">O(1)</code></p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024395"></a><code class="fm-code-in-text2">Contains (naïve</code><a id="marker-1024422"></a><code class="fm-code-in-text2">)</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024397"></a><code class="fm-code-in-text2">O(n)</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024399"></a><code class="fm-code-in-text2">O(1)</code></p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024401"></a><code class="fm-code-in-text2">Contains</code><a id="marker-1024423"></a></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024403"></a><code class="fm-code-in-text2">O(1)<a class="calibre14" href="#pgfId-1024451"><sup class="footnotenumber2">a</sup></a></code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024405"></a><code class="fm-code-in-text2">O(n)<a class="calibre14" href="#pgfId-1024451"><sup class="footnotenumber2">a</sup></a></code></p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024407"></a><code class="fm-code-in-text2">UpdatePriority</code><a id="marker-1024424"></a></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024409"></a><code class="fm-code-in-text2">O(log(n))<a class="calibre14" href="#pgfId-1024451"><sup class="footnotenumber2">a</sup></a></code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024411"></a><code class="fm-code-in-text2">O(n)<a class="calibre14" href="#pgfId-1024451"><sup class="footnotenumber2">a</sup></a></code></p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024413"></a><code class="fm-code-in-text2">Heapify</code><a id="marker-1024425"></a></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024415"></a><code class="fm-code-in-text2">O(n)</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024417"></a><code class="fm-code-in-text2">O(1)</code></p>
      </td>
    </tr>
  </table>

  <p class="fm-footnote"><sup class="footnotenumber">a</sup> <a id="pgfId-1024451"></a>Using the advanced version of contains and maintaining an extra map from elements to indices</p>

  <p class="body"><a id="pgfId-1007215"></a>As with most things in computer science, time versus space is often a tradeoff. Nevertheless, sometimes there is a tendency to neglect the extra memory factor in informal analysis. With the volumes we’ve operated since the dawn of the era of big data, however, our data structures need to hold and process billions of elements, or even more. Therefore, a fast algorithm that consumes quadratic space could be the best choice for small volumes of data, but it becomes impractical for some real case scenarios where you need to scale out. And so a slower algorithm using constant or logarithmic space could be the choice of election as our dataset grows.</p>

  <p class="body"><a id="pgfId-1007232"></a>The takeaway is that it’s even more important to take the memory factor into account as early as possible when we design a system that needs to scale.</p>

  <p class="body"><a id="pgfId-1007243"></a>For heaps, consider that we naturally need constant extra space per element, and linear extra space in total, to host a map from elements to indices.</p>

  <p class="body"><a id="pgfId-1007252"></a>We have closely examined all operations. Yet, it’s worth spending a few more words on a couple of things.</p>

  <p class="body"><a id="pgfId-1007261"></a>For <code class="fm-code-in-text">insert</code><a id="marker-1009140"></a> and <code class="fm-code-in-text">top</code><a id="marker-1009144"></a>, the running time guarantee is amortized, not worst case. If a dynamic array is used to provide a flexible size, some calls will require linear time to resize the array. It can be proven that to fill a dynamic array with <code class="fm-code-in-text">n</code> elements, at most <code class="fm-code-in-text">2<sub class="subscript1">n</sub></code> swaps are needed. However, the worst-case logarithmic guarantee can be offered only if the heap size is set from the beginning. For this reason, and for allocation/garbage collection efficiency, in some languages (for instance, Java), it is advisable to initialize your heaps to their expected size, if you have a reasonable estimate that will remain true for most of the container’s life.</p>

  <p class="body"><a id="pgfId-1007282"></a>The performance for <code class="fm-code-in-text">remove</code><a id="marker-1009148"></a> and <code class="fm-code-in-text">updatePriority</code><a id="marker-1009152"></a> relies on the efficient implementation of <code class="fm-code-in-text">contains</code><a id="marker-1009156"></a>, in order to provide a logarithmic guarantee. To have efficient search, however, we need to keep a second data structure besides the array for fast indirection. The choice is between a hash table or a bloom filter (see chapter 4).</p>

  <p class="body"><a id="pgfId-1007303"></a>In case either is used, the running time for contains is assumed to be constant, with a caveat: the hash for each element needs to be computable in constant time. Otherwise, we will need to take that cost into account in our <a id="marker-1009160"></a><a id="marker-1009164"></a>analysis.</p>

  <h3 class="fm-head2" id="heading_id_28"><a id="pgfId-1007315"></a><a id="id_Toc507447628"></a>2.6.10 From pseudo-code to implementation</h3>

  <p class="body"><a id="pgfId-1007329"></a>We <a id="marker-1009168"></a><a id="marker-1009172"></a>have seen how a d-way heap works in a language-agnostic way. Pseudo-code provides a good way to outline and explain a data structure, without worrying about the implementation details so you can focus on its behavior.</p>

  <p class="body"><a id="pgfId-1007343"></a>At the same time, however, pseudo-code is of little practical use. To be able to move from theory to practice, we need to choose a programming language and implement our d-way heap. Independently of what platform we choose, language-specific concerns will arise and different problematics need to be taken into consideration.</p>

  <p class="body"><a id="pgfId-1007358"></a>We’ll provide implementations of the algorithms in this book, in an effort to give readers a way to experiment and get their hands dirty with these data structures.</p>

  <p class="body"><a id="pgfId-1007369"></a>The full code, including tests, can be found in our book’s <span class="fm-hyperlink">repo</span> <a id="marker-1025390"></a><a id="marker-1025391"></a>on <a id="marker-1025392"></a><a id="marker-1025393"></a><a id="marker-1025394"></a>GitHub.<a href="#pgfId-1025376"><sup class="footnotenumber">14</sup></a></p>

  <h2 class="fm-head" id="heading_id_29"><a id="pgfId-1007389"></a>2.7 Use case: Find the k largest elements</h2>

  <p class="body"><a id="pgfId-1007403"></a>In <a id="marker-1009196"></a><a id="marker-1009200"></a>this section we are going to describe how we can use a priority queue to keep track of the <code class="fm-code-in-text">k</code> largest elements of a set.</p>

  <p class="body"><a id="pgfId-1007417"></a>If we have the full set of <code class="fm-code-in-text">n</code> elements in advance, we have a few alternatives that don’t need any auxiliary data structure:</p>

  <ul class="calibre19">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre14" id="pgfId-1007430"></a>We could sort the input and take the last <code class="fm-code-in-text">k</code> elements. This naïve approach requires <code class="fm-code-in-text">O(n*log(n))</code> comparisons and swaps and, depending on the algorithm, might require additional memory.</p>
    </li>

    <li class="fm-list-numbered-last">
      <p class="list"><a class="calibre14" id="pgfId-1007449"></a>We could find the largest element from the set and move it to the end of the array, then look at the remaining <code class="fm-code-in-text">n-1</code> elements and find the second to last and move it to position <code class="fm-code-in-text">n-2</code>, and so on. Basically, this algorithm runs the inner cycle of <code class="fm-code-in-text">Selection Sort</code> algorithm<a class="calibre14" id="marker-1009204"></a> <code class="fm-code-in-text">k</code> times, requiring <code class="fm-code-in-text">O(k)</code> swaps and <code class="fm-code-in-text">O(n*k)</code> comparisons. No additional memory would be needed.</p>
    </li>
  </ul>

  <p class="body"><a id="pgfId-1007479"></a>In this section we will see that by using a heap, we can achieve our goal using <code class="fm-code-in-text">O(n+k*log(k))</code> comparisons and swaps, and <code class="fm-code-in-text">O(k)</code> extra memory. This is a game-changing improvement if <code class="fm-code-in-text">k</code> is much smaller than <code class="fm-code-in-text">n</code>. In a typical situation, <code class="fm-code-in-text">n</code> could be on the order of millions or billions of elements, and <code class="fm-code-in-text">k</code> between a hundred and a few thousand.</p>

  <p class="body"><a id="pgfId-1007508"></a>Moreover, by using an auxiliary heap, the algorithm can naturally be adapted to work on dynamic streams of data and also to allow consuming elements from the heap.</p>

  <h3 class="fm-head2" id="heading_id_30"><a id="pgfId-1007519"></a><a id="id_Toc507447816"></a>2.7.1 The right data structure . . .</h3>

  <p class="body"><a id="pgfId-1007532"></a>When <a id="marker-1009208"></a>your problem involves finding a subset of largest/smallest elements, priority queues seem like a natural solution.</p>

  <p class="body"><a id="pgfId-1007545"></a>In programming, choosing the right data structure can make a difference.<a href="#pgfId-1013228"><sup class="footnotenumber">15</sup></a> That’s not always enough, because you also need to use it correctly.</p>

  <p class="body"><a id="pgfId-1007556"></a>Suppose, for instance, that we have a static set of elements available from the beginning. We could use a max-heap, insert all <code class="fm-code-in-text">n</code> elements, and then extract the largest <code class="fm-code-in-text">k</code> of them.</p>

  <p class="body"><a id="pgfId-1007569"></a>We would need <code class="fm-code-in-text">O(n)</code> extra space for the heap, and then use <code class="fm-code-in-text">heapify</code><a id="marker-1009212"></a> to create it from the full set in linear time, <code class="fm-code-in-text">O(n)</code>. Then we would call <code class="fm-code-in-text">top k</code> times, with a cost of <code class="fm-code-in-text">O(log(n))</code> for each call. The total cost for this solution would be <code class="fm-code-in-text">O(n+k*log(n))</code> comparisons and swaps.</p>

  <p class="body"><a id="pgfId-1007605"></a>That’s already better than the naïve solutions, but, if you think about it, if<a href="#pgfId-1013244"><sup class="footnotenumber">16</sup></a> <code class="fm-code-in-text">n&gt;&gt;k</code>, we are creating a huge heap just to extract a few elements. That certainly sounds <a id="marker-1009216"></a>wasteful.</p>

  <h3 class="fm-head2" id="heading_id_31"><a id="pgfId-1007623"></a>2.7.2 <a id="id_Toc507447817"></a> . . . and the right use</h3>

  <p class="body"><a id="pgfId-1007636"></a>So <a id="marker-1009220"></a><a id="marker-1009224"></a>our goal should be having a small heap with <code class="fm-code-in-text">k</code> elements. Using a max-heap doesn’t really work anymore. Let’s see why with an example.</p>

  <p class="body"><a id="pgfId-1007650"></a>Suppose we want to find the largest three of the following numbers: 2, 4, 1, 3, 7, 6. We add the first three and we have the following max-heap: [4, 2, 1]. Now we proceed to the next number in the list, and it’s 3. It’s larger than two out of three elements currently in the heap, but we have no way of knowing this, because we can only peek at the top of the heap. Then we can insert 3 into the heap, and we obtain [4, 3, 1, 2]. Now, if we want to keep the size of the heap at <code class="fm-code-in-text">k</code> elements, we need to remove one, which is the minimum. How do we know where it is inside the heap? We only know where the maximum is (at the top of the max-heap), and so the search for the min could take up to linear time (even noting that the minimum will be in one of the leaves, there are unfortunately a linear number of them, <code class="fm-code-in-text">n/D</code>).</p>

  <p class="body"><a id="pgfId-1007683"></a>You can verify that even by inserting the elements in a different order, we often find a similar situation.</p>

  <p class="body"><a id="pgfId-1007692"></a>The catch is that when we want the <code class="fm-code-in-text">k</code> largest elements, at each step we are interested in understanding if the next number we evaluate is larger than the smallest of the <code class="fm-code-in-text">k</code> elements we already have. Hence, rather than a max-heap, we can use a min-heap bound to <code class="fm-code-in-text">k</code> elements where we store the largest elements found so far.</p>

  <p class="body"><a id="pgfId-1007707"></a>For each new element, we compare it to the top of the heap, and if the new one is smaller, we are sure it’s not one of the <code class="fm-code-in-text">k</code> largest elements. If our new element is larger than the heap’s top (that is, the <i class="fm-italics">smallest</i> of our <code class="fm-code-in-text">k</code> elements), then we extract the top from the heap and then add our newly arrived. This way, updating the heap at each iteration costs us only constant time,<a href="#pgfId-1013263"><sup class="footnotenumber">17</sup></a> instead of the linear time bound if we used a <a id="marker-1009228"></a><a id="marker-1009232"></a>max-heap.</p>

  <h3 class="fm-head2" id="heading_id_32"><a id="pgfId-1007733"></a>2.7.3 Coding it up</h3>

  <p class="body"><a id="pgfId-1007745"></a>That’s <a id="marker-1009236"></a>neat, right? And simple to implement. Since code is worth a thousand words, let’s see our heap in action <a id="marker-1009240"></a>in <a id="marker-1009244"></a><a id="marker-1009248"></a>listing 2.11.</p>

  <p class="fm-code-listing-caption"><a id="pgfId-1023492"></a>Listing 2.11 Top <code class="fm-code-in-text">k</code> elements of a list</p>
  <pre class="programlisting"><b class="strong">function</b> topK(A, k)
heap ← DWayHeap()                                   <span class="fm-combinumeral">❶</span>
<b class="strong">for</b> el <b class="strong">in</b> A <b class="strong">do</b>                                      <span class="fm-combinumeral">❷</span>
  <b class="strong">if</b> (heap.size == k <b class="strong">and</b> heap.peek() &lt; el) <b class="strong">then</b>     <span class="fm-combinumeral">❸</span>
    heap.top()                                      <span class="fm-combinumeral">❹</span>
  <b class="strong">if</b> (heap.size &lt; k) <b class="strong">then</b>                           <span class="fm-combinumeral">❺</span>
    heap.insert(el)                                 <span class="fm-combinumeral">❻</span>
<b class="strong">return</b> heap                                         <span class="fm-combinumeral">❼</span></pre>

  <p class="fm-code-annotation"><a id="pgfId-1034338"></a><span class="fm-combinumeral">❶</span> Creates an empty min-heap</p>

  <p class="fm-code-annotation"><a id="pgfId-1034377"></a><span class="fm-combinumeral">❷</span> Iterates through the elements in the array <code class="fm-code-in-text2">A</code></p>

  <p class="fm-code-annotation"><a id="pgfId-1034426"></a><span class="fm-combinumeral">❸</span> If we have already added at least <code class="fm-code-in-text2">k</code> elements, check if the current element is larger than the top of the heap.</p>

  <p class="fm-code-annotation"><a id="pgfId-1034443"></a><span class="fm-combinumeral">❹</span> In that case, we can safely remove and discard the heap’s top, because it won’t be among the <code class="fm-code-in-text2">k</code> largest elements. After this, the heap will have <code class="fm-code-in-text2">k-1</code> elements.</p>

  <p class="fm-code-annotation"><a id="pgfId-1034460"></a><span class="fm-combinumeral">❺</span> If, at this check, the heap size is less than <code class="fm-code-in-text2">k</code> . . .</p>

  <p class="fm-code-annotation"><a id="pgfId-1034477"></a><span class="fm-combinumeral">❻</span> . . . we must add the current element.</p>

  <p class="fm-code-annotation"><a id="pgfId-1034342"></a><span class="fm-combinumeral">❼</span> Returns the heap with the largest <code class="fm-code-in-text2">k</code> elements. We might as well use heapsort to return the elements in the right order, at a small additional cost.</p>

  <h2 class="fm-head" id="heading_id_33"><a id="pgfId-1007979"></a><a id="id_Toc507447820"></a>2.8 More use cases</h2>

  <p class="body"><a id="pgfId-1007993"></a>The heap is one of the most universally used data structures. Together with stack and queue, it is the basis of almost every algorithm that needs to process the input in a specific order.</p>

  <p class="body"><a id="pgfId-1008002"></a>Replacing a binary heap with a d-ary heap can improve virtually any piece of code that uses a priority queue. Before delving into a few algorithms that can benefit from the use of a heap, make sure you are familiar with graphs, because most of these algorithms will concern this data structure. To that end, chapter 14 provides a quick introduction to graphs.</p>

  <p class="body"><a id="pgfId-1008020"></a>Let’s now discuss some algorithms that can benefit from the use of a heap.</p>

  <h3 class="fm-head2" id="heading_id_34"><a id="pgfId-1008031"></a><a id="id_Hlk534499914"></a><a id="id_Toc507447821"></a>2.8.1 Minimum distance in graphs: Dijkstra</h3>

  <p class="body"><a id="pgfId-1008045"></a>Priority <a id="marker-1009252"></a><a id="marker-1009256"></a><a id="marker-1009260"></a><a id="marker-1009264"></a>queues are crucial to implementing Dijkstra and A* algorithms, described in detail in chapter 14, sections 14.4 and 14.5. Figure 2.13 shows a minimal example of a graph, illustrating the concept of shortest path between two vertices. As we will discuss in chapter 14, the running time of these fundamental algorithms on graphs (which compute the minimum distance to a target) heavily depends on the implementation chosen for the priority queue, and upgrading from a binary to a d-ary heap can provide a consistent <a id="marker-1009268"></a><a id="marker-1009272"></a><a id="marker-1009276"></a><a id="marker-1009280"></a>speedup.<a id="id_Hlk534499932"></a></p>

  <p class="fm-figure"><img alt="" class="calibre23" src="../Images/ch02_F13.png"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1046804"></a>Figure 2.13 A directed graph showing the shortest path between vertices <code class="fm-code-in-text">A</code> and <code class="fm-code-in-text">C</code></p>

  <h3 class="fm-head2" id="heading_id_35"><a id="pgfId-1008093"></a><a id="id_Toc507447812"></a><a id="id_Toc507447823"></a>2.8.2 More graphs: Prim's algorithm</h3>

  <p class="body"><a id="pgfId-1008109"></a>Prim’s <a id="marker-1009284"></a><a id="marker-1009288"></a><a id="marker-1009292"></a><a id="marker-1009296"></a>algorithm computes the <a id="id_Hlk55630221"></a>minimum spanning tree (MST<a id="marker-1009300"></a>) of an undirected, connected graph <code class="fm-code-in-text">G</code>.</p>

  <p class="body"><a id="pgfId-1008131"></a>Suppose <code class="fm-code-in-text">G</code> has <code class="fm-code-in-text">n</code> vertices. The minimum spanning tree of <code class="fm-code-in-text">G</code> is</p>

  <ol class="calibre18">
    <li class="fm-list-numbered">
      <p class="list"><a class="calibre14" id="pgfId-1008146"></a>A tree (a connected, undirected, acyclic graph)</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-1008159"></a>That is a subgraph of <code class="fm-code-in-text">G</code> with <code class="fm-code-in-text">n</code> vertices and</p>
    </li>

    <li class="fm-list-numbered-last">
      <p class="list"><a class="calibre14" id="pgfId-1008176"></a>Whose sum of edges’ weights is the least possible among all of the subgraphs of <code class="fm-code-in-text">G</code> that are also trees and span over all <code class="fm-code-in-text">n</code> vertices</p>
    </li>
  </ol>

  <p class="body"><a id="pgfId-1008193"></a>Considering the graph in the example shown in section 2.8.1, its minimum spanning tree would be the one in figure 2.14.</p>

  <p class="fm-figure"><img alt="" class="calibre23" src="../Images/ch02_F14.png"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1046850"></a>Figure 2.14 A spanning tree for the graph in figure 2.13</p>

  <p class="body"><a id="pgfId-1008226"></a>Prim’s algorithm works exactly as Dijkstra’s, except</p>

  <ul class="calibre19">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre14" id="pgfId-1008237"></a>Without keeping track of the distance from the source.</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-1008249"></a>Storing the edge that connected the front of the visited vertices to the next closest vertex.</p>
    </li>

    <li class="fm-list-numbered-last">
      <p class="list"><a class="calibre14" id="pgfId-1008261"></a>The vertex used as “source” for Prim’s algorithm is going to be the root of the MST.</p>
    </li>
  </ul>

  <p class="body"><a id="pgfId-1008279"></a>It should be no surprise that its running time is similar to <a id="marker-1009304"></a><a id="marker-1009308"></a><a id="marker-1009312"></a><a id="marker-1009316"></a>Dijkstra’s:</p>

  <ul class="calibre19">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre14" id="pgfId-1008293"></a><code class="fm-code-in-text">O(V<sup class="superscript1">2</sup>)</code> using arrays (sorted or unsorted) for the priority queue</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-1008308"></a><code class="fm-code-in-text">O(V*log(V) + E*log(V))</code> using binary or d-ary heap</p>
    </li>

    <li class="fm-list-numbered-last">
      <p class="list"><a class="calibre14" id="pgfId-1008322"></a><code class="fm-code-in-text">O(V*log(V) + E)</code> using Fibonacci heap</p>
    </li>
  </ul>

  <h3 class="fm-head2" id="heading_id_36"><a id="pgfId-1008336"></a><a id="id_Toc507447824"></a>2.8.3 Data compression: Huffman codes</h3>

  <p class="body"><a id="pgfId-1008352"></a>Huffman’s <a id="marker-1009320"></a><a id="marker-1009324"></a><a id="marker-1009328"></a><a id="marker-1009332"></a>algorithm is probably the most famous data compression algorithm, and you have likely already heard of it if you took an “introduction to CS” course. It is a simple, brilliant, <i class="calibre17">greedy</i> algorithm that, despite not being the state of the art for compression anymore, was a major breakthrough in the ‘50s.</p>

  <p class="body"><a id="pgfId-1008372"></a>A Huffman code is a tree, built bottom-up, starting with the list of different characters appearing in a text and their frequency. The algorithm iteratively</p>

  <ol class="calibre18">
    <li class="fm-list-numbered">
      <p class="list"><a class="calibre14" id="pgfId-1008382"></a>Selects and removes the two elements in the list with the smallest frequency</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-1008395"></a>Then creates a new node by combining them (summing the two frequencies)</p>
    </li>

    <li class="fm-list-numbered-last">
      <p class="list"><a class="calibre14" id="pgfId-1008408"></a>And finally adds back the new node to the list</p>
    </li>
  </ol>

  <p class="body"><a id="pgfId-1008421"></a>While the tree itself is not a heap, a key step of the algorithm is based on efficiently retrieving the smallest elements in the list, as well as efficiently adding new elements to the list. You probably have guessed by now that, once again, that’s where heaps come to the rescue.</p>

  <p class="body"><a id="pgfId-1008430"></a>Let’s take a look at the algorithm itself in listing 2.12.</p>

  <p class="fm-figure"><img alt="" class="calibre23" src="../Images/ch02_F15.png"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1046895"></a>Figure 2.15 A Huffman coding tree built from this character frequency table: A=0.6, B=0.2, C=0.07, D=0.06, E=0.05, and F=0.02</p>

  <p class="body"><a id="pgfId-1008462"></a>We assume the input for the algorithm is a text, stored in a string (of course, the actual text might be stored in a file or stream, but we can always have a way to convert it to a string<a href="#pgfId-1013288"><sup class="footnotenumber">18</sup></a>), and the output is a map from characters to binary sequences.</p>

  <p class="body"><a id="pgfId-1008473"></a>The first sub-task that we need to perform is to transform the text: we want to compute some statistics on it to identify the most used and least used characters in it. To that end, we compute the frequency of characters in the text.<a href="#pgfId-1013310"><sup class="footnotenumber">19</sup></a></p>

  <p class="body"><a id="pgfId-1008486"></a>The details of the <code class="fm-code-in-text">ComputeFrequencies</code> method<a id="marker-1009336"></a> at line #2 are both out of scope and (at least in its basic version) simple enough, and there is no need to delve into that helper method here.</p>

  <p class="body"><a id="pgfId-1008499"></a>Once we have computed the frequency map, we create a new priority queue and then at lines #4 and #5 we iterate over the frequency map, creating a new <code class="fm-code-in-text">TreeNode</code><a id="marker-1024518"></a> for each character and then adding it to the priority queue, as in listing 2.12. Obviously, considering the subject of this chapter, for the queue we use a heap, and in particular a min-heap, where the element at the top is the one with the smallest value for the priority field. And in this case the priority field is (not surprisingly) the frequency field of the <code class="fm-code-in-text">TreeNode</code>.</p>

  <p class="fm-code-listing-caption"><a id="pgfId-1023518"></a>Listing 2.12 The Huffman coding algorithm</p>
  <pre class="programlisting"><b class="calibre21">function</b> huffman(text)
  charFrequenciesMap ← ComputeFrequencies(text)
  priorityQueue ← MinHeap()
  <b class="calibre21">for</b> (char, frequency) <b class="calibre21">in</b> charFrequenciesMap <b class="calibre21">do</b>
    priorityQueue.insert(TreeNode([char], frequency))
  <b class="calibre21">while</b> priorityQueue.size &gt; 1 <b class="calibre21">do</b>
    left ← priorityQueue.top()
    right ← priorityQueue.top()
    parent ← TreeNode(left.chars + right.chars,
                      left.frequency + right.frequency)
    parent.left ← left
    parent.right ← right
    priorityQueue.insert(parent)
  <b class="calibre21">return</b> buildTable(priorityQueue.top(), [], Map())</pre>

  <p class="body"><a id="pgfId-1008689"></a>Each <code class="fm-code-in-text">TreeNode</code><a id="marker-1009344"></a>, in fact, contains two fields (besides the pointers to its children): a set of characters and the frequency of those characters in the text, computed as the sum of the frequencies of individual characters.</p>

  <p class="body"><a id="pgfId-1008701"></a>If you look at figure 2.15, you can see that the root of the final tree is the set of all characters in our example text, and hence the total frequency is 1.</p>

  <p class="body"><a id="pgfId-1008710"></a>This set is split into two groups, each of which is assigned to one of the root’s children, and so each internal node is similarly split until we get to leaves, each of which contains just one character.</p>

  <p class="body"><a id="pgfId-1008758"></a>Back to our algorithm, you can see how the tree in figure 2.15 is constructed bottom-up, and lines #2 to #5 in listing 2.12 take care of the first step, creating the leaves of the tree and adding them to the priority queue.</p>

  <p class="body"><a id="pgfId-1008767"></a>Now, from line #6 we enter the core of the algorithm: until there is only one element left in the queue, we extract the top <code class="fm-code-in-text">TreeNode</code><a id="marker-1046926"></a> entries, in lines #7 and #8. As you can see in figure 2.16 (B), those two elements will be the subtrees with the lowest frequencies so far.</p>

  <p class="fm-figure"><img alt="" class="calibre23" src="../Images/ch02_F16.png"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1046959"></a>Figure 2.16 The first step in the Huffman coding algorithm. As mentioned in the text, the algorithm will use two auxiliary data structures, a priority queue and a binary tree. Each tree node will have a value, a set of characters in the text, and a priority, the sum of the frequencies of those characters in the text. (A) Initially, we create one tree node for each character, associated with its frequency in the text. We also add each node into a priority queue, using the frequency as its priority (smaller frequency means higher priority hence we would use a min-heap). (B) We extract two elements from the top of the priority queue.(C) We create a new tree node to which we add the two nodes extracted at step (B) as its children. By convention, we assume that the smallest node will be added as left child and the second-smallest as right child (but any consistent convention works here). The newly created node will hold the union of the set of characters in its children as value, and the sum of the two priorities as priority. (D) Finally, we can add the new root for this subtree back to the priority queue. Note that the nodes in the heap are showed in sorted order, but for the sake of simplicity the order in which nodes are stored inside a priority queue is an implementation detail, the contract for PQ’s API only guarantees that when we dequeue two elements, those will be the ones with the smallest frequencies.</p>

  <p class="body"><a id="pgfId-1008780"></a>Let’s call these subtrees <code class="fm-code-in-text">L</code> and <code class="fm-code-in-text">R</code> (the reason for these names will be apparent soon).</p>

  <p class="body"><a id="pgfId-1008793"></a>Figure 2.16 (C) shows the actions performed in lines #9 to #11 of our pseudocode: a new <code class="fm-code-in-text">TreeNode</code> is created (let’s call it <code class="fm-code-in-text">P</code>) by merging the two entries’ character sets and setting its frequency as the sum of the old subtrees’ frequencies. Then the new node and two subtrees are combined in a new subtree, where the new node <code class="fm-code-in-text">P</code> is the root and the subtrees <code class="fm-code-in-text">L</code> and <code class="fm-code-in-text">R</code> are its children.</p>

  <p class="body"><a id="pgfId-1008814"></a><a id="id_Hlk529721688"></a>Finally, <a id="id_Hlk529721675"></a>at line #12 we add this new subtree back into the queue. As it’s shown in figure 2.16 (D), it can sometimes be placed at the top of the queue, but that’s not always the case; the priority queue will take care of this detail for us (notice that here the priority queue is used as a black box, as we discussed in section 2.4).</p>

  <p class="fm-code-listing-caption"><a id="pgfId-1023551"></a>The Huffman coding algorithm (building a table from the tree)</p>
  <pre class="programlisting"><b class="calibre21">function</b> buildTable(node, sequence, charactersToSequenceMap)
  <b class="calibre21">if</b> node.characters.size == 1 <b class="calibre21">then</b>
    charactersToSequenceMap[node.characters[0]] ← sequence 
  <b class="calibre21">else</b>
    <b class="calibre21">if</b> node.left &lt;&gt; <b class="calibre21">null then</b>
      buildTable(node.left, 0 + sequence, charactersToSequenceMap) 
    <b class="calibre21">if</b> node.right &lt;&gt; <b class="calibre21">null then</b>
      buildTable(node.right, 1 + sequence, charactersToSequenceMap) 
  <b class="calibre21">return</b> charactersToSequenceMap</pre>

  <p class="body"><a id="pgfId-1008948"></a>These steps are repeated until there is only one element left in the queue (figure 2.17 shows a few more steps), and that last element will be the <code class="fm-code-in-text">TreeNode</code><a id="marker-1009352"></a> that is the root of the final tree.</p>

  <p class="fm-figure"><img alt="" class="calibre23" src="../Images/ch02_F17.png"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1047004"></a>Figure 2.17 The result of the next couple of steps in the Huffman coding algorithm. (A) We dequeue and merge the top two nodes on the heap, C and D. At the end of this step, EF and CD become the two smallest nodes in the heap. (B) Now we merge those two nodes into CDEF, and we add it back to the heap. Which node between CDEF and B will be kept at the top of the priority queue is an implementation detail, and it’s irrelevant for the Huffman coding algorithm (the code will change slightly depending on which one is extracted first, but its compression ratio will remain unchanged). The next steps are easy to figure, also using figure 2.15 as a reference.</p>

  <p class="body"><a id="pgfId-1008964"></a>We can then use it in line #13 to create a compression table, which will be the final output of the <code class="fm-code-in-text">huffman</code> method<a id="marker-1009356"></a>. In turn, the compression table can be used to perform the compression of the text by translating each one of its characters into a sequence of bits.</p>

  <p class="body"><a id="pgfId-1008978"></a>While we won’t show this last step,<a href="#pgfId-1013324"><sup class="footnotenumber">20</sup></a> we provide listing 2.13 with the steps needed to create a compression table from the tree in figure 2.15. And even if this goes beyond the scope of this chapter (because the method doesn’t use a priority queue), providing a brief explanation should help those readers interested in writing an implementation of Huffman coding.</p>

  <p class="body"><a id="pgfId-1009020"></a>We wrote the <code class="fm-code-in-text">buildTable</code> method<a id="marker-1028762"></a> using recursive form. As explained in appendix E, this allows us to provide cleaner and more easily understandable code, but in some languages concrete implementations can be more performant when implemented using explicit iterations.</p>

  <p class="body"><a id="pgfId-1009033"></a>We pass three arguments to the method: a <code class="fm-code-in-text">TreeNode node</code><a id="marker-1009364"></a> that is the current node in the traversal of the tree, a sequence that is the path from the root to current node (where we add a 0 for a “left turn” and a 1 for a “right turn”), and the <code class="fm-code-in-text">Map</code><a id="marker-1009368"></a> that will hold the associations between characters and bit sequences.</p>

  <p class="body"><a id="pgfId-1009050"></a>At line #2, we check if the set of characters in the node has only one character. If it does, it means we have reached a leaf, and so the recursion can stop. The bit sequence that is associated with the character in the node is the path from root to current node, stored in the <code class="fm-code-in-text">sequence</code> variable.</p>

  <p class="body"><a id="pgfId-1009066"></a>Otherwise, we check whether the node has left and right children (it will have at least one, because it’s not a leaf) and traverse them. The crucial point here is how we build the <code class="fm-code-in-text">sequence</code> argument in the recursive calls: if we traverse the left child of current node, we add a 0 at the start of the sequence, while if we traverse the right child, we add a 1.</p>

  <p class="body"><a id="pgfId-1009079"></a>Table 2.5 shows the compression table produced starting from the tree shown in figure 2.15; the last column would not be part of the actual compression table, but it’s useful to understand how the most used characters end up translated into shorter sequences (which is the key to an efficient compression).</p>

  <p class="fm-table-caption"><a id="pgfId-1024628"></a>Table 2.5 The compression table created from the Huffman tree in figure 2.15</p>

  <table border="1" class="contenttable" width="100%">
    <tr class="calibre8">
      <th class="fm-contenttable" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1024634"></a>Character</p>
      </th>

      <th class="fm-contenttable" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1024636"></a>Bit sequence</p>
      </th>

      <th class="fm-contenttable" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1024638"></a>Frequency</p>
      </th>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024640"></a><code class="fm-code-in-text2">A</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024642"></a>0</p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024644"></a>0.6</p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024646"></a><code class="fm-code-in-text2">B</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024648"></a>10</p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024650"></a>0.2</p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024652"></a><code class="fm-code-in-text2">C</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024654"></a>1100</p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024656"></a>0.07</p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024658"></a><code class="fm-code-in-text2">D</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024660"></a>1101</p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024662"></a>0.06</p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024664"></a><code class="fm-code-in-text2">E</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024666"></a>1110</p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024668"></a>0.05</p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024670"></a><code class="fm-code-in-text2">F</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024672"></a>1111</p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024674"></a>0.02</p>
      </td>
    </tr>
  </table>

  <p class="body"><a id="pgfId-1009399"></a>Looking at the sequences, the most important property is that they form a prefix code: no sequence is the prefix of another sequence in the code.</p>

  <p class="body"><a id="pgfId-1009634"></a>This property is the key point for the decoding: iterating on the compressed text, we immediately know how to break it into characters.</p>

  <p class="body"><a id="pgfId-1009643"></a>For instance, in the compressed text <code class="fm-code-in-text">1001101</code>, if we start from the first character, we can immediately see that sequence <code class="fm-code-in-text">10</code> matches <code class="fm-code-in-text">B</code>, then the next <code class="fm-code-in-text">0</code> matches <code class="fm-code-in-text">A</code>, and finally <code class="fm-code-in-text">1101</code> matches <code class="fm-code-in-text">D</code>, so the compressed bit sequence is translated <a id="marker-1010441"></a><a id="marker-1010445"></a><a id="marker-1010449"></a><a id="marker-1010453"></a>into <code class="fm-code-in-text">“BAD”</code>.</p>

  <h2 class="fm-head" id="heading_id_37"><a id="pgfId-1009676"></a>2.9 Analysis of branching factor<a href="#pgfId-1013338"><sup class="footnotenumber3">21</sup></a></h2>

  <p class="body"><a id="pgfId-1009689"></a>Now <a id="marker-1010457"></a><a id="marker-1010461"></a><a id="marker-1010465"></a>that we know how d-way heaps work, the next question we need to ask is this: Wouldn’t we be just fine with a regular, binary heap? Is there an advantage in a higher branching factor?</p>

  <h3 class="fm-head2" id="heading_id_38"><a id="pgfId-1009708"></a>2.9.1 Do we need d-ary heaps?</h3>

  <p class="body"><a id="pgfId-1009722"></a>Usually <a id="marker-1010469"></a><a id="marker-1010473"></a><a id="marker-1010477"></a>binary heaps are enough for all our programming needs. The main advantage of this data structure is that it guarantees a logarithmic running time for each one of the common operations. In particular, being a binary balanced tree, the main operations are guaranteed to require a number of comparisons proportional, in the worst case, to <code class="fm-code-in-text">log</code><sub class="subscript">2</sub><code class="fm-code-in-text">(N)</code>. As we discuss in appendix B, this guarantees that we can run these methods on much larger containers than if the running time was linear. Consider that even with a billion elements, <code class="fm-code-in-text">log</code><sub class="subscript">2</sub><code class="fm-code-in-text">(N)</code> just evaluates to about 30.</p>

  <p class="body"><a id="pgfId-1009752"></a>As we have seen in the introduction, constant factors are irrelevant for the running time, that is, <code class="fm-code-in-text">O(c*N) = O(N)</code>, and we know from algebra that two logarithms with different bases only differ by a constant factor, in particular</p>
  <pre class="programlisting">log<sub class="calibre25">b</sub><code class="fm-code-in-text2">(N) = log</code><sub class="calibre25">2</sub><code class="fm-code-in-text2">(N) / log</code><sub class="calibre25">2</sub><code class="fm-code-in-text2">(b)</code></pre>

  <p class="body"><a id="pgfId-1009782"></a>So, in conclusion, we have</p>
  <pre class="programlisting">O(log<sub class="calibre25">2</sub>(N)) = O(log<sub class="calibre25">3</sub>(N)) = O(log(N)) </pre>

  <p class="body"><a id="pgfId-1009805"></a>When we move to the implementation, however, constant factors matter. They matter so much that, in some edge cases, algorithms that would be better according to the running time analysis actually are slower than a simpler algorithm with worse running time, at least for any practical input (for instance, if you compare <code class="fm-code-in-text">2<sup class="superscript1">n</sup></code> and <code class="fm-code-in-text">n*100<sup class="superscript1">100000</sup></code>, then for the constant factor not to matter anymore, the input should be huge).</p>

  <p class="body"><a id="pgfId-1009824"></a>A prominent example of this behavior is given by Fibonacci heap<a href="#pgfId-1013354"><sup class="footnotenumber">22</sup></a>: in theory they provide amortized constant time for some crucial operations such as insert or priority update, but in practice they are both complicated to implement and slow for any viable input size.</p>

  <p class="body"><a id="pgfId-1009842"></a>The constant factors, in general, are due to several different reasons that include</p>

  <ul class="calibre19">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre14" id="pgfId-1009852"></a>Lag for reading/writing to memory (scattered vs localized readings)</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-1009865"></a>The cost of maintaining counters or to iterate loops</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-1009878"></a>The cost of recursion</p>
    </li>

    <li class="fm-list-numbered-last">
      <p class="list"><a class="calibre14" id="pgfId-1009891"></a>Nitty/gritty coding details that in the asymptotic analysis are abstracted away (for instance, as we have seen, static vs dynamic arrays)</p>
    </li>
  </ul>

  <p class="body"><a id="pgfId-1009907"></a>So, at this point it should be clear that in any implementation we should strive to keep this constant multiplicators as small as possible.</p>

  <p class="body"><a id="pgfId-1009916"></a>Consider this formula:</p>

  <p class="fm-equation"><code class="fm-code-in-text3">log<sub class="subscript">b</sub>(N) = log</code><sub class="subscript">2</sub><code class="fm-code-in-text3">(N) / log<sub class="subscript">2</sub>(b)</code></p>

  <p class="body"><a id="pgfId-1009942"></a>If <code class="fm-code-in-text">b &gt; 2</code>, it’s apparent that <code class="fm-code-in-text">log<sub class="subscript1">b</sub>(N) &lt; log<sub class="subscript1">2</sub>(N)</code>, and therefore if we have a logarithmic factor in our algorithm’s running time, and we manage to provide an implementation that instead of <code class="fm-code-in-text">log<sub class="subscript1">2</sub>(N)</code> steps will require <code class="fm-code-in-text">log<sub class="subscript1">b</sub>(N)</code>, while all other factors stay unchanged, then we will have provided a (constant-time) speed-up.</p>

  <p class="body"><a id="pgfId-1009971"></a>In section 2.10 <code class="fm-code-in-text">we</code> will further investigate how this applies to d-ary <a id="marker-1010481"></a><a id="marker-1010485"></a><a id="marker-1010489"></a>heaps.</p>

  <h3 class="fm-head2" id="heading_id_39"><a id="pgfId-1009986"></a><a id="id_Toc507447813"></a>2.9.2 Running time</h3>

  <p class="body"><a id="pgfId-1009998"></a>So <a id="marker-1010493"></a><a id="marker-1010497"></a>the answer is yes, there is an advantage in tuning the heap’s branching factor, but compromise is the key.</p>

  <p class="body"><a id="pgfId-1010013"></a>The insertion will always be quicker with larger branching factors, as we at most need to bubble up the new element to the root, with <code class="fm-code-in-text">O(log<sub class="subscript1">D</sub>(n))</code> comparisons and swaps at most.</p>

  <p class="body"><a id="pgfId-1010027"></a>Instead, the branching factor will affect deletion and priority update. If you recall the algorithms for popping elements, for each node we need to first find the highest priority among all its children, then compare it to the element we are pushing down.</p>

  <p class="body"><a id="pgfId-1010047"></a>The larger the branch factor, the smaller the height of the tree (it shrinks logarithmically with the branching factor). But, on the other hand, the number of children to compare at each level also grows linearly with the branch factor. As you can imagine, a branching factor of 1000 wouldn’t work very well (and it would translate into a linear search for less than 1001 elements!).</p>

  <p class="body"><a id="pgfId-1010064"></a>In practice, through profiling and performance tests, the conclusion has been reached that in most situations, <code class="fm-code-in-text">D=4</code> is the best <a id="marker-1010501"></a><a id="marker-1010505"></a>compromise.</p>

  <h3 class="fm-head2" id="heading_id_40"><a id="pgfId-1010083"></a><a id="id_Toc507447814"></a>2.9.3 Finding the optimal branching factor</h3>

  <p class="body"><a id="pgfId-1010095"></a>If <a id="marker-1010509"></a><a id="marker-1010513"></a>you are looking for an optimal value for <code class="fm-code-in-text">D</code> that works in every situation, then you are going to be disappointed. To a certain extent, theory comes to the rescue by showing us a range of optimal values. It can be shown that the optimal value can’t be greater than <code class="fm-code-in-text">5</code>. Or, to put it another way, it can be mathematically proven that</p>

  <ul class="calibre19">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre14" id="pgfId-1010109"></a>The tradeoff between insert and delete is best balanced with <code class="fm-code-in-text">2 &lt;= D &lt;= 5.</code></p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-1010123"></a>A 3-way heap is in theory faster than a 2-way heap.</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-1010136"></a>4-way heaps and 3-way heaps have similar performance.</p>
    </li>

    <li class="fm-list-numbered-last">
      <p class="list"><a class="calibre14" id="pgfId-1010149"></a>5-way heaps are a bit slower.</p>
    </li>
  </ul>

  <p class="body"><a id="pgfId-1010161"></a>In practice, the best value for <code class="fm-code-in-text">D</code> depends on the details of the implementation and of the data you are going to store in the heap. The optimal branching factor for a heap can only be determined empirically, case by case. There is no overall optimal branching factor, and it depends on the actual data and on the ratio of insertions/deletions, or, for instance, how expensive it is to compute priority versus copying elements, among other things.</p>

  <p class="body"><a id="pgfId-1010196"></a>In common experience, binary heaps are never the fastest, 5-way heaps are seldom faster (for narrow domains), and the best choice usually falls between 3 and 4, depending on nuances.</p>

  <p class="body"><a id="pgfId-1010205"></a>So while I feel safe suggesting starting with a branching factor of 4, if this data structure is used in a key section of your application and small performance improvement can make a relevant difference, then you need to tune the branching factor as a <a id="marker-1031910"></a><a id="marker-1031911"></a>parameter.</p>

  <h3 class="fm-head2" id="heading_id_41"><a id="pgfId-1010217"></a>2.9.4 Branching factor vs memory</h3>

  <p class="body"><a id="pgfId-1010229"></a>Notice <a id="marker-1010525"></a><a id="marker-1010529"></a>that I suggested the larger branching factor among the two best performing ones for a reason. It turns out there is, in fact, another consideration to be made when looking for the optimal branching factor for heaps: locality of reference.</p>

  <p class="body"><a id="pgfId-1010245"></a>When the size of the heap is larger than available cache or than the available memory, or in any case where caching and multiple levels of storage are involved, then on average a binary heap requires more cache misses or page faults than a d-ary heap. Intuitively, this is due to the fact that children are stored in clusters, and that on update or deletion, for every node reached, all its children will have to be examined. The larger the branching factor becomes, the more the heap becomes short and wide, and the more the principle of locality applies.</p>

  <p class="body"><a id="pgfId-1010256"></a>D-way heap appears to be the best traditional data structure for reducing page faults.<a href="#pgfId-1013386"><sup class="footnotenumber">23</sup></a> New alternatives focused on reducing cache misses and page swaps have been proposed over the years; for instance, you can check out splay trees.</p>

  <p class="body"><a id="pgfId-1010269"></a>While these alternatives aren’t in general able to have the same balance between practical and theoretical performance as heaps, when the cost of page faults or disk access dominates, it might be better to resort to a linearithmic<a href="#pgfId-1013403"><sup class="footnotenumber">24</sup></a> algorithm with higher locality rather than sticking with a linear algorithm with <a id="marker-1010533"></a><a id="marker-1010537"></a>poor <a id="marker-1010541"></a><a id="marker-1010545"></a><a id="marker-1010549"></a>locality.</p>

  <h2 class="fm-head" id="heading_id_42"><a id="pgfId-1010289"></a>2.10 Performance analysis: Finding the best branching factor</h2>

  <p class="body"><a id="pgfId-1010307"></a>We’ve <a id="marker-1010553"></a><a id="marker-1010557"></a>discussed the theory. Now let’s try to apply it to a real case and describe how to profile the implementation of a data structure and an application.</p>

  <p class="body"><a id="pgfId-1010324"></a>We have seen that priority queues are a key component in the Huffman compression pipeline. If we measure the performance of our heap’s methods as the number of swaps performed, we have shown that we have at most <code class="fm-code-in-text">h</code> swaps per method call, if <code class="fm-code-in-text">h</code> is the height of the heap. In section 2.5 we also showed that because the heap is a complete balanced tree<a id="marker-1010561"></a>, the height of a d-ary heap is exactly <code class="fm-code-in-text">log<sub class="subscript1">D</sub>(n)</code>.<a href="#pgfId-1013425"><sup class="footnotenumber">25</sup></a></p>

  <p class="body"><a id="pgfId-1010354"></a>Therefore, for both methods <code class="fm-code-in-text">insert</code><a id="marker-1010565"></a> and <code class="fm-code-in-text">top</code><a id="marker-1010569"></a>, it would seem that the larger the branching factor, the smaller the height, and in turn the better heap performance should be.</p>

  <p class="body"><a id="pgfId-1010369"></a>But just limiting to swaps doesn’t tell us the whole story. In section 2.9 we delve into the performance analysis of these two methods and take into consideration also the number of array accesses, or equivalently the number of comparisons on heap elements that are needed for each method. While <code class="fm-code-in-text">insert</code><a id="marker-1010573"></a> accesses only one element per heap’s level, method <code class="fm-code-in-text">top</code><a id="marker-1010577"></a> traverses the tree from root to leaves, and at each level it needs to go through the list of children of a node. Therefore, it needs approximately up to <code class="fm-code-in-text">D*log<sub class="subscript1">D</sub>(n)</code> accesses on a heap with branching factor <code class="fm-code-in-text">D</code> and containing <code class="fm-code-in-text">n</code> elements.</p>

  <p class="body"><a id="pgfId-1010403"></a>Tables 2.6 and 2.7 summarize the performance analysis for the three main methods in heaps’ API.</p>

  <p class="fm-table-caption"><a id="pgfId-1024727"></a>Table 2.6 Main operations provided by a d-ary heap, and the number of swaps (assuming n elements)</p>

  <table border="1" class="contenttable" width="100%">
    <tr class="calibre8">
      <th class="fm-contenttable" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1024733"></a>Operation</p>
      </th>

      <th class="fm-contenttable" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1024735"></a>Number of swaps</p>
      </th>

      <th class="fm-contenttable" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1024737"></a>Extra space</p>
      </th>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024739"></a><code class="fm-code-in-text2">Insert</code><a id="marker-1024756"></a></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024741"></a><code class="fm-code-in-text2">~log<sub class="subscript">D</sub>(n)</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024743"></a><code class="fm-code-in-text2">O(1)</code></p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024745"></a><code class="fm-code-in-text2">Top</code><a id="marker-1024757"></a></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024747"></a><code class="fm-code-in-text2">~log<sub class="subscript">D</sub>(n)</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024749"></a><code class="fm-code-in-text2">O(1)</code></p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024751"></a><code class="fm-code-in-text2">Heapify</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024753"></a><code class="fm-code-in-text2">~n</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024755"></a><code class="fm-code-in-text2">O(1)</code></p>
      </td>
    </tr>
  </table>

  <p class="body"><a id="pgfId-1010586"></a>For method <code class="fm-code-in-text">top</code><a id="marker-1025493"></a>, a larger branching factor doesn’t always improve performance, because while <code class="fm-code-in-text">log<sub class="subscript1">D</sub>(n)</code> becomes smaller, <code class="fm-code-in-text">D</code> becomes larger. Bringing it to an extreme, if we choose <code class="fm-code-in-text">D &gt; n-1</code>, then the heap becomes a root with a list of <code class="fm-code-in-text">n-1</code> children, and so while <code class="fm-code-in-text">insert</code><a id="marker-1025495"></a> will require just <code class="fm-code-in-text">1</code> comparison and <code class="fm-code-in-text">1</code> swap, <code class="fm-code-in-text">top</code> method<a id="marker-1025496"></a> will need <code class="fm-code-in-text">n</code> comparisons and <code class="fm-code-in-text">1</code> swap (in practice, as bad as keeping an unsorted list<a id="marker-1025497"></a> of elements).</p>

  <p class="body"><a id="pgfId-1010783"></a>There is no easy<a href="#pgfId-1013446"><sup class="footnotenumber">26</sup></a> way to find a value for <code class="fm-code-in-text">D</code> that minimizes function <code class="fm-code-in-text">f(n) = D*log<sub class="subscript1">D</sub>(n)</code> for all values of <code class="fm-code-in-text">n</code>, and besides, this formula gives us just an estimate of the maximum number of accesses/swaps performed. The exact number of comparisons and swaps actually performed depends on the sequence of operations and on the order in which elements are added.</p>

  <p class="fm-table-caption"><a id="pgfId-1024811"></a>Table 2.7 Cost of main operations provided by heaps as a number of comparisons (assuming n elements)</p>

  <table border="1" class="contenttable" width="100%">
    <tr class="calibre8">
      <th class="fm-contenttable" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1024817"></a>Operation</p>
      </th>

      <th class="fm-contenttable" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1024819"></a>Number of comparisons</p>
      </th>

      <th class="fm-contenttable" colspan="1" rowspan="1">
        <p class="fm-table-head"><a id="pgfId-1024821"></a>Extra space</p>
      </th>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024823"></a><code class="fm-code-in-text2">Insert</code><a id="marker-1025516"></a></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024825"></a><code class="fm-code-in-text2">~log<sub class="subscript">D</sub>(n)</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024827"></a><code class="fm-code-in-text2">O(1)</code></p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024829"></a><code class="fm-code-in-text2">Top</code><a id="marker-1025523"></a></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024831"></a><code class="fm-code-in-text2">~D*log<sub class="subscript">D</sub>(n)</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024833"></a><code class="fm-code-in-text2">O(1)</code></p>
      </td>
    </tr>

    <tr class="calibre8">
      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024835"></a><code class="fm-code-in-text2">Heapify</code><a id="marker-1025530"></a></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024837"></a><code class="fm-code-in-text2">~n</code></p>
      </td>

      <td class="fm-contenttable1" colspan="1" rowspan="1">
        <p class="fm-table-body"><a id="pgfId-1024839"></a><code class="fm-code-in-text2">O(1)</code></p>
      </td>
    </tr>
  </table>

  <p class="body"><a id="pgfId-1010854"></a>Then the question arises: How do we choose the best value for the branching factor?</p>

  <p class="body"><a id="pgfId-1011022"></a>The best we can do here is profile our applications to choose the best value for this parameter. In theory, applications with more calls to <code class="fm-code-in-text">insert</code><a id="marker-1012621"></a> than to <code class="fm-code-in-text">top</code><a id="marker-1012625"></a> will perform better with larger branching factors, while when the ratio of calls between the two methods approaches 1.0, a more balanced choice will be best.</p>

  <h3 class="fm-head2" id="heading_id_43"><a id="pgfId-1011039"></a>2.10.1 Please welcome profiling</h3>

  <p class="body"><a id="pgfId-1011056"></a>And <a id="marker-1012629"></a>so we are stuck with <i class="calibre17">profiling</i><a id="marker-1012633"></a>. If you are asking yourself “What’s profiling?” or “Where do I start?”, here are a few tips:</p>

  <ul class="calibre19">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre14" id="pgfId-1011070"></a>Profiling means measuring the running time and possibly the memory consumption of different parts of your code.</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-1011082"></a>It can be done at a high level (measuring the calls to high level functions) or a lower level, for each instruction, and although you can set it up manually (measuring the time before and after a call), there are great tools to aid you—usually guaranteeing an error-free measurement.</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-1011096"></a>Profiling can’t give you general-purpose answers: it can measure the performance of <i class="calibre15">your</i> code on the input you provide.</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-1011110"></a>In turn, this means that the result of profiling is as good as the input you use, meaning that if you only use a very specific input, you might tune your code for an edge case, and it could perform poorly on different inputs. Also, another key factor is the data volume: to be statistically significant, it can be nice to collect profiling results on many runs over (pseudo)random inputs.</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-1011123"></a>It also means that results are not generalizable to different programming languages, or even different implementations in the same language.</p>
    </li>

    <li class="fm-list-numbered-last">
      <p class="list"><a class="calibre14" id="pgfId-1011135"></a>Profiling requires time. The more in depth you go with tuning, the more time it requires. Remember Donald Knuth’s advice: “premature optimization is the root of all evil.” Meaning you should only get into profiling to optimize critical code paths. Spending two days to shave 5 milliseconds on an application that takes 1 minute is frankly a waste of time (and possibly, if you end up making your code more complicated to tune your app, it will also make your code worse).</p>
    </li>
  </ul>

  <p class="body"><a id="pgfId-1011153"></a>If, in spite all of these disclaimers, you realize that your application actually needs some tuning, then brace yourself and choose the best profiling tool available for your framework.</p>

  <p class="body"><a id="pgfId-1011164"></a>To perform profiling, obviously we will have to abandon pseudocode and choose an actual implementation; in our example, we will profile a <code class="fm-code-in-text">Python</code> implementation of Huffman encoding and d-ary heap. You can check out the implementation on our <span class="fm-hyperlink">repo<a href="#pgfId-1013463"><sup class="footnotenumber">27</sup></a></span> on GitHub.</p>

  <p class="body"><a id="pgfId-1011178"></a>Code and tests are written in Python 3, specifically using version 3.7.4, the latest stable version at the time of writing. We are going to use a few libraries and tools to make sense of the profiling stats we collect:</p>

  <ul class="calibre19">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre14" id="pgfId-1011187"></a><span class="fm-hyperlink1">Pandas</span><a class="calibre14" id="marker-1012637"></a></p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-1011202"></a><span class="fm-hyperlink1">Matplotlib</span><a class="calibre14" id="marker-1012641"></a></p>
    </li>

    <li class="fm-list-numbered-last">
      <p class="list"><a class="calibre14" id="pgfId-1011217"></a><span class="fm-hyperlink1">Jupyter Notebook</span></p>
    </li>
  </ul>

  <p class="body"><a id="pgfId-1011230"></a>To make your life easier, if you’d like to try out the code I suggest you install the <span class="fm-hyperlink">Anaconda</span><a id="marker-1012645"></a> distribution, which already includes the latest Python distribution and all the packages listed.</p>

  <p class="body"><a id="pgfId-1011246"></a>To do the actual profiling, we use <code class="fm-code-in-text">cProfile</code> package<a id="marker-1012649"></a>, which is already included in the basic <code class="fm-code-in-text">Python</code> distro.</p>

  <p class="body"><a id="pgfId-1011261"></a>We won’t explain in detail how to use <code class="fm-code-in-text">cProfile</code> (lots of free material online covers this, starting from the Python docs linked previously), but to sum it up, <code class="fm-code-in-text">cProfile</code> allows running a method or function and records the per-call, total, and cumulative time taken by every method involved.</p>

  <p class="body"><a id="pgfId-1011300"></a>Using <code class="fm-code-in-text">pStats</code><span class="fm-hyperlink">.</span><code class="fm-code-in-text">Stats</code><a id="marker-1012653"></a>, we can retrieve and print (or process) those stats; the output of profiling looks something like what’s shown in figure 2.18.</p>

  <p class="fm-figure"><img alt="" class="calibre23" src="../Images/ch02_F18.png"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1047046"></a>Figure 2.18 Printing Stats after profiling Huffman encoding function.</p>

  <p class="body"><a id="pgfId-1011314"></a>Now, to reduce the noise, we are only interested in a few methods, specifically the functions that use a heap: in particular <code class="fm-code-in-text">_frequency_table_to_heap</code><a id="marker-1012657"></a>, which takes the dictionary with the frequency (or number of occurrences) of each character in the input text and creates a heap with one entry per character, and <code class="fm-code-in-text">_heap_to_tree</code><a id="marker-1012661"></a>, which in turn takes the heap created by the former function and uses it to create the Huffman encoding tree.</p>

  <p class="body"><a id="pgfId-1011329"></a>We also want to track down the calls to the heap methods used: <code class="fm-code-in-text">_heapify</code><a id="marker-1012665"></a>, <code class="fm-code-in-text">top</code><a id="marker-1012669"></a>, and <code class="fm-code-in-text">insert</code><a id="marker-1012673"></a>. Instead of just printing those stats, we can read them as a dictionary, and filter the entries corresponding to those five functions.</p>

  <p class="body"><a id="pgfId-1011349"></a>To have meaningful, reliable results, we also need to profile several calls to the method <code class="fm-code-in-text">huffman.create_encoding</code><a id="marker-1012677"></a>, and so processing the stats and saving the result to a CSV file seems the best choice anyway.</p>

  <p class="body"><a id="pgfId-1011362"></a>To see the profiling in action, check out our <span class="fm-hyperlink">example<a href="#pgfId-1032128"><sup class="footnotenumber">28</sup></a></span> on GitHub. The example profiles several calls to the method creating a Huffman encoding over an ensemble of large text files<a href="#pgfId-1013479"><sup class="footnotenumber">29</sup></a> and a bitmap image. The bitmap needs to be duly pre-processed in order to make it processable as text. The details of this pre-processing are not particularly interesting, but for the curious reader we encode image bytes in base64 to have valid <a id="marker-1012681"></a>characters.</p>

  <h3 class="fm-head2" id="heading_id_44"><a id="pgfId-1011381"></a>2.10.2 Interpreting results</h3>

  <p class="body"><a id="pgfId-1011395"></a>Now <a id="marker-1012685"></a>that we’ve stored the results of profiling in a CSV file, we <i class="calibre17">just</i> need to interpret them to understand what’s the best choice of branching factor for our Huffman encoding app. At this point it should look like a piece of cake, right?</p>

  <p class="body"><a id="pgfId-1011419"></a>We can do it in many ways, but my personal favorite is displaying some plots in a Jupyter Notebook: take a look <span class="fm-hyperlink">here</span> at an example.<a href="#pgfId-1013497"><sup class="footnotenumber">30</sup></a> Isn’t it great that GitHub lets you already display the Notebook without having to run it locally?</p>

  <p class="body"><a id="pgfId-1011443"></a>Before delving into the results, though, we need to take a step back: because we will use a <span class="fm-hyperlink">boxplot<a href="#pgfId-1032218"><sup class="footnotenumber">31</sup></a></span><a id="marker-1012689"></a> to display our data, let’s make sure we know how to interpret these plots first. If you feel you could use a hint, figure 2.19 comes to the rescue!</p>

  <p class="fm-figure"><img alt="" class="calibre23" src="../Images/ch02_F19.png"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1047096"></a>Figure 2.19 Explaining how to read an example boxplot. Boxplots show the distribution of samples using a nice and effective chart. The main idea is that the most relevant samples are those whose values lie between the first and third quartile. That is, we find three values, Q1, Q2 (aka the median), and Q3 such that 25% of the samples are smaller than Q1; 50% of the samples are smaller than Q2 (which is the very definition of median, by the way); and 75% of the samples are smaller than Q3. The box in the boxplot is meant to clearly visualize the values for Q1 and Q3. Whiskers, instead, shows how far from the median the data extends. To that end, we could also display outliers, that is, samples that are outside the whiskers’ span. Sometimes outliers, though, end up being more confusing than useful, so in this example we will not use them.</p>

  <p class="body"><a id="pgfId-1011479"></a>To make sense of the data our example notebook uses <i class="calibre17">Pandas</i> library<a id="marker-1028923"></a>, with which we read the CSV file with the stats and transform it into a <code class="fm-code-in-text">DataFrame</code><a id="marker-1028925"></a>, an internal Pandas representation. You can think about it as a SQL table on steroids. In fact, using this <code class="fm-code-in-text">DataFrame</code> we can partition data by test case (<i class="calibre17">image</i> versus <i class="calibre17">text</i>), then group it by method, and finally process each method separately and display results, for each method, grouped by branching factor. Figure 2.20 shows these results for encoding a large text, comparing the two main functions in Huffman encoding that use a heap.</p>

  <p class="fm-figure"><img alt="" class="calibre23" src="../Images/ch02_F20.png"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1047138"></a>Figure 2.20 The distribution of running times for the two high-level functions in Huffman.py using a heap. (Top) Mean running time by branching factor. (Bottom) Boxplots for the distribution of running times for each branching factor. All charts are created using data about the running time per single call for the compression of an ensemble of text files.</p>

  <p class="body"><a id="pgfId-1011535"></a>If we look at those results, we can confirm a few points we mentioned in section 2.9:</p>

  <ul class="calibre19">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre14" id="pgfId-1011544"></a>2 is never the best choice for a branching factor.</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-1011557"></a>A branching factor of 4 or 5 seems a good compromise.</p>
    </li>

    <li class="fm-list-numbered-last">
      <p class="list"><a class="calibre14" id="pgfId-1011570"></a>There is a consistent difference (even -50% for <code class="fm-code-in-text">_frequency_table_to_heap</code><a class="calibre14" id="marker-1012701"></a>) between a binary heap and the d-ary heap with best branching factor.</p>
    </li>
  </ul>

  <p class="body"><a id="pgfId-1011585"></a>There is, however, also something that might look surprising: <code class="fm-code-in-text">_frequency_table_ to_heap</code><a id="marker-1012705"></a> seems to improve with larger branching factors, while <code class="fm-code-in-text">_heap_to_tree</code><a id="marker-1012709"></a> has a minimum for branching factors around 9 and 10.</p>

  <p class="body"><a id="pgfId-1011600"></a>As explained in section 2.6, which shows the pseudocode implementation of heap methods (and as you can see from the code on GitHub), the former method only calls the<code class="fm-code-in-text">_push_down</code> helper method<a id="marker-1012713"></a>, while the latter uses both <code class="fm-code-in-text">top</code><a id="marker-1012717"></a> (which in turn calls <code class="fm-code-in-text">_push_down</code>) and <code class="fm-code-in-text">insert</code><a id="marker-1012721"></a> (relying on <code class="fm-code-in-text">_bubble_up</code><a id="marker-1012725"></a> instead), so we would expect to see the opposite result. Anyway, it is true that even <code class="fm-code-in-text">_heap_to_tree</code><a id="marker-1012729"></a> has a ratio of two calls to <code class="fm-code-in-text">top</code> per <code class="fm-code-in-text">insert</code>.</p>

  <p class="body"><a id="pgfId-1011635"></a>Let’s now delve into the internals of these high-level methods, and see the running time per call of heap’s internal method <code class="fm-code-in-text">_heapify</code><a id="marker-1012733"></a> (figure 2.22), and of API’s methods <code class="fm-code-in-text">top</code><a id="marker-1012737"></a> and <code class="fm-code-in-text">insert</code> and their helper methods <code class="fm-code-in-text">_push_down</code><a id="marker-1012741"></a> and <code class="fm-code-in-text">_bubble_up</code><a id="marker-1012745"></a> (figures 2.21 and 2.23).</p>

  <p class="fm-figure"><img alt="" class="calibre23" src="../Images/ch02_F21.png"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1047191"></a>Figure 2.21 The distribution of recorded running times per call for <code class="fm-code-in-text">insert</code><a id="marker-1047190"></a> and <code class="fm-code-in-text">_bubble_up</code></p>

  <p class="body"><a id="pgfId-1011689"></a>Before digging into the most interesting part, let’s quickly check out the <code class="fm-code-in-text">insert</code><a id="marker-1012753"></a> method. Figure 2.21 shows there are no surprises here; the method tends to improve with larger branching factors, as does <code class="fm-code-in-text">_bubble_up</code><a id="marker-1012757"></a>, its main helper.</p>

  <p class="fm-figure"><img alt="" class="calibre23" src="../Images/ch02_F22.png"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1047243"></a>Figure 2.22 The distribution of recorded running times per call for <code class="fm-code-in-text">heapify</code><a id="marker-1047242"></a>.</p>

  <p class="body"><a id="pgfId-1011732"></a>The <code class="fm-code-in-text">_heapify</code> method<a id="marker-1012765"></a>, as expected, shows a trend similar to <code class="fm-code-in-text">_frequency_table_to_heap</code><a id="marker-1012769"></a><code class="fm-code-in-text">,</code> because all this method does is create a heap from the frequency table. Still, is it a bit surprising that <code class="fm-code-in-text">_heapify</code>‘s running time doesn’t degrade with larger branching factors?</p>

  <p class="fm-figure"><img alt="" class="calibre23" src="../Images/ch02_F23.png"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1047293"></a>Figure 2.23 The distribution of recorded running times per call for top<a id="marker-1047290"></a><a id="marker-1047291"></a> and _push_down<a id="marker-1047292"></a></p>

  <p class="body"><a id="pgfId-1011759"></a>Now to the juicy part. Let’s take a look at <code class="fm-code-in-text">top</code><a id="marker-1012773"></a> in figure 2.23. If we look at the running time per call, the median and distribution clearly show a local minimum (around <code class="fm-code-in-text">D==9</code>), as we would have expected, considering that the method’s running time is <code class="fm-code-in-text">O(D*log<sub class="subscript1">D</sub>(n))</code>, confirming what we have previously discussed and summarized in table 2.7. Not surprisingly, the <code class="fm-code-in-text">_push_down</code> helper method<a id="marker-1012777"></a> has an identical distribution.</p>

  <p class="body"><a id="pgfId-1011798"></a>If we look at listings 2.7 and 2.4 and sections 2.6.2 and 2.6.4, it’s clear how <code class="fm-code-in-text">pushDown</code><a id="id_Hlk18408375"></a> is the heart of the <code class="fm-code-in-text">top</code> method, and in turn the largest chunk of work for <code class="fm-code-in-text">pushDown</code><a id="marker-1012781"></a> is the method that at each heap’s level retrieves the child of current node. We called it <code class="fm-code-in-text">HighestPriorityChild</code>.<code class="fm-code-in-text"><a class="calibre14" href="#pgfId-1013514"><sup class="footnotenumber4">32</sup></a></code><a id="marker-1012785"></a></p>

  <p class="body"><a id="pgfId-1011852"></a>And if then we look at the running time <i class="calibre17">per call</i> for <code class="fm-code-in-text">_highest_priority_child</code><a id="marker-1012801"></a> (figure 2.24 (A)), we have a confirmation that our profiling does make sense, because the running time per call increases with the branching factor. The larger <code class="fm-code-in-text">D</code> is, the longer the list of children for each node, which this method needs to traverse entirely in order to find which tree branch should be traversed next.</p>

  <p class="fm-figure"><img alt="" class="calibre23" src="../Images/ch02_F24.png"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1047338"></a>Figure 2.24 (A) The distribution of recorded running times per-call for <code class="fm-code-in-text">_highest_priority_child</code><a id="marker-1047339"></a>. (B) The distribution of cumulative running times for <code class="fm-code-in-text">_highest_priority_child</code>.</p>

  <p class="body"><a id="pgfId-1011882"></a>You might then wonder why <code class="fm-code-in-text">_push_down</code><a id="marker-1012809"></a> doesn’t have the same trend. Remember that while the running time for <code class="fm-code-in-text">_highest_priority_child</code><a id="marker-1012813"></a> is <code class="fm-code-in-text">O(D)</code>, in particular with <code class="fm-code-in-text">D</code> comparisons, <code class="fm-code-in-text">_push_down</code> performs (at most) <code class="fm-code-in-text">log<sub class="subscript1">D</sub>(n)</code> swap sand <code class="fm-code-in-text">D*log<sub class="subscript1">D</sub>(n)</code> comparisons, because it calls <code class="fm-code-in-text">_highest_priority_child</code> at most <code class="fm-code-in-text">log<sub class="subscript1">D</sub>(n)</code> times.</p>

  <p class="body"><a id="pgfId-1011944"></a>The larger the branching factor <code class="fm-code-in-text">D</code>, the fewer calls are made to <code class="fm-code-in-text">_highest_priority_ child</code>. This becomes apparent if, instead of plotting the running time per-call for <code class="fm-code-in-text">_highest_priority_child</code><a id="marker-1012821"></a>, we use the total cumulative time (the sum of all calls to each method), as shown in figure 2.24 (B). There we can see again how this composite function, <code class="fm-code-in-text">f(D) = D*log<sub class="subscript1">D</sub>(n)</code>, has a minimum at <a id="marker-1012825"></a><code class="fm-code-in-text">D==9</code>.</p>

  <h3 class="fm-head2" id="heading_id_45"><a id="pgfId-1011970"></a>2.10.3 The mystery with heapify</h3>

  <p class="body"><a id="pgfId-1011986"></a>Summing <a id="marker-1012829"></a>up, <code class="fm-code-in-text">_heapify</code><a id="marker-1012833"></a> keeps improving even at larger branching factors, although we can also say it practically plateaus after <code class="fm-code-in-text">D==13</code>, but this behavior is not caused by the methods <code class="fm-code-in-text">top</code><a id="marker-1012837"></a> and <code class="fm-code-in-text">_push_down</code><a id="marker-1012841"></a>, which do behave as expected.</p>

  <p class="body"><a id="pgfId-1012008"></a>There could be a few explanations for how the <code class="fm-code-in-text">_heapify</code><a id="marker-1012845"></a> running time grows:</p>

  <ol class="calibre18">
    <li class="fm-list-numbered">
      <p class="list"><a class="calibre14" id="pgfId-1012020"></a>It’s possible that, checking larger branching factors, we discover that there is a minimum (we just haven’t found it yet).</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-1012032"></a>The performance of this method heavily depends on the order of insertions: with sorted data it performs way better than with random data.</p>
    </li>

    <li class="fm-list-numbered-last">
      <p class="list"><a class="calibre14" id="pgfId-1012044"></a>Implementation-specific details make the contribution of calls to <code class="fm-code-in-text">_push_down</code><a class="calibre14" id="marker-1012849"></a> less relevant over the total running time.</p>
    </li>
  </ol>

  <p class="body"><a id="pgfId-1012059"></a>But . . . are we sure that this is in contrast with theory? You should know by now that I like rhetorical questions; this means it is time to get into some math.</p>

  <p class="body"><a id="pgfId-1012083"></a>And indeed, if we take a closer look at section 2.6.7, we can find out that the number of swaps performed by <code class="fm-code-in-text">_heapify</code><a id="marker-1012853"></a> is limited by:</p>

  <p class="fm-figure"><img alt="" class="calibre23" src="../Images/ch02_F_EQ3.png"/></p>

  <p class="body"><a id="pgfId-1012104"></a>As you can imagine, analyzing this function is not straightforward. But, and here is the fun part, now you can certainly plot the function using your (possibly newly acquired) Jupyter Notebook skills. It turns out that, indeed, plotting this function of <code class="fm-code-in-text">D</code> for a few values of <code class="fm-code-in-text">n</code>, we get the charts in figure 2.25, showing that, despite the fact that the single calls to <code class="fm-code-in-text">_push_down</code><a id="marker-1012857"></a> will be slower with a higher branching factor, the total number of swaps is expected to decrease.</p>

  <p class="fm-figure"><img alt="" class="calibre23" src="../Images/ch02_F25.png"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1047381"></a>Figure 2.25 The upper bound for the number of swaps needed by the heapify method<a id="marker-1047382"></a>, as a function of the branching factor D. Each line is a different value of n. Notice that the y axis uses a logarithmic scale.</p>

  <p class="body"><a id="pgfId-1012126"></a>So, mystery solved; <code class="fm-code-in-text">_heapify</code><a id="marker-1029156"></a> does behave as expected. And good news, too: it gets faster as we increase the branching factor<a id="marker-1029158"></a><a id="marker-1029159"></a>.</p>

  <h3 class="fm-head2" id="heading_id_46"><a id="pgfId-1012173"></a>2.10.4 Choosing the best branching factor</h3>

  <p class="body"><a id="pgfId-1012191"></a>For <a id="marker-1012881"></a>a mystery solved, there is still a big question standing: What is the best branching factor to speed up our Huffman encoding method? We digressed, delving into the details of the analysis of heaps and somehow left the most important question behind.</p>

  <p class="body"><a id="pgfId-1012202"></a>To answer this question, there is only one way: looking at figure 2.26, showing the running time for the main method of our Huffman encoding library.</p>

  <p class="fm-figure"><img alt="" class="calibre23" src="../Images/ch02_F26.png"/></p>

  <p class="fm-figure-caption"><a id="pgfId-1047427"></a>Figure 2.26 Distribution of per-call running time for the method huffman.create_encoding<a id="marker-1047428"></a></p>

  <p class="body"><a id="pgfId-1012211"></a>It shows three interesting facts:</p>

  <ul class="calibre19">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre14" id="pgfId-1012220"></a>The best choice seems to be <code class="fm-code-in-text">D==9.</code></p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-1012235"></a>Choosing any value larger than <code class="fm-code-in-text">7</code> will likely be as good.</p>
    </li>

    <li class="fm-list-numbered-last">
      <p class="list"><a class="calibre14" id="pgfId-1012248"></a>While the max gain for <code class="fm-code-in-text">_frequency_table_to_heap</code><a class="calibre14" id="marker-1012885"></a> is 50%, and for <code class="fm-code-in-text">_heapify</code><a class="calibre14" id="marker-1012889"></a> even up to 80%, we merely get to a 5% here.</p>
    </li>
  </ul>

  <p class="body"><a id="pgfId-1012266"></a>Notice how the chart for <code class="fm-code-in-text">create_encoding</code><a id="marker-1012893"></a> looks more similar to the method <code class="fm-code-in-text">_heap_ to_tree</code><a id="marker-1012897"></a> than to <code class="fm-code-in-text">_frequency_table_to_heap</code><a id="marker-1012901"></a>. Also, considering the third point, the explanation is that the operation on the heap only contributes to a fraction of the running time, while the most demanding methods needs to be searched elsewhere. (Hint: for <code class="fm-code-in-text">create_frequency_table</code><a id="marker-1012905"></a>, the running time depends on the length of the input file, while for the other methods it only depends on the size of the alphabet.)</p>

  <p class="body"><a id="pgfId-1012325"></a>You can check out the full results, including the other examples, on the notebook on GitHub. Keep in mind that this analysis uses a limited input, and as such is likely to be biased. This is just a starting point, and I highly encourage you to try running a more thorough profiling using more runs on different inputs.</p>

  <p class="body"><a id="pgfId-1012340"></a>You can also pull the full profiling and visualization code and delve even deeper into the analysis.</p>

  <p class="body"><a id="pgfId-1012349"></a>To wrap up, I’d like to highlight a few takeaways:</p>

  <ul class="calibre19">
    <li class="fm-list-bullet">
      <p class="list"><a class="calibre14" id="pgfId-1012358"></a>D-ary heaps are faster than binary ones.</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-1012370"></a>If you have parametric code, profiling is the way to tune your parameter. The best choice depends on your implementation as well as on input.</p>
    </li>

    <li class="fm-list-numbered-last">
      <p class="list"><a class="calibre14" id="pgfId-1012387"></a>Be sure to run your profiling on a representative sample of your domain. If you use a limited subset, you will likely optimize for an edge case, and your results will be biased.</p>
    </li>
  </ul>

  <p class="body"><a id="pgfId-1012404"></a>As a general rule, make sure to optimize the right thing: only profile critical code, and perform high-level profiling first to spot the critical section of code whose optimization would give you the largest improvement, and verify that this improvement is worth the time you’ll spend <a id="marker-1012913"></a>on <a id="marker-1012917"></a><a id="marker-1012921"></a>it.</p>

  <h2 class="fm-head" id="heading_id_47"><a id="pgfId-1012423"></a>Summary</h2>

  <ul class="calibre19">
    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-1012435"></a>The theory behind the functioning and analysis of d-way heaps makes heavy use of the basic structures and tools we describe in appendices A to F.</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-1012450"></a>There is a difference between concrete and abstract data structures, where the latter are better served to be used as black boxes, during the design of an application or algorithm using them.</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-1012473"></a>When we move from abstract data structures to their concrete implementations in a programming language, we need to pay attention to those nitty-gritty details that are specific to the language we chose, and make sure we don’t slow down our methods by choosing the wrong implementation.</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-1012488"></a>A heap is conceptually a tree, but it’s implemented using an array for the sake of efficiency.</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-1012501"></a>Changing the branching factor of a heap won’t affect asymptotic running time for its methods, but will still provide a constant factor improvement that matters when we move from pure theory to applications with a massive amount of data to manage.</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-1012513"></a>For several advanced algorithms we make use of priority queues to improve their performance: BFS, Dijkstra, and Huffman codes are just some examples.</p>
    </li>

    <li class="fm-list-numbered1">
      <p class="list"><a class="calibre14" id="pgfId-1012528"></a>When high performance is paramount, and the data structures we use allow parameters (such as <i class="calibre15">branching factor</i><a class="calibre14" id="marker-1012925"></a> for heaps), the only way to find the best parameters for our implementation is profiling our <a class="calibre14" id="marker-1012929"></a><a class="calibre14" id="marker-1012933"></a>code.</p>
    </li>
  </ul>
  <hr class="calibre22"/>

  <p class="fm-footnote"><sup class="footnotenumber">1.</sup> <a id="pgfId-1012948"></a>Application Programming Interface (API<a id="marker-1012969"></a>).</p>

  <p class="fm-footnote"><sup class="footnotenumber">2.</sup> <a id="pgfId-1012974"></a>Often bug-tracking suites associate lower numbers with higher priority. To keep things simple in our discussion, we will instead assume higher numbers mean higher priority.</p>

  <p class="fm-footnote"><sup class="footnotenumber">3.</sup> <a id="pgfId-1012988"></a>With an array implementation, we could find the right position for our item in logarithmic time, using binary search. But then we would need to move all the elements on the right of the insertion point to make room for it, and this requires linear time on average.</p>

  <p class="fm-footnote"><sup class="footnotenumber">4.</sup> <a id="pgfId-1013002"></a>Besides performance, there are other aspects we might need to check, depending on our context. For instance, in a distributed environment, we must make sure our implementation is thread-safe, or we will incur race conditions, the nastiest possible bugs that could afflict our applications.</p>

  <p class="fm-footnote"><sup class="footnotenumber">5.</sup> <a id="pgfId-1013016"></a>You can find an introduction to algorithm analysis and big-O notation in appendix B.</p>

  <p class="fm-footnote"><sup class="footnotenumber">6.</sup> <a id="pgfId-1013030"></a>Whether a problem is really tractable or not for a certain size of the input also depends on the kind of operations performed and on the time they take. But even if each operation takes as little as 1 nanosecond, if the input has 1 million elements, a quadratic algorithm will take more than 16 minutes, while a linearithmic algorithm would require less than 10 milliseconds.</p>

  <p class="fm-footnote"><sup class="footnotenumber">7.</sup> <a id="pgfId-1013046"></a>A leaf is a tree node that doesn’t have any children. An internal node is a node that has at least one child or, equivalently, a node that is not a leaf.</p>

  <p class="fm-footnote"><sup class="footnotenumber">8.</sup> <a id="pgfId-1013060"></a>We use explicit parenthesis for the following expressions. In the rest of the book, we will generally omit redundant parentheses, so that, for instance, we will write <code class="fm-code-in-text1">2*i + 1.</code></p>

  <p class="fm-footnote"><sup class="footnotenumber">9.</sup> <a id="pgfId-1013079"></a>(a<sub class="subscript2">1</sub>, b<sub class="subscript2">1</sub>, c<sub class="subscript2">1</sub>,...) &lt; (a<sub class="subscript2">2</sub>, b<sub class="subscript2">2</sub>, c<sub class="subscript2">2</sub>,...) if and only if a<sub class="subscript2">1</sub> &lt; a<sub class="subscript2">2</sub> or (a<sub class="subscript2">1</sub> == a<sub class="subscript2">2</sub> and (b<sub class="subscript2">1</sub>, c<sub class="subscript2">1</sub>,...) &lt; (b<sub class="subscript2">2</sub>, c<sub class="subscript2">2</sub>,...)).</p>

  <p class="fm-footnote"><sup class="footnotenumber">10.</sup> <a id="pgfId-1013124"></a>The branching factor of a tree is the maximum number of children a node can have. For example, a binary heap, which in turn is a binary tree, has a branching factor of 2. See appendix C for more details.</p>

  <p class="fm-footnote"><sup class="footnotenumber">11.</sup> <a id="pgfId-1013138"></a>As we explain in appendix C, this doesn’t change the asymptotic analysis, because it can be proven that inserting <code class="fm-code-in-text1">n</code> elements in a dynamic array requires at most <code class="fm-code-in-text1">2<sub class="subscript2">n</sub></code> assignments, so each insertion requires an amortized constant time.</p>

  <p class="fm-footnote"><sup class="footnotenumber">12.</sup> <a id="pgfId-1013170"></a>For instance, in Java’s <code class="fm-code-in-text1">PriorityQueue</code><a id="marker-1013194"></a>, a class provided in standard library, you need to remove an element and then insert the new one to perform the same operation. This is far from ideal, especially because the removal of a random element is implemented inefficiently, requiring linear time.</p>

  <p class="fm-footnote"><sup class="footnotenumber">13.</sup> <a id="pgfId-1013199"></a>Using Fibonacci heaps, it could be implemented even in amortized constant time, at least in theory.</p>

  <p class="fm-footnote"><sup class="footnotenumber">14.</sup> <a id="pgfId-1025376"></a>See <span class="fm-hyperlink"><a href="https://github.com/mlarocca/AlgorithmsAndDataStructuresInAction#d-ary-heap">https://github.com/mlarocca/AlgorithmsAndDataStructuresInAction#d-ary-heap</a></span>.</p>

  <p class="fm-footnote"><sup class="footnotenumber">15.</sup> <a id="pgfId-1013228"></a>Usually, though, the greatest concern is to avoid choosing the wrong data structure.</p>

  <p class="fm-footnote"><sup class="footnotenumber">16.</sup> <a id="pgfId-1013244"></a><code class="fm-code-in-text1">n&gt;&gt;k</code> is normally interpreted as “n is much larger than k.”</p>

  <p class="fm-footnote"><sup class="footnotenumber">17.</sup> <a id="pgfId-1013263"></a><code class="fm-code-in-text1">O(log(k))</code> to be precise, but since <code class="fm-code-in-text1">k</code> in this context is a constant (much smaller than, and not depending on <code class="fm-code-in-text1">n</code>), then <code class="fm-code-in-text1">O(log(k))==O(1)</code>.</p>

  <p class="fm-footnote"><sup class="footnotenumber">18.</sup> <a id="pgfId-1013288"></a>Additional challenges can occur if the text is so large that either it can’t be contained in memory, or a map-reduce approach is advisable: we encapsulate all that complexity in the <code class="fm-code-in-text1">ComputeFrequencies</code> method<a id="marker-1046942"></a>.</p>

  <p class="fm-footnote"><sup class="footnotenumber">19.</sup> <a id="pgfId-1013310"></a>Instead of the actual frequency it might be easier, and equivalent for the algorithm, just counting the number of occurrences of each character.</p>

  <p class="fm-footnote"><sup class="footnotenumber">20.</sup> <a id="pgfId-1013324"></a>It’s simply going to be a 1:1 mapping over the characters in the text, with extra attention needed to efficiently construct the bits encoding in output.</p>

  <p class="fm-footnote"><sup class="footnotenumber">21.</sup> <a id="pgfId-1013338"></a>This section includes advanced concepts.</p>

  <p class="fm-footnote"><sup class="footnotenumber">22.</sup> <a id="pgfId-1013354"></a>The Fibonacci heap is an advanced version of priority queue that is implemented with a set of heaps. For a Fibonacci heap, find-minimum, insert, and update priority operations take constant amortized time, <code class="fm-code-in-text1">O(1)</code>, while deleting an element (including the minimum) requires <code class="fm-code-in-text1">O(log n)</code> amortized time, where <code class="fm-code-in-text1">n</code> is the size of the heap. So, in theory, Fibonacci heaps are faster than any other heap, although in practice, being overly complicated, their implementations end up being slower than simple binary heaps.</p>

  <p class="fm-footnote"><sup class="footnotenumber">23.</sup> <a id="pgfId-1013386"></a>See <span class="fm-hyperlink"><a href="http://comjnl.oxfordjournals.org/content/34/5/428">http://comjnl.oxfordjournals.org/content/34/5/428</a></span>.</p>

  <p class="fm-footnote"><sup class="footnotenumber">24.</sup> <a id="pgfId-1013403"></a><code class="fm-code-in-text1">O(n*log(n))</code>, for an input of size n.</p>

  <p class="fm-footnote"><sup class="footnotenumber">25.</sup> <a id="pgfId-1013425"></a>Where D is the branching factor for the d-ary heap under analysis.</p>

  <p class="fm-footnote"><sup class="footnotenumber">26.</sup> <a id="pgfId-1013446"></a>It is, obviously, possible to find a formula for <code class="fm-code-in-text1">f(D)</code>’s minima using calculus, and in particular computing the first and second order derivatives of the function.</p>

  <p class="fm-footnote"><sup class="footnotenumber">27.</sup> <a id="pgfId-1013463"></a>See <span class="fm-hyperlink"><a href="https://github.com/mlarocca/AlgorithmsAndDataStructuresInAction#huffman-compression">https://github.com/mlarocca/AlgorithmsAndDataStructuresInAction#huffman-compression</a></span>.</p>

  <p class="fm-footnote"><sup class="footnotenumber">28.</sup> <a id="pgfId-1032128"></a><span class="fm-hyperlink"><a href="https://github.com/mlarocca/AlgorithmsAndDataStructuresInAction/blob/master/Python/mlarocca/tests/huffman_profile.py">https://github.com/mlarocca/AlgorithmsAndDataStructuresInAction/blob/master/Python/mlarocca/tests/huffman_profile.py</a></span>.</p>

  <p class="fm-footnote"><sup class="footnotenumber">29.</sup> <a id="pgfId-1013479"></a>We used copyright-free novels downloaded from Project Gutenberg, <span class="fm-hyperlink"><a href="http://www.gutenberg.org">http://www.gutenberg.org</a></span> (worth checking out!).</p>

  <p class="fm-footnote"><sup class="footnotenumber">30.</sup> <a id="pgfId-1013497"></a>Disclaimer: There are many possible ways to do this, and possibly better ways too. This is just one of the possible ways. <span class="fm-hyperlink"><a href="https://github.com/mlarocca/AlgorithmsAndDataStructuresInAction/blob/master/Python/mlarocca/notebooks/Huffman_profiling.ipynb">https://github.com/mlarocca/AlgorithmsAndDataStructuresInAction/blob/master/Python/mlarocca/notebooks/Huffman_profiling.ipynb</a></span>.</p>

  <p class="fm-footnote"><sup class="footnotenumber">31.</sup> <a id="pgfId-1032218"></a><span class="fm-hyperlink"><a href="https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.boxplot.html">https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.boxplot.html</a></span>.</p>

  <p class="fm-footnote"><sup class="footnotenumber">32.</sup> <a id="pgfId-1013514"></a>In our Python implementation, the names become respectively _push_down<a id="marker-1013536"></a> and <code class="fm-code-in-text1">_highest_priority_ child</code><a id="marker-1013540"></a>, to follow Python naming conventions.</p>
</body>
</html>
