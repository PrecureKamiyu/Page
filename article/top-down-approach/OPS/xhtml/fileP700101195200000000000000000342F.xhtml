<?xml version="1.0" encoding="utf-8"?><html xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:svg="http://www.w3.org/2000/svg" xmlns:epub="http://www.idpf.org/2007/ops" xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" epub:prefix="index: http://www.index.com/"><head>
<meta name="dcterms.conformsTo" content="PXE Basic 1.0"></meta>
<meta name="generator" content="PXE Tools version 1.39.109"></meta>
<!--Created by pxe.pl for standard version PXE Basic 1.0,data-profile-product=standard by PXE Tools 1.39.109, partial=false-->
<title>9.2 Streaming Stored Video</title><link rel="alternate stylesheet" type="text/css" title="sepia" href="../css/sepia.css"></link><link rel="alternate stylesheet" type="text/css" title="night" href="../css/night.css"></link><link rel="stylesheet" type="text/css" title="day" href="../css/main.css"></link><link rel="stylesheet" type="text/css" title="day" href="../css/print.css"></link>
<script src="js/format_lg_obj.js"></script>
</head><body epub:type="bodymatter">
<section id="P700101195200000000000000000342F" class="level1"><header><h1 class="title" id="P700101195200000000000000000BB31" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB31" epub:type="title"><span class="number">9.2</span> Streaming Stored Video</h1></header>
<p id="P700101195200000000000000000BB32" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB32">For streaming video applications, prerecorded videos are placed on servers, and users send requests to these servers to view the videos on demand. The user may watch the video from beginning to end without interruption, may stop watching the video well before it ends, or interact with the video by pausing or repositioning to a future or past scene. Streaming video systems can be classified into three categories: <span class="keyword" id="P7001011952000000000000000003432" data-uri="M09_KURO4140_07_SE_C09.xhtml#P7001011952000000000000000003432"><b>UDP streaming</b></span>, <span class="keyword" id="P7001011952000000000000000003433" data-uri="M09_KURO4140_07_SE_C09.xhtml#P7001011952000000000000000003433"><b>HTTP streaming</b></span>, and <span class="keyword" id="P7001011952000000000000000003434" data-uri="M09_KURO4140_07_SE_C09.xhtml#P7001011952000000000000000003434"><b>adaptive HTTP streaming</b></span> (see <a class="xref" href="fileP7001011952000000000000000000DC1.xhtml#P7001011952000000000000000000DC1" data-foobar="7"><span class="label">Section</span> <span class="number">2.6</span></a>). Although all three types of systems are used in practice, the majority of today’s systems employ HTTP streaming and adaptive HTTP streaming.</p>
<p id="P700101195200000000000000000BB33" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB33">A common characteristic of all three forms of video streaming is the extensive use of client-side application buffering to mitigate the effects of varying end-to-end delays and varying amounts of available bandwidth between server and client. For streaming video (both stored and live), users generally can tolerate a small several-second initial delay between when the client requests a video and when video playout begins at the client. Consequently, when the video starts to arrive at the client, the client need not immediately begin playout, but can instead build up a reserve of video in an application buffer. Once the client has built up a reserve of several seconds of <span class="pagebreak" title="682" id="P7001011952000000000000000003436" data-uri="M09_KURO4140_07_SE_C09.xhtml#P7001011952000000000000000003436" epub:type="pagebreak" role="doc-pagebreak"></span>buffered-but-not-yet-played video, the client can then begin video playout. There are two important advantages provided by such <span class="keyword" id="P7001011952000000000000000003437" data-uri="M09_KURO4140_07_SE_C09.xhtml#P7001011952000000000000000003437"><b>client buffering</b></span>. First, client-side buffering can absorb variations in server-to-client delay. If a particular piece of video data is delayed, as long as it arrives before the reserve of received-but-not-yet-played video is exhausted, this long delay will not be noticed. Second, if the server-to-client bandwidth briefly drops below the video consumption rate, a user can continue to enjoy continuous playback, again as long as the client application buffer does not become completely drained.</p>
<p id="P700101195200000000000000000BB34" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB34"><a class="xref" href="#P7001011952000000000000000003439" data-foobar="1"><span class="label">Figure</span> <span class="number">9.1</span></a> illustrates client-side buffering. In this simple example, suppose that video is encoded at a fixed bit rate, and thus each video block contains video frames that are to be played out over the same fixed amount of time, Δ. The server transmits the first video block at <i>t</i><sub>0</sub>, the second block at <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="61" altimg-height="18" altimg="../images/ch09math02.png"><m:mrow><m:msub><m:mi>t</m:mi><m:mn>0</m:mn></m:msub><m:mo>+</m:mo><m:mi>Δ</m:mi><m:mo>,</m:mo></m:mrow></m:math></span> the third block at <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="70" altimg-height="18" altimg="../images/ch09math03.png"><m:mrow><m:msub><m:mi>t</m:mi><m:mn>0</m:mn></m:msub><m:mo>+</m:mo><m:mn>2</m:mn><m:mi>Δ</m:mi><m:mo>,</m:mo></m:mrow></m:math></span> and so on. Once the client begins playout, each block should be played out Δ time units after the previous block in order to reproduce the timing of the original recorded video. Because of the variable end-to-end network delays, different video blocks experience different delays. The first video block arrives at the client at <i>t</i><sub>1</sub> and the second block arrives at <i>t</i><sub>2</sub>. The network delay for the <i>i</i>th block is the horizontal distance between the time the block was transmitted by the server and the time it is received at the client; note that the network delay varies from one video block to another. In this example, if the client were to begin playout as soon as the first block arrived at <i>t</i><sub>1</sub>, then the second block would not have arrived in time to be played out at out at <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="56" altimg-height="18" altimg="../images/ch09math04.png"><m:mrow><m:msub><m:mi>t</m:mi><m:mn>1</m:mn></m:msub><m:mo>+</m:mo><m:mi>Δ</m:mi></m:mrow></m:math></span>. In this case, video playout would either have to stall (waiting for block 2 to arrive) or block 2 could be skipped—both resulting in undesirable playout impairments. Instead, if the client were to delay the start of playout until <i>t</i><sub>3</sub>, when blocks 1 through 6 have all arrived, periodic playout can proceed with <i>all</i> blocks having been received before their playout time.</p>
<figure id="P7001011952000000000000000003439" class="figure" data-uri="M09_KURO4140_07_SE_C09.xhtml#P7001011952000000000000000003439">
<img alt="Illustration of client playout delay in video streaming." height="323" width="671" aria-describedby="P700101195200000000000000000343D" id="P700101195200000000000000000BB35" data-uri="P7001011952000000000000000005632" src="../images/4055109001.png"></img>
<figcaption id="P700101195200000000000000000BB36" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB36"><header><h1 class="title" id="P700101195200000000000000000BB37" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB37" epub:type="title"><span class="label">Figure </span><span class="number">9.1</span> Client playout delay in video streaming</h1></header>

</figcaption>
</figure><div class="longdesc" id="P700101195200000000000000000343D" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000343D" aria-hidden="false"><a class="xref" aria-hidden="false" href="../longalt/la_4055109001.xhtml#la_4055109001"><span class="label">Description</span></a></div>
<section id="P7001011952000000000000000003442" data-uri="M09_KURO4140_07_SE_C09.xhtml#P7001011952000000000000000003442" class="level2"><header><h1 class="title" id="P700101195200000000000000000BB3C" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB3C" epub:type="title"><span class="pagebreak" title="683" id="P7001011952000000000000000003444" data-uri="M09_KURO4140_07_SE_C09.xhtml#P7001011952000000000000000003444" epub:type="pagebreak" role="doc-pagebreak"></span><span class="number">9.2.1</span> UDP Streaming</h1></header>
<p id="P700101195200000000000000000BB3D" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB3D">We only briefly discuss UDP streaming here, referring the reader to more in-depth discussions of the protocols behind these systems where appropriate. With UDP streaming, the server transmits video at a rate that matches the client’s video consumption rate by clocking out the video chunks over UDP at a steady rate. For example, if the video consumption rate is 2 Mbps and each UDP packet carries 8,000 bits of video, then the server would transmit one UDP packet into its socket every <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="252" altimg-height="17" altimg="../images/ch09math05.png"><m:mrow><m:mrow><m:mo>(</m:mo><m:mrow><m:mn>8000</m:mn><m:mtext> bits</m:mtext></m:mrow><m:mo>)</m:mo></m:mrow><m:mo>/</m:mo><m:mrow><m:mo>(</m:mo><m:mrow><m:mn>2</m:mn><m:mtext> Mbps</m:mtext></m:mrow><m:mo>)</m:mo></m:mrow><m:mo>=</m:mo><m:mn>4</m:mn><m:mtext> msec</m:mtext></m:mrow></m:math></span>. As we learned in <a class="xref" href="fileP70010119520000000000000000010EC.xhtml#P70010119520000000000000000010EC" data-foobar="7"><span class="label">Chapter</span> <span class="number">3</span></a>, because UDP does not employ a congestion-control mechanism, the server can push packets into the network at the consumption rate of the video without the rate-control restrictions of TCP. UDP streaming typically uses a small client-side buffer, big enough to hold less than a second of video.</p>
<p id="P700101195200000000000000000BB3E" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB3E">Before passing the video chunks to UDP, the server will encapsulate the video chunks within transport packets specially designed for transporting audio and video, using the Real-Time Transport Protocol (RTP) <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003B83" data-foobar="7">[RFC 3550]</a> or a similar (possibly proprietary) scheme. We delay our coverage of RTP until <a class="xref" href="fileP7001011952000000000000000003477.xhtml#P7001011952000000000000000003477" data-foobar="7"><span class="label">Section</span> <span class="number">9.3</span></a>, where we discuss RTP in the context of conversational voice and video systems.</p>
<p id="P700101195200000000000000000BB3F" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB3F">Another distinguishing property of UDP streaming is that in addition to the server-to-client video stream, the client and server also maintain, in parallel, a separate control connection over which the client sends commands regarding session state changes (such as pause, resume, reposition, and so on). The Real-Time Streaming Protocol (RTSP) <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003B31" data-foobar="7">[RFC 2326]</a>, explained in some detail in the Web site for this textbook, is a popular open protocol for such a control connection.</p>
<p id="P700101195200000000000000000BB40" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB40">Although UDP streaming has been employed in many open-source systems and proprietary products, it suffers from three significant drawbacks. First, due to the unpredictable and varying amount of available bandwidth between server and client, constant-rate UDP streaming can fail to provide continuous playout. For example, consider the scenario where the video consumption rate is 1 Mbps and the server-to-client available bandwidth is usually more than 1 Mbps, but every few minutes the available bandwidth drops below 1 Mbps for several seconds. In such a scenario, a UDP streaming system that transmits video at a constant rate of 1 Mbps over RTP/UDP would likely provide a poor user experience, with freezing or skipped frames soon after the available bandwidth falls below 1 Mbps. The second drawback of UDP streaming is that it requires a media control server, such as an RTSP server, to process client-to-server interactivity requests and to track client state (e.g., the client’s playout point in the video, whether the video is being paused or played, and so on) for <i>each</i> ongoing client session. This increases the overall cost and complexity of deploying a large-scale video-on-demand system. The third drawback is that many firewalls are configured to block UDP traffic, preventing the users behind these firewalls from receiving UDP video.</p>
</section>
<section id="P7001011952000000000000000003449" data-uri="M09_KURO4140_07_SE_C09.xhtml#P7001011952000000000000000003449" class="level2"><header><h1 class="title" id="P700101195200000000000000000BB41" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB41" epub:type="title"><span class="pagebreak" title="684" id="P700101195200000000000000000344B" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000344B" epub:type="pagebreak" role="doc-pagebreak"></span><span class="number">9.2.2</span> HTTP Streaming</h1></header>
<p id="P700101195200000000000000000BB42" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB42">In HTTP streaming, the video is simply stored in an HTTP server as an ordinary file with a specific URL. When a user wants to see the video, the client establishes a TCP connection with the server and issues an HTTP GET request for that URL. The server then sends the video file, within an HTTP response message, as quickly as possible, that is, as quickly as TCP congestion control and flow control will allow. On the client side, the bytes are collected in a client application buffer. Once the number of bytes in this buffer exceeds a predetermined threshold, the client application begins playback—specifically, it periodically grabs video frames from the client application buffer, decompresses the frames, and displays them on the user’s screen.</p>
<p id="P700101195200000000000000000BB43" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB43">We learned in <a class="xref" href="fileP70010119520000000000000000010EC.xhtml#P70010119520000000000000000010EC" data-foobar="7"><span class="label">Chapter</span> <span class="number">3</span></a> that when transferring a file over TCP, the server-to-client transmission rate can vary significantly due to TCP’s congestion control mechanism. In particular, it is not uncommon for the transmission rate to vary in a “saw-tooth” manner associated with TCP congestion control. Furthermore, packets can also be significantly delayed due to TCP’s retransmission mechanism. Because of these characteristics of TCP, the conventional wisdom in the 1990s was that video streaming would never work well over TCP. Over time, however, designers of streaming video systems learned that TCP’s congestion control and reliable-data transfer mechanisms do not necessarily preclude continuous playout when client buffering and prefetching (discussed in the next section) are used.</p>
<p id="P700101195200000000000000000BB44" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB44">The use of HTTP over TCP also allows the video to traverse firewalls and NATs more easily (which are often configured to block most UDP traffic but to allow most HTTP traffic). Streaming over HTTP also obviates the need for a media control server, such as an RTSP server, reducing the cost of a large-scale deployment over the Internet. Due to all of these advantages, most video streaming applications today—including YouTube and Netflix—use HTTP streaming (over TCP) as its underlying streaming protocol.</p>
<section id="P700101195200000000000000000344F" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000344F" class="level3"><header><h1 class="title" id="P700101195200000000000000000BB45" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB45" epub:type="title">Prefetching Video</h1></header>
<p id="P700101195200000000000000000BB46" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB46">As we just learned, client-side buffering can be used to mitigate the effects of varying end-to-end delays and varying available bandwidth. In our earlier example in <a class="xref" href="#P7001011952000000000000000003439" data-foobar="1"><span class="label">Figure</span> <span class="number">9.1</span></a>, the server transmits video at the rate at which the video is to be played out. However, for streaming <i>stored</i> video, the client can attempt to download the video at a rate <i>higher</i> than the consumption rate, thereby <span class="keyword" id="P7001011952000000000000000003452" data-uri="M09_KURO4140_07_SE_C09.xhtml#P7001011952000000000000000003452"><b>prefetching</b></span> video frames that are to be consumed in the future. This prefetched video is naturally stored in the client application buffer. Such prefetching occurs naturally with TCP streaming, since TCP’s congestion avoidance mechanism will attempt to use all of the available bandwidth between server and client.</p>
<p id="P700101195200000000000000000BB47" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB47">To gain some insight into prefetching, let’s take a look at a simple example. Suppose the video consumption rate is 1 Mbps but the network is capable of delivering the video from server to client at a constant rate of 1.5 Mbps. Then the client will <span class="pagebreak" title="685" id="P7001011952000000000000000003454" data-uri="M09_KURO4140_07_SE_C09.xhtml#P7001011952000000000000000003454" epub:type="pagebreak" role="doc-pagebreak"></span>not only be able to play out the video with a very small playout delay, but will also be able to increase the amount of buffered video data by 500 Kbits every second. In this manner, if in the future the client receives data at a rate of less than 1 Mbps for a brief period of time, the client will be able to continue to provide continuous playback due to the reserve in its buffer. <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003C6F" data-foobar="7">[Wang 2008]</a> shows that when the average TCP throughput is roughly twice the media bit rate, streaming over TCP results in minimal starvation and low buffering delays.</p>
</section>
<section id="P7001011952000000000000000003455" data-uri="M09_KURO4140_07_SE_C09.xhtml#P7001011952000000000000000003455" class="level3"><header><h1 class="title" id="P700101195200000000000000000BB48" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB48" epub:type="title">Client Application Buffer and TCP Buffers</h1></header>
<p id="P700101195200000000000000000BB49" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB49"><a class="xref" href="#P7001011952000000000000000003458" data-foobar="1"><span class="label">Figure</span> <span class="number">9.2</span></a> illustrates the interaction between client and server for HTTP streaming. At the server side, the portion of the video file in white has already been sent into the server’s socket, while the darkened portion is what remains to be sent. After “passing through the socket door,” the bytes are placed in the TCP send buffer before being transmitted into the Internet, as described in <a class="xref" href="fileP70010119520000000000000000010EC.xhtml#P70010119520000000000000000010EC" data-foobar="7"><span class="label">Chapter</span> <span class="number">3</span></a>. In <a class="xref" href="#P7001011952000000000000000003458" data-foobar="1"><span class="label">Figure</span> <span class="number">9.2</span></a>, because the TCP send buffer at the server side is shown to be full, the server is momentarily prevented from sending more bytes from the video file into the socket. On the client side, the client application (media player) reads bytes from the TCP receive buffer (through its client socket) and places the bytes into the client application buffer. At the same time, the client application periodically grabs video frames from the client application buffer, decompresses the frames, and displays them on the user’s screen. Note that if the client application buffer is larger than the video file, then the whole process of moving bytes from the server’s storage to the client’s application buffer is equivalent to an ordinary file download over HTTP—the client simply pulls the video off the server as fast as TCP will allow!</p>
<figure id="P7001011952000000000000000003458" class="figure" data-uri="M09_KURO4140_07_SE_C09.xhtml#P7001011952000000000000000003458">
<img alt="Illustration of streaming stored video over HTTP/TCP." height="352" width="813" aria-describedby="P700101195200000000000000000345C" id="P700101195200000000000000000BB4A" data-uri="P7001011952000000000000000005633" src="../images/4055109002.png"></img>
<figcaption id="P700101195200000000000000000BB4B" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB4B"><header><h1 class="title" id="P700101195200000000000000000BB4C" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB4C" epub:type="title"><span class="label">Figure </span><span class="number">9.2</span> Streaming stored video over HTTP/TCP</h1></header>

</figcaption>
</figure><div class="longdesc" id="P700101195200000000000000000345C" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000345C" aria-hidden="false"><a class="xref" aria-hidden="false" href="../longalt/la_4055109002.xhtml#la_4055109002"><span class="label">Description</span></a></div>
<p id="P700101195200000000000000000BB4E" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB4E"><span class="pagebreak" title="686" id="P700101195200000000000000000345F" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000345F" epub:type="pagebreak" role="doc-pagebreak"></span>Consider now what happens when the user pauses the video during the streaming process. During the pause period, bits are not removed from the client application buffer, even though bits continue to enter the buffer from the server. If the client application buffer is finite, it may eventually become full, which will cause “back pressure” all the way back to the server. Specifically, once the client application buffer becomes full, bytes can no longer be removed from the client TCP receive buffer, so it too becomes full. Once the client receive TCP buffer becomes full, bytes can no longer be removed from the server TCP send buffer, so it also becomes full. Once the TCP becomes full, the server cannot send any more bytes into the socket. Thus, if the user pauses the video, the server may be forced to stop transmitting, in which case the server will be blocked until the user resumes the video.</p>
<p id="P700101195200000000000000000BB4F" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB4F">In fact, even during regular playback (that is, without pausing), if the client application buffer becomes full, back pressure will cause the TCP buffers to become full, which will force the server to reduce its rate. To determine the resulting rate, note that when the client application removes <i>f</i> bits, it creates room for <i>f</i> bits in the client application buffer, which in turn allows the server to send <i>f</i> additional bits. Thus, the server send rate can be no higher than the video consumption rate at the client. Therefore, <i>a full client application buffer indirectly imposes a limit on the rate that video can be sent from server to client when streaming over HTTP.</i></p>
</section>
<section id="P7001011952000000000000000003461" data-uri="M09_KURO4140_07_SE_C09.xhtml#P7001011952000000000000000003461" class="level3"><header><h1 class="title" id="P700101195200000000000000000BB50" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB50" epub:type="title">Analysis of Video Streaming</h1></header>
<p id="P700101195200000000000000000BB51" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB51">Some simple modeling will provide more insight into initial playout delay and freezing due to application buffer depletion. As shown in <a class="xref" href="#P7001011952000000000000000003464" data-foobar="1"><span class="label">Figure</span> <span class="number">9.3</span></a>, let <i>B</i> denote the size</p>
<figure id="P7001011952000000000000000003464" class="figure" data-uri="M09_KURO4140_07_SE_C09.xhtml#P7001011952000000000000000003464">
<img alt="Analysis of client-side buffering for video streaming." height="387" width="671" aria-describedby="P7001011952000000000000000003468" id="P700101195200000000000000000BB52" data-uri="P7001011952000000000000000005634" src="../images/4055109003.png"></img>
<figcaption id="P700101195200000000000000000BB53" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB53"><header><h1 class="title" id="P700101195200000000000000000BB54" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB54" epub:type="title"><span class="label">Figure </span><span class="number">9.3</span> Analysis of client-side buffering for video streaming</h1></header>

</figcaption>
</figure><div class="longdesc" id="P7001011952000000000000000003468" data-uri="M09_KURO4140_07_SE_C09.xhtml#P7001011952000000000000000003468" aria-hidden="false"><a class="xref" aria-hidden="false" href="../longalt/la_4055109003.xhtml#la_4055109003"><span class="label">Description</span></a></div>
<p class="continued" id="P700101195200000000000000000BB56" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB56"><span class="pagebreak" title="687" id="P700101195200000000000000000346B" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000346B" epub:type="pagebreak" role="doc-pagebreak"></span>(in bits) of the client’s application buffer, and let <i>Q</i> denote the number of bits that must be buffered before the client application begins playout. (Of course, <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="60" altimg-height="17" altimg="../images/ch09math06.png"><m:mrow><m:mi>Q</m:mi><m:mo>&lt;</m:mo><m:mi>B</m:mi><m:mo>.</m:mo></m:mrow></m:math></span>) Let <i>r</i> denote the video consumption rate—the rate at which the client draws bits out of the client application buffer during playback. So, for example, if the video’s frame rate is 30 frames/sec, and each (compressed) frame is 100,000 bits, then <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="95" altimg-height="17" altimg="../images/ch09math07.png"><m:mrow><m:mi>r</m:mi><m:mo>=</m:mo><m:mn>3</m:mn><m:mtext> Mbps</m:mtext></m:mrow></m:math></span>. To see the forest through the trees, we’ll ignore TCP’s send and receive buffers.</p>
<p id="P700101195200000000000000000BB57" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB57">Let’s assume that the server sends bits at a constant rate <i>x</i> whenever the client buffer is not full. (This is a gross simplification, since TCP’s send rate varies due to congestion control; we’ll examine more realistic time-dependent rates <i>x</i>(<i>t</i>) in the problems at the end of this chapter.) Suppose at time <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="50" altimg-height="16" altimg="../images/ch09math08.png"><m:mrow><m:mi>t</m:mi><m:mo>=</m:mo><m:mn>0</m:mn><m:mo>,</m:mo></m:mrow></m:math></span> the application buffer is empty and video begins arriving to the client application buffer. We now ask at what time <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="48" altimg-height="18" altimg="../images/ch09math09.png"><m:mrow><m:mi>t</m:mi><m:mo>=</m:mo><m:msub><m:mi>t</m:mi><m:mi>p</m:mi></m:msub></m:mrow></m:math></span> does playout begin? And while we are at it, at what time <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="47" altimg-height="18" altimg="../images/ch09math10.png"><m:mrow><m:mi>t</m:mi><m:mo>=</m:mo><m:msub><m:mi>t</m:mi><m:mi>f</m:mi></m:msub></m:mrow></m:math></span> does the client application buffer become full?</p>
<p id="P700101195200000000000000000BB58" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB58">First, let’s determine <i>t<sub>p</sub></i>, the time when <i>Q</i> bits have entered the application buffer and playout begins. Recall that bits arrive to the client application buffer at rate <i>x</i> and <i>no</i> bits are removed from this buffer before playout begins. Thus, the amount of time required to build up <i>Q</i> bits (the initial buffering delay) is <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="69" altimg-height="20" altimg="../images/ch09math11.png"><m:mrow><m:msub><m:mi>t</m:mi><m:mi>p</m:mi></m:msub><m:mo>=</m:mo><m:mrow><m:mi>Q</m:mi><m:mo>/</m:mo><m:mi>x</m:mi></m:mrow></m:mrow></m:math></span>.</p>
<p id="P700101195200000000000000000BB59" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB59">Now let’s determine <i>t<sub>f</sub></i>, the point in time when the client application buffer becomes full. We first observe that if <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="50" altimg-height="13" altimg="../images/ch09math12.png"><m:mrow><m:mi>x</m:mi><m:mo>&lt;</m:mo><m:mi>r</m:mi></m:mrow></m:math></span> (that is, if the server send rate is less than the video consumption rate), then the client buffer will never become full! Indeed, starting at time <i>t<sub>p</sub></i>, the buffer will be depleted at rate <i>r</i> and will only be filled at rate <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="49" altimg-height="12" altimg="../images/ch09math13.png"><m:mrow><m:mi>x</m:mi><m:mo>&lt;</m:mo><m:mi>r</m:mi></m:mrow></m:math></span>. Eventually the client buffer will empty out entirely, at which time the video will freeze on the screen while the client buffer waits another <i>t<sub>p</sub></i> seconds to build up <i>Q</i> bits of video. <i>Thus, when the available rate in the network is less than the video rate, playout will alternate between periods of continuous playout and periods of freezing.</i> In a homework problem, you will be asked to determine the length of each continuous playout and freezing period as a function of <i>Q</i>, <i>r</i>, and <i>x</i>. Now let’s determine <i>t<sub>f</sub></i> for when <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="51" altimg-height="12" altimg="../images/ch09math14.png"><m:mrow><m:mi>x</m:mi><m:mo>&gt;</m:mo><m:mi>r</m:mi><m:mo>.</m:mo></m:mrow></m:math></span> In this case, starting at time <i>t<sub>p</sub></i>, the buffer increases from <i>Q</i> to <i>B</i> at rate <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="47" altimg-height="9" altimg="../images/ch09math15.png"><m:mrow><m:mi>x</m:mi><m:mo>−</m:mo><m:mi>r</m:mi></m:mrow></m:math></span> since bits are being depleted at rate <i>r</i> but are arriving at rate <i>x</i>, as shown in <a class="xref" href="#P7001011952000000000000000003464" data-foobar="1"><span class="label">Figure</span> <span class="number">9.3</span></a>. Given these hints, you will be asked in a homework problem to determine <i>t<sub>f</sub></i>, the time the client buffer becomes full. Note that <i>when the available rate in the network is more than the video rate, after the initial buffering delay, the user will enjoy continuous playout until the video ends.</i></p>
</section>
<section id="P700101195200000000000000000346F" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000346F" class="level3"><header><h1 class="title" id="P700101195200000000000000000BB5A" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB5A" epub:type="title">Early Termination and Repositioning the Video</h1></header>
<p id="P700101195200000000000000000BB5B" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB5B">HTTP streaming systems often make use of the <span class="keyword" id="P7001011952000000000000000003472" data-uri="M09_KURO4140_07_SE_C09.xhtml#P7001011952000000000000000003472"><b>HTTP byte-range header</b></span> in the HTTP GET request message, which specifies the specific range of bytes the client currently wants to retrieve from the desired video. This is particularly useful when the user wants to reposition (that is, jump) to a future point in time in the video. When the user repositions to a new position, the client sends a new HTTP request, indicating with the byte-range header from which byte in the file should the server send data. When the server receives the new HTTP request, it can forget about any earlier request and instead send bytes beginning with the byte indicated in the byte-range request.</p>
<p id="P700101195200000000000000000BB5C" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB5C"><span class="pagebreak" title="688" id="P7001011952000000000000000003474" data-uri="M09_KURO4140_07_SE_C09.xhtml#P7001011952000000000000000003474" epub:type="pagebreak" role="doc-pagebreak"></span>While we are on the subject of repositioning, we briefly mention that when a user repositions to a future point in the video or terminates the video early, some prefetched-but-not-yet-viewed data transmitted by the server will go unwatched—a waste of network bandwidth and server resources. For example, suppose that the client buffer is full with <i>B</i> bits at some time <i>t</i><sub>0</sub> into the video, and at this time the user repositions to some instant <span class="inlineequation"><m:math display="inline" alttext="" data-uri="" altimg-width="101" altimg-height="17" altimg="../images/ch09math16.png"><m:mrow><m:mi>t</m:mi><m:mo>&gt;</m:mo><m:msub><m:mi>t</m:mi><m:mn>0</m:mn></m:msub><m:mo>+</m:mo><m:mi>B</m:mi><m:mo>/</m:mo><m:mi>r</m:mi></m:mrow></m:math></span> into the video, and then watches the video to completion from that point on. In this case, all <i>B</i> bits in the buffer will be unwatched and the bandwidth and server resources that were used to transmit those <i>B</i> bits have been completely wasted. There is significant wasted bandwidth in the Internet due to early termination, which can be quite costly, particularly for wireless links <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P700101195200000000000000000398D" data-foobar="7">[Ihm 2011]</a>. For this reason, many streaming systems use only a moderate-size client application buffer, or will limit the amount of prefetched video using the byte-range header in HTTP requests <a class="biblioref" href="fileP70010119520000000000000000037E0.xhtml#P7001011952000000000000000003AD2" data-foobar="7">[Rao 2011]</a>.</p>
<p id="P700101195200000000000000000BB5D" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB5D">Repositioning and early termination are analogous to cooking a large meal, eating only a portion of it, and throwing the rest away, thereby wasting food. So the next time your parents criticize you for wasting food by not eating all your dinner, you can quickly retort by saying they are wasting bandwidth and server resources when they reposition while watching movies over the Internet! But, of course, two wrongs do not make a right—both food and bandwidth are not to be wasted!</p>
<p id="P700101195200000000000000000BB5E" data-uri="M09_KURO4140_07_SE_C09.xhtml#P700101195200000000000000000BB5E">In <a class="xref" href="#P7001011952000000000000000003442" data-foobar="1"><span class="label">Sections</span> <span class="number">9.2.1</span></a> and <a class="xref" href="#P7001011952000000000000000003449" data-foobar="1"><span class="number">9.2.2</span></a>, we covered UDP streaming and HTTP streaming, respectively. A third type of streaming is Dynamic Adaptive Streaming over HTTP (DASH), which uses multiple versions of the video, each compressed at a different rate. DASH is discussed in detail in <a class="xref" href="fileP7001011952000000000000000000DC1.xhtml#P7001011952000000000000000000DCB" data-foobar="7"><span class="label">Section</span> <span class="number">2.6.2</span></a>. CDNs are often used to distribute stored and live video. CDNs are discussed in detail in <a class="xref" href="fileP7001011952000000000000000000DC1.xhtml#P7001011952000000000000000000DD5" data-foobar="7"><span class="label">Section</span> <span class="number">2.6.3</span></a>.</p>
</section>
</section>
</section></body></html>