<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>22.7  Query Optimization for Parallel Execution</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part405.htm">&lt; 上一个</a><span> | </span><a href="../database.html">内容</a><span> | </span><a href="part407.htm">下一个 &gt;</a></p><p class="s65" style="padding-top: 8pt;padding-left: 40pt;text-indent: 0pt;text-align: left;">22.7  <span style=" color: #00AEEF;">Query Optimization for Parallel Execution</span></p><p style="padding-top: 12pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">Query optimizers for parallel query evaluation are more complicated than query op- timizers for sequential query evaluation. First, the space of plan alternatives can be much larger than that for sequential plans. In particular, in a parallel setting, we need to take into account the diﬀerent possible ways of partitioning the inputs and interme- diate results, since diﬀerent partitioning schemes can lead to diﬀerent query execution costs, which is not an issue for a sequential plan.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Second, the cost models are more complicated, since the cost of partitioning must be taken into account, and issues such as skew and resource contention must be ad- dressed.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 88pt;text-indent: 0pt;text-align: left;">22.7.1 Parallel Query Plan Space</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">As we have seen in Section 15.1, a sequential query plan can be expressed as an alge- braic expression tree, where each node is a physical operator, such as a sort operator, a hash join operator, a merge-join operator, etc. Such a plan may be further annotated with instructions on what operations are to be pipelined and what intermediate results are to be materialized, as we saw in Section 15.7.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 42pt;text-indent: 0pt;text-align: center;">In addition to the above, a parallel query plan must specify</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s39" style="padding-left: 139pt;text-indent: -16pt;text-align: justify;">• <span class="s40">How to parallelize each operation, including deciding what algorithm to use, and how to partition the inputs and intermediate results. Exchange operators can be used to partition inputs as well as intermediate results and ﬁnal results.</span></p><p class="s39" style="padding-top: 4pt;padding-left: 123pt;text-indent: 0pt;text-align: justify;">• <span class="s40">How the plan is to be </span><span class="s63">scheduled</span><span class="p">; speciﬁcally:</span></p><p class="s50" style="padding-top: 7pt;padding-left: 145pt;text-indent: 0pt;text-align: left;">° <span class="s51">How many nodes to use for each operation.</span></p><p class="s50" style="padding-top: 2pt;padding-left: 145pt;text-indent: 0pt;text-align: left;">° <span class="s51">What operations to pipeline within the same node, or across diﬀerent nodes.</span></p><p class="s50" style="padding-top: 2pt;padding-left: 145pt;text-indent: 0pt;text-align: left;">° <span class="s51">What operations to execute sequentially, one after the other.</span></p><p class="s50" style="padding-top: 2pt;padding-left: 145pt;text-indent: 0pt;text-align: left;">° <span class="s51">What operations to execute independently in parallel.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s149" style="padding-left: 119pt;text-indent: 17pt;line-height: 60%;text-align: justify;"><span class="p">As an example of the partitioning decision, a join </span><span class="s13">r </span><span class="s86">⋈</span>r<span class="s167">.</span>A<span class="s136">=</span>s<span class="s167">.</span>A<span class="s136">∧</span>r<span class="s167">.</span>B<span class="s136">=</span>s<span class="s167">.</span>B <span class="s168">s </span><span class="p">can be paral- lelized by partitioning </span><span class="s13">r </span><span class="p">and </span><span class="s13">s </span><span class="p">on the attributes </span><span class="s13">r</span><span class="s83">.</span><span class="s13">A </span><span class="p">and </span><span class="s13">s</span><span class="s83">.</span><span class="s13">A </span><span class="p">alone, or on the attributes</span></p><p class="s13" style="padding-left: 119pt;text-indent: 0pt;line-height: 13pt;text-align: justify;">r<span class="s83">.</span>B <span class="p">and </span>s<span class="s83">.</span>B <span class="p">alone, or on (</span>r<span class="s83">.</span>A<span class="p">, </span>r<span class="s83">.</span>B<span class="p">) and (</span>s<span class="s83">.</span>A<span class="p">, </span>s<span class="s83">.</span>B<span class="p">). The last option is likely to be the best</span></p><p style="padding-left: 119pt;text-indent: 0pt;line-height: 9pt;text-align: justify;">if we consider only this join, since it minimizes the chances of skew which can arise if</p><p class="s13" style="padding-left: 119pt;text-indent: 0pt;line-height: 16pt;text-align: justify;"><span class="p">the cardinalities of </span>r<span class="s83">.</span>A<span class="p">, </span>r<span class="s83">.</span>B<span class="p">, </span>s<span class="s83">.</span>A <span class="p">or </span>s<span class="s83">.</span>B <span class="p">are low.</span></p><p class="s13" style="padding-left: 119pt;text-indent: 17pt;line-height: 60%;text-align: justify;"><span class="p">But consider now the query </span><span class="s149">r</span><span class="s167">.</span><span class="s149">A</span><span class="s15">γ</span><b>sum</b><span class="s98">(</span><span class="s123">s</span><span class="s124">.</span><span class="s123">C</span><span class="s98">)</span><span class="p">(</span>r <span class="s86">⋈</span><span class="s149">r</span><span class="s167">.</span><span class="s149">A</span><span class="s136">=</span><span class="s149">s</span><span class="s167">.</span><span class="s149">A</span><span class="s136">∧</span><span class="s149">r</span><span class="s167">.</span><span class="s149">B</span><span class="s136">=</span><span class="s149">s</span><span class="s167">.</span><span class="s149">B </span><span class="s168">s</span><span class="p">). If we perform the join by partitioning on (</span>r<span class="s83">.</span>A<span class="p">, </span>r<span class="s83">.</span>B<span class="p">) (and (</span>s<span class="s83">.</span>A<span class="p">, </span>s<span class="s83">.</span>B<span class="p">)), we would then need to repartition the join result by </span>r<span class="s83">.</span>A <span class="p">to compute the aggregate. On the other hand, if we performed the join by partitioning on </span>r <span class="p">and </span>s <span class="p">on </span>r<span class="s83">.</span>A <span class="p">and </span>s<span class="s83">.</span>A <span class="p">respectively, both the join and the aggregate</span></p><p class="s13" style="padding-left: 119pt;text-indent: 0pt;line-height: 76%;text-align: justify;"><span class="p">can be computed without any repartitioning, which could reduce the cost. This option is particularly likely to be a good option if </span>r<span class="s83">.</span>A <span class="p">and </span>s<span class="s83">.</span>A <span class="p">have high cardinality and few duplicates, since the chance of skew is less in this case.</span></p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Thus, the optimizer has to consider a larger space of alternatives, taking partition- ing into account. References with more details about how to implement query optimiza- tion for parallel query processing systems, taking partitioning alternatives into account, may be found in the Further Reading section at the end of the chapter.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">22.7.2 Cost of Parallel Query Evaluation</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">The cost of a sequential query plan is typically estimated based on the total resource consumption of the plan, adding up the <span class="s44">CPU </span>and <span class="s44">I/O </span>costs of the operators in a query plan. The <i>resource consumption </i>cost model can also be used in a parallel system, addi- tionally taking into account the network cost, and adding it along with the other costs. As discussed in Section 15.2, even in a sequential system, the resource consumption cost model does not guarantee minimization of the execution time of an individual query. There are other cost models that are better at modeling the time to complete a query; however, the resource consumption cost model has the beneﬁt of reducing the cost of query optimization, and is thus widely used. We return to the issue of other cost models later in the section.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 17pt;text-align: justify;">We now study how the cost of a parallel query plan can be estimated based on the resource consumption model. If a query plan is data parallel, then each operation, other than the exchange operation, runs locally; the cost of such operations can be esti- mated using techniques we have seen earlier in Chapter 15, if we assume that the input relations are uniformly partitioned across <i>n </i>nodes, with each node receiving 1<span class="s15">∕</span><i>n</i>th of the overall input.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The cost of the exchange operation can be estimated based on the network topol- ogy, the amount of data transferred, and the network bandwidth; as before it is assumed that each node is equally loaded during the exchange operation. The cost of a query plan under the <i>resource-consumption </i>model can then be found by adding up the costs of the individual operations.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">However, in a parallel system, two plans with the same resource consumption may have signiﬁcantly diﬀerent time to completion. A <span class="s63">response-time cost model </span>is a cost model that attempts to better estimate the time to completion of a query. If a particular operation is able to perform <span class="s44">I/O </span>operations in parallel with <span class="s44">CPU </span>execution, the response time would be better modeled as <i>max</i>(<span class="s44">CPU </span>cost, <span class="s44">I/O </span>cost), rather than the resource consumption cost model of (<span class="s44">CPU </span>cost <span class="s15">+ </span><span class="s42">I/O </span><span class="s43">cost). Similarly, if two operations </span><i>o</i><span class="s98">1</span> and <i>o</i><span class="s130">2 </span><span class="s94">are in a pipeline on a single node, and their </span><span class="s189">CPU </span><span class="s94">and </span><span class="s189">I/O </span><span class="s94">costs are </span><i>c</i><span class="s130">1</span><span class="s94">, </span><i>io</i><span class="s130">1 </span><span class="s94">and </span><i>c</i><span class="s130">2</span><span class="s94">, </span><i>io</i><span class="s130">2</span></p><p class="s13" style="padding-left: 88pt;text-indent: 0pt;line-height: 77%;text-align: left;"><span class="p">respectively, then their response time cost would be </span>max<span class="p">(</span>c<span class="s130">1 </span><span class="s15">+ </span>c<span class="s130">2</span><span class="s94">, </span>io<span class="s130">1 </span><span class="s15">+ </span>io<span class="s130">2</span><span class="s94">). Similarly,</span></p><p style="padding-left: 88pt;text-indent: 0pt;line-height: 12pt;text-align: left;">if operations <i>o</i><span class="s98">1</span> and <i>o</i><span class="s98">2</span> are executed sequentially, then their response time cost would</p><p class="s13" style="padding-left: 88pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="p">be </span>max<span class="p">(</span>c<span class="s93">1</span><span class="s94">, </span>io<span class="s93">1</span><span class="s94">) </span><span class="s15">+ </span>max<span class="p">(</span>c<span class="s93">2</span><span class="s94">, </span>io<span class="s93">2</span><span class="s94">).</span></p><p style="padding-left: 106pt;text-indent: 0pt;line-height: 12pt;text-align: left;">When executing operations in parallel across multiple nodes, the response time</p><p style="padding-left: 88pt;text-indent: 0pt;text-align: left;">cost model would have to take into account:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s39" style="padding-left: 91pt;text-indent: 0pt;text-align: justify;">• <span class="s46">Start-up costs </span><span class="p">for initiating an operation at multiple nodes.</span></p><p class="s39" style="padding-top: 3pt;padding-left: 107pt;text-indent: -16pt;text-align: justify;">• <span class="s46">Skew </span><span class="p">in the distribution of work among the nodes, with some nodes getting a larger number of tuples than others, and thus taking longer to complete. It is the time to completion of the slowest node that determines the time to completion of the operation.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 90pt;text-indent: 0pt;text-align: right;">Thus, any skew in the distribution of the work across nodes greatly aﬀects performance. Estimating the time to completion of the slowest node due to skew is not an easy task since it is highly data dependent. However, statistics such as number of distinct values of partitioning attributes, histograms on the distribution of values of partitioning attributes, and counts of most frequent values can be used to estimate the potential for skew. Partitioning algorithms that can detect and minimize the eﬀect of skew, such as</p><p style="padding-left: 88pt;text-indent: 0pt;text-align: left;">those discussed in Section 21.3, are important to minimize skew.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 88pt;text-indent: 0pt;text-align: justify;">22.7.3 Choosing a Parallel Query Plan</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">The number of parallel evaluation plans from which to choose is much larger than the number of sequential evaluation plans. Optimization of parallel queries by consider- ing all alternatives is therefore much more expensive than optimization of sequential</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 119pt;text-indent: 0pt;text-align: left;">queries. Hence, we usually adopt heuristic approaches to reduce the number of parallel execution plans that we have to consider. We describe two popular approaches here.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s63" style="padding-left: 145pt;text-indent: -16pt;text-align: justify;">1. <span class="p">A simple approach is to choose the most eﬃcient sequential evaluation plan, and then to choose the optimal way to parallelize the operations in that evaluation plan. When choosing a sequential plan, the optimizer may use a basic sequential cost model; or it may use a simple cost model that takes some aspects of paral- lel execution into account but does not consider issues such as partitioning or scheduling. This option allows an existing sequential query optimizer to be used with minimal changes for the ﬁrst step.</span></p><p style="padding-left: 145pt;text-indent: 13pt;text-align: justify;">Next, the optimizer decides how to create an optimal parallel plan correspond- ing to the chosen sequential plan. At this point, choices of what partitioning techniques to use and how to schedule operators can be made in a cost-based manner.</p><p style="padding-left: 145pt;text-indent: 14pt;text-align: justify;">The chosen sequential plan may not be optimal in the parallel context, since the exact cost formulae for parallel execution were not used when choosing it; nevertheless, the approach works reasonably well in many cases.</p><p class="s63" style="padding-top: 6pt;padding-left: 145pt;text-indent: -17pt;text-align: justify;">2. <span class="p">A more principled approach is to ﬁnd the best plan, assuming that each operation is executed in parallel across all the nodes (operations with very small inputs may be executed on fewer nodes). Scheduling of independent operations in parallel on diﬀerent nodes is not considered at this stage.</span></p><p style="padding-left: 145pt;text-indent: 15pt;text-align: justify;">Partitioning of inputs and intermediate results is taken into consideration when estimating the cost of a query plan. Existing techniques for query optimiza- tion have been extended by considering partitioning as a physical property, in addition to physical properties such as sort orders that are already taken into ac- count when choosing a sequential query plan. Just as sort operators are added to a query plan to get a desired sort order, exchange operators are added to get the desired partitioning property. The cost model used in practice is typically a resource consumption model, which we saw earlier. Although response-time cost models oﬀer better estimates of query execution time, the cost of query opti- mization is higher when using a response-time cost model compared to the cost of optimization when using a resource-consumption cost model. References pro- viding more information on the response-time cost model may be found in the Further Reading section at the end of the chapter.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Yet another dimension of optimization is the design of physical-storage organiza- tion to speed up queries. For example, a relation can be stored partitioned on any of several diﬀerent attributes, and it may even be replicated and replicas can be stored partitioned on diﬀerent attributes. For example, a relation <i>r</i>(<i>A</i>, <i>B</i>, <i>C</i>) could be stored partitioned on <i>A</i>, and a replica could be partitioned on <i>B</i>. The query optimizer chooses the replica that is best suited for the query. The optimal physical organization diﬀers</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">for diﬀerent queries. The database administrator must choose a physical organization that appears to be good for the expected mix of database queries.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-top: 7pt;padding-left: 88pt;text-indent: 0pt;text-align: left;">22.7.4 Colocation of Data</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">Even with parallel data storage and parallel processing of operations, the execution time of some queries can be too slow for the needs of some applications. In particular, queries that access small amounts of data stored at multiple nodes may run quite slowly when executed in parallel, as compared to the execution of the same query on a single node, if all the data were available at that node. There are many applications that need such queries to return answers with very low latency.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">An important technique to speed up such queries is to colocate data that a query accesses in a single node. For example, suppose an application needs to access student information, along with information about courses taken by the student. Then, the <i>student </i>relation may be partitioned on the <span class="s69">ID</span>, and the <i>takes </i>relation also partitioned in exactly the same manner on <span class="s69">ID</span>. Tuples in the <i>course </i>relation, which is a small relation, may be replicated to all nodes. With such a partitioning, any query involving these three relations that retrieves data for a single <span class="s69">ID </span>can be answered locally at a single node. The query processing engine just detects which node is responsible for that <span class="s69">ID </span>and sends the query to that node, where it is executed locally.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Colocation of tuples from diﬀerent relations is supported by many data storage systems. If the data storage system does not natively support colocation, an alternative is to create an object containing related tuples that share a key (e.g., <i>student </i>and <i>takes </i>records corresponding to a particular <span class="s69">ID</span>), and store it in the data storage system with the associated key (<span class="s69">ID</span>, in our example).</p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3214.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3215.png"/></span></p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The colocation technique, however, does not work directly if diﬀerent queries need a relation partitioned in diﬀerent ways. For example, if the goal is to ﬁnd all students who have taken a particular course section, the <i>takes </i>relation needs to be partitioned on the section information (<i>course id</i>, <i>year</i>, <i>semester</i>, <i>sec id</i>) instead of being partitioned on <span class="s69">ID</span>.</p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3216.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3217.png"/></span></p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">A simple technique to handle this situation is to allow multiple copies of a rela- tion, partitioned on diﬀerent attributes. These copies can be modeled as indices on the relation, partitioned on diﬀerent attributes; when tuples in the relation are updated, so are the copies, to keep them consistent. In our example, one copy of <i>takes </i>can be partitioned on <span class="s69">ID </span>to be colocated with the <i>student </i>partitions, while another copy is par- titioned on (<i>course id</i>, <i>year</i>, <i>semester</i>, <i>sec id</i>) to be colocated with the <i>section </i>relation.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Colocation helps optimize queries that compute joins between two relations; it can extend to three or more relations if either the remaining relations are replicated, or if all relations share a common set of join attributes. In the latter case, all tuples that would join together can be colocated by partitioning on the common join attributes. In either case, the join can be computed locally at a single node, if the query only wants the results for a speciﬁc value of the join attribute, as we saw earlier. However, not all join</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">queries are amenable to evaluation at a single node by using colocation. Materialized views, which we discuss next, oﬀer a more general alternative.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 119pt;text-indent: 0pt;text-align: left;">22.7.5 Parallel Maintenance of Materialized Views</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">Materialized views, which we saw in Section 4.2.3 for speeding up queries in centralized databases, can also be used to speed up queries in parallel databases. Materialized views need to be maintained when the database is updated, as we saw in Section 16.5. Materialized views in a parallel database can have a very large amount of data, and must, therefore, be stored partitioned across multiple nodes.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">As in the centralized case, materialized views in a parallel database speed up query answering at the cost of the overhead of view maintenance at the time of processing updates.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">We consider ﬁrst a very simple case of materialized views. It is often useful to store an extra copy of a relation, partitioned on diﬀerent attributes, to speed up answering of some queries. Such a repartitioning can be considered a very simple case of a material- ized view; view maintenance for such a view is straightforward, just requiring updates to be sent to the appropriate partition.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Indices can be considered a form of materialized views. Recall from Section 21.5 how parallel indices are maintained. Consider the case of maintenance of a parallel secondary index on an attribute <i>B </i>of a relation <i>r</i>(<i>A</i>, <i>B</i>, <i>C</i>), with primary key <i>A</i>. The sec- ondary index would be sorted on attribute <i>B </i>and would include unique key <i>A</i>; assume it also includes attribute <i>C</i>. Suppose now that attribute <i>B </i>of a tuple (<i>a</i>1, <i>b</i>1, <i>c</i>1) is updated from <i>b</i>1 to <i>b</i>2. This update results in two updates to the secondary index: delete the index entry with key (<i>b</i>1, <i>a</i>1, <i>c</i>1), and add an entry (<i>b</i>2, <i>a</i>1, <i>c</i>1). Since the secondary in- dex is itself partitioned, these two updates need to be sent to the appropriate partition, based on the unique key attributes (<i>B</i>, <i>A</i>).</p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3218.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3219.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3220.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3221.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3222.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_3223.png"/></span></p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">In some cases, materialized view maintenance can be done by partitioning fol- lowed by local view maintenance. Consider a view that groups <i>takes </i>tuples by (<i>course id</i>, <i>year</i>, <i>semester</i>, <i>sec id</i>), and then counts the number of students who have taken that course section. Such a materialized view would be stored partitioned on the grouping attributes (<i>course id</i>, <i>year</i>, <i>semester</i>, <i>sec id</i>). It can be computed by maintaining a copy of the <i>takes </i>relation partitioned on (<i>course id</i>, <i>year</i>, <i>semester</i>, <i>sec id</i>), and materializing the aggregates locally at each node. When there is an update, say an insert or delete to the <i>takes </i>relation, that update must be propagated to the appropriate node based on the partitioning chosen above. The materialized aggregate can be maintained locally at each node, as updates are received for the set of local tuples of the <i>takes </i>relation.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">For more complex views, materialized view maintenance cannot be done by a single step of partitioning and local view maintenance. We consider a more general approach next.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">First, consider an operator <i>o</i>, whose result is materialized, and an update (insert or delete) to one of the input relations of <i>o </i>that requires maintenance of the materialized result of <i>o</i>. Suppose the execution of operator <i>o </i>is parallelized using the exchange op-</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;"><a name="bookmark479">erator model (Section 22.5.2) where the inputs are partitioned, and then operators are executed at each node on data made available locally by (re)partitioning. To support materialized view maintenance of the result of </a><i>o</i>, we materialize the output of <i>o </i>at each node and additionally materialize (store) the input partitions sent to the node when the materialized view result is initially computed.<a name="bookmark524">&zwnj;</a></p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Now, when there is an update (insert or delete) to an input to <i>o</i>, we send the update to the appropriate node using the same partition function used during the initial com- putation of <i>o</i>. Consider a node that has received such an update. Now, the maintenance of the locally materialized result at the node can be done using standard (nonparallel) view maintenance techniques using only locally available data.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Note that as we saw in Section 22.5.2, a variety of operations can be parallelized using the exchange operator model, and hence the preceding scheme provides a parallel view maintenance technique for all such operators.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Next, consider a query with multiple operators. Such a query can be parallelized using the exchange operator model. The exchange operators repartition data between nodes, and each node computing (possibly multiple) operations using data made avail- able locally by the exchange operators, as we saw in Section 22.5.2.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">We can materialize the inputs and results at each node. Now, when there is a change to an input at a node, we use standard view maintenance techniques locally to ﬁnd the change to the materialized result, say <i>v</i>, at that node. If that result <i>v </i>is the ﬁnal output of the query, we are done. Otherwise, there must be an exchange operator above it; we use the exchange operator to route the updates (inserts or delete) to <i>v </i>to the next operator. That operator in turn computes the change to its result, and propagates it further if required, until we get to the root of the original materialized view.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The issue of consistency of materialized views in the face of concurrent updates to the underlying relations is addressed in Section 23.6.3.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part405.htm">&lt; 上一个</a><span> | </span><a href="../database.html">内容</a><span> | </span><a href="part407.htm">下一个 &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
