<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xmlns:mml="http://www.w3.org/1998/Math/MathML" lang="EN" xml:lang="en"><head><meta content="text/html; charset=utf-8" http-equiv="default-style"/><title>The Art of Multiprocessor Programming</title><link href="Elsevier_eBook.css" rel="stylesheet" type="text/css"/><link href="math.css" rel="stylesheet" type="text/css"/><link href="media.css" media="only screen" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:4f1c4a5b-a3e2-48ff-98f3-ff17812cd57a" name="Adept.expected.resource"/></head><body><section epub:type="chapter" role="doc-chapter"><div aria-label="Page 129" epub:type="pagebreak" id="page_129" role="doc-pagebreak"/><div id="CN"><a id="c0010tit1"/></div><header><hgroup><h1 class="chaptitle" id="c0010tit">Chapter 6: Universality of consensus</h1></hgroup><section epub:type="preamble"><div class="abstract"><h2 class="h1hd" id="ab0010"><a id="st0010"/>Abstract</h2><p class="abspara">This chapter describes how to use consensus objects to build a <i>universal construction</i>, an algorithm for implementing a linearizable concurrent object for any sequential object type. It presents two algorithms, a lock-free one and a wait-free one. These universal constructions demonstrate the consensus objects are universal; that is, they can be used to implement a wait-free linearizable implementation of any object type.</p></div></section><section id="ks0010"><h3 class="h2hd" id="st0015">Keywords</h3><p class="keywords">wait-free universal construction; lock-free universal construction; consensus objects; universal object classes</p></section></header><section><h2 class="h1hd" id="s0010"><a id="st0020"/>6.1 Introduction</h2><p class="textfl" id="p0010">In Chapter <a href="B9780124159501000148.xhtml">5</a>, we considered a simple technique for proving statements of the form “there is no wait-free implementation of <i>X</i> by <i>Y</i>.” We considered object classes with deterministic sequential specifications.<sup><a epub:type="noteref" href="#fn001" id="cf0010" role="doc-noteref">1</a></sup> We derived a hierarchy in which no object from one level can implement an object at a higher level (see <a href="#f0010" id="cf0015">Fig. 6.1</a>). Recall that each object has an associated <i>consensus number</i>, which is the maximum number of threads for which the object can solve the consensus problem. In a system of <i>n</i> or more concurrent threads, it is impossible to construct a wait-free implementation of an object with consensus number <i>n</i> from objects with lower consensus numbers. The same result holds for lock-free implementations, and henceforth unless we explicitly state otherwise, it is implied that a result that holds for wait-free implementations holds for lock-free ones as well.</p><div class="pageavoid"><figure class="fig" id="f0010"><img alt="Image" height="182" src="images/B978012415950100015X/gr001.jpg" width="505"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 6.1</span> Concurrent computability and the universality hierarchy of synchronization operations.</div></figcaption></figure></div><p class="text" id="p0015">The impossibility results of Chapter <a href="B9780124159501000148.xhtml">5</a> do not by any means imply that wait-free synchronization is impossible or infeasible. In this chapter, we show that there are classes of objects that are <i>universal</i>: Given sufficiently many of them, one can construct a wait-free linearizable implementation of <i>any</i> concurrent object.</p><p class="text" id="p0020">A class is universal in a system of <i>n</i> threads if and only if it has a consensus number greater than or equal to <i>n</i>. In <a href="#f0010" id="cf0020">Fig. 6.1</a>, each class at level <i>n</i> is universal for a system of <i>n</i> threads. A machine architecture or programming language is computationally powerful enough to support arbitrary wait-free synchronization if and only if it provides objects of a universal class as primitives. For example, modern multiprocessor machines that provide a <img alt="Image" height="12" src="images/B978012415950100015X/fx001.jpg" width="97"/> operation are universal for any number of threads: They can implement any concurrent object in a wait-free manner.</p><p class="text" id="p0025">This chapter describes a <i>universal construction</i> that implements any concurrent object from consensus objects. The chapter does <i>not</i> describe practical techniques for implementing wait-free objects. Like classical computability theory, understanding the universal construction and its implications allows us to avoid the naïve mistake of trying to solve unsolvable problems. Once we understand <i>why</i> consensus is powerful enough to implement any kind of object, we will be better prepared to undertake the engineering effort needed to make such constructions efficient.<span aria-label="Page 130" epub:type="pagebreak" id="page_130" role="doc-pagebreak"/></p></section><section><h2 class="h1hd" id="s0015"><a id="st0025"/>6.2 Universality</h2><p class="textfl" id="p0030">A class <i>C</i> is <i>universal</i> if one can construct a wait-free implementation of any object from some number of objects of <i>C</i> and some number of read–write registers. Our construction uses multiple objects of class <i>C</i> because we are ultimately interested in understanding the synchronization power of machine instructions, and most machines allow their instructions to be applied to multiple memory locations. We allow an implementation to use multiple read–write registers because it is convenient for bookkeeping, and memory is usually in plentiful supply on modern architectures. To avoid distraction, we use an unlimited number of read–write registers and consensus objects, leaving the question of recycling memory as an exercise. We begin by presenting a lock-free implementation, later extending it to a slightly more complex wait-free one.<span aria-label="Page 131" epub:type="pagebreak" id="page_131" role="doc-pagebreak"/></p></section><section><h2 class="h1hd" id="s0020"><a id="st0030"/>6.3 A lock-free universal construction</h2><p class="textfl" id="p0035"><a href="#f0015" id="cf0025">Fig. 6.2</a> shows a <i>generic</i> definition for a sequential object, based on the invocation–response formulation of Chapter <a href="B9780124159501000124.xhtml">3</a>. Each object is created in a fixed initial state. The <img alt="Image" height="11" src="images/B978012415950100015X/fx002.jpg" width="32"/>() method takes as argument an <i>invocation</i> which describes the method being called and its arguments, and returns a <i>response</i> containing the call's termination condition (normal or exceptional) and the return value, if any. For example, a stack invocation might be <img alt="Image" height="11" src="images/B978012415950100015X/fx004.jpg" width="25"/>() with an argument, and the corresponding response would be normal and <img alt="Image" height="9" src="images/B978012415950100015X/fx005.jpg" width="26"/>.</p><div class="pageavoid"><figure class="fig" id="f0015"><img alt="Image" height="43" src="images/B978012415950100015X/gr002.jpg" width="294"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 6.2</span> A generic sequential object: The <img alt="Image" height="11" src="images/B978012415950100015X/fx002.jpg" width="32"/>() method applies the invocation and returns a response.</div></figcaption></figure></div><p class="text" id="p0040"><a href="#f0020" id="cs0010">Figs. 6.3</a> and <a href="#f0025">6.4</a> show a universal construction that transforms any sequential object into a lock-free linearizable concurrent object. This construction assumes that sequential objects are <i>deterministic</i>: If we apply a method to an object in a particular state, then there is only one possible response and one possible new object state. We can represent any object as a combination of a sequential object in its initial state and a <i>log</i>: a linked list of nodes representing the sequence of method calls applied to the object (and hence the object's sequence of state transitions). A thread executes a method call by adding the new call to the head of the list. It then traverses the list, from tail to head, applying the method calls to a private copy of the object. The thread finally returns the result of applying its own operation. It is important to understand that only the head of the log is mutable: The initial state and nodes preceding the head never change.</p><div class="pageavoid"><figure class="fig" id="f0020"><img alt="Image" height="290" src="images/B978012415950100015X/gr003.jpg" width="407"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 6.3</span> The <img alt="Image" height="9" src="images/B978012415950100015X/fx003.jpg" width="25"/> class.</div></figcaption></figure></div><div class="pageavoid"><figure class="fig" id="f0025"><img alt="Image" height="454" src="images/B978012415950100015X/gr004.jpg" width="331"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 6.4</span> The lock-free universal construction.</div></figcaption></figure></div><p class="text" id="p0045">How do we make this log-based construction concurrent, that is, allow threads to make concurrent calls to <img alt="Image" height="11" src="images/B978012415950100015X/fx002.jpg" width="32"/>()? A thread attempting to call <img alt="Image" height="11" src="images/B978012415950100015X/fx002.jpg" width="32"/>() creates a node to hold its invocation. The threads then compete to append their respective nodes to the head of the log by running an <i>n</i>-thread consensus protocol to agree which node was appended to the log. The inputs to this consensus are references to the threads' nodes, and the result is the unique winning node.</p><p class="text" id="p0050">The winner can then proceed to compute its response. It does so by creating a local copy of the sequential object and traversing the log, following <span aria-label="Page 132" epub:type="pagebreak" id="page_132" role="doc-pagebreak"/><img alt="Image" height="8" src="images/B978012415950100015X/fx006.jpg" width="25"/> references from tail to head, applying the operations in the log to its copy, finally returning the response associated with its own invocation. This algorithm works even when <img alt="Image" height="11" src="images/B978012415950100015X/fx002.jpg" width="32"/>() calls are concurrent because the prefix of the log up to the thread's own node never changes. The losing threads, which were not chosen by the consensus object, must try again to set the node currently at the head of the log (which changes between attempts) to point to them.</p><p class="text" id="p0055">We now consider this construction in detail. The code for the lock-free universal construction appears in <a href="#f0025" id="cf0030">Fig. 6.4</a>. A sample execution appears in <a href="#f0030" id="cf0035">Fig. 6.5</a>. The object state is defined by a linked list of nodes, each one containing an invocation. The code for a node appears in <a href="#f0020" id="cf0040">Fig. 6.3</a>. The node's <img alt="Image" height="9" src="images/B978012415950100015X/fx007.jpg" width="66"/> field is a consensus object used to decide which node is appended next in the list, and <img alt="Image" height="8" src="images/B978012415950100015X/fx006.jpg" width="25"/> is the field in which the outcome of that consensus, the reference to the next node, is recorded. The <img alt="Image" height="9" src="images/B978012415950100015X/fx008.jpg" width="18"/> field is the node's sequence number in the list. This field <span aria-label="Page 133" epub:type="pagebreak" id="page_133" role="doc-pagebreak"/>is 0 while the node is not yet threaded onto the list, and positive otherwise. Sequence numbers for successive nodes in the list increase by 1. Initially, the log consists of a unique sentinel node with sequence number 1.</p><div class="pageavoid"><figure class="fig" id="f0030"><img alt="Image" height="192" src="images/B978012415950100015X/gr005.jpg" width="469"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 6.5</span> Execution of the lock-free universal construction. Thread 2 appends the second node in the log winning consensus on <img alt="Image" height="9" src="images/B978012415950100015X/fx007.jpg" width="66"/> in the sentinel node. It then sets the node's sequence number from 0 to 2, and refers to it from its entry in the <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/> array. Thread 7 loses the <img alt="Image" height="9" src="images/B978012415950100015X/fx007.jpg" width="66"/> consensus at the sentinel node, sets the <img alt="Image" height="8" src="images/B978012415950100015X/fx006.jpg" width="25"/> reference and sequence number of the decided successor node to 2 (they were already set to the same values by thread 2), and refers to the node from its entry in the <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/> array. Thread 5 appends the third node, updates its sequence number to 3, and updates its entry in the <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/> array to this node. Finally, thread 2 appends the fourth node, sets its sequence number to 4, and refers to it from its entry in the <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/> array. The maximal value in the head array keeps track of the head of the log.</div></figcaption></figure></div><p class="text" id="p0060">The hard part about designing the concurrent lock-free universal construction is that consensus objects can be used only once.<sup><a epub:type="noteref" href="#fn002" id="cf0045" role="doc-noteref">2</a></sup></p><p class="text" id="p0065">In our lock-free algorithm in <a href="#f0025" id="cf0050">Fig. 6.4</a>, each thread allocates a node holding its invocation, and repeatedly tries to append that node to the head of the log. Each node has a <img alt="Image" height="9" src="images/B978012415950100015X/fx007.jpg" width="66"/> field, which is a consensus object. A thread tries to append its node by proposing it as input to a consensus protocol on the head's <img alt="Image" height="9" src="images/B978012415950100015X/fx007.jpg" width="66"/> field. Because threads that do not participate in this consensus may need to traverse the list, the result of this consensus is stored in the node's <img alt="Image" height="8" src="images/B978012415950100015X/fx006.jpg" width="25"/> field. Multiple threads may update this field simultaneously, but they all write the same value. When a thread appends a node, it sets the node's sequence number.</p><p class="text" id="p0070">Once a thread's node is part of the log, the thread computes the response to its invocation by traversing the log from the tail to the newly added node. It applies each of the invocations to a private copy of the object, and <span aria-label="Page 134" epub:type="pagebreak" id="page_134" role="doc-pagebreak"/>returns the response from its own invocation. Note that when a thread computes its response, all its predecessors' <img alt="Image" height="8" src="images/B978012415950100015X/fx006.jpg" width="25"/> references must already be set, because these nodes have already been added to the head of the list. Any thread that added a node to the list has updated the <img alt="Image" height="8" src="images/B978012415950100015X/fx006.jpg" width="25"/> reference of its predecessor with the result of the <img alt="Image" height="9" src="images/B978012415950100015X/fx007.jpg" width="66"/> consensus.</p><p class="text" id="p0075">How do we locate the head of the log? We cannot track the head with a consensus object because the head must be updated repeatedly, and consensus objects can only be accessed once by each thread. Instead, we create a per-thread structure of the kind used in the bakery algorithm (Section <a href="B9780124159501000112.xhtml">2.7</a>). We use an <i>n</i>-entry array <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/>, where <img alt="Image" height="12" src="images/B978012415950100015X/fx011.jpg" width="40"/> is the last node in the list that thread <i>i</i> has observed. Initially all entries refer to the <img alt="Image" height="9" src="images/B978012415950100015X/fx012.jpg" width="23"/> sentinel node. The head is the node with the maximum sequence number among the nodes referenced in the <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/> array. The <img alt="Image" height="6" src="images/B978012415950100015X/fx013.jpg" width="19"/>() method in <a href="#f0020" id="cf0055">Fig. 6.3</a> performs a collect, reading <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/> and returning the node with the highest sequence number.</p><p class="text" id="p0080">The construction is a linearizable implementation of the sequential object. Each <img alt="Image" height="11" src="images/B978012415950100015X/fx002.jpg" width="32"/>() call can be linearized to the <img alt="Image" height="9" src="images/B978012415950100015X/fx014.jpg" width="39"/>() call adding the node to the log.</p><p class="text" id="p0085">Why is this construction lock-free? The head of the log, the latest node appended, is added to the <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/> array within a finite number of steps. The node's predecessor must appear in the head array, so any node repeatedly attempting to add a new node will repeatedly run the <img alt="Image" height="6" src="images/B978012415950100015X/fx013.jpg" width="19"/>() function on the head array. It detects this predecessor, applies consensus on its <img alt="Image" height="9" src="images/B978012415950100015X/fx007.jpg" width="66"/> field, and then updates the winning node's fields, including its sequence number. Finally, it stores the decided node in that thread's head array entry. The new head node always eventually appears in <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/>. It follows that the only way a thread can repeatedly fail to add its own node to the log is if other threads repeatedly succeed in appending their own nodes to the log. Thus, a node can starve only if other nodes are continually completing their invocations, implying that the construction is lock-free.</p></section><section><h2 class="h1hd" id="s0025"><a id="st0035"/>6.4 A wait-free universal construction</h2><p class="textfl" id="p0090">How do we make a lock-free algorithm wait-free? The full wait-free algorithm appears in <a href="#f0035" id="cf0060">Fig. 6.6</a>. We must guarantee that every thread completes an <img alt="Image" height="11" src="images/B978012415950100015X/fx002.jpg" width="32"/>() call within a finite number of steps; that is, no thread starves. To guarantee this property, threads making progress help less fortunate threads complete their calls. This <i>helping</i> pattern shows up later in a specialized form in other wait-free algorithms.</p><div class="pageavoid"><figure class="fig" id="f0035"><img alt="Image" height="602" src="images/B978012415950100015X/gr006.jpg" width="402"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 6.6</span> The wait-free universal construction.</div></figcaption></figure></div><p class="text" id="p0095">To enable helping, each thread shares with other threads the <img alt="Image" height="11" src="images/B978012415950100015X/fx002.jpg" width="32"/>() call that it is trying to complete. We add an <i>n</i>-element <img alt="Image" height="12" src="images/B978012415950100015X/fx015.jpg" width="61"/> array, where <img alt="Image" height="12" src="images/B978012415950100015X/fx016.jpg" width="67"/> is the node that thread <i>i</i> is currently trying to append to the list. Initially, all entries refer to the sentinel node, which has a sequence number 1. Thread <i>i announces</i> a node when it stores the node in <img alt="Image" height="12" src="images/B978012415950100015X/fx016.jpg" width="67"/>.</p><p class="text" id="p0100">To execute <img alt="Image" height="11" src="images/B978012415950100015X/fx002.jpg" width="32"/>(), a thread first announces its new node. This step ensures that if the thread itself does not succeed in appending its node onto the list, some other thread can append that node on its behalf. It then proceeds as before, attempting to append the node into the log. To do so, it reads the <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/> array only once (line 15), and then enters the main loop of the algorithm, which it executes until <span aria-label="Page 135" epub:type="pagebreak" id="page_135" role="doc-pagebreak"/>its own node has been appended to the list (detected on line 16 after its sequence number becomes nonzero). Here is a change from the lock-free algorithm. A thread first checks to see if there is a node that needs help ahead of it in the <img alt="Image" height="12" src="images/B978012415950100015X/fx015.jpg" width="61"/> array (line 18). The node to be helped must be determined dynamically because nodes are continually added to the log. A thread attempts to help nodes in the <img alt="Image" height="12" src="images/B978012415950100015X/fx015.jpg" width="61"/> array in increasing <span aria-label="Page 136" epub:type="pagebreak" id="page_136" role="doc-pagebreak"/>order, determined by the sequence number modulo the width <i>n</i> of the <img alt="Image" height="12" src="images/B978012415950100015X/fx015.jpg" width="61"/> array. We prove that this approach guarantees that any node that does not make progress on its own will eventually be helped by others once its owner thread's index matches the maximal sequence number modulo <i>n</i>. If this helping step were omitted, then an individual thread could be overtaken an arbitrary number of times. If the node selected for help does not require help (i.e., its sequence number is nonzero in line 19), then each thread attempts to append its own node (line 22). (All <img alt="Image" height="12" src="images/B978012415950100015X/fx015.jpg" width="61"/> array entries are initialized to the sentinel node, with sequence number 1.) The rest of the algorithm is almost the same as in the lock-free algorithm. A node is appended when its sequence number becomes nonzero. In this case, the thread proceeds as before to compute its result based on the immutable segment of the log from the tail to its own node.</p><p class="text" id="p0105"><a href="#f0040" id="cf0065">Fig. 6.7</a> shows an execution of the wait-free universal construction in which, starting from the initial state, <span aria-label="Page 137" epub:type="pagebreak" id="page_137" role="doc-pagebreak"/>thread 5 announces its new node and appends it to the log, and pauses before adding the node to <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/>. Thread 7 then takes steps. The value of (<img alt="Image" height="11" src="images/B978012415950100015X/fx018.jpg" width="65"/> + 1) mod n is 2, but thread 2 is not trying to add a node, so thread 7 tries to add its own node. It loses the consensus on the sentinel node's <img alt="Image" height="9" src="images/B978012415950100015X/fx007.jpg" width="66"/> object since thread 5 already won, and thus completes the operation of thread 5, setting the node's sequence number to 2 and adding the node to the <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/> array. Next, thread 3 announces its node and pauses before entering the main loop. Then thread 7 helps thread 3: it appends thread 3's node, but pauses after setting its sequence number to 3 but before adding the node to <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/>. Now thread 3 wakes up. It does not enter the main loop because its node's sequence number is nonzero, but updates <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/> on line 28 and computes its output value using a copy of the sequential object.</p><div class="pageavoid"><figure class="fig" id="f0040"><img alt="Image" height="303" src="images/B978012415950100015X/gr007.jpg" width="451"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 6.7</span> Execution of the wait-free universal construction. Thread 5 announces its new node and appends it to the log, but halts before adding it to the <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/> array. Thread 7 does not see thread 5's node in the <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/> array. Since thread 2 (whose ID is (<img alt="Image" height="11" src="images/B978012415950100015X/fx017.jpg" width="65"/> + 1) mod n) is not trying to add a node, thread 7 tries to add its own node. However, it loses the consensus on the sentinel node's <img alt="Image" height="9" src="images/B978012415950100015X/fx007.jpg" width="66"/> object since thread 5 already won. Thread 7 therefore completes updating the fields of thread 5's node, setting the node's sequence number to 2, and adding the node to the <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/> array. Note that thread 5's own entry in the <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/> array is not yet set to its announced node. Next, thread 3 announces its node and then pauses before entering the main loop. Thread 7 now successfully helps thread 3, appending its node and setting its sequence number to 3. Now thread 3 wakes up. It does not enter the main loop because its node's sequence number is nonzero, but will update the <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/> array and compute its output value using a copy of the sequential object.</div></figcaption></figure></div><p class="text" id="p0110">There is a delicate point to understand about these modifications to the lock-free algorithm. Since more than one thread can attempt to append a particular node to the log, we must make sure that no node is appended twice. One thread might append the node and set the node's sequence number at the same time that another thread appends the same node and sets its sequence number. The algorithm avoids this error because of the order in which threads read the maximum <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/> array value and the sequence number of a node in the <img alt="Image" height="12" src="images/B978012415950100015X/fx015.jpg" width="61"/> array. Let <i>a</i> be a node created by thread <i>A</i> and appended by threads <i>A</i> and <i>B</i>. It must be added at least once to <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/> before the second append. Note, however, that the <img alt="Image" height="9" src="images/B978012415950100015X/fx019.jpg" width="38"/> node read from <img alt="Image" height="12" src="images/B978012415950100015X/fx020.jpg" width="45"/> by <i>B</i> (line 17) must be <i>a</i> itself, or a successor of <i>a</i> in the log. Moreover, before any node is added to <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/> (either on line 26 or on line 28), its sequence number is made nonzero (line 25). The order of operations ensures that <i>B</i> sets its <img alt="Image" height="12" src="images/B978012415950100015X/fx021.jpg" width="46"/> entry (the entry based on which <i>B</i>'s <img alt="Image" height="9" src="images/B978012415950100015X/fx019.jpg" width="38"/> variable will be set, resulting in an erroneous append) in line 15 or line 26, and only then validates that the sequence number of <i>a</i> is nonzero in line 16 or line 19 (depending on whether <i>A</i> or another thread performs the operation). It follows that the validation of the erroneous second append will fail because the sequence number of node <i>a</i> will already be nonzero, and it will not be added to the log a second time.</p><p class="text" id="p0115">Linearizability follows because no node is ever added twice, and the order in which nodes are appended to the log is clearly compatible with the natural partial order of the corresponding method calls.</p><p class="text" id="p0120">To prove that the algorithm is wait-free, we must show that the helping mechanism guarantees that any node that is announced is eventually added to the <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/> array (implying that it is in the log) and the announcing thread can complete computation of its outcome. To assist in the proof, it is convenient to define some notation. Let <img alt="Image" height="12" src="images/B978012415950100015X/fx022.jpg" width="72"/> be the node with the largest sequence number in the <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/> array, and let “<i>c</i>∈<img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/>” denote the assertion that <img alt="Image" height="12" src="images/B978012415950100015X/fx011.jpg" width="40"/> is set to node <i>c</i>, for some <i>i</i>.</p><p class="text" id="p0125">An <i>auxiliary</i> variable (sometimes called a <i>ghost</i> variable) is one that does not appear explicitly in the code, does not alter the program's behavior in any way, and yet helps us reason about the behavior of the algorithm. We use the following auxiliary variables:</p><div><ul><li class="bulllist" id="u0010">•  <span class="hiddenClass"><mml:math><mml:mrow><mml:mi mathvariant="italic">concur</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B978012415950100015X/si1.png" style="vertical-align:middle" width="70"/></span> is the set of nodes that have been stored in the <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/> array since thread <i>A</i>'s last announcement.</li><li class="bulllist" id="u0015">•  <span class="hiddenClass"><mml:math><mml:mrow><mml:mi mathvariant="italic">start</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B978012415950100015X/si2.png" style="vertical-align:middle" width="55"/></span> is the sequence number of <img alt="Image" height="12" src="images/B978012415950100015X/fx022.jpg" width="72"/> when thread <i>A</i> last announced. <span aria-label="Page 138" epub:type="pagebreak" id="page_138" role="doc-pagebreak"/></li></ul></div><p class="textfl"> The code reflecting the auxiliary variables and how they are updated appears in <a href="#f0045" id="cf0070">Fig. 6.8</a>. For example, the statement</p><div class="pageavoid"><figure class="fig" id="f0050"><img alt="Image" class="img" height="11" src="images/B978012415950100015X/fx023.jpg" width="236"/></figure></div><p class="textfl"> means that the node <i>after</i> is added to <span class="hiddenClass"><mml:math><mml:mrow><mml:mi mathvariant="italic">concur</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B978012415950100015X/si3.png" style="vertical-align:middle" width="67"/></span> for all threads <i>j</i>. The code statements within the angled brackets are considered to be executed atomically. This atomicity can be assumed because auxiliary variables do not affect the computation in any way. For brevity, we slightly abuse the notation by letting the function <span class="hiddenClass"><mml:math><mml:mi mathvariant="normal">max</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B978012415950100015X/si4.png" style="vertical-align:middle" width="41"/></span> applied to a node or array of nodes return the maximal among their sequence numbers.</p><div class="pageavoid"><figure class="fig" id="f0045"><img alt="Image" height="405" src="images/B978012415950100015X/gr008.jpg" width="479"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 6.8</span> The <img alt="Image" height="11" src="images/B978012415950100015X/fx002.jpg" width="32"/>() method of the wait-free universal construction with auxiliary variables. Operations in angled brackets are assumed to happen atomically.</div></figcaption></figure></div><p class="text" id="p0140">Note the following property is invariant throughout the execution of the universal construction:</p><div class="showClass"><p class="fig"><img alt="Image" height="12" src="images/B978012415950100015X/fx024.jpg" width="232"/><a id="deq1"/><span class="eqnum">(6.4.1) </span></p></div><p class="textfl"/><p class="text" id="p0145"/><div class="boxg1" id="enun0010"><p class="b1num">Lemma 6.4.1 </p><div><p class="b1textfl" id="p0150">For all threads <i>A</i>, the following claim is always true:</p><div class="showClass"><p class="fig"><img alt="Image" height="12" src="images/B978012415950100015X/fx025.jpg" width="249"/><a id="deq2"/></p></div><p class="b1textfl"/></div></div><p class="textfl"> </p><div class="boxg1" id="enun0015"><p class="b1num">Proof </p><div><p class="b1textfl" id="p0155">Let <img alt="Image" height="12" src="images/B978012415950100015X/fx026.jpg" width="99"/>. If <span class="hiddenClass"><mml:math><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mi mathvariant="italic">concur</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">|</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B978012415950100015X/si5.png" style="vertical-align:middle" width="77"/></span> &gt;<i>n</i>, then <span class="hiddenClass"><mml:math><mml:mrow><mml:mi mathvariant="italic">concur</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B978012415950100015X/si1.png" style="vertical-align:middle" width="70"/></span> includes successive nodes <i>b</i> and <i>c</i> (appended to the log by threads <i>B</i> and <i>C</i>) whose respective sequence numbers plus 1 are equal to <span class="hiddenClass"><mml:math><mml:mi>A</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">−</mml:mo><mml:mn>1</mml:mn></mml:math></span><span><img alt="Image" height="11" src="images/B978012415950100015X/si6.png" style="vertical-align:middle" width="39"/></span> and <i>A</i> modulo <i>n</i> (note that <i>B</i> and <i>C</i> are the threads that add <i>b</i> and <i>c</i> to the log, not necessarily the ones that announced them). Thread <i>C</i> appends to the log the node located in <img alt="Image" height="12" src="images/B978012415950100015X/fx027.jpg" width="72"/> at the time it executes lines 18–22, unless it had already been added to the log. We need to show that when <i>C</i> reads <img alt="Image" height="12" src="images/B978012415950100015X/fx027.jpg" width="72"/>, <i>A</i> has already announced <i>a</i>, so <i>c</i> adds <i>a</i> to the log, or <i>a</i> was already added. Later, when <i>c</i> is added to <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/> and <span class="hiddenClass"><mml:math><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mi mathvariant="italic">concur</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mo linebreak="goodbreak" linebreakstyle="after">&gt;</mml:mo><mml:mi>n</mml:mi></mml:math></span><span><img alt="Image" height="14" src="images/B978012415950100015X/si7.png" style="vertical-align:middle" width="106"/></span>, <i>a</i> will be in <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/> as the lemma requires.</p><p class="b1text" id="p0160">To see why <i>a</i> must have already been announced when <i>C</i> reached lines 18–22, note that (1) because <i>C</i> appended its node <i>c</i> to <i>b</i>, it must have read <i>b</i> as the <i>before</i> node on line 17, implying that <i>B</i> added <i>b</i> to the log before it was read from <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/> by <i>C</i> on line 17, and (2) because <i>b</i> is in <span class="hiddenClass"><mml:math><mml:mrow><mml:mi mathvariant="italic">concur</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B978012415950100015X/si1.png" style="vertical-align:middle" width="70"/></span>, <i>A</i> announced <i>a</i> before <i>b</i> was added to <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/>. From (1) and (2), it follows that <i>A</i> announced before <i>C</i> executed lines 18–22, and the claim follows. □</p></div></div><p class="textfl"/><p class="text" id="p0165"><span aria-label="Page 139" epub:type="pagebreak" id="page_139" role="doc-pagebreak"/><a href="#enun0010" id="cf0075">Lemma 6.4.1</a> places a bound on the number of nodes that can be appended while a method call is in progress. We now give a sequence of lemmas showing that when <i>A</i> finishes scanning the <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/> array, either <img alt="Image" height="12" src="images/B978012415950100015X/fx027.jpg" width="72"/> is appended or <img alt="Image" height="12" src="images/B978012415950100015X/fx020.jpg" width="45"/> lies within <span class="hiddenClass"><mml:math><mml:mi>n</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">+</mml:mo><mml:mn>1</mml:mn></mml:math></span><span><img alt="Image" height="13" src="images/B978012415950100015X/si8.png" style="vertical-align:middle" width="37"/></span> nodes of the end of the list.</p><p class="text" id="p0170"/><div class="boxg1" id="enun0020"><p class="b1num">Lemma 6.4.2 </p><div><p class="b1textfl" id="p0175">The following property always holds:</p><div class="showClass"><p class="fig"><img alt="Image" height="12" src="images/B978012415950100015X/fx028.jpg" width="144"/><a id="deq3"/></p></div><p class="b1textfl"/></div></div><p class="textfl"> </p><div class="boxg1" id="enun0025"><p class="b1num">Proof </p><div><p class="b1textfl" id="p0180">The sequence number for each <img alt="Image" height="12" src="images/B978012415950100015X/fx011.jpg" width="40"/> is nondecreasing. □</p></div></div><p class="textfl"/><p class="text" id="p0185"/><div class="boxg1" id="enun0030"><p class="b1num">Lemma 6.4.3 </p><div><p class="b1textfl" id="p0190">The following is a loop invariant for line 13 of <a href="#f0020" id="cf0080">Fig. 6.3</a> (i.e., it holds during each iteration of the loop):</p><div class="showClass"><p class="fig"><img alt="Image" height="12" src="images/B978012415950100015X/fx029.jpg" width="282"/><a id="deq4"/></p></div><p class="b1textfl"> where <i>i</i> is the loop index, <img alt="Image" height="6" src="images/B978012415950100015X/fx013.jpg" width="19"/> is the node with the maximum sequence number found so far, and <i>A</i> is the thread executing the loop.</p></div></div><p class="textfl"> In other words, the maximum sequence number of <img alt="Image" height="6" src="images/B978012415950100015X/fx013.jpg" width="19"/> and all <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/> entries from the current value of <i>i</i> to the end of the loop never become smaller than the maximum value in the array when <i>A</i> announced.</p><p class="text" id="p0195"/><div class="boxg1" id="enun0035"><p class="b1num">Proof </p><div><p class="b1textfl" id="p0200">When <i>i</i> is 1, the assertion is implied by <a href="#enun0020" id="cf0085">Lemma 6.4.2</a> (since <img alt="Image" height="12" src="images/B978012415950100015X/fx030.jpg" width="84"/>). The truth of the assertion is preserved at each iteration, when <img alt="Image" height="6" src="images/B978012415950100015X/fx013.jpg" width="19"/> is replaced by the node with the sequence number <img alt="Image" height="12" src="images/B978012415950100015X/fx031.jpg" width="108"/>. □</p></div></div><p class="textfl"/><p class="text" id="p0205"/><div class="boxg1" id="enun0040"><p class="b1num">Lemma 6.4.4 </p><div><p class="b1textfl" id="p0210">The following assertion holds just before line 16 (of <a href="#f0045" id="cf0090">Fig. 6.8</a>):</p><div class="showClass"><p class="fig"><img alt="Image" height="12" src="images/B978012415950100015X/fx032.jpg" width="145"/><a id="deq5"/></p></div><p class="b1textfl"/></div></div><p class="textfl"/><p class="text" id="p0215"><span aria-label="Page 140" epub:type="pagebreak" id="page_140" role="doc-pagebreak"/></p><div class="boxg1" id="enun0045"><p class="b1num">Proof </p><div><p class="b1textfl" id="p0220">After the call to <img alt="Image" height="9" src="images/B978012415950100015X/fx003.jpg" width="25"/>.<img alt="Image" height="6" src="images/B978012415950100015X/fx013.jpg" width="19"/>() at line 15, the result follows from <a href="#enun0030" id="cf0095">Lemma 6.4.3</a>. Otherwise, <img alt="Image" height="12" src="images/B978012415950100015X/fx020.jpg" width="45"/> is set to point to <i>A</i>'s last appended node on line 26, which increases <img alt="Image" height="12" src="images/B978012415950100015X/fx020.jpg" width="45"/>.<img alt="Image" height="9" src="images/B978012415950100015X/fx008.jpg" width="18"/> by 1. □</p></div></div><p class="textfl"/><p class="text" id="p0225"/><div class="boxg1" id="enun0050"><p class="b1num">Lemma 6.4.5 </p><div><p class="b1textfl" id="p0230">The following property always holds:</p><div class="showClass"><p class="fig"><img alt="Image" height="12" src="images/B978012415950100015X/fx033.jpg" width="259"/><a id="deq6"/></p></div><p class="b1textfl"/></div></div><p class="textfl"> </p><div class="boxg1" id="enun0055"><p class="b1num">Proof </p><div><p class="b1textfl" id="p0235">The lower bound follows from <a href="#enun0040" id="cf0100">Lemma 6.4.4</a>, and the upper bound follows from Eq. <a href="#deq1" id="cf0105">(6.4.1)</a>. □</p></div></div><p class="textfl"/><p class="text" id="p0240"/><div class="boxg1" id="enun0060"><p class="b1num">Theorem 6.4.6 </p><div><p class="b1textfl" id="p0245">The algorithm in <a href="#f0035" id="cf0110">Fig. 6.6</a> is correct and wait-free.</p></div></div><p class="textfl"> </p><div class="boxg1" id="enun0065"><p class="b1num">Proof </p><div><p class="b1textfl" id="p0250">To see that the algorithm is wait-free, note that <i>A</i> can execute the main loop no more than <span class="hiddenClass"><mml:math><mml:mi>n</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">+</mml:mo><mml:mn>1</mml:mn></mml:math></span><span><img alt="Image" height="13" src="images/B978012415950100015X/si8.png" style="vertical-align:middle" width="37"/></span> times. At each successful iteration, <img alt="Image" height="12" src="images/B978012415950100015X/fx020.jpg" width="45"/>.<img alt="Image" height="9" src="images/B978012415950100015X/fx008.jpg" width="18"/> increases by 1. After <span class="hiddenClass"><mml:math><mml:mi>n</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">+</mml:mo><mml:mn>1</mml:mn></mml:math></span><span><img alt="Image" height="13" src="images/B978012415950100015X/si8.png" style="vertical-align:middle" width="37"/></span> iterations, <a href="#enun0050" id="cf0115">Lemma 6.4.5</a> implies that</p><div class="showClass"><p class="fig"><img alt="Image" height="12" src="images/B978012415950100015X/fx034.jpg" width="260"/><a id="deq7"/></p></div><p class="b1textfl"> <a href="#enun0010" id="cf0120">Lemma 6.4.1</a> implies that <img alt="Image" height="12" src="images/B978012415950100015X/fx027.jpg" width="72"/> must have been added to <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/>. □</p></div></div><p class="textfl"/></section><section><h2 class="h1hd" id="s0030"><a id="st0040"/>6.5 Chapter notes</h2><p class="textfl" id="p0255">The universal construction described here is adapted from Maurice Herlihy's 1991 paper <a epub:type="noteref" href="#br0345" id="cf0125" role="doc-noteref">[69]</a>. An alternative lock-free universal construction using <i>load-linked/store-conditional</i> appears in <a epub:type="noteref" href="#br0325" id="cf0130" role="doc-noteref">[65]</a>. The complexity of this construction can be improved in several ways. Yehuda Afek, Dalia Dauber, and Dan Touitou <a epub:type="noteref" href="#br0015" id="cf0135" role="doc-noteref">[3]</a> showed how to improve the time complexity to depend on the number of concurrent threads, not the maximum possible number of threads. Mark Moir <a epub:type="noteref" href="#br0650" id="cf0140" role="doc-noteref">[130]</a> showed how to design lock-free and wait-free constructions that do not require copying the entire object. James Anderson and Mark Moir <a epub:type="noteref" href="#br0055" id="cf0145" role="doc-noteref">[11]</a> extended the construction to allow multiple objects to be updated. Prasad Jayanti <a epub:type="noteref" href="#br0445" id="cf0150" role="doc-noteref">[89]</a> showed that any universal construction has worst-case <span class="hiddenClass"><mml:math><mml:mi mathvariant="normal">Ω</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B978012415950100015X/si9.png" style="vertical-align:middle" width="35"/></span> complexity, where <i>n</i> is the maximal number of threads. Tushar Chandra, Prasad Jayanti, and King Tan <a epub:type="noteref" href="#br0135" id="cf0155" role="doc-noteref">[27]</a> identified a large class of objects for which a more efficient universal construction exists.</p><p class="text" id="p0260">Our classification of dependent progress conditions has implications for the foundations of shared-memory computability. Lamport's register-based approach to read–write memory computability <a epub:type="noteref" href="#br0495" id="cs0015" role="doc-noteref">[99</a>,<a epub:type="noteref" href="#br0525" role="doc-noteref">105]</a> is based on wait-free implementations of one register type from another. Similarly, Herlihy's consensus hierarchy <a epub:type="noteref" href="#br0345" id="cf0160" role="doc-noteref">[69]</a> applies to wait-free or lock-free object implementations. Combined, these structures form the basis of a theory of concurrent shared-memory computability that explains what objects can be used to implement other objects in an asynchronous shared-memory multiprocessor environment. One might ask why such a theory should rest on nonblocking progress conditions (that is, wait-free or lock-free) <span aria-label="Page 141" epub:type="pagebreak" id="page_141" role="doc-pagebreak"/>and not on locks. After all, locking implementations are common in practice. Moreover, the obstruction-free condition is a nonblocking progress condition where read–write registers are universal <a epub:type="noteref" href="#br0340" id="cf0165" role="doc-noteref">[68]</a>, effectively leveling the consensus hierarchy. We are now in a position to address this question. Perhaps surprisingly, <a href="B9780124159501000124.xhtml">Fig. 3.10</a> suggests that the lock-free and wait-free conditions provide a sound basis for a concurrent computability theory because they are independent progress conditions (i.e., they do not rely on the good behavior of the operating system scheduler). A theory based on a dependent condition would require strong, perhaps arbitrary assumptions about the environment in which programs are executed. When studying the computational power of synchronization primitives, it is unsatisfactory to rely on the operating system to ensure progress, both because it obscures the inherent synchronization power of the primitives, and because we might want to use such primitives in the construction of the operating system itself. For these reasons, a satisfactory theory of shared-memory computability should rely on independent progress conditions such as wait-freedom or lock-freedom, not on dependent properties.</p></section><section><h2 class="h1hd" id="s0035"><a id="st0045"/>6.6 Exercises</h2><p class="textfl" id="p0265"/><div class="boxg1" id="enun0070"><p class="b1num">Exercise 6.1 </p><div><p class="b1textfl" id="p0270">Consider a concurrent atomic <img alt="Image" height="9" src="images/B978012415950100015X/fx035.jpg" width="86"/>(<i>k</i>) object: an atomic <img alt="Image" height="9" src="images/B978012415950100015X/fx036.jpg" width="32"/> with an added <img alt="Image" height="9" src="images/B978012415950100015X/fx037.jpg" width="25"/> operation. It allows each of <i>n</i> threads to execute <img alt="Image" height="11" src="images/B978012415950100015X/fx004.jpg" width="25"/>() and <img alt="Image" height="9" src="images/B978012415950100015X/fx038.jpg" width="18"/>() operations atomically with the usual LIFO semantics. In addition, it offers a <img alt="Image" height="9" src="images/B978012415950100015X/fx037.jpg" width="25"/> operation, the first <i>k</i> calls of which return the value at the bottom of the stack (the least recently pushed value that is currently in the stack) without popping it. All subsequent calls to <img alt="Image" height="9" src="images/B978012415950100015X/fx037.jpg" width="25"/> after the first <i>k</i> return <i>null</i>. Also, <img alt="Image" height="9" src="images/B978012415950100015X/fx037.jpg" width="25"/> returns <i>null</i> when the <img alt="Image" height="9" src="images/B978012415950100015X/fx036.jpg" width="32"/> is empty.</p><div><ul><li class="b1bulllist" id="u0020">•  Is it possible to construct a wait-free <img alt="Image" height="11" src="images/B978012415950100015X/fx009.jpg" width="32"/> (accessed by at most two threads) from an arbitrary number of <img alt="Image" height="9" src="images/B978012415950100015X/fx035.jpg" width="86"/>(1) (i.e., with <span class="hiddenClass"><mml:math><mml:mi>k</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>1</mml:mn></mml:math></span><span><img alt="Image" height="12" src="images/B978012415950100015X/si10.png" style="vertical-align:middle" width="36"/></span>) objects and atomic read–write registers? Prove your claim.</li><li class="b1bulllist" id="u0025">•  Is it possible to construct a wait-free <i>n</i>-thread <img alt="Image" height="9" src="images/B978012415950100015X/fx035.jpg" width="86"/>(2) object from an arbitrary number of atomic <img alt="Image" height="9" src="images/B978012415950100015X/fx036.jpg" width="32"/> objects and atomic read–write registers? Prove your claim.</li></ul></div><p class="b1textfl"/></div></div><p class="textfl"/><p class="text" id="p0285"/><div class="boxg1" id="enun0075"><p class="b1num">Exercise 6.2 </p><div><p class="b1textfl" id="p0290">Give an example showing how the universal construction can fail for objects with nondeterministic sequential specifications.</p></div></div><p class="textfl"/><p class="text" id="p0295"/><div class="boxg1" id="enun0080"><p class="b1num">Exercise 6.3 </p><div><p class="b1textfl" id="p0300">Propose a way to fix the universal construction of <a href="#f0045" id="cf0170">Fig. 6.8</a> to work for objects with nondeterministic sequential specifications.</p></div></div><p class="textfl"/><p class="text" id="p0305"/><div class="boxg1" id="enun0085"><p class="b1num">Exercise 6.4 </p><div><p class="b1textfl" id="p0310">In both the lock-free and wait-free universal constructions, the sequence number of the sentinel node at the <img alt="Image" height="9" src="images/B978012415950100015X/fx012.jpg" width="23"/> of the list is initially set to 1. Which of these algorithms, if any, would cease to work correctly if the sentinel node's sequence number were initially set to 0?</p></div></div><p class="textfl"/><p class="text" id="p0315"><span aria-label="Page 142" epub:type="pagebreak" id="page_142" role="doc-pagebreak"/></p><div class="boxg1" id="enun0090"><p class="b1num">Exercise 6.5 </p><div><p class="b1textfl" id="p0320">In the lock-free universal construction, every thread has its own view of the head pointer. To append a new method invocation, at line 14 of <a href="#f0025" id="cf0175">Fig. 6.4</a>, a thread selects the furthest among these head pointers:</p><div class="pageavoid"><figure class="fig" id="f0055"><img alt="Image" class="img" height="11" src="images/B978012415950100015X/fx039.jpg" width="173"/></figure></div><p class="textfl"> Consider changing this line to:</p><div class="pageavoid"><figure class="fig" id="f0060"><img alt="Image" class="img" height="11" src="images/B978012415950100015X/fx040.jpg" width="131"/></figure></div><p class="textfl"> Does the construction still work?</p></div></div><p class="textfl"/><p class="text" id="p0325"/><div class="boxg1" id="enun0095"><p class="b1num">Exercise 6.6 </p><div><p class="b1textfl" id="p0330">Suppose, instead of a universal construction, you simply want to use consensus to implement a wait-free linearizable register with <img alt="Image" height="9" src="images/B978012415950100015X/fx041.jpg" width="25"/>() and <img alt="Image" height="12" src="images/B978012415950100015X/fx001.jpg" width="97"/> methods. Show how you would adapt this algorithm to do so.</p></div></div><p class="textfl"/><p class="text" id="p0335"/><div class="boxg1" id="enun0100"><p class="b1num">Exercise 6.7 </p><div><p class="b1textfl" id="p0340">In the wait-free universal construction shown in Section <a href="#s0025" id="cf0180">6.4</a>, each thread first looks for another thread to help, and then tries to append its own node.</p><p class="b1text" id="p0345">Suppose that instead, each thread first tries to append its own node, and then tries to help the other thread. Explain whether this alternative approach works. Justify your answer.</p></div></div><p class="textfl"/><p class="text" id="p0350"/><div class="boxg1" id="enun0105"><p class="b1num">Exercise 6.8 </p><div><p class="b1textfl" id="p0355">In the construction in <a href="#f0025" id="cf0185">Fig. 6.4</a>, we use a “distributed” implementation of a “head” reference (to the node whose <img alt="Image" height="9" src="images/B978012415950100015X/fx007.jpg" width="66"/> field it will try to modify) to avoid having to create an object that allows repeated consensus. Replace this implementation with one that has no head reference at all, and finds the next “head” by traversing down the log from the start until it reaches a node with a sequence number of 0 or with the highest nonzero sequence number.</p></div></div><p class="textfl"/><p class="text" id="p0360"/><div class="boxg1" id="enun0110"><p class="b1num">Exercise 6.9 </p><div><p class="b1textfl" id="p0365">In the wait-free protocol, a thread adds its newly appended node to the <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/> array on line 28 even though it may have already added it on line 26. This is done because, unlike in the lock-free protocol, it could be that the thread's node was added by another thread on line 26, and that “helping” thread stopped at line 26 right after updating the node's sequence number but before updating the <img alt="Image" height="12" src="images/B978012415950100015X/fx010.jpg" width="34"/> array.</p><div><ol><li class="b1numlist" id="o0010">1.  Explain how removing line 28 would violate <a href="#enun0040" id="cf0190">Lemma 6.4.4</a>.</li><li class="b1numlist" id="o0015">2.  Would the algorithm still work correctly?</li></ol></div><p class="b1textfl"/></div></div><p class="textfl"/><p class="text" id="p0380"/><div class="boxg1" id="enun0115"><p class="b1num">Exercise 6.10 </p><div><p class="b1textfl" id="p0385">Propose a way to fix the universal construction to work with a bounded amount of memory, that is, a bounded number of consensus objects and a bounded number of read–write registers.</p><p class="b1text" id="p0390">Hint: Add a <img alt="Image" height="9" src="images/B978012415950100015X/fx019.jpg" width="38"/> field to the nodes and build a memory recycling scheme into the code.</p></div></div><p class="textfl"/><p class="text" id="p0395"/><div class="boxg1" id="enun0120"><p class="b1num">Exercise 6.11 </p><div><p class="b1textfl" id="p0400">Implement a consensus object that is accessed more than once by each thread using <img alt="Image" height="9" src="images/B978012415950100015X/fx041.jpg" width="25"/>() and <img alt="Image" height="12" src="images/B978012415950100015X/fx001.jpg" width="97"/> methods, creating a “multiple access” consensus object. Do not use the universal construction.</p></div></div><p class="textfl"/><p class="text" id="p0405"><span aria-label="Page 143" epub:type="pagebreak" id="page_143" role="doc-pagebreak"/></p><div class="boxg1" id="enun0125"><p class="b1num">Exercise 6.12 </p><div><p class="b1textfl" id="p0410">Your mission is to transform a sequential stack implementation into a wait-free, linearizable stack implementation, without regard for questions of efficiency or memory use.</p><p class="b1text" id="p0415">You are given a “black-box” <img alt="Image" height="11" src="images/B978012415950100015X/fx042.jpg" width="52"/> type with the following methods: You can atomically <i>append</i> an item to the end of the sequence. For example, if the sequence is <span class="hiddenClass"><mml:math><mml:mo stretchy="false">〈</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">〉</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B978012415950100015X/si11.png" style="vertical-align:middle" width="51"/></span>, and you append 4, the sequence becomes <span class="hiddenClass"><mml:math><mml:mo stretchy="false">〈</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo stretchy="false">〉</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B978012415950100015X/si12.png" style="vertical-align:middle" width="66"/></span>. This operation is wait-free and linearizable: if a concurrent thread tries to append 5, the sequence becomes either <span class="hiddenClass"><mml:math><mml:mo stretchy="false">〈</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo stretchy="false">〉</mml:mo></mml:math></span><span><img alt="Image" height="15" src="images/B978012415950100015X/si13.png" style="vertical-align:middle" width="82"/></span>. or <span class="hiddenClass"><mml:math><mml:mo stretchy="false">〈</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo stretchy="false">〉</mml:mo></mml:math></span><span><img alt="Image" height="15" src="images/B978012415950100015X/si14.png" style="vertical-align:middle" width="82"/></span>. Note that <img alt="Image" height="11" src="images/B978012415950100015X/fx042.jpg" width="52"/> items <i>do not</i> have to be integers: they can be any kind of object you like.</p><p class="b1text" id="p0420">You can also iterate through the elements of a sequence. Here, we iterate through a sequence printing each value until we see the string <img alt="Image" height="11" src="images/B978012415950100015X/fx043.jpg" width="37"/>.</p><div class="pageavoid"><figure class="fig" id="f0065"><img alt="Image" class="img" height="60" src="images/B978012415950100015X/fx044.jpg" width="167"/></figure></div><p class="textfl"> (Note that if another thread is appending new values while you are iterating through a sequence, you might keep going forever.)</p><p class="b1text" id="p0425">Implement a wait-free linearizable stack using an atomic sequence object, and as much atomic read–write memory and sequential stack objects as you like. Your stack should support both <img alt="Image" height="11" src="images/B978012415950100015X/fx004.jpg" width="25"/>() and <img alt="Image" height="9" src="images/B978012415950100015X/fx038.jpg" width="18"/>() operations with the usual meanings. Again, do not worry about efficiency or memory use.</p><p class="b1text" id="p0430">Explain briefly why your construction is wait-free and linearizable (in particular, identify the linearization points).</p></div></div><p class="textfl"/></section><footer><section epub:type="bibliography" role="doc-bibliography"><div id="bl0235"><h2 class="reftitle" id="st0050">Bibliography</h2><p class="reflist" epub:type="biblioentry footnote" id="br0015" role="doc-biblioentry">[3] Yehuda Afek, Dalia Dauber, Dan Touitou,  Wait-free made fast,   <i>STOC '95: Proceedings of the Twenty-Seventh Annual ACM Symposium on Theory of Computing</i>.  New York, NY, USA: ACM Press; 1995:538–547.</p><p class="reflist1" epub:type="biblioentry footnote" id="br0055" role="doc-biblioentry">[11] James H. Anderson, Mark Moir,  Universal constructions for multi-object operations,   <i>PODC '95: Proceedings of the Fourteenth Annual ACM Symposium on Principles of Distributed Computing</i>.  New York, NY, USA: ACM Press; 1995:184–193.</p><p class="reflist1" epub:type="biblioentry footnote" id="br0135" role="doc-biblioentry">[27] Tushar Deepak Chandra, Prasad Jayanti, King Tan,  A polylog time wait-free construction for closed objects,   <i>PODC '98: Proceedings of the Seventeenth Annual ACM Symposium on Principles of Distributed Computing</i>.  New York, NY, USA: ACM Press; 1998:287–296.</p><p class="reflist1" epub:type="biblioentry footnote" id="br0325" role="doc-biblioentry">[65] M. Herlihy,  A methodology for implementing highly concurrent data objects,   <cite><i>ACM Transactions on Programming Languages and Systems</i></cite> November 1993;15(5):745–770.</p><p class="reflist1" epub:type="biblioentry footnote" id="br0340" role="doc-biblioentry">[68] M. Herlihy, V. Luchangco, M. Moir,  Obstruction-free synchronization: double-ended queues as an example,   <i>Proceedings of the 23rd International Conference on Distributed Computing Systems</i>.  IEEE; 2003:522–529.</p><p class="reflist1" epub:type="biblioentry footnote" id="br0345" role="doc-biblioentry">[69] Maurice Herlihy,  Wait-free synchronization,   <cite><i>ACM Transactions on Programming Languages and Systems</i></cite> 1991;13(1):124–149.</p><p class="reflist1" epub:type="biblioentry footnote" id="br0445" role="doc-biblioentry">[89] Prasad Jayanti,  A lower bound on the local time complexity of universal constructions,   <i>PODC '98: Proceedings of the Seventeenth Annual ACM Symposium on Principles of Distributed Computing</i>.  New York, NY, USA: ACM Press; 1998:183–192.</p><p class="reflist1" epub:type="biblioentry footnote" id="br0495" role="doc-biblioentry">[99] L. Lamport,  On interprocess communication,   <cite><i>Distributed Computing</i></cite> 1986;1:77–101.</p><p class="reflist2" epub:type="biblioentry footnote" id="br0525" role="doc-biblioentry">[105] Leslie Lamport,  On interprocess communication (part II),   <cite><i>Distributed Computing</i></cite> January 1986;1(1):203–213.</p><p class="reflist2" epub:type="biblioentry footnote" id="br0650" role="doc-biblioentry">[130] Mark Moir,  Laziness pays! Using lazy synchronization mechanisms to improve non-blocking constructions,   <i>PODC '00: Proceedings of the Nineteenth Annual ACM Symposium on Principles of Distributed Computing</i>.  New York, NY, USA: ACM Press; 2000:61–70.</p></div></section><section epub:type="rearnotes"><div class="ftnote"><hr/><p class="ftnote1" epub:type="footnote" id="fn001" role="doc-footnote"><sup><a epub:type="noteref" href="#cf0010" role="doc-noteref">1 </a></sup> <a id="np0010"/>“The situation with nondeterministic objects is significantly more complicated.”</p><p class="ftnote1" epub:type="footnote" id="fn002" role="doc-footnote"><sup><a epub:type="noteref" href="#cf0045" role="doc-noteref">2 </a></sup> <a id="np0015"/>“Creating a reusable consensus object, or even one whose decision is readable, is not a simple task. It is essentially the same problem as the universal construction we are about to design. For example, consider the queue-based consensus protocol in Section <a href="B9780124159501000148.xhtml">5.4</a>. It is not obvious how to use a <img alt="Image" height="11" src="images/B978012415950100015X/fx009.jpg" width="32"/> to allow repeated reading of the consensus object state after it is decided.”</p></div></section></footer></section></body></html>