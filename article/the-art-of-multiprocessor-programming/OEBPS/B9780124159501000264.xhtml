<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xmlns:mml="http://www.w3.org/1998/Math/MathML" lang="EN" xml:lang="en"><head><meta content="text/html; charset=utf-8" http-equiv="default-style"/><title>The Art of Multiprocessor Programming</title><link href="Elsevier_eBook.css" rel="stylesheet" type="text/css"/><link href="math.css" rel="stylesheet" type="text/css"/><link href="media.css" media="only screen" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:4f1c4a5b-a3e2-48ff-98f3-ff17812cd57a" name="Adept.expected.resource"/></head><body><section epub:type="chapter" role="doc-chapter"><div aria-label="Page 377" epub:type="pagebreak" id="page_377" role="doc-pagebreak"/><div id="CN"><a id="c0010tit1"/></div><header><hgroup><h1 class="chaptitle" id="c0010tit">Chapter 16: Scheduling and work distribution</h1></hgroup><section epub:type="preamble"><div class="abstract"><h2 class="h1hd" id="ab0010"><a id="st0010"/>Abstract</h2><p class="abspara">Some applications break down naturally into many parallel tasks. This chapter shows how to decompose and analyze such applications, introducing the notions of work and span. The chapter also introduces thread pools, an efficient and robust mechanism for executing such applications that insulates the programmer from platform-dependent details. Finally, it examines work stealing and other techniques for distributing the tasks among threads in a thread pool, and shows how to implement work stealing efficiently using specialized double-ended queues.</p></div></section><section id="ks0010"><h3 class="h2hd" id="st0015">Keywords</h3><p class="keywords">fork-join pools; thread pools; executor service; analysis of parallelism: work and span and speedup; greedy schedules; work distribution; work stealing; work balancing; double-ended queue (deque)</p></section></header><section><h2 class="h1hd" id="s0010"><a id="st0020"/>16.1 Introduction</h2><p class="textfl" id="p0010">In this chapter, we show how to decompose certain kinds of tasks into subtasks that can be executed in parallel. Some applications break down naturally into parallel tasks. For example, when a request arrives at a web server, the server can just create a thread (or assign an existing thread) to handle the request. Applications that can be structured as producers and consumers also tend to be easily parallelizable. In this chapter, however, we look at applications that have inherent parallelism, but where it may not be obvious how to take advantage of it.</p><p class="text" id="p0015">Let us start by thinking about how to multiply two matrices in parallel. Recall that if <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></span><span><img alt="Image" height="11" src="images/B9780124159501000264/si1.png" style="vertical-align:middle" width="20"/></span> is the value at position <span class="hiddenClass"><mml:math><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000264/si2.png" style="vertical-align:middle" width="33"/></span> of matrix <i>A</i>, then the product <i>C</i> of two <span class="hiddenClass"><mml:math><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:math></span><span><img alt="Image" height="8" src="images/B9780124159501000264/si3.png" style="vertical-align:middle" width="39"/></span> matrices <i>A</i> and <i>B</i> is given by</p><p class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="badbreak" linebreakstyle="after">=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo linebreak="badbreak" linebreakstyle="after">=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo linebreak="badbreak" linebreakstyle="after">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:math></p><div class="showClass"><p class="fig"><img alt="Image" height="65" src="images/B9780124159501000264/si4.png" width="160"/><a id="deq1"/></p></div><p class="textfl"> As a first step, we could put one thread in charge of computing each <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></span><span><img alt="Image" height="11" src="images/B9780124159501000264/si5.png" style="vertical-align:middle" width="18"/></span>. <a href="#f0010" id="cf0010">Fig. 16.1</a> shows a matrix multiplication program that creates an <span class="hiddenClass"><mml:math><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:math></span><span><img alt="Image" height="8" src="images/B9780124159501000264/si3.png" style="vertical-align:middle" width="39"/></span> array of <img alt="Image" height="9" src="images/B9780124159501000264/fx001.jpg" width="39"/> threads (line 14), where the worker thread in position <span class="hiddenClass"><mml:math><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000264/si2.png" style="vertical-align:middle" width="33"/></span> computes <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></span><span><img alt="Image" height="11" src="images/B9780124159501000264/si5.png" style="vertical-align:middle" width="18"/></span>. The program starts each task (line 19) and then waits for each one to finish (line 25).<sup><a epub:type="noteref" href="#fn001" id="cf0015" role="doc-noteref">1</a></sup> Each worker computes one entry in the product matrix (<a href="#f0015" id="cf0020">Fig. 16.2</a>).</p><div class="pageavoid"><figure class="fig" id="f0010"><img alt="Image" height="487" src="images/B9780124159501000264/gr001.jpg" width="328"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 16.1</span> The <img alt="Image" height="9" src="images/B9780124159501000264/fx002.jpg" width="52"/> task: matrix multiplication using threads.</div></figcaption></figure></div><div class="pageavoid"><figure class="fig" id="f0015"><img alt="Image" height="224" src="images/B9780124159501000264/gr002.jpg" width="306"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 16.2</span> The <img alt="Image" height="9" src="images/B9780124159501000264/fx002.jpg" width="52"/> task: inner <img alt="Image" height="9" src="images/B9780124159501000264/fx001.jpg" width="39"/> thread class.</div></figcaption></figure></div><p class="text" id="p0020">At first glance, this design seems ideal: The program is highly parallel, and the threads do not even have to synchronize. In practice, this design would perform poorly for all but very small matrices. Here is why: Threads require memory for stacks and other bookkeeping information. Creating, scheduling, and destroying threads takes a substantial amount of computation. Creating lots of short-lived threads is an inefficient way to organize a multithreaded computation, like manufacturing a new car whenever you need to run an errand, and scrapping it when you are done.</p><p class="text" id="p0025">A more effective way to organize such a program is to create a <i>pool</i> of long-lived threads. Each thread in the pool repeatedly waits until it is assigned a <i>task</i>, a short-lived unit of computation. The thread executes its assigned task, and when the task is complete, the thread rejoins the pool to await its next assignment. <span aria-label="Page 378" epub:type="pagebreak" id="page_378" role="doc-pagebreak"/>Thread pools can be platform-dependent: For example, large-scale multiprocessors may provide large pools, and small multiprocessors may provide small pools. Thread pools avoid the cost of creating and destroying threads in response to short-term fluctuations in demand. Using a thread pool is like calling a taxi or ride sharing service whenever you need to run an errand.</p><p class="text" id="p0030">In addition to performance benefits, thread pools have a less obvious but equally important advantage: they insulate application programmers from platform-specific details such as the number of concurrent threads that can be scheduled efficiently. Thread pools make it possible to write a single program that runs equally well on a uniprocessor, a small-scale multiprocessor, and a large-scale multiprocessor. They provide a simple interface that hides complex, platform-dependent engineering trade-offs.</p><p class="text" id="p0035"><span aria-label="Page 379" epub:type="pagebreak" id="page_379" role="doc-pagebreak"/>In Java, thread pools are given a uniform structure through the <i>executor service</i> interface (<img alt="Image" height="11" src="images/B9780124159501000264/fx004.jpg" width="167"/>). This interface provides methods to submit a task, to wait for a set of submitted tasks to complete, and to cancel uncompleted tasks. There are many different kinds of thread pools, adapted to many different kinds of tasks and scheduling strategies. Here, we restrict our attention to one particular executor service, called <img alt="Image" height="9" src="images/B9780124159501000264/fx005.jpg" width="76"/>, intended for tasks that can split their work into smaller parallel tasks.</p><p class="text" id="p0040">Fork-join tasks that return a value of type <img alt="Image" height="9" src="images/B9780124159501000264/fx006.jpg" width="5"/> inherit from <img alt="Image" height="9" src="images/B9780124159501000264/fx007.jpg" width="106"/>, while those that produce only side effects inherit from <img alt="Image" height="9" src="images/B9780124159501000264/fx008.jpg" width="99"/>. A task's <img alt="Image" height="9" src="images/B9780124159501000264/fx009.jpg" width="25"/>() method allocates a thread from the pool to execute that task, and the task's <img alt="Image" height="11" src="images/B9780124159501000264/fx010.jpg" width="25"/>() method allows the caller to wait for that task to complete. A task's work is done by its <img alt="Image" height="12" src="images/B9780124159501000264/fx011.jpg" width="57"/> method. Fork-join tasks work best when tasks do not acquire locks, and all tasks are of roughly equal size.</p><p class="text" id="p0045">Here is the simplest way to create a fork-join pool:</p><div class="pageavoid"><figure class="fig" id="f0025"><img alt="Image" class="img" height="11" src="images/B9780124159501000264/fx012.jpg" width="281"/></figure></div><p class="textfl"> This call creates a pool where the number of threads is determined by the available resources. It is also possible to request a specific number of threads, and to set a number of other, more advanced parameters.</p><p class="text" id="p0050">It is important to understand that assigning a task to a thread (“forking” that task) does not guarantee that any computation actually happens in parallel. Instead, forking a task is <i>advisory</i>: It tells the underlying thread pool that it may execute that task in parallel, if it has the resources to do so.</p><p class="text" id="p0055">We now consider how to implement parallel matrix operations using fork-join tasks. <a href="#f0020" id="cf0025">Fig. 16.3</a> shows a <img alt="Image" height="9" src="images/B9780124159501000264/fx003.jpg" width="39"/> class that provides <img alt="Image" height="11" src="images/B9780124159501000264/fx013.jpg" width="19"/>() and <img alt="Image" height="8" src="images/B9780124159501000264/fx014.jpg" width="18"/>() methods to access matrix elements (lines 16–21), <span aria-label="Page 380" epub:type="pagebreak" id="page_380" role="doc-pagebreak"/>along with a constant-time <img alt="Image" height="11" src="images/B9780124159501000264/fx015.jpg" width="32"/>() method that splits an <i>n</i>-by-<i>n</i> matrix into four <span class="hiddenClass"><mml:math><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">/</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000264/si6.png" style="vertical-align:middle" width="37"/></span>-by-<span class="hiddenClass"><mml:math><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">/</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000264/si6.png" style="vertical-align:middle" width="37"/></span> submatrices (lines 25–31). These submatrices are <i>backed</i> by the original matrix, meaning that changes to the submatrices are reflected in the original, and vice versa. This class also provides methods (not shown) to add and multiply matrices in the usual sequential way.</p><div class="pageavoid"><figure class="fig" id="f0020"><img alt="Image" height="536" src="images/B9780124159501000264/gr003.jpg" width="351"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 16.3</span> The <img alt="Image" height="9" src="images/B9780124159501000264/fx003.jpg" width="39"/> class.</div></figcaption></figure></div><p class="text" id="p0060">For simplicity, we consider only matrices whose dimension <i>n</i> is a power of 2. Any such matrix can be decomposed into four submatrices:</p><p class="hiddenClass"><mml:math><mml:mi>A</mml:mi><mml:mo linebreak="badbreak" linebreakstyle="after">=</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mtable columnspacing="0em"><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>00</mml:mn></mml:mrow></mml:msub><mml:mspace width="1em"/></mml:mtd><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>01</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mspace width="1em"/></mml:mtd><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:math></p><div class="showClass"><p class="fig"><img alt="Image" height="53" src="images/B9780124159501000264/si7.png" width="192"/><a id="deq2"/></p></div><p class="textfl"><span aria-label="Page 381" epub:type="pagebreak" id="page_381" role="doc-pagebreak"/> Matrix addition <span class="hiddenClass"><mml:math><mml:mi>C</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mi>A</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">+</mml:mo><mml:mi>B</mml:mi></mml:math></span><span><img alt="Image" height="13" src="images/B9780124159501000264/si8.png" style="vertical-align:middle" width="75"/></span> can be decomposed as follows:</p><p class="hiddenClass"><mml:math><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mtable columnspacing="0em"><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>00</mml:mn></mml:mrow></mml:msub><mml:mspace width="1em"/></mml:mtd><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>01</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mspace width="1em"/></mml:mtd><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo id="mmlbr0001" linebreak="badbreak" linebreakstyle="after">=</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mtable columnspacing="0em"><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>00</mml:mn></mml:mrow></mml:msub><mml:mspace width="1em"/></mml:mtd><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>01</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mspace width="1em"/></mml:mtd><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">+</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mtable columnspacing="0em"><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>00</mml:mn></mml:mrow></mml:msub><mml:mspace width="1em"/></mml:mtd><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>01</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mspace width="1em"/></mml:mtd><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo indentalign="id" indenttarget="mmlbr0001" linebreak="newline" linebreakstyle="before">=</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mtable columnspacing="0em"><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>00</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>00</mml:mn></mml:mrow></mml:msub><mml:mspace width="1em"/></mml:mtd><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>01</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>01</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mspace width="1em"/></mml:mtd><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:math></p><div class="showClass"><p class="fig"><img alt="Image" height="115" src="images/B9780124159501000264/si9.png" width="500"/><a id="deq3"/></p></div><p class="textfl"> These four sums can be done in parallel.</p><p class="text" id="p0065"><a href="#f0030" id="cf0030">Fig. 16.4</a> shows the <img alt="Image" height="9" src="images/B9780124159501000264/fx016.jpg" width="86"/> class, a parallel matrix addition class based on the fork-join framework. Because the <img alt="Image" height="9" src="images/B9780124159501000264/fx016.jpg" width="86"/> does not return a result, it extends <img alt="Image" height="9" src="images/B9780124159501000264/fx008.jpg" width="99"/>. It has three fields (lines 5–8), initialized by the constructor: <img alt="Image" height="9" src="images/B9780124159501000264/fx017.jpg" width="18"/> (“left-hand side”) and <img alt="Image" height="9" src="images/B9780124159501000264/fx018.jpg" width="18"/> (“right-hand side”) are the matrices to be summed, and <img alt="Image" height="6" src="images/B9780124159501000264/fx019.jpg" width="19"/> is the result, which is updated in place. Each task does the following: If the matrix size falls below a certain platform-dependent threshold, the sum is computed sequentially (lines 12–13). Otherwise, it creates new recursive tasks for each of its arguments' four submatrices and places them in a list (lines 16–25). It then forks each of those tasks (lines 27–28), and then joins them<sup><a epub:type="noteref" href="#fn002" id="cf0035" role="doc-noteref">2</a></sup> (lines 30–31). Note that the order of the forks and joins is important: to maximize the opportunity for parallelism, we must complete all <img alt="Image" height="9" src="images/B9780124159501000264/fx009.jpg" width="25"/>() calls before making any <img alt="Image" height="11" src="images/B9780124159501000264/fx010.jpg" width="25"/>() calls.</p><div class="pageavoid"><figure class="fig" id="f0030"><img alt="Image" height="553" src="images/B9780124159501000264/gr004.jpg" width="383"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 16.4</span> The <img alt="Image" height="9" src="images/B9780124159501000264/fx016.jpg" width="86"/> class: fork-join parallel matrix addition.</div></figcaption></figure></div><p class="text" id="p0070"><a href="#f0035" id="cf0040">Fig. 16.5</a> shows how to set up a simple matrix addition using a fork-join pool. The top-level code initializes the three matrices (lines 1–3) and creates a top-level task (line 4) and a fork-join pool (line 5). The pool's <img alt="Image" height="12" src="images/B9780124159501000264/fx020.jpg" width="50"/> method (line 6) schedules the top-level task, which splits itself into smaller parallel tasks, and returns when the entire computation is complete.</p><div class="pageavoid"><figure class="fig" id="f0035"><img alt="Image" height="92" src="images/B9780124159501000264/gr005.jpg" width="409"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 16.5</span> Top-level code for matrix addition.</div></figcaption></figure></div><p class="text" id="p0075">Matrix multiplication <span class="hiddenClass"><mml:math><mml:mi>C</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mi>A</mml:mi><mml:mo>⋅</mml:mo><mml:mi>B</mml:mi></mml:math></span><span><img alt="Image" height="11" src="images/B9780124159501000264/si10.png" style="vertical-align:middle" width="67"/></span> can be decomposed as follows:</p><p class="hiddenClass"><mml:math><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mtable columnspacing="0em"><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>00</mml:mn></mml:mrow></mml:msub><mml:mspace width="0.2em"/></mml:mtd><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>01</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mspace width="0.2em"/></mml:mtd><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo id="mmlbr0002" linebreak="badbreak" linebreakstyle="after">=</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mtable columnspacing="0em"><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>00</mml:mn></mml:mrow></mml:msub><mml:mspace width="0.2em"/></mml:mtd><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>01</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mspace width="0.2em"/></mml:mtd><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mtable columnspacing="0em"><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>00</mml:mn></mml:mrow></mml:msub><mml:mspace width="0.2em"/></mml:mtd><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>01</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mspace width="0.2em"/></mml:mtd><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo indentalign="id" indenttarget="mmlbr0002" linebreak="newline" linebreakstyle="before">=</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mtable columnspacing="0em"><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>00</mml:mn></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>00</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>01</mml:mn></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mspace width="0.2em"/></mml:mtd><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>00</mml:mn></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>01</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>01</mml:mn></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>00</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mspace width="0.2em"/></mml:mtd><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>01</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo indentalign="id" indenttarget="mmlbr0002" linebreak="newline" linebreakstyle="before">=</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mtable columnspacing="0em"><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>00</mml:mn></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>00</mml:mn></mml:mrow></mml:msub><mml:mspace width="0.2em"/></mml:mtd><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>00</mml:mn></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>01</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>00</mml:mn></mml:mrow></mml:msub><mml:mspace width="0.2em"/></mml:mtd><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>01</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">+</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mtable columnspacing="0em"><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>01</mml:mn></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mspace width="0.2em"/></mml:mtd><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>01</mml:mn></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mspace width="0.2em"/></mml:mtd><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:math></p><div class="showClass"><p class="fig"><img alt="Image" height="178" src="images/B9780124159501000264/si11.png" width="701"/><a id="deq4"/></p></div><p class="textfl"/><p class="text" id="p0080">The eight product terms can be computed in parallel, and when those computations are done, the sum can be computed. (We have seen that the matrix summation program itself has internal parallelism.)</p><p class="text" id="p0085"><a href="#f0040" id="cf0045">Fig. 16.6</a> shows the parallel matrix multiplication task. Matrix multiplication is structured in a similar way to addition. Because the <img alt="Image" height="9" src="images/B9780124159501000264/fx021.jpg" width="86"/> does not return a result, it extends <img alt="Image" height="9" src="images/B9780124159501000264/fx008.jpg" width="99"/>. It has three fields (lines 4–7) initialized by the constructor: <img alt="Image" height="9" src="images/B9780124159501000264/fx017.jpg" width="18"/> and <img alt="Image" height="9" src="images/B9780124159501000264/fx018.jpg" width="18"/> are the matrices to be multiplied, and <img alt="Image" height="11" src="images/B9780124159501000264/fx022.jpg" width="45"/> is the result, updated in place. Each <span aria-label="Page 382" epub:type="pagebreak" id="page_382" role="doc-pagebreak"/><span aria-label="Page 383" epub:type="pagebreak" id="page_383" role="doc-pagebreak"/>task does the following: If the matrix size falls below a certain platform-dependent threshold, the product is computed sequentially (lines 11–12). Otherwise, it allocates two temporary matrices to hold intermediate terms (line 15). It then creates new, recursive tasks for each of the eight submatrix products, and places them in a list (lines 16–28). <span aria-label="Page 384" epub:type="pagebreak" id="page_384" role="doc-pagebreak"/>It then forks each of those tasks (lines 29–30), and then joins them (lines 32–33). Finally, it creates a new <img alt="Image" height="9" src="images/B9780124159501000264/fx016.jpg" width="86"/> to sum the temporary matrices, and calls its <img alt="Image" height="12" src="images/B9780124159501000264/fx011.jpg" width="57"/> method directly (line 35).</p><div class="pageavoid"><figure class="fig" id="f0040"><img alt="Image" height="618" src="images/B9780124159501000264/gr006.jpg" width="410"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 16.6</span> The <img alt="Image" height="9" src="images/B9780124159501000264/fx021.jpg" width="86"/> class: fork-join parallel matrix addition.</div></figcaption></figure></div><p class="text" id="p0090">The matrix examples use fork-join tasks only for their side effects. Fork-join tasks can also be used to pass values from completed tasks. For example, here is how to decompose the well-known Fibonacci function into a multithreaded program. Recall that the Fibonacci sequence is defined as follows:</p><p class="hiddenClass"><mml:math><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo linebreak="badbreak" linebreakstyle="after">=</mml:mo><mml:mrow><mml:mo stretchy="true">{</mml:mo><mml:mtable columnspacing="0em"><mml:mtr><mml:mtd columnalign="left"><mml:mn>0</mml:mn><mml:mspace width="1em"/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>if </mml:mtext><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mtext>,</mml:mtext></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mn>1</mml:mn><mml:mspace width="1em"/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>if </mml:mtext><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mtext>,</mml:mtext></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mspace width="1em"/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>if </mml:mtext><mml:mi>n</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></p><div class="showClass"><p class="fig"><img alt="Image" height="80" src="images/B9780124159501000264/si12.png" width="384"/><a id="deq5"/></p></div><p class="textfl"> <a href="#f0045" id="cf0050">Fig. 16.7</a> shows one way to use fork-join tasks to compute Fibonacci numbers. (This particular implementation is very inefficient, but we use it here to illustrate multithreaded dependencies.) The <img alt="Image" height="12" src="images/B9780124159501000264/fx011.jpg" width="57"/> method creates and forks a <i>right</i> subtask to compute <span class="hiddenClass"><mml:math><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo linebreak="badbreak" linebreakstyle="after">−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000264/si13.png" style="vertical-align:middle" width="60"/></span>. It then creates a <i>left</i> subtask to compute <span class="hiddenClass"><mml:math><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo linebreak="badbreak" linebreakstyle="after">−</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000264/si14.png" style="vertical-align:middle" width="60"/></span>, and calls that task's <img alt="Image" height="12" src="images/B9780124159501000264/fx011.jpg" width="57"/> method directly. It then joins the right task, and sums the subtasks' results. (Think about why this structure is more efficient than forking both subtasks.)<span aria-label="Page 385" epub:type="pagebreak" id="page_385" role="doc-pagebreak"/></p><div class="pageavoid"><figure class="fig" id="f0045"><img alt="Image" height="257" src="images/B9780124159501000264/gr007.jpg" width="325"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 16.7</span> The <img alt="Image" height="9" src="images/B9780124159501000264/fx023.jpg" width="45"/> class: Fibonacci using fork-join tasks.</div></figcaption></figure></div></section><section><h2 class="h1hd" id="s0015"><a id="st0025"/>16.2 Analyzing parallelism</h2><p class="textfl" id="p0095">Think of a multithreaded computation as a <i>directed acyclic graph</i>, or <i>dag</i> for short, where each node represents a task, and each directed edge links a <i>predecessor</i> task to a <i>successor</i> task, where the successor depends on the predecessor's result. For example, a conventional thread is just a chain of nodes where each node depends on its predecessor. By contrast, a node that forks a task has two successors: One node is its successor in the same thread, and the other is the first node in the forked task's computation. There is also an edge in the other direction, from child to parent, that occurs when a thread that has forked a task calls that task's <img alt="Image" height="11" src="images/B9780124159501000264/fx010.jpg" width="25"/>() method, waiting for the child computation to complete. <a href="#f0050" id="cf0055">Fig. 16.8</a> shows the dag corresponding to a short Fibonacci execution.</p><div class="pageavoid"><figure class="fig" id="f0050"><img alt="Image" height="243" src="images/B9780124159501000264/gr008.jpg" width="383"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 16.8</span> The dag created by a multithreaded Fibonacci execution. The caller creates a FibTask(4) task, which in turn creates FibTask(3) and FibTask(2) tasks. The round nodes represent computation steps and the arrows between the nodes represent dependencies. For example, there are arrows pointing from the first two nodes in FibTask(4) to the first nodes in FibTask(3) and FibTask(2), respectively, representing <img alt="Image" height="9" src="images/B9780124159501000264/fx009.jpg" width="25"/>() calls, and arrows from the last nodes in FibTask(3) and FibTask(2) to the last node in FibTask(4), representing <img alt="Image" height="11" src="images/B9780124159501000264/fx010.jpg" width="25"/>() calls. The computation's span has length 8 and is marked by numbered nodes.</div></figcaption></figure></div><p class="text" id="p0100">Some computations are inherently more parallel than others. Let us make this notion precise. Assume that all individual computation steps take the same amount of time, which constitutes our basic measuring unit. Let <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:math></span><span><img alt="Image" height="13" src="images/B9780124159501000264/si15.png" style="vertical-align:middle" width="19"/></span> be the minimum time (measured in computation steps) needed to execute a multithreaded program on a system of <i>P</i> dedicated processors. <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:math></span><span><img alt="Image" height="13" src="images/B9780124159501000264/si15.png" style="vertical-align:middle" width="19"/></span> is thus the program's <i>latency</i>, the time it would take it to run from start to finish, as measured by an outside observer. We emphasize that <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:math></span><span><img alt="Image" height="13" src="images/B9780124159501000264/si15.png" style="vertical-align:middle" width="19"/></span> is an idealized measure: It may not always be possible for every processor to find steps to execute, and actual computation time may be limited by other concerns, such as memory usage. Nevertheless, <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:math></span><span><img alt="Image" height="13" src="images/B9780124159501000264/si15.png" style="vertical-align:middle" width="19"/></span> is clearly a lower bound on how much parallelism one can extract from a multithreaded computation.</p><p class="text" id="p0105">Some instances of <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:math></span><span><img alt="Image" height="13" src="images/B9780124159501000264/si15.png" style="vertical-align:middle" width="19"/></span> are important enough to have special names. <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></span><span><img alt="Image" height="13" src="images/B9780124159501000264/si16.png" style="vertical-align:middle" width="15"/></span>, the number of steps needed to execute the program on a single processor, is called the computation's <i>work</i>. Work is also the total number of steps in the entire computation. In one time step (of the outside observer), <i>P</i> processors can execute <span aria-label="Page 386" epub:type="pagebreak" id="page_386" role="doc-pagebreak"/>at most <i>P</i> computation steps, yielding the following <i>work law</i>:</p><p class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mo>⩾</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">/</mml:mo><mml:mi>P</mml:mi><mml:mo>.</mml:mo></mml:math></p><div class="showClass"><p class="fig"><img alt="Image" height="19" src="images/B9780124159501000264/si17.png" width="105"/><a id="deq6"/><span class="eqnum">(16.2.1) </span></p></div><p class="textfl"> The other extreme is also of special importance: <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo>∞</mml:mo></mml:mrow></mml:msub></mml:math></span><span><img alt="Image" height="13" src="images/B9780124159501000264/si18.png" style="vertical-align:middle" width="22"/></span>, the number of steps to execute the program on an unlimited number of processors, is called the <i>span</i>.<sup><a epub:type="noteref" href="#fn003" id="cf0060" role="doc-noteref">3</a></sup> Because finite resources cannot do better than infinite resources, we have the following <i>span law</i>:</p><p class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mo>⩾</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo>∞</mml:mo></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:math></p><div class="showClass"><p class="fig"><img alt="Image" height="18" src="images/B9780124159501000264/si19.png" width="87"/><a id="deq7"/><span class="eqnum">(16.2.2) </span></p></div><p class="textfl"> The <i>speedup</i> on <i>P</i> processors is the ratio</p><p class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">/</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:math></p><div class="showClass"><p class="fig"><img alt="Image" height="19" src="images/B9780124159501000264/si20.png" width="64"/><a id="deq8"/></p></div><p class="textfl"> We say a computation has <i>linear speedup</i> if <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">/</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000264/si21.png" style="vertical-align:middle" width="100"/></span>. Finally, a computation's <i>parallelism</i> is the maximum possible speedup: <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">/</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo>∞</mml:mo></mml:mrow></mml:msub></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000264/si22.png" style="vertical-align:middle" width="46"/></span>. A computation's parallelism is also the <i>average</i> amount of work available at each step along its longest path, and so provides a good estimate of the number of processors one should devote to a computation. In particular, it makes little sense to use substantially more processors than dictated by the problem's parallelism.</p><p class="text" id="p0110">To illustrate these concepts, we now revisit the concurrent matrix add and multiply implementations introduced in Section <a href="#s0010" id="cf0065">16.1</a>.</p><p class="text" id="p0115">Let <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000264/si23.png" style="vertical-align:middle" width="44"/></span> be the number of steps needed to add two <span class="hiddenClass"><mml:math><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:math></span><span><img alt="Image" height="8" src="images/B9780124159501000264/si3.png" style="vertical-align:middle" width="39"/></span> matrices on <i>P</i> processors. The matrix addition requires four half-size matrix additions, plus a constant amount of work to split the matrices. The work <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000264/si24.png" style="vertical-align:middle" width="41"/></span> is given by the recurrence</p><p class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo id="mmlbr0003" linebreak="badbreak" linebreakstyle="after">=</mml:mo><mml:mn>4</mml:mn><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">/</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo linebreak="goodbreak" linebreakstyle="after">+</mml:mo><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo indentalign="id" indenttarget="mmlbr0003" linebreak="newline" linebreakstyle="before">=</mml:mo><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:math></p><div class="showClass"><p class="fig"><img alt="Image" height="52" src="images/B9780124159501000264/si25.png" width="272"/><a id="deq9"/></p></div><p class="textfl"> This work is the same as the conventional doubly nested loop implementation.</p><p class="text" id="p0120">Because the half-size additions can be done in parallel, the span is</p><p class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mo>∞</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo id="mmlbr0004" linebreak="badbreak" linebreakstyle="after">=</mml:mo><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mo>∞</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">/</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo linebreak="goodbreak" linebreakstyle="after">+</mml:mo><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo indentalign="id" indenttarget="mmlbr0004" linebreak="newline" linebreakstyle="before">=</mml:mo><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:math></p><div class="showClass"><p class="fig"><img alt="Image" height="53" src="images/B9780124159501000264/si26.png" width="278"/><a id="deq10"/></p></div><p class="textfl"> Let <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000264/si27.png" style="vertical-align:middle" width="47"/></span> be the number of steps needed to multiply two <span class="hiddenClass"><mml:math><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:math></span><span><img alt="Image" height="8" src="images/B9780124159501000264/si3.png" style="vertical-align:middle" width="39"/></span> matrices on <i>P</i> processors. The matrix multiplication requires eight half-size matrix multiplications and one full-size matrix addition. The work <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000264/si28.png" style="vertical-align:middle" width="43"/></span> is given by the recurrence</p><p class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo id="mmlbr0005" linebreak="badbreak" linebreakstyle="after">=</mml:mo><mml:mn>8</mml:mn><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">/</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo linebreak="goodbreak" linebreakstyle="after">+</mml:mo><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo indentalign="id" indenttarget="mmlbr0005" linebreak="newline" linebreakstyle="before">=</mml:mo><mml:mn>8</mml:mn><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">/</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo linebreak="goodbreak" linebreakstyle="after">+</mml:mo><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo indentalign="id" indenttarget="mmlbr0005" linebreak="newline" linebreakstyle="before">=</mml:mo><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:math></p><div class="showClass"><p class="fig"><img alt="Image" height="84" src="images/B9780124159501000264/si29.png" width="290"/><a id="deq11"/></p></div><p class="textfl"><span aria-label="Page 387" epub:type="pagebreak" id="page_387" role="doc-pagebreak"/> This work is also the same as the conventional triply nested loop implementation. The half-size multiplications can be done in parallel, but the addition cannot start until the multiplications are complete, so the span is</p><p class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mo>∞</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo id="mmlbr0006" linebreak="badbreak" linebreakstyle="after">=</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mo>∞</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">/</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo linebreak="goodbreak" linebreakstyle="after">+</mml:mo><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mo>∞</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo indentalign="id" indenttarget="mmlbr0006" linebreak="newline" linebreakstyle="before">=</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mo>∞</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">/</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo linebreak="goodbreak" linebreakstyle="after">+</mml:mo><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo indentalign="id" indenttarget="mmlbr0006" linebreak="newline" linebreakstyle="before">=</mml:mo><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:msup><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:math></p><div class="showClass"><p class="fig"><img alt="Image" height="84" src="images/B9780124159501000264/si30.png" width="318"/><a id="deq12"/></p></div><p class="textfl"> The parallelism for matrix multiplication is given by</p><p class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">/</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mo>∞</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo linebreak="badbreak" linebreakstyle="after">=</mml:mo><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">/</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>⁡</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:math></p><div class="showClass"><p class="fig"><img alt="Image" height="25" src="images/B9780124159501000264/si31.png" width="288"/><a id="deq13"/></p></div><p class="textfl"> which is pretty high. For example, suppose we want to multiply two 1000-by-1000 matrices. Here, <span class="hiddenClass"><mml:math><mml:msup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mn>9</mml:mn></mml:mrow></mml:msup></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000264/si32.png" style="vertical-align:middle" width="60"/></span>, and <span class="hiddenClass"><mml:math><mml:mi mathvariant="normal">log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>n</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mi mathvariant="normal">log</mml:mi><mml:mo>⁡</mml:mo><mml:mn>1000</mml:mn><mml:mo>≈</mml:mo><mml:mn>10</mml:mn></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000264/si33.png" style="vertical-align:middle" width="143"/></span> (logs are base 2), so the parallelism is approximately <span class="hiddenClass"><mml:math><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mn>9</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">/</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mn>7</mml:mn></mml:mrow></mml:msup></mml:math></span><span><img alt="Image" height="17" src="images/B9780124159501000264/si34.png" style="vertical-align:middle" width="95"/></span>. Roughly speaking, this instance of matrix multiplication could, in principle, keep roughly ten million processors busy, a number well beyond the powers of any multiprocessor we are likely to see in the near future.</p><p class="text" id="p0125">You should understand that a computation's parallelism is a highly idealized upper bound on the performance of any multithreaded matrix multiplication program. For example, when there are idle threads, it may not be easy to assign those threads to idle processors. Moreover, a program that displays less parallelism but consumes less memory may perform better because it encounters fewer page faults. The actual performance of a multithreaded computation remains a complex engineering problem, but the kind of analysis presented in this chapter is an indispensable first step in understanding the degree to which a problem can be solved in parallel.</p></section><section><h2 class="h1hd" id="s0020"><a id="st0030"/>16.3 Realistic multiprocessor scheduling</h2><p class="textfl" id="p0130">Our analysis so far has been based on the assumption that each multithreaded program has <i>P</i> dedicated processors. This assumption, unfortunately, is not realistic. Multiprocessors typically run a mix of jobs, where jobs come and go dynamically. One might start, say, a matrix multiplication application on <i>P</i> processors. At some point, the operating system may decide to download a new software upgrade, preempting one processor, and the application then runs on <span class="hiddenClass"><mml:math><mml:mi>P</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">−</mml:mo><mml:mn>1</mml:mn></mml:math></span><span><img alt="Image" height="11" src="images/B9780124159501000264/si35.png" style="vertical-align:middle" width="39"/></span> processors. The upgrade program pauses waiting for a disk read or write to complete, and in the interim the matrix application has <i>P</i> processors again.</p><p class="text" id="p0135">Modern operating systems provide user-level <i>threads</i> that encompass a program counter and a stack. (A thread that includes its own address space is often called a <i>process</i>.) The operating system kernel includes a <i>scheduler</i> that runs threads on physical processors. The application, however, typically has no control over the mapping between threads and processors, and so cannot control when threads are scheduled.</p><p class="text" id="p0140">As we have seen, one way to bridge the gap between user-level threads and operating system-level processors is to provide the software developer <span aria-label="Page 388" epub:type="pagebreak" id="page_388" role="doc-pagebreak"/>with a three-level model. At the top level, multithreaded programs (such as matrix multiplication) decompose an application into a dynamically varying number of short-lived <i>tasks</i>. At the middle level, a user-level <i>scheduler</i> maps these tasks to a fixed number of <i>threads</i>. At the bottom level, the <i>kernel</i> maps these threads onto hardware <i>processors</i>, whose availability may vary dynamically. This last level of mapping is not under the application's control: Applications cannot tell the kernel how to schedule threads (indeed, commercially available operating systems kernels are hidden from users).</p><p class="text" id="p0145">Assume for simplicity that the kernel works in discrete steps: At step <i>i</i>, the kernel chooses an arbitrary subset of user-level threads to run for one step. A node is <i>ready</i> at a step if its associated computational step in the program dag is ready to execute. A schedule is <i>greedy</i> if it executes as many of the ready nodes as possible.</p><p class="text" id="p0150"/><div class="boxg1" id="enun0010"><p class="b1num">Theorem 16.3.1 </p><div><p class="b1textfl" id="p0155">For a multithreaded program with work <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></span><span><img alt="Image" height="13" src="images/B9780124159501000264/si16.png" style="vertical-align:middle" width="15"/></span>, span <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo>∞</mml:mo></mml:mrow></mml:msub></mml:math></span><span><img alt="Image" height="13" src="images/B9780124159501000264/si18.png" style="vertical-align:middle" width="22"/></span>, and <i>P</i> user-level threads, any greedy execution has length <i>T</i>, which is at most</p><p class="hiddenClass"><mml:math><mml:mi>T</mml:mi><mml:mo>⩽</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:mfrac><mml:mo linebreak="badbreak" linebreakstyle="after">+</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo>∞</mml:mo></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:math></p><div class="showClass"><p class="fig"><img alt="Image" height="46" src="images/B9780124159501000264/si36.png" width="129"/><a id="deq14"/></p></div><p class="b1textfl"/></div></div><p class="textfl"> </p><div class="boxg1" id="enun0015"><p class="b1num">Proof </p><div><p class="b1textfl" id="p0160">Let <i>P</i> be the number of available processors. A <i>complete step</i> is one where at least <i>P</i> nodes are ready, so a greedy schedule runs some choice of <i>P</i> nodes. By contrast, an <i>incomplete step</i> is one where fewer than <i>P</i> nodes are ready, so a greedy schedule runs them all. Every step in the execution is either complete or incomplete. The number of complete steps cannot exceed <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">/</mml:mo><mml:mi>P</mml:mi></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000264/si37.png" style="vertical-align:middle" width="36"/></span>, because each such step executes <i>P</i> nodes. The number of incomplete steps cannot exceed <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo>∞</mml:mo></mml:mrow></mml:msub></mml:math></span><span><img alt="Image" height="13" src="images/B9780124159501000264/si18.png" style="vertical-align:middle" width="22"/></span>, because each incomplete step shortens the span of the unexecuted dag by 1. □</p></div></div><p class="textfl"/><p class="text" id="p0165">It turns out that this bound is within a factor of 2 of optimal. Achieving an optimal schedule is NP-complete, so greedy schedules are a simple and practical way to achieve performance that is reasonably close to optimal. </p><div class="boxg1" id="enun0020"><p class="b1num">Theorem 16.3.2 </p><div><p class="b1textfl" id="p0170">Any greedy scheduler is within a factor of 2 of optimal.</p></div></div><p class="textfl"> </p><div class="boxg1" id="enun0025"><p class="b1num">Proof </p><div><p class="b1textfl" id="p0175">Recall that <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:math></span><span><img alt="Image" height="13" src="images/B9780124159501000264/si15.png" style="vertical-align:middle" width="19"/></span> is a program's optimal execution time on a platform with <i>P</i> processors. Let <span class="hiddenClass"><mml:math><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mo>⁎</mml:mo></mml:mrow></mml:msubsup></mml:math></span><span><img alt="Image" height="17" src="images/B9780124159501000264/si38.png" style="vertical-align:middle" width="19"/></span> be its execution time under a greedy schedule. From the work law (Eq. <a href="#deq6" id="cf0070">(16.2.1)</a>) and the span law (Eq. <a href="#deq7" id="cf0075">(16.2.2)</a>),</p><p class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mo>⩾</mml:mo><mml:mi mathvariant="normal">max</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo>∞</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:math></p><div class="showClass"><p class="fig"><img alt="Image" height="46" src="images/B9780124159501000264/si39.png" width="177"/><a id="deq15"/></p></div><p class="b1textfl"> From <a href="#enun0010" id="cf0080">Theorem 16.3.1</a>,</p><p class="hiddenClass"><mml:math><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mo>⁎</mml:mo></mml:mrow></mml:msubsup><mml:mo id="mmlbr0007">⩽</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:mfrac><mml:mo linebreak="badbreak" linebreakstyle="after">+</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo>∞</mml:mo></mml:mrow></mml:msub><mml:mo indentalign="id" indenttarget="mmlbr0007" linebreak="newline" linebreakstyle="before">⩽</mml:mo><mml:mn>2</mml:mn><mml:mi mathvariant="normal">max</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo>∞</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:math></p><div class="showClass"><p class="fig"><img alt="Image" height="100" src="images/B9780124159501000264/si40.png" width="226"/><a id="deq16"/></p></div><p class="b1textfl"> It follows that</p><p class="hiddenClass"><mml:math><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mo>⁎</mml:mo></mml:mrow></mml:msubsup><mml:mo>⩽</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:math></p><div class="showClass"><p class="fig"><img alt="Image" height="23" src="images/B9780124159501000264/si41.png" width="94"/><a id="deq17"/></p></div><p class="b1textfl"> □</p></div></div><p class="textfl"/><p class="text" id="p0180"><span aria-label="Page 389" epub:type="pagebreak" id="page_389" role="doc-pagebreak"/></p><div class="boxg1" id="enun0030"><p class="b1num">Theorem 16.3.3 </p><div><p class="b1textfl" id="p0185">Any greedy scheduler achieves near-perfect linear speedup whenever <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">/</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo>∞</mml:mo></mml:mrow></mml:msub><mml:mo>≫</mml:mo><mml:mi>P</mml:mi></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000264/si42.png" style="vertical-align:middle" width="81"/></span>.</p></div></div><p class="textfl"> </p><div class="boxg1" id="enun0035"><p class="b1num">Proof </p><div><p class="b1textfl" id="p0190">From</p><p class="hiddenClass"><mml:math><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mo>⁎</mml:mo></mml:mrow></mml:msubsup><mml:mo id="mmlbr0008">⩽</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">/</mml:mo><mml:mi>P</mml:mi><mml:mo linebreak="badbreak" linebreakstyle="after">+</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo>∞</mml:mo></mml:mrow></mml:msub><mml:mo indentalign="id" indenttarget="mmlbr0008" linebreak="newline" linebreakstyle="before">≈</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">/</mml:mo><mml:mi>P</mml:mi><mml:mo>,</mml:mo></mml:math></p><div class="showClass"><p class="fig"><img alt="Image" height="54" src="images/B9780124159501000264/si43.png" width="190"/><a id="deq18"/></p></div><p class="b1textfl"> implying the speedup <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">/</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mo>≈</mml:mo><mml:mi>P</mml:mi></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000264/si44.png" style="vertical-align:middle" width="75"/></span>. □</p></div></div><p class="textfl"/></section><section><h2 class="h1hd" id="s0025"><a id="st0035"/>16.4 Work distribution</h2><p class="textfl" id="p0195">We now understand that the key to achieving a good speedup is to keep user-level threads supplied with tasks, so that the resulting schedule is as greedy as possible. Multithreaded computations, however, create and destroy tasks dynamically, sometimes in unpredictable ways. A <i>work distribution</i> algorithm is needed to assign ready tasks to idle threads as efficiently as possible.</p><p class="text" id="p0200">One simple approach to work distribution is <i>work dealing</i>: an overloaded task tries to offload tasks to other, less heavily loaded threads. This approach may seem sensible, but it has a basic flaw: If most threads are overloaded, then they waste effort in a futile attempt to exchange tasks. Instead, we first consider <i>work stealing</i>, in which a thread that runs out of work tries to “steal” work from others. An advantage of work stealing is that if all threads are already busy, then they do not waste time trying to offload work on one another.</p><section><h3 class="h2hd" id="s0030"><a id="st0040"/>16.4.1 Work stealing</h3><p class="textfl" id="p0205">Each thread keeps a pool of tasks waiting to be executed in the form of a <i>double-ended queue</i>, or <i>deque</i> (<img alt="Image" height="11" src="images/B9780124159501000264/fx024.jpg" width="32"/>), providing <img alt="Image" height="11" src="images/B9780124159501000264/fx025.jpg" width="66"/>(), <img alt="Image" height="11" src="images/B9780124159501000264/fx026.jpg" width="59"/>(), and <img alt="Image" height="11" src="images/B9780124159501000264/fx027.jpg" width="38"/>() methods (a <img alt="Image" height="11" src="images/B9780124159501000264/fx028.jpg" width="45"/>() method is not needed). When a thread creates a new task, it calls <img alt="Image" height="11" src="images/B9780124159501000264/fx025.jpg" width="66"/>() to push that task onto its deque. When a thread needs a task to work on, it calls <img alt="Image" height="11" src="images/B9780124159501000264/fx026.jpg" width="59"/>() to remove a task from its own deque. If the thread discovers its deque is empty, then it becomes a <i>thief</i>: it chooses a <i>victim</i> thread, and calls the <img alt="Image" height="11" src="images/B9780124159501000264/fx027.jpg" width="38"/>() method of that thread's deque to “steal” a task for itself.</p><p class="text" id="p0210">In Section <a href="#s0040" id="cf0085">16.5</a>, we present an efficient linearizable implementation of a deque. <a href="#f0055" id="cf0090">Fig. 16.9</a> shows one possible way to implement a thread used by a work-stealing thread pool. The threads share an array of deques (line 2), one for each thread. Each thread repeatedly removes a task from its own deque and executes it (lines 10–13). If it runs out, then it repeatedly chooses a victim thread at random and tries to steal a task from the top of the victim's deque (lines 14–20). To avoid code clutter, we ignore the possibility that stealing may trigger an exception.</p><div class="pageavoid"><figure class="fig" id="f0055"><img alt="Image" height="372" src="images/B9780124159501000264/gr009.jpg" width="446"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 16.9</span> The <img alt="Image" height="11" src="images/B9780124159501000264/fx029.jpg" width="119"/> class: a simplified work-stealing thread pool.</div></figcaption></figure></div><p class="text" id="p0215">This simple thread pool may keep trying to steal forever, long after all work in all queues has been completed. To prevent threads from endlessly searching for nonexistent work, we can use a termination detecting barrier as described in Section <a href="B9780124159501000288.xhtml">18.6</a>.<span aria-label="Page 390" epub:type="pagebreak" id="page_390" role="doc-pagebreak"/></p></section><section><h3 class="h2hd" id="s0035"><a id="st0045"/>16.4.2 Yielding and multiprogramming</h3><p class="textfl" id="p0220">As noted earlier, multiprocessors provide a three-level model of computation: Short-lived <i>tasks</i> are executed by system-level <i>threads</i>, which are scheduled by the operating system on a fixed number of <i>processors</i>. A <i>multiprogrammed environment</i> is one in which there are more threads than processors, implying that not all threads can run at the same time, and that any thread can be preemptively suspended at any time. To guarantee progress, we must ensure that threads that have work to do are not unreasonably delayed by (<i>thief</i>) threads that are idle except for task stealing. To prevent this situation, we have each thief call <img alt="Image" height="12" src="images/B9780124159501000264/fx030.jpg" width="91"/> immediately before trying to steal a task (line 15 in <a href="#f0055" id="cf0095">Fig. 16.9</a>). This call yields the thief's processor to another thread, allowing descheduled threads to regain a processor and make progress. (Calling <img alt="Image" height="11" src="images/B9780124159501000264/fx031.jpg" width="33"/>() has no effect if there are no descheduled threads capable of running.)<span aria-label="Page 391" epub:type="pagebreak" id="page_391" role="doc-pagebreak"/></p></section></section><section><h2 class="h1hd" id="s0040"><a id="st0050"/>16.5 Work-stealing deques</h2><p class="textfl" id="p0225">Here is how to implement a work-stealing deque: Ideally, a work-stealing algorithm should provide a linearizable implementation whose <img alt="Image" height="9" src="images/B9780124159501000264/fx032.jpg" width="18"/> methods always return a task if one is available. In practice, however, we can settle for something weaker, allowing a <img alt="Image" height="11" src="images/B9780124159501000264/fx027.jpg" width="38"/>() call to return <i>null</i> if it conflicts with a concurrent <img alt="Image" height="11" src="images/B9780124159501000264/fx027.jpg" width="38"/>() call. Though we could have the unsuccessful thief simply try again, it makes more sense in this context to have a thread retry the <img alt="Image" height="11" src="images/B9780124159501000264/fx027.jpg" width="38"/>() operation on a different, randomly chosen deque each time. To support such a retry, a <img alt="Image" height="11" src="images/B9780124159501000264/fx027.jpg" width="38"/>() call may return <i>null</i> if it conflicts with a concurrent <img alt="Image" height="11" src="images/B9780124159501000264/fx027.jpg" width="38"/>() call.</p><p class="text" id="p0230">We now describe two implementations of the work-stealing deque. The first is simpler, because it has bounded capacity. The second is somewhat more complex, but virtually unbounded in its capacity; that is, it does not suffer from the possibility of overflow.</p><section><h3 class="h2hd" id="s0045"><a id="st0055"/>16.5.1 A bounded work-stealing deque</h3><p class="textfl" id="p0235">For the thread pool deque, the common case is for a thread to push and pop a task from its own queue, calling <img alt="Image" height="11" src="images/B9780124159501000264/fx025.jpg" width="66"/>() and <img alt="Image" height="11" src="images/B9780124159501000264/fx026.jpg" width="59"/>(). The uncommon case is to steal a task from another thread's deque by calling <img alt="Image" height="11" src="images/B9780124159501000264/fx027.jpg" width="38"/>(). Naturally, it makes sense to optimize the common case. The key idea behind the <img alt="Image" height="11" src="images/B9780124159501000264/fx033.jpg" width="79"/> in <a href="#f0060" id="cs0010">Figs. 16.10</a> and <a href="#f0065">16.11</a> is to allow the <img alt="Image" height="11" src="images/B9780124159501000264/fx025.jpg" width="66"/>() and <img alt="Image" height="11" src="images/B9780124159501000264/fx026.jpg" width="59"/>() methods to use only reads and writes in the common case. The <img alt="Image" height="11" src="images/B9780124159501000264/fx033.jpg" width="79"/> consists of an array of <img alt="Image" height="9" src="images/B9780124159501000264/fx034.jpg" width="31"/> indexed by <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> and <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> fields that reference the top and bottom of the deque, as depicted in <a href="#f0070" id="cf0100">Fig. 16.12</a>. The <img alt="Image" height="11" src="images/B9780124159501000264/fx025.jpg" width="66"/>() and <img alt="Image" height="11" src="images/B9780124159501000264/fx026.jpg" width="59"/>() methods use reads and writes to manipulate the <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> reference. However, once the <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> and <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> fields are close (there might be only a single item in the array), <img alt="Image" height="11" src="images/B9780124159501000264/fx026.jpg" width="59"/>() switches to <img alt="Image" height="12" src="images/B9780124159501000264/fx037.jpg" width="97"/> calls to coordinate with potential <img alt="Image" height="11" src="images/B9780124159501000264/fx027.jpg" width="38"/>() calls.</p><div class="pageavoid"><figure class="fig" id="f0060"><img alt="Image" height="306" src="images/B9780124159501000264/gr010.jpg" width="376"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 16.10</span> The <img alt="Image" height="11" src="images/B9780124159501000264/fx033.jpg" width="79"/> class: fields, constructor, <img alt="Image" height="11" src="images/B9780124159501000264/fx025.jpg" width="66"/>(), and <img alt="Image" height="11" src="images/B9780124159501000264/fx038.jpg" width="45"/>() methods.</div></figcaption></figure></div><div class="pageavoid"><figure class="fig" id="f0065"><img alt="Image" height="537" src="images/B9780124159501000264/gr011.jpg" width="404"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 16.11</span> The <img alt="Image" height="11" src="images/B9780124159501000264/fx033.jpg" width="79"/> class: <img alt="Image" height="11" src="images/B9780124159501000264/fx027.jpg" width="38"/>() and <img alt="Image" height="11" src="images/B9780124159501000264/fx026.jpg" width="59"/>() methods.</div></figcaption></figure></div><div class="pageavoid"><figure class="fig" id="f0070"><img alt="Image" height="189" src="images/B9780124159501000264/gr012.jpg" width="469"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 16.12</span> The <img alt="Image" height="11" src="images/B9780124159501000264/fx033.jpg" width="79"/> implementation. In part (a), <img alt="Image" height="11" src="images/B9780124159501000264/fx027.jpg" width="38"/>() and <img alt="Image" height="11" src="images/B9780124159501000264/fx026.jpg" width="59"/>() are called concurrently while there is more than one task in the <img alt="Image" height="11" src="images/B9780124159501000264/fx033.jpg" width="79"/>. The <img alt="Image" height="11" src="images/B9780124159501000264/fx027.jpg" width="38"/>() method reads the element in entry 2 and calls <img alt="Image" height="12" src="images/B9780124159501000264/fx037.jpg" width="97"/> to redirect the top reference to entry 3. The <img alt="Image" height="11" src="images/B9780124159501000264/fx026.jpg" width="59"/>() method redirects the <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> reference from 5 to 4 using a simple store and then, after checking that <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> is greater than <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/>, it removes the task in entry 4. In part (b), there is only a single task. When <img alt="Image" height="11" src="images/B9780124159501000264/fx026.jpg" width="59"/>() detects that, after redirecting from 4 to 3, <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> and <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> are equal, it attempts to redirect <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> with a <img alt="Image" height="12" src="images/B9780124159501000264/fx037.jpg" width="97"/>. Before doing so, it redirects <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> to 0 because this last task will be removed by one of the two popping methods. If <img alt="Image" height="11" src="images/B9780124159501000264/fx027.jpg" width="38"/>() detects that <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> and <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> are equal, it gives up; otherwise, it tries to advance <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> using <img alt="Image" height="12" src="images/B9780124159501000264/fx037.jpg" width="97"/>. If both methods apply <img alt="Image" height="12" src="images/B9780124159501000264/fx037.jpg" width="97"/> to the <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/>, one wins and removes the task. In any case, win or lose, <img alt="Image" height="11" src="images/B9780124159501000264/fx026.jpg" width="59"/>() resets <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> to 0 since the <img alt="Image" height="11" src="images/B9780124159501000264/fx033.jpg" width="79"/> is now empty.</div></figcaption></figure></div><p class="text" id="p0240">Let us describe the algorithm in more detail. The <img alt="Image" height="11" src="images/B9780124159501000264/fx033.jpg" width="79"/> algorithm is clever in the way it avoids the use of costly <img alt="Image" height="12" src="images/B9780124159501000264/fx037.jpg" width="97"/> calls. This elegance comes at a cost: It is delicate and the order among instructions is crucial. We suggest the reader take time to understand how interactions among methods are determined by the order in which reads, writes, and <img alt="Image" height="12" src="images/B9780124159501000264/fx037.jpg" width="97"/> calls occur.</p><p class="text" id="p0245">The <img alt="Image" height="11" src="images/B9780124159501000264/fx033.jpg" width="79"/> class has three fields: <img alt="Image" height="9" src="images/B9780124159501000264/fx034.jpg" width="31"/>, <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/>, and <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> (<a href="#f0060" id="cf0105">Fig. 16.10</a>, lines 2–4). The <img alt="Image" height="9" src="images/B9780124159501000264/fx034.jpg" width="31"/> field is an array that holds the <img alt="Image" height="9" src="images/B9780124159501000264/fx008.jpg" width="99"/> tasks in the queue, <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> is the index of the first empty slot in <img alt="Image" height="9" src="images/B9780124159501000264/fx034.jpg" width="31"/>, and <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> is an <img alt="Image" height="11" src="images/B9780124159501000264/fx039.jpg" width="208"/> (see <a href="B9780124159501000203.xhtml">Pragma 10.6.1</a>). The <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> field encompasses two logical fields; the <i>reference</i> is the index of the first task in the queue, and the <i>stamp</i> is a counter incremented each time the reference is reset to 0. The stamp is needed to avoid an “ABA problem” of the type that often arises when using <img alt="Image" height="12" src="images/B9780124159501000264/fx037.jpg" width="97"/>. Suppose thread <i>A</i> calls <img alt="Image" height="11" src="images/B9780124159501000264/fx027.jpg" width="38"/>() to steal a task using only <img alt="Image" height="12" src="images/B9780124159501000264/fx037.jpg" width="97"/> on the task (without the stamp). <i>A</i> records the task whose index is given by <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/>, but then is delayed before it can steal the task by calling <img alt="Image" height="12" src="images/B9780124159501000264/fx037.jpg" width="97"/> to increment <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/>. While <i>A</i> is suspended, the owner thread <i>B</i> removes all tasks from the deque and replaces them with new tasks, eventually restoring <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> to its prior value. When <i>A</i> resumes, its <img alt="Image" height="12" src="images/B9780124159501000264/fx037.jpg" width="97"/> call will succeed, but <i>A</i> will have stolen the wrong task. The stamp, incremented each time the deque becomes empty, ensures that <i>A</i>'s <img alt="Image" height="12" src="images/B9780124159501000264/fx037.jpg" width="97"/> call will fail because the stamps no longer match.</p><p class="text" id="p0250"><span aria-label="Page 392" epub:type="pagebreak" id="page_392" role="doc-pagebreak"/>The <img alt="Image" height="11" src="images/B9780124159501000264/fx027.jpg" width="38"/>() method (<a href="#f0065" id="cf0110">Fig. 16.11</a>) checks whether the <img alt="Image" height="11" src="images/B9780124159501000264/fx033.jpg" width="79"/> is empty, and if not, tries to steal the top element by calling <img alt="Image" height="12" src="images/B9780124159501000264/fx037.jpg" width="97"/> to increment <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/>. If the <img alt="Image" height="12" src="images/B9780124159501000264/fx037.jpg" width="97"/> succeeds, the theft is successful, and otherwise the method simply returns <i>null</i>. This method is nondeterministic: Returning <i>null</i> does not necessarily mean that the queue is empty.</p><p class="text" id="p0255">As we noted earlier, we optimize for the common case, where each thread pushes and pops from its own local <img alt="Image" height="11" src="images/B9780124159501000264/fx033.jpg" width="79"/>. Most of the time, a thread can push and pop tasks on and off its own <img alt="Image" height="11" src="images/B9780124159501000264/fx033.jpg" width="79"/> by simply loading and storing the <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> index. If there is only one task in the queue, then the caller might encounter interference from a thief trying to steal that task. So if <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> is close to <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/>, the calling thread switches to using <img alt="Image" height="12" src="images/B9780124159501000264/fx037.jpg" width="97"/> to pop tasks.</p><p class="text" id="p0260">The <img alt="Image" height="11" src="images/B9780124159501000264/fx025.jpg" width="66"/>() method (<a href="#f0060" id="cf0115">Fig. 16.10</a>, line 10) simply stores the new task at the <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> queue location and increments <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/>.</p><p class="text" id="p0265">The <img alt="Image" height="11" src="images/B9780124159501000264/fx026.jpg" width="59"/>() method (<a href="#f0065" id="cf0120">Fig. 16.11</a>) is more complex. If <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> is 0, then the queue is empty, and the method returns immediately (line 15). Otherwise, it decrements <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/>, claiming a task (line 17). Here is a subtle but important point. If the claimed task was the last in the queue, then it is important that thieves notice that the <img alt="Image" height="11" src="images/B9780124159501000264/fx033.jpg" width="79"/> is empty (line 6). But, because <img alt="Image" height="11" src="images/B9780124159501000264/fx026.jpg" width="59"/>()'s decrement is neither atomic nor synchronized, the Java memory model does not guarantee that the decrement will be observed <span aria-label="Page 393" epub:type="pagebreak" id="page_393" role="doc-pagebreak"/>right away by concurrent thieves. To ensure that thieves can recognize an empty <img alt="Image" height="11" src="images/B9780124159501000264/fx033.jpg" width="79"/>, the <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> field must be declared <img alt="Image" height="9" src="images/B9780124159501000264/fx040.jpg" width="53"/>.<sup><a epub:type="noteref" href="#fn004" id="cf0125" role="doc-noteref">4</a></sup> Repeatedly rereading <img alt="Image" height="9" src="images/B9780124159501000264/fx040.jpg" width="53"/> variables can be expensive, so the code uses a local copy (<img alt="Image" height="9" src="images/B9780124159501000264/fx041.jpg" width="59"/>) of <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/>, which is safe because that field is not written by any other thread.</p><p class="text" id="p0270">After the decrement, the caller reads the task at the new <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> index (line 18), and tests whether the current <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> <span aria-label="Page 394" epub:type="pagebreak" id="page_394" role="doc-pagebreak"/>field refers to a smaller index. If so, the caller cannot conflict with a thief, and the method returns (line 24). Otherwise, if the <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> and <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> fields are equal, then there is only one task left in the <img alt="Image" height="11" src="images/B9780124159501000264/fx033.jpg" width="79"/>, and there is a danger that the caller conflicts with a thief. The caller resets <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> to 0 (line 27). (Either the caller will succeed in claiming the task, or a thief will steal it.) The caller resolves the potential conflict by calling <img alt="Image" height="12" src="images/B9780124159501000264/fx037.jpg" width="97"/> to reset <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> to 0 (incrementing the stamp as it does so), matching <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> (line 26). If this <img alt="Image" height="12" src="images/B9780124159501000264/fx037.jpg" width="97"/> succeeds, the <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> has been reset to 0, and the task has been claimed, so the method returns. Otherwise, the queue must be empty because a thief succeeded, but this means that <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> points to some entry greater than <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/>, which was set to 0 earlier. So before the caller returns <i>null</i>, it resets <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> to 0 (line 31).</p><p class="text" id="p0275">As noted, an attractive aspect of this design is that an expensive <img alt="Image" height="12" src="images/B9780124159501000264/fx037.jpg" width="97"/> call is needed rarely, only when the <img alt="Image" height="11" src="images/B9780124159501000264/fx033.jpg" width="79"/> is almost empty.</p><p class="text" id="p0280">We linearize each unsuccessful <img alt="Image" height="11" src="images/B9780124159501000264/fx027.jpg" width="38"/>() call at the point where it detects that the <img alt="Image" height="11" src="images/B9780124159501000264/fx033.jpg" width="79"/> is empty, or at a failed <img alt="Image" height="12" src="images/B9780124159501000264/fx037.jpg" width="97"/>. Successful <img alt="Image" height="11" src="images/B9780124159501000264/fx027.jpg" width="38"/>() calls are linearized at the point when a successful <img alt="Image" height="12" src="images/B9780124159501000264/fx037.jpg" width="97"/> took place. We linearize <img alt="Image" height="11" src="images/B9780124159501000264/fx025.jpg" width="66"/>() calls when <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> is incremented, and <img alt="Image" height="11" src="images/B9780124159501000264/fx026.jpg" width="59"/>() calls when <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> is decremented or set to 0, though the outcome of <img alt="Image" height="11" src="images/B9780124159501000264/fx026.jpg" width="59"/>() in the latter case is determined by the success or failure of the <img alt="Image" height="12" src="images/B9780124159501000264/fx037.jpg" width="97"/> that follows.</p><p class="text" id="p0285">The <img alt="Image" height="11" src="images/B9780124159501000264/fx038.jpg" width="45"/>() method of <img alt="Image" height="11" src="images/B9780124159501000264/fx042.jpg" width="92"/> (<a href="#f0080" id="cf0130">Fig. 16.14</a>) first reads <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> and then <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/>, checking whether <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> is less than or equal to <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> (line 33). The <span aria-label="Page 395" epub:type="pagebreak" id="page_395" role="doc-pagebreak"/>order is important for linearizability because <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> never decreases unless <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> is first reset to 0, so if a thread reads <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> after <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> and sees it is not greater, the queue is indeed empty because a concurrent modification of <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> could only have increased <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/>. On the other hand, if <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> is greater than <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/>, then even if <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> is increased after it was read and before <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> is read (and the queue becomes empty), it is still true that the <img alt="Image" height="11" src="images/B9780124159501000264/fx033.jpg" width="79"/> must not have been empty when <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> was read. The only alternative is that <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> is reset to 0 and then <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> is reset to 0, so reading <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> and then <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> will correctly return empty. It follows that the <img alt="Image" height="11" src="images/B9780124159501000264/fx038.jpg" width="45"/>() method is linearizable.</p><p class="text" id="p0290">For simplicity, the bounded deque algorithm assumes the deque never becomes full.</p></section><section><h3 class="h2hd" id="s0050"><a id="st0060"/>16.5.2 An unbounded work-stealing deque</h3><p class="textfl" id="p0295">A limitation of the <img alt="Image" height="11" src="images/B9780124159501000264/fx033.jpg" width="79"/> class is that the queue has a fixed size. For some applications, it may be difficult to predict this size, especially if some threads create significantly more tasks than others. Assigning each thread its own <img alt="Image" height="11" src="images/B9780124159501000264/fx033.jpg" width="79"/> of maximal capacity wastes space.</p><p class="text" id="p0300">To address these limitations, we now consider the <img alt="Image" height="11" src="images/B9780124159501000264/fx042.jpg" width="92"/> class, an <i>unbounded double-ended queue</i> that dynamically resizes itself as needed.</p><p class="text" id="p0305">We implement the <img alt="Image" height="11" src="images/B9780124159501000264/fx042.jpg" width="92"/> as a cyclic array, with <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> and <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> fields as in the <img alt="Image" height="11" src="images/B9780124159501000264/fx033.jpg" width="79"/> (except indexed modulo the array's capacity). As before, if <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> is less than or equal to <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/>, the <img alt="Image" height="11" src="images/B9780124159501000264/fx042.jpg" width="92"/> is empty. Using a cyclic array eliminates the need to reset <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> and <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> to 0. Moreover, it permits <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> to be incremented but never decremented, eliminating the need for <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> to be an <img alt="Image" height="11" src="images/B9780124159501000264/fx043.jpg" width="147"/>. Moreover, in the <img alt="Image" height="11" src="images/B9780124159501000264/fx042.jpg" width="92"/>, if <img alt="Image" height="11" src="images/B9780124159501000264/fx025.jpg" width="66"/>() discovers that the current circular array is full, it can resize (enlarge) it, copying the tasks into a bigger array, and pushing the new task into the new (larger) array. Because the array is indexed modulo its capacity, there is no need to update the <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> or <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> fields when moving the elements into a bigger array (although the actual array indices where the elements are stored might change).</p><p class="text" id="p0310">The <img alt="Image" height="11" src="images/B9780124159501000264/fx044.jpg" width="86"/> class is depicted in <a href="#f0075" id="cf0135">Fig. 16.13</a>. It provides <img alt="Image" height="11" src="images/B9780124159501000264/fx013.jpg" width="19"/>() and <img alt="Image" height="11" src="images/B9780124159501000264/fx045.jpg" width="18"/>() methods that add and remove tasks and a <img alt="Image" height="9" src="images/B9780124159501000264/fx046.jpg" width="38"/>() method that allocates a new circular array and copies the old array's contents into the new array. The use of modular arithmetic ensures that even though the array has changed size and the tasks may have shifted positions, thieves can still use the <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> field to find the next task to steal.</p><div class="pageavoid"><figure class="fig" id="f0075"><img alt="Image" height="405" src="images/B9780124159501000264/gr013.jpg" width="374"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 16.13</span> The <img alt="Image" height="11" src="images/B9780124159501000264/fx042.jpg" width="92"/> class: the circular task array.</div></figcaption></figure></div><p class="text" id="p0315">The <img alt="Image" height="11" src="images/B9780124159501000264/fx042.jpg" width="92"/> class has three fields: <img alt="Image" height="9" src="images/B9780124159501000264/fx034.jpg" width="31"/>, <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/>, and <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> (<a href="#f0080" id="cf0140">Fig. 16.14</a>, lines 3–5). The <img alt="Image" height="11" src="images/B9780124159501000264/fx026.jpg" width="59"/>() and <img alt="Image" height="11" src="images/B9780124159501000264/fx027.jpg" width="38"/>() methods (<a href="#f0085" id="cf0145">Fig. 16.15</a>) are almost the same as those of the <img alt="Image" height="11" src="images/B9780124159501000264/fx033.jpg" width="79"/>, with one key difference: The use of modular arithmetic to compute indices means the <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> index need never be decremented. As noted, there is no need for a stamp to prevent ABA problems. Both methods, when competing for the last task, steal it by incrementing <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/>. To reset the <img alt="Image" height="11" src="images/B9780124159501000264/fx042.jpg" width="92"/> to empty, simply increment the <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> field to equal <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/>. In the code, <img alt="Image" height="11" src="images/B9780124159501000264/fx026.jpg" width="59"/>(), immediately after the <img alt="Image" height="12" src="images/B9780124159501000264/fx037.jpg" width="97"/> on line 55, sets <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> to equal <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> +1 whether or not the <img alt="Image" height="12" src="images/B9780124159501000264/fx037.jpg" width="97"/> succeeds: If it failed, a <span aria-label="Page 396" epub:type="pagebreak" id="page_396" role="doc-pagebreak"/>concurrent thief must have stolen the last task and incremented <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/>. Storing <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> +1 into <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> makes <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> and <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> equal, resetting the <img alt="Image" height="11" src="images/B9780124159501000264/fx042.jpg" width="92"/> object to an empty state.</p><div class="pageavoid"><figure class="fig" id="f0080"><img alt="Image" height="454" src="images/B9780124159501000264/gr014.jpg" width="380"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 16.14</span> The <img alt="Image" height="11" src="images/B9780124159501000264/fx042.jpg" width="92"/> class: fields, constructor, <img alt="Image" height="11" src="images/B9780124159501000264/fx025.jpg" width="66"/>(), and <img alt="Image" height="11" src="images/B9780124159501000264/fx038.jpg" width="45"/>() methods.</div></figcaption></figure></div><div class="pageavoid"><figure class="fig" id="f0085"><img alt="Image" height="487" src="images/B9780124159501000264/gr015.jpg" width="290"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 16.15</span> The <img alt="Image" height="11" src="images/B9780124159501000264/fx042.jpg" width="92"/> class: <img alt="Image" height="11" src="images/B9780124159501000264/fx027.jpg" width="38"/>() and <img alt="Image" height="11" src="images/B9780124159501000264/fx026.jpg" width="59"/>() methods.</div></figcaption></figure></div><p class="text" id="p0320">The <img alt="Image" height="11" src="images/B9780124159501000264/fx038.jpg" width="45"/>() method (<a href="#f0080" id="cf0150">Fig. 16.14</a>) first reads <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> and then <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/>, checking whether <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> is less than or equal to <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> (line 33). The order is important because <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> never decreases, and so if a thread reads <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> after <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> and sees it is no greater, the queue is indeed empty because a concurrent modification of <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> could only have increased the <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> value. The same principle applies in the <img alt="Image" height="11" src="images/B9780124159501000264/fx027.jpg" width="38"/>() method call. <a href="#f0090" id="cf0155">Fig. 16.16</a> shows an example execution.</p><div class="pageavoid"><figure class="fig" id="f0090"><img alt="Image" height="235" src="images/B9780124159501000264/gr016.jpg" width="497"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 16.16</span> The <img alt="Image" height="11" src="images/B9780124159501000264/fx042.jpg" width="92"/> class implementation. In part (a), <img alt="Image" height="11" src="images/B9780124159501000264/fx027.jpg" width="38"/>() and <img alt="Image" height="11" src="images/B9780124159501000264/fx026.jpg" width="59"/>() are executed concurrently while there is more than one task in the <img alt="Image" height="11" src="images/B9780124159501000264/fx042.jpg" width="92"/> object. In part (b), there is only a single task, and initially <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> refers to entry 3 and <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> to 2. The <img alt="Image" height="11" src="images/B9780124159501000264/fx026.jpg" width="59"/>() method first decrements <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> from 3 to 2 (we denote this change by a dashed line pointing to entry 2 since it will change again soon). Then, when <img alt="Image" height="11" src="images/B9780124159501000264/fx026.jpg" width="59"/>() detects that the gap between the newly set <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> and <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> is 0, it attempts to increment <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> by 1 (rather than reset it to 0 as in the <img alt="Image" height="11" src="images/B9780124159501000264/fx033.jpg" width="79"/>). The <img alt="Image" height="11" src="images/B9780124159501000264/fx027.jpg" width="38"/>() method attempts to do the same. The <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> field is incremented by one of them, and the winner takes the last task. Finally, the <img alt="Image" height="11" src="images/B9780124159501000264/fx026.jpg" width="59"/>() method sets <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> back to entry 3, which is equal to <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/>.</div></figcaption></figure></div><p class="text" id="p0325">The <img alt="Image" height="11" src="images/B9780124159501000264/fx025.jpg" width="66"/>() method (<a href="#f0080" id="cf0160">Fig. 16.14</a>) is almost the same as that of the <img alt="Image" height="11" src="images/B9780124159501000264/fx033.jpg" width="79"/>. One difference is that the method must enlarge the circular array if the current push is about to cause it to exceed its capacity. Another is that <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> does not need to be a <img alt="Image" height="11" src="images/B9780124159501000264/fx047.jpg" width="160"/>. The ability to resize carries a price: Every call to <img alt="Image" height="11" src="images/B9780124159501000264/fx025.jpg" width="66"/>() must read <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> (line 21) to determine if a resize is necessary, possibly causing more cache misses because <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> is modified by all threads. We can reduce this overhead by having the owner thread save a local value of <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/>, which can be <span aria-label="Page 397" epub:type="pagebreak" id="page_397" role="doc-pagebreak"/>used to compute an upper bound on the <img alt="Image" height="11" src="images/B9780124159501000264/fx042.jpg" width="92"/> size, since the other methods can only make the <img alt="Image" height="11" src="images/B9780124159501000264/fx042.jpg" width="92"/> smaller. The owner thread rereads <img alt="Image" height="11" src="images/B9780124159501000264/fx036.jpg" width="18"/> only when this bound on size approaches the threshold where a <img alt="Image" height="9" src="images/B9780124159501000264/fx046.jpg" width="38"/>() may be necessary.</p><p class="text" id="p0330">In summary, we have seen two ways to design a nonblocking linearizable <img alt="Image" height="11" src="images/B9780124159501000264/fx024.jpg" width="32"/> class. We can get away with using only loads and stores in the most common manipulations of the deque, but at the price of having more complex algorithms. Such algorithms are justifiable for an application such as a thread pool whose performance may be critical to a concurrent multithreaded system.<span aria-label="Page 398" epub:type="pagebreak" id="page_398" role="doc-pagebreak"/><span aria-label="Page 399" epub:type="pagebreak" id="page_399" role="doc-pagebreak"/></p></section><section><h3 class="h2hd" id="s0055"><a id="st0065"/>16.5.3 Work dealing</h3><p class="textfl" id="p0335">We have seen that in work-stealing algorithms, idle threads steal tasks from others. An alternative approach is to have each thread periodically <i>balance</i> its workloads with a randomly chosen partner. To ensure that heavily loaded threads do not waste effort trying to rebalance, we make lightly loaded threads more likely to initiate rebalancing. More precisely, each thread periodically flips a biased coin to decide whether to balance with another. The thread's probability of balancing is inversely proportional to the number of tasks in the thread's queue. In other words, threads with few tasks are likely to rebalance, and threads with nothing to do are certain to rebalance. A thread rebalances by selecting a victim uniformly at random, and, if the difference between its workload and the victim's exceeds a predefined threshold, they transfer tasks until their queues contain the same number of tasks. It can be shown that this algorithm provides strong fairness guarantees: The expected length of each thread's task queue is pretty close to the average. One advantage of this approach is that the balancing operation moves multiple tasks at each exchange. A second advantage occurs if one thread has much more work than the others, especially if tasks require approximately equal computation. In the work-stealing algorithm presented here, contention could occur if many threads try to steal individual tasks from the overloaded thread. In such a case, in the work-stealing thread pool, if some thread has a lot of work, chances are that other threads will have to repeatedly compete on the same local task queue in an attempt to steal at most a single task each time. On the other hand, in the work-sharing thread pool, balancing multiple tasks at a time means that work will quickly be spread out among tasks, and there will not be a synchronization overhead per individual task.</p><p class="text" id="p0340"><a href="#f0095" id="cf0165">Fig. 16.17</a> illustrates a work-sharing thread pool. Each thread has its own queue of tasks, kept in an array shared by all threads (line 2). Each thread repeatedly deques the next task from its queue (line 10). If the queue was empty, the <img alt="Image" height="11" src="images/B9780124159501000264/fx048.jpg" width="19"/>() call returns <i>null</i>; otherwise, the thread executes the task (line 11). At this point, the thread decides whether to rebalance. If the thread's task queue has size <i>s</i>, then the thread decides to rebalance with probability <span class="hiddenClass"><mml:math><mml:mn>1</mml:mn><mml:mo stretchy="false">/</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo linebreak="badbreak" linebreakstyle="after">+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000264/si45.png" style="vertical-align:middle" width="61"/></span> (line 13). To rebalance, the thread chooses a <i>victim</i> thread uniformly at random. The thread locks both queues (lines 15–18), in thread ID order (to avoid deadlock). If the difference in queue size exceeds a threshold, it evens out the queue sizes (<a href="#f0095" id="cf0170">Fig. 16.17</a>, lines 25–33).<span aria-label="Page 400" epub:type="pagebreak" id="page_400" role="doc-pagebreak"/><span aria-label="Page 401" epub:type="pagebreak" id="page_401" role="doc-pagebreak"/></p><div class="pageavoid"><figure class="fig" id="f0095"><img alt="Image" height="536" src="images/B9780124159501000264/gr017.jpg" width="446"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 16.17</span> The <img alt="Image" height="11" src="images/B9780124159501000264/fx049.jpg" width="113"/> class: a simplified work-sharing thread pool.</div></figcaption></figure></div></section></section><section><h2 class="h1hd" id="s0060"><a id="st0070"/>16.6 Chapter notes</h2><p class="textfl" id="p0345">The dag-based model for analysis of multithreaded computation was introduced by Robert Blumofe and Charles Leiserson <a epub:type="noteref" href="#br0090" id="cf0175" role="doc-noteref">[18]</a>. They also gave the first deque-based implementation of work stealing. Some of the examples in this chapter were adapted from a tutorial by Charles Leiserson and Harald Prokop <a epub:type="noteref" href="#br0560" id="cf0180" role="doc-noteref">[112]</a>. The bounded lock-free deque algorithm is credited to Anish Arora, Robert Blumofe, and Greg Plaxton <a epub:type="noteref" href="#br0065" id="cf0185" role="doc-noteref">[13]</a>. The unbounded timestamps used in this algorithm can be made bounded using a technique due to Mark Moir <a epub:type="noteref" href="#br0645" id="cf0190" role="doc-noteref">[129]</a>. The unbounded deque algorithm is credited to David Chase and Yossi Lev <a epub:type="noteref" href="#br0145" id="cf0195" role="doc-noteref">[29]</a>. The original proof of <a href="#enun0010" id="cf0200">Theorem 16.3.1</a> is due to Anish Arora, Robert Blumofe, and Greg Plaxton <a epub:type="noteref" href="#br0065" id="cf0205" role="doc-noteref">[13]</a>. The work-sharing algorithm is by Larry Rudolph, Tali Slivkin-Allaluf, and Eli Upfal <a epub:type="noteref" href="#br0755" id="cf0210" role="doc-noteref">[151]</a>. The algorithm of Anish Arora, Robert Blumofe, and Greg Plaxton <a epub:type="noteref" href="#br0065" id="cf0215" role="doc-noteref">[13]</a> was later improved by Danny Hendler and Nir Shavit <a epub:type="noteref" href="#br0305" id="cf0220" role="doc-noteref">[61]</a> to include the ability to steal half of the items in a deque.</p><p class="text" id="p0350">Some illustrations were adapted from class notes prepared by Charles Leiserson.</p></section><section><h2 class="h1hd" id="s0065"><a id="st0075"/>16.7 Exercises</h2><p class="textfl" id="p0355"/><div class="boxg1" id="enun0040"><p class="b1num">Exercise 16.1 </p><div><p class="b1textfl" id="p0360">Rewrite <img alt="Image" height="9" src="images/B9780124159501000264/fx016.jpg" width="86"/> and <img alt="Image" height="9" src="images/B9780124159501000264/fx021.jpg" width="86"/> to use an executor service.</p></div></div><p class="textfl"/><p class="text" id="p0365"/><div class="boxg1" id="enun0045"><p class="b1num">Exercise 16.2 </p><div><p class="b1textfl" id="p0370">Consider the following code for an in-place merge-sort:</p><div class="pageavoid"><figure class="fig" id="f0100"><img alt="Image" class="img" height="125" src="images/B9780124159501000264/fx050.jpg" width="291"/></figure></div><p class="textfl"> (Here, <img alt="Image" height="12" src="images/B9780124159501000264/fx051.jpg" width="50"/> starts the task and immediately returns, and <img alt="Image" height="12" src="images/B9780124159501000264/fx052.jpg" width="118"/> waits until all submitted tasks have finished.)</p><p class="b1text" id="p0375">Assuming that the merge method has no internal parallelism, give the work, span, and parallelism of this algorithm. Give your answers both as recurrences and as <span class="hiddenClass"><mml:math><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000264/si46.png" style="vertical-align:middle" width="58"/></span>, for some function <i>f</i>.</p></div></div><p class="textfl"/><p class="text" id="p0380"/><div class="boxg1" id="enun0050"><p class="b1num">Exercise 16.3 </p><div><p class="b1textfl" id="p0385">Assume that the actual running time of a parallel program on a dedicated <i>P</i>-processor machine is</p><p class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="badbreak" linebreakstyle="after">=</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">/</mml:mo><mml:mi>P</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">+</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo>∞</mml:mo></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:math></p><div class="showClass"><p class="fig"><img alt="Image" height="19" src="images/B9780124159501000264/si47.png" width="161"/><a id="deq19"/></p></div><p class="b1textfl"> Your research group has produced two chess programs, a simple one and an optimized one. The simple one has <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>2048</mml:mn></mml:math></span><span><img alt="Image" height="13" src="images/B9780124159501000264/si48.png" style="vertical-align:middle" width="67"/></span> seconds and <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo>∞</mml:mo></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>1</mml:mn></mml:math></span><span><img alt="Image" height="13" src="images/B9780124159501000264/si49.png" style="vertical-align:middle" width="49"/></span> second. When you run it on your 32-processor machine, sure enough, the running time is 65 steps. Your students then produce an “optimized” version with <span class="hiddenClass"><mml:math><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>1024</mml:mn></mml:math></span><span><img alt="Image" height="18" src="images/B9780124159501000264/si50.png" style="vertical-align:middle" width="68"/></span> seconds and <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo>∞</mml:mo></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>8</mml:mn></mml:math></span><span><img alt="Image" height="13" src="images/B9780124159501000264/si51.png" style="vertical-align:middle" width="50"/></span> seconds. When you run it on your 32-processor machine, the running time is 40 steps, as predicted by our formula.</p><p class="b1text" id="p0390">Which program will scale better to a 512-processor machine?</p></div></div><p class="textfl"/><p class="text" id="p0395"/><div class="boxg1" id="enun0055"><p class="b1num">Exercise 16.4 </p><div><p class="b1textfl" id="p0400">Write an <img alt="Image" height="11" src="images/B9780124159501000264/fx053.jpg" width="53"/> class that provides a method</p><div class="pageavoid"><figure class="fig" id="f0105"><img alt="Image" class="img" height="11" src="images/B9780124159501000264/fx054.jpg" width="178"/></figure></div><p class="textfl"> that uses divide-and-conquer to sum the elements of the array argument in parallel.</p></div></div><p class="textfl"/><p class="text" id="p0405"><span aria-label="Page 402" epub:type="pagebreak" id="page_402" role="doc-pagebreak"/></p><div class="boxg1" id="enun0060"><p class="b1num">Exercise 16.5 </p><div><p class="b1textfl" id="p0410">Professor Jones takes some measurements of his (deterministic) multithreaded program, which is scheduled using a greedy scheduler, and finds that <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>80</mml:mn></mml:math></span><span><img alt="Image" height="13" src="images/B9780124159501000264/si52.png" style="vertical-align:middle" width="52"/></span> seconds and <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>64</mml:mn></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>10</mml:mn></mml:math></span><span><img alt="Image" height="13" src="images/B9780124159501000264/si53.png" style="vertical-align:middle" width="58"/></span> seconds. What is the fastest that the professor's computation could possibly run on 10 processors? Use the following inequalities and the bounds implied by them to derive your answer (<i>P</i> is the number of processors):</p><p class="hiddenClass"><mml:math><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mo>⩾</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></p><div class="showClass"><p class="fig"><img alt="Image" height="46" src="images/B9780124159501000264/si54.png" width="84"/><a id="deq20"/><span class="eqnum">(16.7.1) </span></p></div><p class="b1textfl"/><p class="hiddenClass"><mml:math><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mo>⩾</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo>∞</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></p><div class="showClass"><p class="fig"><img alt="Image" height="18" src="images/B9780124159501000264/si55.png" width="88"/><a id="deq21"/><span class="eqnum">(16.7.2) </span></p></div><p class="b1textfl"/><p class="hiddenClass"><mml:math><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mo>⩽</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo linebreak="badbreak" linebreakstyle="after">−</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo>∞</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:mfrac><mml:mo linebreak="badbreak" linebreakstyle="after">+</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo>∞</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></p><div class="showClass"><p class="fig"><img alt="Image" height="46" src="images/B9780124159501000264/si56.png" width="211"/><a id="deq22"/><span class="eqnum">(16.7.3) </span></p></div><p class="b1textfl"> where the last inequality holds on a greedy scheduler.</p></div></div><p class="textfl"/><p class="text" id="p0415"/><div class="boxg1" id="enun0065"><p class="b1num">Exercise 16.6 </p><div><p class="b1textfl" id="p0420">Give an implementation of the <img alt="Image" height="9" src="images/B9780124159501000264/fx003.jpg" width="39"/> class used in this chapter. Make sure your <img alt="Image" height="11" src="images/B9780124159501000264/fx015.jpg" width="32"/>() method takes constant time.</p></div></div><p class="textfl"/><p class="text" id="p0425"/><div class="boxg1" id="enun0070"><p class="b1num">Exercise 16.7 </p><div><p class="b1textfl" id="p0430">Let <span class="hiddenClass"><mml:math><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msubsup><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo linebreak="badbreak" linebreakstyle="after">=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:math></span><span><img alt="Image" height="20" src="images/B9780124159501000264/si57.png" style="vertical-align:middle" width="121"/></span> and <span class="hiddenClass"><mml:math><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msubsup><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo linebreak="badbreak" linebreakstyle="after">=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:math></span><span><img alt="Image" height="20" src="images/B9780124159501000264/si58.png" style="vertical-align:middle" width="120"/></span> be polynomials of degree <i>d</i>, where <i>d</i> is a power of 2. We can write</p><p class="hiddenClass"><mml:math><mml:mi id="mmlbr0009">P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo linebreak="badbreak" linebreakstyle="after">=</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo linebreak="goodbreak" linebreakstyle="after">+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo stretchy="false">/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo indentalign="id" indenttarget="mmlbr0009" linebreak="newline" linebreakstyle="after">,</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo linebreak="goodbreak" linebreakstyle="after">+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo stretchy="false">/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:math></p><div class="showClass"><p class="fig"><img alt="Image" height="57" src="images/B9780124159501000264/si59.png" width="321"/><a id="deq23"/></p></div><p class="b1textfl"> where <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000264/si60.png" style="vertical-align:middle" width="132"/></span>, and <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000264/si61.png" style="vertical-align:middle" width="42"/></span> are polynomials of degree <span class="hiddenClass"><mml:math><mml:mi>d</mml:mi><mml:mo stretchy="false">/</mml:mo><mml:mn>2</mml:mn></mml:math></span><span><img alt="Image" height="15" src="images/B9780124159501000264/si62.png" style="vertical-align:middle" width="28"/></span>.</p><p class="b1text" id="p0435">The <img alt="Image" height="11" src="images/B9780124159501000264/fx055.jpg" width="63"/> class shown in <a href="#f0110" id="cf0225">Fig. 16.18</a> provides <img alt="Image" height="11" src="images/B9780124159501000264/fx045.jpg" width="18"/>() and <img alt="Image" height="11" src="images/B9780124159501000264/fx013.jpg" width="19"/>() methods to access coefficients and it provides a constant-time <img alt="Image" height="11" src="images/B9780124159501000264/fx015.jpg" width="32"/>() method that splits a <i>d</i>-degree polynomial <span class="hiddenClass"><mml:math><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000264/si63.png" style="vertical-align:middle" width="34"/></span> into the two <span class="hiddenClass"><mml:math><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">/</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="15" src="images/B9780124159501000264/si64.png" style="vertical-align:middle" width="37"/></span>-degree polynomials <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000264/si65.png" style="vertical-align:middle" width="38"/></span> and <span class="hiddenClass"><mml:math><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000264/si66.png" style="vertical-align:middle" width="38"/></span> defined above, where changes to the split polynomials are reflected in the original, and vice versa. Your task is to devise parallel addition and multiplication algorithms for this <img alt="Image" height="11" src="images/B9780124159501000264/fx055.jpg" width="63"/> class.</p><div><ul><li class="b1bulllist" id="u0010">•  The <i>sum</i> of <span class="hiddenClass"><mml:math><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000264/si63.png" style="vertical-align:middle" width="34"/></span> and <span class="hiddenClass"><mml:math><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000264/si67.png" style="vertical-align:middle" width="35"/></span> can be decomposed as follows:</li></ul><p class="hiddenClass"><mml:math><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo linebreak="badbreak" linebreakstyle="after">+</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo linebreak="badbreak" linebreakstyle="after">+</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo linebreak="goodbreak" linebreakstyle="after">+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo linebreak="badbreak" linebreakstyle="after">+</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo stretchy="false">/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:math></p><div class="showClass"><p class="fig"><img alt="Image" height="25" src="images/B9780124159501000264/si68.png" width="529"/><a id="deq24"/></p></div><ul><li class="b1bulllist"><ul><li class="b1bulllist1" id="u0015">•  Use this decomposition to construct a task-based concurrent polynomial addition algorithm in the manner of <a href="#f0080" id="cf0230">Fig. 16.14</a>.</li><li class="b1bulllist1" id="u0020">•  Compute the work and span of this algorithm.</li></ul></li><li class="b1bulllist" id="u0025">•  The <i>product</i> of <span class="hiddenClass"><mml:math><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000264/si63.png" style="vertical-align:middle" width="34"/></span> and <span class="hiddenClass"><mml:math><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000264/si67.png" style="vertical-align:middle" width="35"/></span> can be decomposed as follows:</li></ul><p class="hiddenClass"><mml:math><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo linebreak="badbreak" linebreakstyle="after">=</mml:mo><mml:mo id="mmlbr0010" stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo linebreak="goodbreak" linebreakstyle="after">+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo linebreak="badbreak" linebreakstyle="after">+</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo stretchy="false">/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo indentalign="id" indenttarget="mmlbr0010" linebreak="newline" linebreakstyle="before">+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:math></p><div class="showClass"><p class="fig"><img alt="Image" height="57" src="images/B9780124159501000264/si69.png" width="673"/><a id="deq25"/></p></div><ul><li class="b1bulllist"><ul><li class="b1bulllist1" id="u0030">•  Use this decomposition to construct a task-based concurrent polynomial multiplication algorithm in the manner of <a href="#f0030" id="cf0235">Fig. 16.4</a>.</li><li class="b1bulllist1" id="u0035">•  Compute the work and span of this algorithm. <span aria-label="Page 403" epub:type="pagebreak" id="page_403" role="doc-pagebreak"/></li></ul></li></ul></div><p class="b1textfl"/><div class="pageavoid"><figure class="fig" id="f0110"><img alt="Image" height="503" src="images/B9780124159501000264/gr018.jpg" width="472"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 16.18</span> The <img alt="Image" height="11" src="images/B9780124159501000264/fx055.jpg" width="63"/> class.</div></figcaption></figure></div></div></div><p class="textfl"/><p class="text" id="p0470"/><div class="boxg1" id="enun0075"><p class="b1num">Exercise 16.8 </p><div><p class="b1textfl" id="p0475">Give an efficient and highly parallel multithreaded algorithm for multiplying an <span class="hiddenClass"><mml:math><mml:mi>n</mml:mi><mml:mspace width="0.2em"/><mml:mo>×</mml:mo><mml:mspace width="0.2em"/><mml:mi>n</mml:mi></mml:math></span><span><img alt="Image" height="8" src="images/B9780124159501000264/si70.png" style="vertical-align:middle" width="43"/></span> matrix by a length-<i>n</i> vector that achieves <span class="hiddenClass"><mml:math><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="17" src="images/B9780124159501000264/si71.png" style="vertical-align:middle" width="42"/></span> work and <span class="hiddenClass"><mml:math><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></span><span><img alt="Image" height="14" src="images/B9780124159501000264/si72.png" style="vertical-align:middle" width="58"/></span> span. Analyze the work and span of your implementation, and give the parallelism.</p></div></div><p class="textfl"/><p class="text" id="p0480"/><div class="boxg1" id="enun0080"><p class="b1num">Exercise 16.9 </p><div><p class="b1textfl" id="p0485">Consider the bounded deque implementation in <a href="#f0060" id="cs0015">Figs. 16.10</a> and <a href="#f0065">16.11</a>.</p><div><ul><li class="b1bulllist" id="u0040">•  The <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> field is volatile to ensure that in <img alt="Image" height="11" src="images/B9780124159501000264/fx026.jpg" width="59"/>(), the decrement on line 17 is immediately visible. Describe a scenario that explains what could go wrong if <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> were not declared as volatile.</li><li class="b1bulllist" id="u0045">•  Why should we attempt to reset the <img alt="Image" height="9" src="images/B9780124159501000264/fx035.jpg" width="39"/> field to 0 as early as possible in the <img alt="Image" height="11" src="images/B9780124159501000264/fx026.jpg" width="59"/>() method? Which line is the earliest in which this reset can be done safely? Can our <img alt="Image" height="11" src="images/B9780124159501000264/fx033.jpg" width="79"/> overflow anyway? Describe how.</li></ul></div><p class="b1textfl"/></div></div><p class="textfl"> <span aria-label="Page 404" epub:type="pagebreak" id="page_404" role="doc-pagebreak"/></p><p class="text" id="p0500"/><div class="boxg1" id="enun0085"><p class="b1num">Exercise 16.10 </p><div><p class="b1textfl" id="p0505">Modify the <img alt="Image" height="11" src="images/B9780124159501000264/fx027.jpg" width="38"/>() method of the linearizable <img alt="Image" height="11" src="images/B9780124159501000264/fx033.jpg" width="79"/> implementation so it will return null only if there are no tasks in the queue. Note that you may need to make its implementation blocking.</p></div></div><p class="textfl"/><p class="text" id="p0510"/><div class="boxg1" id="enun0090"><p class="b1num">Exercise 16.11 </p><div><p class="b1textfl" id="p0515">Do you expect that the <img alt="Image" height="11" src="images/B9780124159501000264/fx038.jpg" width="45"/>() method call of a <img alt="Image" height="11" src="images/B9780124159501000264/fx033.jpg" width="79"/> in the executor pool code will actually improve its performance?</p></div></div><p class="textfl"/><p class="text" id="p0520"/><div class="boxg1" id="enun0095"><p class="b1num">Exercise 16.12 </p><div><p class="b1textfl" id="p0525">Consider the <img alt="Image" height="11" src="images/B9780124159501000264/fx027.jpg" width="38"/>() method of <img alt="Image" height="11" src="images/B9780124159501000264/fx042.jpg" width="92"/> (<a href="#f0085" id="cf0240">Fig. 16.15</a>).</p><div><ul><li class="b1bulllist" id="u0050">•  If the <img alt="Image" height="12" src="images/B9780124159501000264/fx037.jpg" width="97"/> on line 38 succeeds, it returns the element it read right before the successful <img alt="Image" height="12" src="images/B9780124159501000264/fx037.jpg" width="97"/> operation. Why is it important to read the element from the array before we do the <img alt="Image" height="12" src="images/B9780124159501000264/fx037.jpg" width="97"/>?</li><li class="b1bulllist" id="u0055">•  Can we use <img alt="Image" height="11" src="images/B9780124159501000264/fx038.jpg" width="45"/>() on line 36?</li></ul></div><p class="b1textfl"/></div></div><p class="textfl"/><p class="text" id="p0540"/><div class="boxg1" id="enun0100"><p class="b1num">Exercise 16.13 </p><div><p class="b1textfl" id="p0545">What are the linearization points of the <img alt="Image" height="11" src="images/B9780124159501000264/fx042.jpg" width="92"/> methods? Justify your answers.</p></div></div><p class="textfl"/><p class="text" id="p0550"/><div class="boxg1" id="enun0105"><p class="b1num">Exercise 16.14 </p><div><p class="b1textfl" id="p0555"><a href="#f0115" id="cf0245">Fig. 16.19</a> shows an alternate way of rebalancing two work queues: first, lock the larger queue, then lock the smaller queue, and rebalance if their difference exceeds a threshold. What is wrong with this code?</p><div class="pageavoid"><figure class="fig" id="f0115"><img alt="Image" height="175" src="images/B9780124159501000264/gr019.jpg" width="326"/><br/><figcaption><div class="figleg" title="figure"><span class="fignum">Figure 16.19</span> Alternate rebalancing code.</div></figcaption></figure></div></div></div><p class="textfl"/></section><footer><section epub:type="bibliography" role="doc-bibliography"><div id="bl0455"><h2 class="reftitle" id="st0080">Bibliography</h2><p class="reflist1" epub:type="biblioentry footnote" id="br0065" role="doc-biblioentry">[13] Nimar S. Arora, Robert D. Blumofe, C. Greg Plaxton,  Thread scheduling for multiprogrammed multiprocessors,   <i>Proceedings of the Tenth Annual ACM Symposium on Parallel Algorithms and Architectures</i>.  ACM Press; 1998:119–129.</p><p class="reflist1" epub:type="biblioentry footnote" id="br0090" role="doc-biblioentry">[18] Robert D. Blumofe, Charles E. Leiserson,  Scheduling multithreaded computations by work stealing,   <cite><i>Journal of the ACM</i></cite> 1999;46(5):720–748.</p><p class="reflist1" epub:type="biblioentry footnote" id="br0145" role="doc-biblioentry">[29] David Chase, Yossi Lev,  Dynamic circular work-stealing deque,   <i>SPAA '05: Proceedings of the Seventeenth Annual ACM Symposium on Parallelism in Algorithms and Architectures</i>.  New York, NY, USA: ACM Press; 2005:21–28.</p><p class="reflist1" epub:type="biblioentry footnote" id="br0305" role="doc-biblioentry">[61] Danny Hendler, Nir Shavit,  Non-blocking steal-half work queues,   <i>Proceedings of the Twenty-First Annual Symposium on Principles of Distributed Computing</i>.  ACM Press; 2002:280–289.</p><p class="reflist2" epub:type="biblioentry footnote" id="br0560" role="doc-biblioentry">[112] C. Leiserson, H. Prokop,  A minicourse on multithreaded programming,   <a href="http://supertech.csail.mit.edu/papers/minicourse.pdf">http://supertech.csail.mit.edu/papers/minicourse.pdf</a>; 1998.</p><p class="reflist2" epub:type="biblioentry footnote" id="br0645" role="doc-biblioentry">[129] Mark Moir,  Practical implementations of non-blocking synchronization primitives,   <i>PODC '97: Proceedings of the Sixteenth Annual ACM Symposium on Principles of Distributed Computing</i>.  New York, NY, USA: ACM Press; 1997:219–228.</p><p class="reflist2" epub:type="biblioentry footnote" id="br0755" role="doc-biblioentry">[151] L. Rudolph, M. Slivkin-Allalouf, E. Upfal,  A simple load balancing scheme for task allocation in parallel machines,   <i>Proceedings of the 3rd Annual ACM Symposium on Parallel Algorithms and Architectures</i>.  ACM Press; July 1991:237–245.</p></div></section><section epub:type="rearnotes"><div class="ftnote"><hr/><p class="ftnote1" epub:type="footnote" id="fn001" role="doc-footnote"><sup><a epub:type="noteref" href="#cf0015" role="doc-noteref">1 </a></sup> <a id="np0010"/>“Real code should check that all the dimensions agree. Here we omit most safety checks for brevity.”</p><p class="ftnote1" epub:type="footnote" id="fn002" role="doc-footnote"><sup><a epub:type="noteref" href="#cf0035" role="doc-noteref">2 </a></sup> <a id="np0015"/>“This code uses the functional notation introduced in Chapter <a href="B9780124159501000276.xhtml">17</a>.”</p><p class="ftnote1" epub:type="footnote" id="fn003" role="doc-footnote"><sup><a epub:type="noteref" href="#cf0060" role="doc-noteref">3 </a></sup> <a id="np0020"/>“Span is sometimes called the <i>critical path length</i>.”</p><p class="ftnote1" epub:type="footnote" id="fn004" role="doc-footnote"><sup><a epub:type="noteref" href="#cf0125" role="doc-noteref">4 </a></sup> <a id="np0025"/>“In a C or C++ implementation, you would need to introduce a <i>write barrier</i>, as described in Appendix <a href="B978012415950100032X.xhtml">B</a>.”</p></div></section></footer></section></body></html>