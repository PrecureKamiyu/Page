<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>10.3  The MapReduce Paradigm</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part204.htm">&lt; 上一个</a><span> | </span><a href="../database.html">内容</a><span> | </span><a href="part206.htm">下一个 &gt;</a></p><p class="s65" style="padding-top: 4pt;padding-left: 72pt;text-indent: 0pt;text-align: left;"><a name="bookmark221">10.3  </a><span style=" color: #00AEEF;">The MapReduce Paradigm</span><a name="bookmark239">&zwnj;</a></p><p style="padding-top: 11pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">The MapReduce paradigm models a common situation in parallel processing, where some processing, identiﬁed by the <span class="s49">map() </span>function, is applied to each of a large num- ber of input records, and then some form of aggregation, identiﬁed by the <span class="s49">reduce() </span>function, is applied to the result of the <span class="s49">map() </span>function. The <span class="s49">map() </span>function is also permitted to specify grouping keys, such that the aggregation speciﬁed in the <span class="s49">reduce() </span>function is applied within each group, identiﬁed by the grouping key, of the <span class="s49">map() </span>out- put. We examine the MapReduce paradigm, and the <span class="s49">map() </span>and <span class="s49">reduce() </span>functions in detail, in the rest of this section.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">The MapReduce paradigm for parallel processing has a long history, dating back several decades, in the functional programming and parallel processing community (the map and reduce functions were supported in the Lisp language, for example).</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 119pt;text-indent: 0pt;text-align: left;">10.3.1 Why MapReduce?</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: right;">As a motivating example for the use of the MapReduce paradigm, we consider the following <i>word count </i>application, which takes a large number of ﬁles as input, and outputs a count of the number of times each word appears, across all the ﬁles. Here, the input would be in the form of a potentially large number of ﬁles stored ina directory.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">We start by considering the case of a single ﬁle. In this case, it is straightforward to write a program that reads in the words in the ﬁle and maintains an in-memory data structure that keeps track of all the words encountered so far, along with their counts. The question is, how to extend the above algorithm, which is sequential in nature, to an environment where there are tens of thousands of ﬁles, each containing tens to hundreds of megabytes of data. It is infeasible to process such a large volume of data sequentially.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">One solution is to extend the above scheme by coding it as a parallel program that would run across many machines with each machine processing a part of the ﬁles. The counts computed locally at each machine must then be combined to get the ﬁnal counts. In this case, the programmer would be responsible for all the “plumbing” required to start up jobs on diﬀerent machines, coordinate them, and to compute the ﬁnal answer. In addition, the “plumbing” code must also deal with ensuring completion of the program in spite of machine failures; failures are quite frequent when the number of participating machines is large, such as in the thousands, and the program runs for a long duration.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">The “plumbing” code to implement the above requirements is quite complex; it makes sense to write it just once and reuse it for all desired applications.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">MapReduce systems provide the programmer a way of specifying the core logic needed for an application, with the details of the earlier-mentioned plumbing handled by the MapReduce system. The programmer needs to provide only <span class="s49">map() </span>and <span class="s49">reduce() </span>functions, plus optionally functions for reading and writing data. The <span class="s49">map() </span>and <span class="s49">re- duce() </span>functions provided by the programmer are invoked on the data by the MapRe-</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">duce system to process data in parallel. The programmer does not need to be aware of the plumbing or its complexity; in fact, she can for the most part ignore the fact that the program is to be executed in parallel on multiple machines.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The MapReduce approach can be used to process large amounts of data for a va- riety of applications. The above-mentioned word count program is a toy example of a class of text and document processing applications. Consider, for example, search engines which take keywords and return documents containing the keywords. MapRe- duce can, for example, be used to process documents and create text indices, which are then used to eﬃciently ﬁnd documents containing speciﬁed keywords.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 88pt;text-indent: 0pt;text-align: left;">10.3.2 MapReduce By Example 1: Word Count</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">Our word count application can be implemented in the MapReduce framework using the following functions, which we deﬁned in pseudocode. Note that our pseudocode is not in any speciﬁc programming language; it is intended to introduce concepts. We describe how to write MapReduce code in speciﬁc languages in later sections.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 113pt;text-indent: -16pt;text-align: justify;"><span class="s63">1. </span>In the MapReduce paradigm, the <span class="s49">map() </span>function provided by the programmer is invoked on each input record and emits zero or more output data items, which are then passed on to the <span class="s49">reduce() </span>function. The ﬁrst question is, what is a record? MapReduce systems provide defaults, treating each line of each input ﬁle as a record; such a default works well for our word count application, but the pro- grammers are allowed to specify their own functions to break up input ﬁles into records.</p><p style="padding-left: 113pt;text-indent: 16pt;text-align: justify;">For the word count application, the <span class="s49">map() </span>function could break up each record (line) into individual words and output a number of records, each of which is a pair (<i>word, count</i>), where count is the number of occurrences of the word in the record. In fact in our simpliﬁed implementation, the <span class="s49">map() </span>function does even less work and outputs each word as it is found, with a count of 1. These counts are added up later by the <span class="s49">reduce()</span>. Pseudocode for the <span class="s49">map() </span>function for the word count program is shown in Figure 10.3.</p><p style="padding-left: 113pt;text-indent: 14pt;text-align: justify;">The function breaks up the record (line) into individual words.<span class="s76">2</span> As each word is found, the <span class="s49">map() </span>function emits (outputs) a record (<i>word</i>, 1). Thus, if the ﬁle contained just the sentence:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s49" style="padding-left: 142pt;text-indent: 0pt;text-align: left;">“One a penny, two a penny, hot cross buns.”</p><p style="padding-top: 6pt;padding-left: 113pt;text-indent: 0pt;text-align: left;">the records output by the <span class="s49">map() </span>function would be</p><p class="s49" style="padding-top: 6pt;padding-left: 56pt;text-indent: 0pt;text-align: center;">(“one”, 1), (“a”, 1), (“penny”, 1),(“two”, 1), (“a”, 1), (“penny”, 1),</p><p class="s49" style="padding-top: 1pt;padding-left: 142pt;text-indent: 0pt;text-align: left;">(“hot”, 1), (“cross”, 1), (“buns”, 1).</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 88pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="95" height="1" alt="image" src="Image_2338.png"/></span></p><p class="s77" style="padding-top: 3pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">2<span class="s78">We omit details of how a line is broken up into words. In a real implementation, non-alphabet characters would be removed, and uppercase characters mapped to lowercase, before breaking up the line based on spaces to generate a list of words.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s49" style="padding-top: 4pt;padding-left: 58pt;text-indent: 0pt;text-align: center;">map(String record) {</p><p class="s49" style="padding-left: 249pt;text-indent: 0pt;text-align: center;">For each word in record emit(word, 1).</p><p class="s49" style="text-indent: 0pt;line-height: 12pt;text-align: center;">}</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_2339.png"/></span></p><p class="s49" style="padding-left: 247pt;text-indent: -21pt;text-align: left;">reduce(String key, List value list) { String word = key;</p><p class="s49" style="padding-left: 247pt;text-indent: 0pt;line-height: 12pt;text-align: left;">int count = 0;</p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_2340.png"/></span></p><p class="s49" style="padding-left: 268pt;text-indent: -21pt;text-align: left;">For each value in value list count = count + value</p><p class="s49" style="padding-left: 247pt;text-indent: 0pt;text-align: left;">output(word, count)</p><p class="s49" style="text-indent: 0pt;text-align: center;">}</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 119pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="494" height="1" alt="image" src="Image_2341.png"/></span></p><p class="s73" style="padding-top: 8pt;padding-left: 135pt;text-indent: 0pt;text-align: left;">Figure 10.3 <span class="s74">Pseudocode of map-reduce job for word counting in a set of files.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 145pt;text-indent: 0pt;text-align: justify;">In general, the <span class="s49">map() </span>function outputs a set of (<i>key, value</i>) pairs for each input record. The ﬁrst attribute (key) of the <span class="s49">map() </span>output record is referred to as a <span class="s63">reduce key</span>, since it is used by the <span class="s49">reduce </span>step, which we study next.</p><p style="padding-top: 6pt;padding-left: 145pt;text-indent: -17pt;text-align: justify;"><span class="s63">2. </span>The MapReduce system takes all the (<i>key, value</i>) pairs emitted by the <span class="s49">map() </span>func- tions and sorts (or at least, groups them) such that all records with a particular key are gathered together. All records whose keys match are grouped together, and a list of all the associated values is created. The (<i>key, list</i>) pairs are then passed to the <span class="s49">reduce() </span>function.</p><p style="padding-left: 145pt;text-indent: 14pt;text-align: justify;">In our word count example, each key is a word, and the associated list is a list of counts generated for diﬀerent lines of diﬀerent ﬁles. With our example data, the result of this step is the following:</p><p class="s49" style="padding-top: 6pt;padding-left: 176pt;text-indent: 0pt;text-align: left;">(“a”, [1,1]), (“buns”, [1]) (“cross”, [1]), (“hot”, [1]), (“one”, [1]),</p><p class="s49" style="padding-top: 1pt;padding-left: 176pt;text-indent: 0pt;text-align: left;">(“penny”, [1,1]), (“two”, [1])</p><p style="padding-top: 6pt;padding-left: 145pt;text-indent: 0pt;text-align: justify;">The <span class="s49">reduce() </span>function for our example combines the list of word counts by adding the counts, and outputs (<i>word, total-count</i>) pairs. For the example input, the records output by the <span class="s49">reduce() </span>function would be as follows:</p><p class="s49" style="padding-top: 6pt;padding-left: 173pt;text-indent: 0pt;text-align: left;">(“one”, 1), (“a”, 2), (“penny”, 2), (“two”, 1), (“hot”, 1), (“cross”, 1),</p><p class="s49" style="padding-top: 1pt;padding-left: 173pt;text-indent: 0pt;text-align: left;">(“buns”, 1).</p><p style="padding-top: 6pt;padding-left: 145pt;text-indent: 0pt;text-align: justify;">Pseudocode for the <span class="s49">reduce() </span>function for the word count program is shown in Figure 10.3. The counts generated by the <span class="s49">map() </span>function are all 1, so the <span class="s49">reduce() </span>function could have just counted the number of values in the list, but adding up the values allows some optimizations that we will see later.</p><p style="padding-left: 145pt;text-indent: 14pt;text-align: justify;">A key issue here is that with many ﬁles, there may be many occurrences of the same word across diﬀerent ﬁles. Reorganizing the outputs of the <span class="s49">map() </span>functions</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 88pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="494" height="1" alt="image" src="Image_2342.png"/></span></p><p class="s185" style="padding-top: 3pt;padding-left: 119pt;text-indent: 0pt;text-align: left;">…</p><p class="s49" style="padding-top: 1pt;padding-left: 119pt;text-indent: 0pt;text-align: left;">2013/02/21 10:31:22.00EST /slide-dir/11.ppt</p><p class="s49" style="padding-top: 1pt;padding-left: 119pt;text-indent: 0pt;text-align: left;">2013/02/21 10:43:12.00EST /slide-dir/12.ppt</p><p class="s49" style="padding-top: 1pt;padding-left: 119pt;text-indent: 0pt;text-align: left;">2013/02/22 18:26:45.00EST /slide-dir/13.ppt</p><p class="s49" style="padding-top: 1pt;padding-left: 119pt;text-indent: 0pt;text-align: left;">2013/02/22 18:26:48.00EST /exer-dir/2.pdf</p><p class="s49" style="padding-top: 1pt;padding-left: 119pt;text-indent: 0pt;text-align: left;">2013/02/22 18:26:54.00EST /exer-dir/3.pdf</p><p class="s49" style="padding-top: 1pt;padding-left: 119pt;text-indent: 0pt;text-align: left;">2013/02/22 20:53:29.00EST /slide-dir/12.ppt</p><p class="s185" style="padding-top: 1pt;padding-left: 119pt;text-indent: 0pt;text-align: left;">…</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 88pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="494" height="1" alt="image" src="Image_2343.png"/></span></p><p class="s73" style="padding-top: 8pt;padding-left: 59pt;text-indent: 0pt;text-align: center;">Figure 10.4 <span class="s74">Log files.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 113pt;text-indent: 0pt;text-align: justify;">is required to bring all the values for a particular key together. In a parallel system with many machines, this requires data for diﬀerent reduce keys to be exchanged between machines, so all the values for any particular reduce key are available at a single machine. This work is done by the <span class="s63">shuﬄe step</span>, which performs data exchange between machines and then sorts the (<i>key, value</i>) pairs to bring all the values for a key together. Observe in our example that the words have actually been sorted alphabetically. Sorting the output records from the <span class="s49">map() </span>is one way for the system to collect all occurrences of a word together; the lists for each word are created from the sorted records.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">By default, the output of the <span class="s49">reduce() </span>function is sent to one or more ﬁles, but MapReduce systems allow programmers to control what happens to the output.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 88pt;text-indent: 0pt;text-align: left;">10.3.3 MapReduce by Example 2: Log Processing</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">As another example of the use of the MapReduce paradigm, which is closer to tradi- tional database query processing, suppose we have a log ﬁle recording accesses to a web site, which is structured as shown in Figure 10.4. The goal of our ﬁle access count application is to ﬁnd how many times each of the ﬁles in the <span class="s49">slide-dir </span>directory was ac- cessed between 2013/01/01 and 2013/01/31. The application illustrates one of a variety of kinds of questions an analyst may ask using data from web log ﬁles.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">For our log-ﬁle processing application, each line of the input ﬁle can be treated as a record. The <span class="s49">map() </span>function would do the following: it would ﬁrst break up the input record into individual ﬁelds, namely date, time, and ﬁlename. If the date is in the required date range, the <span class="s49">map() </span>function would emit a record (<i>filename, 1</i>), which indicates that the ﬁlename appeared once in that record. Pseudocode for the <span class="s49">map() </span>function for this example is shown in Figure 10.5.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The shuﬄe step brings all the values for a particular <i>reduce </i>key (in our case, a ﬁle name) together as a list. The <span class="s49">reduce() </span>function provided by the programmer, shown in Figure 10.6, is then invoked for each <i>reduce </i>key value. The ﬁrst argument of <span class="s49">reduce() </span>is the <i>reduce </i>key itself, while the second argument is a list containing the values in the</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s49" style="padding-top: 4pt;padding-left: 163pt;text-indent: -21pt;text-align: left;">map(String record) { String attribute[3];</p><p class="s49" style="padding-left: 185pt;text-indent: -21pt;text-align: left;">break up record into tokens (based on space character), and store the tokens in array attributes</p><p class="s49" style="padding-left: 163pt;text-indent: 0pt;text-align: left;">String date = attribute[0]; String time = attribute[1]; String filename = attribute[2];</p><p class="s49" style="padding-left: 163pt;text-indent: 0pt;line-height: 12pt;text-align: left;">if(date between 2013/01/01 and 2013/01/31</p><p class="s49" style="padding-left: 185pt;text-indent: 21pt;text-align: left;"><a href="http://db-book.com/slide-dir" class="s56" target="_blank">and filename starts with “</a>http://db-book.com/slide-dir”) emit(filename, 1).</p><p class="s49" style="padding-left: 142pt;text-indent: 0pt;text-align: left;">}</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 119pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="494" height="1" alt="image" src="Image_2344.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s73" style="padding-top: 4pt;padding-left: 155pt;text-indent: 0pt;text-align: left;">Figure 10.5 <span class="s74">Pseudocode of map functions for counting file accesses.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">records emitted by the <span class="s49">map() </span>function for that <i>reduce </i>key. In our example, the values for a particular key are added to get the total number of accesses for a ﬁle. This number is then output by the <span class="s49">reduce() </span>function.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">If we were to use the values generated by the <span class="s49">map() </span>function, the values would be “1” for all emitted records, and we could have just counted the number of elements in the list. However, MapReduce systems support optimizations such as performing a partial addition of values from each input ﬁle, before they are redistributed. In that case, the values received by the <span class="s49">reduce() </span>function may not necessarily be ones, and we therefore add the values.</p><p style="padding-top: 1pt;padding-left: 119pt;text-indent: 17pt;line-height: 92%;text-align: justify;">Figure 10.7 shows a schematic view of the ﬂow of keys and values through the <span class="s49">map() </span>and <span class="s49">reduce() </span>functions. In the ﬁgure the mk<span class="s149">i</span>’s denote <i>map </i>keys, mv<span class="s149">i</span>’s denote map input values, rk<span class="s149">i</span>’s denote <i>reduce </i>keys, and rv<span class="s149">i </span>’s denote reduce input values. Reduce outputs are not shown.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 119pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="494" height="1" alt="image" src="Image_2345.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_2346.png"/></span></p><p class="s49" style="padding-top: 4pt;padding-left: 247pt;text-indent: -21pt;text-align: left;">reduce(String key, List value list) { String filename = key;</p><p class="s49" style="padding-left: 247pt;text-indent: 0pt;text-align: left;">int count = 0;</p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="1" alt="image" src="Image_2347.png"/></span></p><p class="s49" style="padding-left: 268pt;text-indent: -21pt;text-align: left;">For each value in value list count = count + value</p><p class="s49" style="padding-left: 247pt;text-indent: 0pt;line-height: 12pt;text-align: left;">output(filename, count)</p><p class="s49" style="text-indent: 0pt;text-align: center;">}</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 119pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="494" height="1" alt="image" src="Image_2348.png"/></span></p><p class="s73" style="padding-top: 8pt;padding-left: 150pt;text-indent: 0pt;text-align: left;">Figure 10.6 <span class="s74">Pseudocode of reduce functions for counting file accesses.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:221.95pt" cellspacing="0"><tr style="height:17pt"><td style="width:20pt;border-top-style:solid;border-top-width:1pt;border-top-color:#77787B;border-left-style:solid;border-left-width:1pt;border-left-color:#77787B;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#77787B;border-right-style:solid;border-right-width:1pt;border-right-color:#231F20"><p class="s267" style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">rk<span class="s268">3</span></p></td><td style="width:23pt;border-top-style:solid;border-top-width:1pt;border-top-color:#77787B;border-left-style:solid;border-left-width:1pt;border-left-color:#231F20;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#77787B;border-right-style:solid;border-right-width:1pt;border-right-color:#77787B"><p class="s267" style="padding-top: 2pt;padding-left: 3pt;text-indent: 0pt;text-align: left;">rv<span class="s268">3</span></p></td></tr><tr style="height:10pt"><td style="width:20pt;border-top-style:solid;border-top-width:1pt;border-top-color:#77787B;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#77787B;border-right-style:solid;border-right-width:1pt;border-right-color:#231F20"><p style="text-indent: 0pt;text-align: left;"><br/></p></td><td style="width:23pt;border-top-style:solid;border-top-width:1pt;border-top-color:#77787B;border-left-style:solid;border-left-width:1pt;border-left-color:#231F20;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#77787B"><p style="text-indent: 0pt;text-align: left;"><br/></p></td></tr><tr style="height:17pt"><td style="width:20pt;border-top-style:solid;border-top-width:1pt;border-top-color:#77787B;border-left-style:solid;border-left-width:1pt;border-left-color:#77787B;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#77787B;border-right-style:solid;border-right-width:1pt;border-right-color:#231F20"><p class="s267" style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">rk<span class="s268">1</span></p></td><td style="width:23pt;border-top-style:solid;border-top-width:1pt;border-top-color:#77787B;border-left-style:solid;border-left-width:1pt;border-left-color:#231F20;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#77787B;border-right-style:solid;border-right-width:1pt;border-right-color:#77787B"><p class="s267" style="padding-top: 1pt;padding-left: 3pt;text-indent: 0pt;text-align: left;">rv<span class="s268">7</span></p></td></tr><tr style="height:17pt"><td style="width:20pt;border-top-style:solid;border-top-width:1pt;border-top-color:#77787B;border-left-style:solid;border-left-width:1pt;border-left-color:#77787B;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#77787B;border-right-style:solid;border-right-width:1pt;border-right-color:#231F20"><p class="s267" style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">rk<span class="s268">2</span></p></td><td style="width:23pt;border-top-style:solid;border-top-width:1pt;border-top-color:#77787B;border-left-style:solid;border-left-width:1pt;border-left-color:#231F20;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#77787B;border-right-style:solid;border-right-width:1pt;border-right-color:#77787B"><p class="s267" style="padding-top: 2pt;padding-left: 3pt;text-indent: 0pt;text-align: left;">rv<span class="s268">8</span></p></td></tr></table><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s90" style="padding-top: 10pt;padding-left: 119pt;text-indent: 0pt;line-height: 86%;text-align: right;">map inputs (key, value)</p><p class="s90" style="padding-top: 9pt;padding-left: 44pt;text-indent: 0pt;text-align: left;">map outputs</p><p class="s90" style="padding-top: 7pt;padding-left: 88pt;text-indent: 0pt;line-height: 86%;text-align: left;">reduce inputs (key, value)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s73" style="padding-top: 4pt;padding-left: 59pt;text-indent: 0pt;text-align: center;">Figure 10.7 <span class="s74">Flow of keys and values in a MapReduce job.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-top: 7pt;padding-left: 88pt;text-indent: 0pt;text-align: left;">10.3.4 Parallel Processing of MapReduce Tasks</p><p style="padding-top: 6pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">Our description of the <span class="s49">map() </span>and <span class="s49">reduce() </span>functions so far has ignored the issue of parallel processing. We can understand the meaning of MapReduce code without con- sidering parallel processing. However, our goal in using the MapReduce paradigm is to enable parallel processing. Thus, MapReduce systems execute the <span class="s49">map() </span>function in parallel on multiple machines, with each map task processing some part of the data, for example some of the ﬁles, or even parts of a ﬁle in case the input ﬁles are very large. Similarly, the <span class="s49">reduce() </span>functions are also executed in parallel on multiple machines, with each reduce task processing a subset of the reduce keys (note that a particular call to the <span class="s49">reduce() </span>function is still for a single reduce key).</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Parallel execution of <span class="s49">map </span>and <span class="s49">reduce </span>tasks is shown pictorially in Figure 10.8. In the ﬁgure, the input ﬁle partitions, denoted as Part <i>i</i>, could be ﬁles or parts of ﬁles. The nodes denoted as Map <i>i </i>are the map tasks, and the nodes denoted Reduce <i>i </i>are the reduce tasks. The master node sends copies of the <span class="s49">map() </span>and <span class="s49">reduce() </span>code to the map and reduce tasks. The map tasks execute the code and write output data to local ﬁles on the machines where the tasks are executed, after being sorted and partitioned based on the reduce key values; separate ﬁles are created for each reduce task at each Map node. These ﬁles are fetched across the network by the reduce tasks; the ﬁles fetched by a reduce task (from diﬀerent map tasks) are merged and sorted to ensure that all occurrences of a particular reduce key are together in the sorted ﬁle. The reduce keys and values are then fed to the <span class="s49">reduce() </span>functions.</p><p style="text-indent: 0pt;text-align: left;"><span><img width="384" height="248" alt="image" src="Image_2349.png"/></span></p><p class="s90" style="padding-top: 2pt;padding-left: 2pt;text-indent: 0pt;text-align: left;">rv<span class="s269">n</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s90" style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">rk<span class="s269">i</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s90" style="padding-top: 2pt;padding-left: 14pt;text-indent: 0pt;text-align: left;">mv<span class="s269">n</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s90" style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">mk<span class="s269">n</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s90" style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">rv<span class="s269">i</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s90" style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">rk<span class="s270">2</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s90" style="padding-top: 2pt;padding-left: 2pt;text-indent: 0pt;text-align: left;">... rv<span class="s269">n</span>,...</p><p style="text-indent: 0pt;text-align: left;"/><p class="s90" style="padding-top: 1pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">rk<span class="s269">i</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s90" style="padding-top: 2pt;padding-left: 2pt;text-indent: 0pt;text-align: left;">rv<span class="s271">2</span>,...</p><p style="text-indent: 0pt;text-align: left;"/><p class="s90" style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">rk<span class="s270">7</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s90" style="padding-top: 2pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">mv<span class="s270">2</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s90" style="padding-top: 2pt;padding-left: 3pt;text-indent: 0pt;text-align: left;">mk<span class="s270">2</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s90" style="padding-top: 2pt;padding-left: 2pt;text-indent: 0pt;text-align: left;">rv<span class="s271">3</span>,...</p><p style="text-indent: 0pt;text-align: left;"/><p class="s90" style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">rk<span class="s270">3</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s90" style="padding-top: 2pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">mv<span class="s270">1</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s90" style="padding-top: 2pt;padding-left: 3pt;text-indent: 0pt;text-align: left;">mk<span class="s270">1</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s90" style="padding-top: 2pt;padding-left: 2pt;text-indent: 0pt;text-align: left;">rv<span class="s271">8</span>,rv<span class="s269">i</span>,...</p><p style="text-indent: 0pt;text-align: left;"/><p class="s90" style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">rk<span class="s270">2</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s90" style="padding-top: 2pt;padding-left: 1pt;text-indent: 0pt;text-align: left;">rv<span class="s271">1</span>,rv<span class="s271">7</span>,...</p><p style="text-indent: 0pt;text-align: left;"/><p class="s90" style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">rk<span class="s270">1</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s90" style="padding-top: 2pt;padding-left: 3pt;text-indent: 0pt;text-align: left;">rv<span class="s270">2</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s90" style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">rk<span class="s270">7</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s90" style="padding-top: 2pt;padding-left: 3pt;text-indent: 0pt;text-align: left;">rv<span class="s270">1</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s90" style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">rk<span class="s270">1</span></p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="412" height="222" alt="image" src="Image_2350.png"/></span></p><p class="s90" style="padding-left: 281pt;text-indent: 0pt;text-align: center;">User Program</p><p class="s90" style="padding-top: 3pt;padding-left: 84pt;text-indent: 0pt;text-align: center;">copy   copy   <span class="s272">copy</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s90" style="padding-left: 84pt;text-indent: 0pt;line-height: 9pt;text-align: center;">Master</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s90" style="padding-left: 119pt;text-indent: 0pt;text-align: right;">Part 1</p><p class="s90" style="padding-left: 119pt;text-indent: 0pt;line-height: 8pt;text-align: right;">Part 2</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s90" style="padding-left: 38pt;text-indent: 0pt;text-align: left;">Map 1</p><p class="s90" style="padding-top: 1pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">assign map</p><p class="s90" style="padding-top: 1pt;padding-left: 30pt;text-indent: 0pt;text-align: left;">assign reduce</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s90" style="padding-top: 10pt;text-indent: 0pt;text-align: left;">Reduce 1      File 1</p><p class="s90" style="padding-top: 3pt;padding-left: 154pt;text-indent: 0pt;line-height: 10pt;text-align: left;">Part 3</p><p class="s90" style="padding-left: 154pt;text-indent: 0pt;text-align: left;">Part 4</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s90" style="padding-left: 155pt;text-indent: 0pt;text-align: left;">Part <span class="s273">n </span><span class="s274">read</span></p><p class="s90" style="padding-top: 7pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">Map 2</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s90" style="padding-left: 10pt;text-indent: 0pt;text-align: left;">Map <span class="s273">n</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s90" style="padding-top: 9pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">local write</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s90" style="padding-top: 10pt;padding-left: 27pt;text-indent: 0pt;line-height: 9pt;text-align: left;">Remote</p><p class="s90" style="padding-top: 6pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">Reduce 1</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s90" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">Reduce <span class="s273">m</span></p><p class="s90" style="padding-top: 1pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">write</p><p class="s90" style="padding-top: 5pt;padding-left: 16pt;text-indent: 0pt;text-align: left;">File 2</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s90" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">File <span class="s273">m</span></p><p class="s275" style="padding-top: 10pt;padding-left: 145pt;text-indent: 0pt;text-align: left;">Input file partitions</p><p class="s90" style="padding-top: 1pt;padding-left: 119pt;text-indent: 0pt;line-height: 10pt;text-align: right;">Read, Sort</p><p class="s275" style="padding-left: 77pt;text-indent: 0pt;text-align: left;">Intermediate files</p><p class="s275" style="padding-top: 10pt;padding-left: 48pt;text-indent: 0pt;text-align: center;">Output files</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s73" style="padding-top: 4pt;padding-left: 193pt;text-indent: 0pt;text-align: left;">Figure 10.8 <span class="s74">Parallel processing of MapReduce job.</span></p><p style="padding-top: 9pt;padding-left: 119pt;text-indent: 17pt;text-align: justify;">MapReduce systems also need to parallelize ﬁle input and output across multiple machines; otherwise the single machine storing the data will become a bottleneck. Par- allelization of ﬁle input and output can be done by using a distributed ﬁle system, such as the <i>Hadoop File System </i>(<i>HDFS</i>). As we saw in Section 10.2, distributed ﬁle systems allow a number of machines to cooperate in storing ﬁles, partitioning the ﬁles across the machines. Further, ﬁle system data are replicated (copied) across several (typically three) machines, so that even if a few of the machines fail, the data are available from other machines which have copies of the data in the failed machine.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Today, in addition to distributed ﬁle systems such as <span class="s44">HDFS</span>, MapReduce systems support input from a variety of Big Data storage systems such as HBase, MongoDB, Cassandra, and Amazon Dynamo, by using storage adapters. Output can similarly be sent to any of these storage systems.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 119pt;text-indent: 0pt;text-align: left;">10.3.5 MapReduce in Hadoop</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: justify;">The Hadoop project provides a widely used open-source implementation of MapRe- duce in the Java language. We summarize its main features here using the Java <span class="s44">API </span>provided by Hadoop. We note that Hadoop provides MapReduce <span class="s44">API</span>s in several other languages, such as Python and C++.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: justify;">Unlike our MapReduce pseudocode, real implementations such as Hadoop require types to be speciﬁed for the input keys and values, as well as the output keys and value, of the <span class="s49">map() </span>function. Similarly, the types of the input as well as output keys and val- ues of the <span class="s49">reduce() </span>function need to be speciﬁed. Hadoop requires the programmer to implement <span class="s49">map() </span>and <span class="s49">reduce() </span>functions as member functions of classes that ex- tend Hadoop <span class="s49">Mapper </span>and <span class="s49">Reducer </span>classes. Hadoop allows the programmer to provide</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">functions to break up the ﬁle into records, or to specify that the ﬁle is one of the ﬁle types for which Hadoop provides built-in functions to break up ﬁles into records. For example, the <span class="s49">TextInputFormat </span>speciﬁes that the ﬁle should be broken up into lines, with each line being a separate record. Compressed ﬁle formats are widely used today, with <i>Avro</i>, <span class="s69">ORC, </span>and <i>Parquet </i>being the most widely used compressed ﬁle formats in the Hadoop world (compressed ﬁle formats are discussed in Section 13.6). Decompression is done by the system, and a programmer writing a query need only specify one of the supported types, and the uncompressed representation is made available to the code implementing the query.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Input ﬁles in Hadoop can come from a ﬁle system of a single machine, but for large datasets, a ﬁle system on a single machine would become a performance bottleneck. Hadoop MapReduce allows input and output ﬁles to be stored in a distributed ﬁle system such as HDFS, allowing multiple machines to read and write data in parallel.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">In addition to the <span class="s49">reduce() </span>function, Hadoop also allows the programmer to deﬁne a <span class="s49">combine() </span>function, which can perform a part of the <span class="s49">reduce() </span>operation at the node where the <span class="s49">map() </span>function is executed. In our word count example, the <span class="s49">combine() </span>func- tion would be the same as the <span class="s49">reduce() </span>function we saw earlier. The <span class="s49">reduce() </span>function would then receive a list of partial counts for a particular word; since the <span class="s49">reduce() </span>func- tion for word count adds up the values, it would work correctly even with the <span class="s49">combine() </span>function. One beneﬁt of using the <span class="s49">combine() </span>function is that it reduces the amount of data that has to be sent over the network: each node that runs <span class="s49">map </span>tasks would send only one entry for a word across the network, instead of multiple entries.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">A single MapReduce step in Hadoop executes a <span class="s49">map </span>and a <span class="s49">reduce </span>function. A program may have multiple MapReduce steps, with each step having its own <span class="s49">map </span>and <span class="s49">reduce </span>functions. The Hadoop <span class="s44">API </span>allows a program to execute multiple such MapReduce steps. The <span class="s49">reduce() </span>output from each step is written to the (distributed) ﬁle system and read back in the following step. Hadoop also allows the programmer to control the number of <span class="s49">map </span>and <span class="s49">reduce </span>tasks to be run in parallel for the job.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The rest of this section assumes a basic knowledge of Java (you may skip the rest of this section without loss of continuity, if you are not familiar with Java).</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Figure 10.9 shows the Java implementation in Hadoop of the word count appli- cation we saw earlier. For brevity we have omitted Java import statements. The code deﬁnes two classes, one that implements the <span class="s49">Mapper </span>interface, and another that im- plements the <span class="s49">Reducer </span>interface. The <span class="s49">Mapper </span>and <span class="s49">Reducer </span>classes are generic classes which take as arguments the types of the keys and values. Speciﬁcally, the generic <span class="s49">Map- per </span>and <span class="s49">Reducer </span>interfaces both takes four type arguments that specify the types of the input key, input value, output key, and output value, respectively.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The type deﬁnition of the <span class="s49">Map </span>class in Figure 10.9, which implements the <span class="s49">Mapper </span>interface, speciﬁes that the <span class="s49">map </span>key is of type <span class="s49">LongWritable</span>, is basically a long integer, and the value which is (all or part of) a document is of type <span class="s49">Text</span>. The output of <span class="s49">map </span>has a key of type <span class="s49">Text</span>, since the key is a word, while the value is of type <span class="s49">IntWritable</span>, which is an integer value.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 119pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="494" height="1" alt="image" src="Image_2351.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s151" style="padding-top: 4pt;padding-left: 125pt;text-indent: 0pt;text-align: left;">public class WordCount {</p><p class="s151" style="padding-left: 163pt;text-indent: -19pt;text-align: left;">public static class Map extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt; { private final static IntWritable one = new IntWritable(1);</p><p class="s151" style="padding-left: 163pt;text-indent: 0pt;line-height: 10pt;text-align: left;">private Text word = new Text();</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s151" style="padding-left: 163pt;text-indent: 0pt;text-align: left;">public void map(LongWritable key, Text value, Context context)</p><p class="s151" style="padding-left: 182pt;text-indent: 94pt;text-align: left;">throws IOException, InterruptedException { String line = value.toString();</p><p class="s151" style="padding-left: 182pt;text-indent: 0pt;text-align: left;">StringTokenizer tokenizer = new StringTokenizer(line); while (tokenizer.hasMoreTokens()) {</p><p class="s151" style="padding-left: 201pt;text-indent: 0pt;text-align: left;">word.set(tokenizer.nextToken()); context.write(word, one);</p><p class="s151" style="padding-left: 182pt;text-indent: 0pt;line-height: 10pt;text-align: left;">}</p><p class="s151" style="padding-left: 163pt;text-indent: 0pt;text-align: left;">}</p><p class="s151" style="padding-left: 144pt;text-indent: 0pt;text-align: left;">}</p><p class="s151" style="padding-left: 163pt;text-indent: -19pt;text-align: left;">public static class Reduce extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; { public void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context)</p><p class="s151" style="padding-left: 277pt;text-indent: 0pt;line-height: 10pt;text-align: left;">throws IOException, InterruptedException {</p><p class="s151" style="padding-left: 182pt;text-indent: 0pt;text-align: left;">int sum = 0;</p><p class="s151" style="padding-left: 201pt;text-indent: -19pt;text-align: left;">for (IntWritable val : values) { sum += val.get();</p><p class="s151" style="padding-left: 182pt;text-indent: 0pt;text-align: left;">}</p><p class="s151" style="padding-left: 182pt;text-indent: 0pt;text-align: left;">context.write(key, new IntWritable(sum));</p><p class="s151" style="padding-left: 163pt;text-indent: 0pt;text-align: left;">}</p><p class="s151" style="padding-left: 144pt;text-indent: 0pt;text-align: left;">}</p><p class="s151" style="padding-left: 163pt;text-indent: -19pt;text-align: left;">public static void main(String[] args) throws Exception { Configuration conf = new Configuration();</p><p class="s151" style="padding-left: 163pt;text-indent: 0pt;text-align: left;">Job job = new Job(conf, &quot;wordcount&quot;);</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s151" style="padding-left: 163pt;text-indent: 0pt;text-align: left;">job.setOutputKeyClass(Text.class); job.setOutputValueClass(IntWritable.class); job.setMapperClass(Map.class); job.setReducerClass(Reduce.class); job.setInputFormatClass(TextInputFormat.class); job.setOutputFormatClass(TextOutputFormat.class); FileInputFormat.addInputPath(job, new Path(args[0])); FileOutputFormat.setOutputPath(job, new Path(args[1]));</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s151" style="padding-top: 4pt;padding-left: 163pt;text-indent: 0pt;text-align: left;">job.waitForCompletion(true);</p><p class="s151" style="padding-left: 144pt;text-indent: 0pt;text-align: left;">}</p><p class="s151" style="padding-left: 125pt;text-indent: 0pt;text-align: left;">}</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 119pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="494" height="1" alt="image" src="Image_2352.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s73" style="padding-top: 4pt;padding-left: 181pt;text-indent: 0pt;text-align: left;">Figure 10.9 <span class="s74">The word count program written in Hadoop.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 119pt;text-indent: 17pt;text-align: left;">The <span class="s49">map() </span>code for the word count example breaks up the input text value into words using <span class="s49">StringTokenizer</span>, and then for each word, it invokes <span class="s49">context.write(word,</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s49" style="padding-top: 4pt;padding-left: 88pt;text-indent: 0pt;text-align: justify;">one) <span class="p">to output a key and value pair; note that </span>one <span class="p">is an </span>IntWritable <span class="p">object with nu- meric value 1.</span></p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">All the values output by the <span class="s49">map() </span>invocations that have a particular key (word, in our example) are collected in a list by the MapReduce system infrastructure. Doing so requires interchange of data from multiple map tasks to multiple reduce tasks; in a distributed setting, the data would have to be sent over the network. To ensure that all values for a particular key come together, the MapReduce system typically sorts the keys output by the <span class="s49">map </span>functions, ensuring all values for a particular key will come together in the sorted order. This list of values for each key is provided to the <span class="s49">reduce() </span>function.</p><p class="s49" style="padding-top: 2pt;padding-left: 88pt;text-indent: 17pt;line-height: 81%;text-align: justify;"><span class="p">The type of the </span>reduce() <span class="p">input key is the same as the type of the </span>map <span class="p">output key. The </span>reduce() <span class="p">input value in our example is a Java </span>Iterable<span class="s186">&lt;</span>IntWritable<span class="s186">&gt; </span><span class="p">object, which contains a list of </span>map <span class="p">output values (</span>IntWritable <span class="p">is the type of the </span>map <span class="p">output</span></p><p style="padding-left: 88pt;text-indent: 0pt;text-align: justify;">value). The output key for <span class="s49">reduce() </span>is a word, of type <span class="s49">Text</span>, while the output value is a word count, of type <span class="s49">IntWritable</span>.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">In our example, the <span class="s49">reduce() </span>simply adds up the values it receives in its input to get the total count; <span class="s49">reduce() </span>writes the word and the total count using the <span class="s49">context.write() </span>function.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Note that in our simple example, the values are all 1, so <span class="s49">reduce() </span>just needs to count the number of values it receives. In general, however, Hadoop allows the programmer to declare a <span class="s49">Combiner </span>class, whose <span class="s49">combine() </span>function is run on the output of a single <span class="s49">map </span>job; the output of this function replaces multiple <span class="s49">map() </span>output values for a single key with a single value. In our example, a <span class="s49">combine() </span>function could just count the number of occurrences of each word and output a single value, which is the local word count at the map task. These outputs are then passed on to the <span class="s49">reduce() </span>function, which would add up the local counts to get the overall count. The <span class="s49">Combiner</span>’s job is to reduce the traﬃc over the network.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">A MapReduce job runs a <span class="s49">map </span>and a <span class="s49">reduce </span>step. A program may have multiple MapReduce steps, and each step would have its own settings for the <span class="s49">map </span>and <span class="s49">reduce </span>functions. The <span class="s49">main() </span>function sets up the parameters for each MapReduce job, and then executes it.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">The example code in Figure 10.9 executes a single MapReduce job; the parameters for the job are as follows:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s49" style="padding-left: 107pt;text-indent: -16pt;text-align: justify;"><span class="s39">• </span><span class="s40">The classes that contain the </span>map <span class="p">and </span>reduce <span class="p">functions for the job, set by the methods </span>setMapperClass <span class="p">and </span>setReducerClass<span class="p">.</span></p><p class="s49" style="padding-top: 4pt;padding-left: 107pt;text-indent: -16pt;text-align: justify;"><span class="s39">• </span><span class="s40">The types of the job’s output key and values, set to </span>Text <span class="p">(for the words) and </span>IntWritable <span class="p">(for the count), respectively, by methods </span>setOutputKeyClass <span class="p">and </span>setOutputValueClass<span class="p">, respectively.</span></p><p class="s49" style="padding-top: 4pt;padding-left: 107pt;text-indent: -16pt;text-align: justify;"><span class="s39">• </span><span class="s40">The input format of the job, set to </span>TextInputFormat <span class="p">by the method </span>job.setInputFormatClass<span class="p">. The default input format in Hadoop is the </span>TextInput- Format<span class="p">, which createsa </span>map <span class="p">key whose value is a byte oﬀset into the ﬁle, and the</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s49" style="padding-top: 4pt;padding-left: 139pt;text-indent: 0pt;text-align: justify;">map <span class="p">value is the contents of one line of the ﬁle. Since ﬁles are allowed to be big- ger than 4 gigabytes, the oﬀset is of type </span>LongWritable<span class="p">. Programmers can provide their own implementations for the input format class, which would process input ﬁles and break the ﬁles into records.</span></p><p class="s39" style="padding-top: 3pt;padding-left: 123pt;text-indent: 0pt;line-height: 15pt;text-align: left;">• <span class="s40">The output format of the job, set to </span><span class="s49">TextOutputFormat </span><span class="p">by the method</span></p><p class="s49" style="padding-left: 139pt;text-indent: 0pt;line-height: 13pt;text-align: left;">job.setOutputFormatClass<span class="p">.</span></p><p class="s49" style="padding-top: 4pt;padding-left: 139pt;text-indent: -16pt;text-align: justify;"><span class="s39">• </span><span class="s40">The directories where the input ﬁles are stored, and where the output ﬁles must be created, set by the methods </span>addInputPath <span class="p">and </span>addOutputPath<span class="p">.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">Hadoop supports many more parameters for MapReduce jobs, such as the number of <span class="s49">map </span>and <span class="s49">reduce </span>tasks to be run in parallel for the job and the amount of memory to be allocated to each map and reduce task, among many others.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 119pt;text-indent: 0pt;text-align: left;">10.3.6 <span class="s81">SQL </span>on MapReduce</p><p style="padding-top: 6pt;padding-left: 119pt;text-indent: 0pt;text-align: right;">Many of the applications of MapReduce are for parallel processing of large amounts of non-relational data, using computations that cannot be expressed easily in <span class="s44">SQL</span>. For example, our word count program cannot be expressed easily in <span class="s44">SQL</span>. There are many real-world uses of MapReduce that cannot be expressed in <span class="s44">SQL</span>. Examples include com- putation of “inverted indices” which are key for web search engines to eﬃciently answer keyword queries, and computation of Google’s PageRank, which is an important mea- sure of the importance of web sites, and is used to rank answers to web search queries. However, there are a large number of applications that have used the MapReduce paradigm for data processing of various kinds, whose logic can be easily expressed using <span class="s44">SQL</span>. If the data were in a database, it would make sense to write such queries using <span class="s44">SQL </span>and execute the queries on a parallel database system (parallel database systems are discussed in detail in Chapter 22. Using <span class="s44">SQL </span>is much easier for users than is coding in the MapReduce paradigm. However, the data for many such applications reside in a ﬁle system, and there are signiﬁcant time and space overhead demands when</p><p style="padding-left: 119pt;text-indent: 0pt;text-align: justify;">loading them into a database.</p><p style="padding-left: 119pt;text-indent: 17pt;text-align: left;">Relational operations can be implemented using map and reduce steps, as illus- trated by the following examples:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s49" style="padding-left: 139pt;text-indent: -16pt;text-align: justify;"><span class="s39">• </span><span class="s40">The relational selection operation can be implemented by a single </span>map() <span class="p">function, without a </span>reduce() <span class="p">function (or with a </span>reduce() <span class="p">function that simply outputs its inputs, without any change).</span></p><p style="padding-top: 4pt;padding-left: 139pt;text-indent: -16pt;text-align: justify;"><span class="s39">• </span><span class="s40">The relational group by and aggregate function </span><span class="s15">γ </span>can be implemented using a single MapReduce step: the <span class="s49">map() </span>outputs records with the group by attribute values as the <span class="s49">reduce </span>key; the <span class="s49">reduce() </span>function receives a list of all the attribute values for a particular group by key and computes the required aggregate on the values in its input list.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s149" style="padding-top: 6pt;padding-left: 107pt;text-indent: -16pt;line-height: 86%;text-align: justify;"><a name="bookmark222"><span class="s39">• </span></a><span class="s40">A join operation can be implemented using a single MapReduce step, Consider the equijoin operation </span><span class="s13">r </span><span class="s86">⋈</span>r<span class="s167">.</span>A<span class="s136">=</span>s<span class="s167">.</span>A <span class="s168">s</span><span class="p">. We deﬁne a </span><span class="s49">map() </span><span class="p">function which for each input</span><a name="bookmark240">&zwnj;</a></p><p class="s13" style="padding-left: 107pt;text-indent: 0pt;line-height: 9pt;text-align: justify;"><span class="p">record </span>r<span class="s97">i </span><span class="p">outputs a pair (</span>r<span class="s97">i</span><span class="s83">.</span>A<span class="p">, </span>r<span class="s97">i</span><span class="p">), and similarly for each input record </span>s<span class="s97">i </span><span class="p">outputs a pair</span></p><p style="padding-left: 107pt;text-indent: 0pt;line-height: 70%;text-align: justify;">(<i>s</i><span class="s97">i</span><span class="s83">.</span><i>A</i>, <i>s</i><span class="s97">i</span>); the map output also includes a tag to indicate which relation (<i>r </i>or <i>s</i>) the output came from. The <span class="s49">reduce() </span>function is invoked for each join-attribute value,</p><p style="padding-top: 1pt;padding-left: 107pt;text-indent: 0pt;text-align: justify;">with a list of all the <i>r</i><span class="s145">i </span>and <i>s</i><span class="s145">i </span>records with that join-attribute value. The function separates out the <i>r </i>and <i>s </i>tuples, and then outputs a cross products of the <i>r </i>tuples and the <i>s </i>tuples, since all of them have the same value for the join attribute.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 88pt;text-indent: 0pt;text-align: justify;">We leave details as an exercise to the reader (Exercise 10.4). More complex tasks, for example a query with multiple operations, can be expressed using multiple stages of map and reduce tasks.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">While it is indeed possible for relational queries to be expressed using the MapRe- duce paradigm, it can be very cumbersome for a human to do so. Writing queries in <span class="s44">SQL </span>is much more concise and easy to understand, but traditional databases did not allow data access from ﬁles, nor did they support parallel processing of such queries.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">A new generation of systems have been developed that allows queries written in (variants of) the <span class="s44">SQL </span>language to be executed in parallel on data stored in ﬁle sys- tems. These systems include <i>Apache Hive </i>(which was initially developed at Facebook), <i>SCOPE</i>, which developed by Microsoft, both of which use variants of <span class="s44">SQL</span>, and <i>Apache Pig </i>(which was initially developed at Yahoo!), which uses a declarative language called <i>Pig Latin</i>, based on the relational algebra. All these systems allow data to be read di- rectly from the ﬁle system but allow the programmer to deﬁne functions that convert the input data to a record format.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">All these systems generate a program containing a sequence of <span class="s49">map </span>and <span class="s49">reduce </span>tasks to execute a given query. The programs are compiled and executed on a MapRe- duce framework such as Hadoop. These systems became very popular, and far more queries are written using these systems today than are written directly using the MapRe- duce paradigm.</p><p style="padding-left: 88pt;text-indent: 17pt;text-align: justify;">Today, Hive implementations provide an option of compiling <span class="s44">SQL </span>code to a tree of algebraic operations that are executed on a parallel environment. Apache Tez and Spark are two widely used platforms that support the execution of a tree (or <span class="s44">DAG</span>) of algebraic operations on a parallel environment, which we study next in Section 10.4.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part204.htm">&lt; 上一个</a><span> | </span><a href="../database.html">内容</a><span> | </span><a href="part206.htm">下一个 &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
